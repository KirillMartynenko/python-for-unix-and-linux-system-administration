## Python в системном администрировании UNIX и Linux

```
Перевод А. Киселева
Главный редактор А. Галунов
Зав. редакцией Н. Макарова
Выпускающий редактор П. Щеголев
Редактор Ю. Бочина
Корректор C. Минин
Верстка Д. Орлова
```
```
Гифт Н., Джонс Д.
Python в системном администрировании UNIX и Linux – Пер. с англ. – СПб.: Символ-Плюс, 2009. – 512 с., ил.
ISBN 978-5-93286-149
```
```
Книга «Python в системном администрировании UNIX и Linux» демонстрирует, как эффективно решать разнообразные задачи управления серверами UNIX и Linux с помощью языка программирования Python. Каждая глава посвящена определенной задаче, например многозадачности, резервному копированию данных или созданию собственных инструментов командной строки, и предла
гает практические методы ее решения на языке Python. Среди рассматриваемых тем: организация ветвления процессов и передача информации между ними с использованием сетевых механизмов, создание интерактивных утилит с графическим интерфейсом, организация взаимодействия с базами данных и создание приложений для Google App Engine. Кроме того, авторы книги соз
дали доступную для загрузки и свободно распространяемую виртуальную машину на базе Ubuntu, включающую исходные тексты примеров из книги и способную выполнять примеры, использующие SNMP, IPython, SQLAlchemy и многие другие утилиты.
Издание рассчитано на широкий круг специалистов – всех, кто только начинает осваивать язык Python, будь то опытные разработчики сценариев на языках командной оболочки или относительно мало знакомые с программированием вообще.
```
```
© Издательство СимволПлюс, 2009
Authorized translation of the English edition © 2008 O’Reilly Media, Inc. This translation is published and sold by permission of O’Reilly Media, Inc., the owner of all rights to publish and sell the same.
Все права на данное издание защищены Законодательством РФ, включая право на полное или частичное воспроизведение в любой форме. Все товарные знаки или зарегистрированные товарные знаки, упоминаемые в настоящем издании, являются собственностью соответствующих фирм.
Издательство «Символ-Плюс». 199034, СанктПетербург, 16 линия, 7, тел. (812) 3245353, http://www.symbol.ru. Лицензия ЛП N 000054 от 25.12.98.
Налоговая льгота – общероссийский классификатор продукции ОК 00593, том 2; 953000 – книги и брошюры.
Подписано в печать 12.01.2009. Формат 70× 100 1 / 16. Печать офсетная.
Объем 32 печ. л. Тираж 1000 экз. Заказ No
Отпечатано с готовых диапозитивов в ГУП «Типография «Наука» 199034, СанктПетербург, 9 линия, 12.
```

## Оглавление


   - Предисловие
   - Введение
- 1. Введение
   - Почему Python?.
   - Мотивация
   - Основы
   - Выполнение инструкций в языке Python.
   - Использование функций в языке Python
   - с помощью инструкции import. Повторное использование программного кода
- 2. IPython
   - Установка IPython
   - Базовые понятия.
   - Справка по специальным функциям.
   - Командная оболочка UNIX
   - Сбор информации
   - Автоматизация и сокращения
   - В заключение.
- 3. Текст
   - Встроенные компоненты Python и модули.
   - Анализ журналов
   - ElementTree
   - В заключение.
- 4. Создание документации и отчетов
   - Автоматизированный сбор информации.
   - Сбор информации вручную
   - Форматирование информации
   - Распространение информации
   - В заключение.
- 5. Сети 8 Оглавление
   - Сетевые клиенты.
   - Средства вызова удаленных процедур.
   - SSH
   - Twisted
   - Scapy
   - Создание сценариев с использованием Scapy.
- 6. Данные
   - Введение.
   - Использование модуля OS для взаимодействия с данными.
   - и удаление данных Копирование, перемещение, переименование
   - Работа с путями, каталогами и файлами
   - Сравнение данных.
   - Объединение данных
   - Поиск файлов и каталогов по шаблону.
   - Обертка для rsync
   - Метаданные: данные о данных.
   - Архивирование, сжатие, отображение и восстановление
   - Использование модуля tarfile для создания архивов TAR
   - содержимого файлов TAR Использование модуля tarfile для проверки
- 7. SNMP
   - Введение.
   - Краткое введение в SNMP
   - IPython и NetSNMP.
   - Исследование центра обработки данных.
   - Получение множества значений с помощью SNMP
   - Создание гибридных инструментов SNMP.
   - Расширение возможностей NetSNMP
   - Управление устройствами через SNMP.
   - Интеграция SNMP в сеть предприятия с помощью Zenoss
- 8. Окрошка из операционных систем
   - Введение.
   - на языке Python в UNIX Кроссплатформенное программирование
   - PyInotify.
   - OS X.
   - Администрирование систем Red Hat Linux
   - Администрирование Ubuntu.
   - Администрирование систем Solaris.
- Оглавление
      - Виртуализация
      - Облачная обработка данных
      - серверами Windows из Linux Использование Zenoss для управления
   - 9. Управление пакетами
      - Введение.
      - Setuptools и пакеты Python Eggs
      - Использование easy_install.
      - Дополнительные особенности easy_install
      - Создание пакетов.
      - Точки входа и сценарии консоли
      - Регистрация пакета в Python Package Index
      - Distutils.
      - Buildout.
      - Использование Buildout.
      - Разработка с использованием Buildout.
      - virtualenv
      - Менеджер пакетов EPM.
   - 10. Процессы и многозадачность
      - Введение.
      - Модуль subprocess.
      - для управления процессами Использование программы Supervisor
      - для управления процессами Использование программы screen
      - Потоки выполнения в Python.
      - Процессы
      - Модуль processing.
      - Планирование запуска процессов Python.
      - Запуск демона
      - В заключение.
   - 11. Создание графического интерфейса
      - Теория создания графического интерфейса.
      - Создание простого приложения PyGTK
      - файла журнала вебсервера Apache Создание приложения PyGTK для просмотра
      - вебсервера Apache с использованием curses Создание приложения для просмотра файла журнала
      - Вебприложения
      - Django
      - В заключение.
- 12. Сохранность данных 10 Оглавление
   - Простая сериализация.
   - Реляционная сериализация
   - В заключение.
- 13. Командная строка
   - Введение.
   - Основы использования потока стандартного ввода.
   - Введение в optparse.
   - Простые шаблоны использования optparse
   - командной строки на языке Python. Внедрение команд оболочки в инструменты
   - Интеграция конфигурационных файлов
   - В заключение.
- 14. Практические примеры
   - Управление DNS с помощью сценариев на языке Python
   - Использование протокола LDAP для работы с OpenLDAP, Active Directory и другими продуктами из сценариев на языке Python
   - Составление отчета на основе файлов журналов Apache
   - Зеркало FTP.
   - Приложение. Функции обратного вызова
   - Алфавитный указатель


## Вступительное слово

Я была приятно взволнована предложением выполнить предварительный обзор книги, посвященной использованию языка Python для нужд
системного администрирования. Я вспомнила свои ощущения, когда впервые познакомилась с языком Python после многих лет программирования на других языках; это было похоже на свежесть весеннего ветра и согревающее тепло солнца после долгой зимы. Программирование на этом языке оказалось настолько необычайно простым и увлекательным делом, что мне удавалось заканчивать программы намного раньше, чем прежде.
Будучи системным администратором, я использовала язык Python в основном для решения задач системного и сетевого администрирования. Я заранее знала, насколько востребованной будет хорошая книга, посвященная применению языка Python в системном администрировании, и рада сказать, что это в полной мере относится к данной книге. Авторам, Ноа (Noah) и Джереми (Jeremy), удалось написать интересную и умную книгу о языке Python, который прочно обосновался в сфере системного администрирования. Я нахожу эту книгу полезной и увлекательной.
Две первые главы представляют собой введение в язык программирования Python для системных администраторов (и других), которые еще
не знакомы с ним. Я отношу себя к программистам на языке Python среднего уровня, поэтому немало нового узнала из этой книги. Я полагаю, что даже искушенные программисты найдут здесь несколько новых приемов. Особенно я рекомендую прочитать главы, посвященные сетевому администрированию и управлению сетевыми службами, SNMP и управлению гетерогенными сетями, потому что в центре их внимания находятся нетривиальные и реальные задачи, с которыми системные администраторы сталкиваются ежедневно.


### Предисловие

**Типографские соглашения**

В этой книге используются следующие типографские соглашения:

_Курсив_

Курсивом выделяются новые термины, адреса URL, адреса электронной почты, имена файлов и их расширения.

`Моноширинный шрифт`

Используется для оформления листингов программ, для обозначения в тексте таких программных элементов, как имена переменных или функций, баз данных, типов данных, переменных окружения, инструкций, ключевых слов, утилит и модулей.

**`Моноширинный жирный шрифт`**


Используется для выделения команд и другого текста, который должен вводиться пользователем.

_`Моноширинный курсив`_


Используется для выделения текста, который пользователь должен заменить своими значениями или значениями, определяемыми контекстом.


Таким способом выделяются советы, предложения и примечания общего характера.

Таким способом выделяются предупреждения и предостережения.

**Использование программного кода примеров**

Данная книга призвана оказать вам помощь в решении ваших задач.
Вообще вы можете свободно использовать примеры программного кода из этой книги в своих программах и в документации. Вам не нужно обращаться в издательство за разрешением, если вы не собираетесь воспроизводить существенные части программного кода. Например, если вы разрабатываете программу и используете в ней несколько отрывков программного кода из книги, вам не нужно обращаться за разрешением. Однако в случае продажи или распространения компакт-дисков с примерами из этой книги вам необходимо получить разрешение от издательства O’Reilly. Для цитирования данной книги или примеров из нее при разъяснении какихлибо вопросов получение разрешения не требуется. При включении существенных объемов программного кода примеров из этой книги в документацию на вашу продукцию вам необходимо получить разрешение издательства.
Мы приветствуем, но не требуем добавлять ссылку на первоисточник при цитировании. Под ссылкой на первоисточник мы подразумеваем указание авторов, издательства и ISBN. Например: «Python for Unix and Linux System Administration by Noah Gift and Jeremy M. Jones. Copyright 2008 Noah Gift and Jeremy M. Jones, 9780596515829».
За получением разрешения на использование значительных объемов программного кода примеров из этой книги обращайтесь по адресу:
permissions@oreilly.com.

**Safari® Books Online**

Если на обложке технической книги есть пиктограмма «Safari® Books Online», это означает, что книга доступна в Сети через O’Reilly Network Safari Bookshelf.
Safari предлагает намного лучшее решение, чем электронные книги.
Это виртуальная библиотека, позволяющая без труда находить тысячи лучших технических книг, вырезать и вставлять примеры кода, загружать главы и находить быстрые ответы, когда требуется наиболее верная и свежая информация. Она свободно доступна по адресу http://safari.oreilly.com.

**Отзывы и предложения**

С вопросами и предложениями, касающимися этой книги, обращайтесь в издательство:
O’Reilly Media
1005 Gravenstein Highway North
Sebastopol, CA 95472
8009989938 (в Соединенных Штатах Америки или в Канаде)
707-829-0515 (международный)
707-829-0104 (факс)
Список опечаток, файлы с примерами и другую дополнительную информацию вы найдете на сайте книги:
http://www.oreilly.com/
Свои пожелания и вопросы технического характера отправляйте по адресу:
bookquestions@oreilly.com

## Предисловие

Дополнительную информацию о книгах, обсуждения, Центр ресурсов издательства O’Reilly вы найдете на сайте:
http://www.oreilly.com

### Благодарности

**От Ноа**

Лист благодарностей этой книги я хочу начать с доктора Джозефа Е. Богена (Joseph E. Bogen), потому что он – человек, который оказал наибольшее влияние на меня в тот момент, когда это было больше всего необходимо. Я встретил доктора Богена, когда работал в фирме Caltech, и он открыл мне глаза на другой мир, давая советы по жизненным ситуациям, психологии, неврологии, математике, по исследованиям в области сознания и во многих других областях. Это был умнейший человек, которого я когдалибо встречал, и я искренне любил его.
Когда-нибудь я напишу книгу об этом опыте. Я опечален тем, что он не сможет прочитать ее; его смерть стала для меня большой утратой.
Я хочу сказать спасибо моей жене Леа (Leah), самой лучшей из всех женщин, встречавшихся мне. Без твоей любви и поддержки мне не удалось бы написать эту книгу. Ты терпелива, как ангел. Я надеюсь
и дальше идти с тобой по жизни, я люблю тебя. Я также хочу поблагодарить моего сына Лиама (Liam), которому полтора года, за то, что терпел, пока я работал над этой книгой. Мне пришлось сильно урезать наши занятия музыкой и спортом, поэтому я должен вернуть тебе в два раза больше, мой маленький козленок.
Моей матушке: я люблю тебя и хочу сказать спасибо, что подбадривала меня все время.
Конечно же, я хочу сказать спасибо Джереми М. Джонсу (Jeremy M. Jones), моему соавтору – за то, что согласился написать эту книгу вместе со мной. Я думаю, из нас получилась отличная команда. У нас разные стили, но они прекрасно дополняют друг друга, и мы написали хорошую книгу. Вы дали мне много новых знаний о языке Python и были для меня хорошим партнером и другом. Спасибо!
Титус Браун (Titus Brown), которого теперь я должен бы называть доктором Брауном, был тем, кто разжег во мне первый интерес к языку Python, когда я встретил его в фирме Caltech. Это еще один пример того, какое важное значение может иметь один человек, и я рад считать его своим «старым» другом, которого не купишь ни за какие деньги.
Он не уставал спрашивать меня: «Почему ты не используешь Python?». И однажды я решил попробовать. Если бы не Титус, я безусловно вернулся бы обратно к языкам Java и Perl. Вы можете почитать
его блог по адресу: http://ivory.idyll.org/blog.
У Шеннона Беренса (Shannon Behrens) золотая голова, острый, как бритва, ум и потрясающее знание языка Python. Я познакомился с Шенноном благодаря Титусу, и мы быстро подружились с ним. Шеннон – настоящий человек дела, во всех смыслах этого слова, и он дал мне огромный объем знаний о языке Python, можно даже сказать, гигантский. Его помощь во всем, что касалось языка Python, и в редактировании этой книги была просто неоценима, и я чрезвычайно обязан ему за это. Иногда я с ужасом думаю, какой могла бы быть эта книга без его помощи. Я не могу себе представить компанию, которая может упустить его, и я надеюсь помочь ему с его первой книгой. Наконец, он просто удивительный технический рецензент. Вы можете почитать его блог по адресу: http://jjinux.blogspot.com/.
Еще одним звездным техническим рецензентом был Дуг Хеллманн (Doug Hellmann). Сотрудничество с ним было исключительно плодотворным и полезным. Джереми и мне необычайно повезло в том, что
нам удалось заполучить специалиста такого масштаба в качестве рецензента. Он не ограничился своим служебным долгом и стал настоящей движущей силой. Он был для нас неиссякаемым источником
вдохновения, пока мы вместе с ним работали в компании Racemi. Вы можете почитать его блог по адресу: http://blog.doughellmann.com/.
Кому еще я хотел бы выразить свою признательность?
Скотту Лирсину (Scott Leerseen) – за обзор книги и за полезные советы в процессе работы над ней. Я получал огромное удовольствие от жарких споров, разгоравшихся вокруг фрагментов программного кода. Но помните – я всегда прав.
Альфредо Деза (Alfredo Deza) – за работу над настройкой виртуальной машины с Ubuntu, которая была необходима для работы над книгой.
Твой опыт был для нас очень ценным.
Лайзе Дейли (Liza Daly) – за отзывы к первым черновым наброскам некоторых частей этой книги. Они были чрезвычайно полезными.
Джеффу Рашу (Jeff Rush) – за помощь и советы в работе с Buildout, Eggs и Virualenv.
Аарону Хиллегассу (Aaron Hillegass), владельцу замечательной обучающей компании Big Nerd Ranch, – за ценные советы и помощь во время работы. Мне крупно повезло, что посчастливилось встретиться
сним.
Марку Лутцу (Mark Lutz), под руководством которого я прошел курс обучения языку Python и который написал несколько замечательных книг по языку Python.
Членам сообщества Python в Атланте и участникам проекта PyAtl:
http://pyatl.org – вы многому научили меня. Рик Коупленд (Rick Copeland), Рик Томас (Rick Thomas), Брендон Родс (Brandon Rhodes), Дерек Ричардсон (Derek Richardson), Джонатан Ла Кур (Jonathan La Cour), известный также под псевдонимом Mr. Metaclass, Дрю Смазерс (Drew Smathers), Кари Халл (Cary Hull), Бернард Меттьюс (Bernard Matthews), Майкл Лангфорд (Michael Langford) и многие другие, кого я забыл упомянуть. Брендон и Рик Коупленд (Brandon and Rick Copeland) были в особенности полезны; они являются высококлассными программистами на языке Python. Вы можете почитать блог Брендона по адресу: http://rhodesmill.org/brandon/.
Григу Георгиу (Grig Gheorghiu) – за то, что делился с нами опытом системного администратора, за проверку советов и за то, что поддавал нам пинка, когда это было необходимо.
Моему работодателю, главному техническому директору и основателю компании Racemi, Чарльзу Уатту (Charles Watt). Я многому научился у вас и был рад, что вы знаете, когда какие кнопки нажимать. Помните, что я всегда готов написать для вас программу, пробежать 26-мильную дистанцию или проехать 200 миль на велосипеде – только сообщите мне, где и когда.
Доктору Нанде Ганесан (Nanda Ganesan), моему наставнику в аспирантуре Калифорнийского государственного университета в городе Лос-Анджелес (CSULA). Вы многому научили меня в области информационных технологий и в жизни и, кроме того, побуждали меня мыслить самостоятельно.
Доктору Синди Хейсс (Cindy Heiss) – моему профессору в мою бытность студентом. Вы приобщили меня к вебразработке, научили верить в свои силы и, в конечном счете, оказали влияние на мою жизнь,
спасибо!
Шелдону Блокбургеру (Sheldon Blockburger), позволившему мне попробовать свои силы в десятиборье в Калифорнийском государственном политехническом университете в городе Сан Луис Обиспо (CalPoly SLO). Даже при том, что я не стал членом команды, вы развили во мне живой дух соперничества, качества борца и научили самодисциплине, предоставив мне самому отрабатывать забеги на короткие дистанции. И поныне еженедельные тренировки позволяют мне не потерять форму, в том числе и как программисту.
Брюсу Дж. Беллу (Bruce J. Bell), с которым я работал в Caltech. В течение нескольких лет совместной работы он учил меня программированию, делился своими знаниями операционной системы UNIX, и я очень признателен ему за это. С его статьями вы можете познакомиться по адресу: http://www.ugcs.caltech.edu/~bruce/.
Альберто Валезу (Alberto Valez), моему боссу в Sony Imageworks, – за то, что он был, пожалуй, лучшим боссом из всех, кто у меня когда-либо был, и за то, что предоставил мне возможность полностью автоматизировать мою работу.
Монтажеру фильмов Эду Фуллеру (Ed Fuller), который помогал мне советами и оставался отличным другом все это время.
Было много и других людей, оказывавших мне неоценимую помощь в работе, включая Дженнифер Девис (Jennifer Davis), еще одного друга по Caltech, которая предоставила несколько ценных отзывов; нескольких друзей и коллег по работе в компании Turner – Дуга Уэйка (Doug Wake), Уэйна Бланкарда (Wayne Blanchard), Сэма Олгуда (Sam Allgood), Дона Воравонга (Don Voravong); моих друзей и коллег по работе в Disney Feature animation, включая Шина Сомероффа (Sean Someroff), Грега Нигла (Greg Neagle) и Бобби Ли (Bobby Lea). Грег Нигл (Greg Neagle), в частности, очень многому меня научил в Mac OS X.
Спасибо также Дж. Ф. Паниссету (J. F. Panisset), с которым я встретился в Sony Imageworks, учившему меня общим принципам разработки. И хотя теперь он главный технический директор, он мог бы считаться ценным кадром в любой компании.
Я хотел бы поблагодарить еще несколько человек, оказавших существенное содействие: Майка Вагнера (Mike Wagner), Криса МакДауэлла (Chris McDowell) и Шона Смута (Shaun Smoot).
Спасибо членам сообщества Python. В первую очередь спасибо Гвидо Ван Россуму (Guido van Rossum) за создание такого замечательного языка, за его качества настоящего лидера и за то, что был терпелив со мной, когда я обращался за советом по поводу этой книги. В сообществе Python есть большое число других знаменитостей, разрабатывающих инструменты, которыми я пользуюсь каждый день. Это Ян Би
кинг (Ian Bicking), Фернандо Перез (Fernando Perez) и Вилле Вайнио (Ville Vainio), Майк Байер (Mike Bayer), Густаво Немейер (Gustavo Niemeyer) и другие. Спасибо Дэвиду Бизели (David Beazely) за его замечательную книгу и его фантастическое руководство «PyCon 2008 on Generators». Спасибо всем, кто пишет о языке Python и о системном администрировании. Ссылки на их работы вы сможете отыскать на странице http://wiki.python.org/moin/systems_administration. Спасибо также команде проекта Repoze: Тресу Сиверу (Tres Seaver) и Крису МакДонаху (Chris McDonough) ( http://repoze.org/index.html ).
Отдельная благодарность Филиппу Дж. Эби (Phillip J. Eby) за замечательный набор инструментальных средств, за проявленное терпение и советы по разделу, посвященному использованию библиотеки setup
tools. Спасибо также Джиму Фултону (Jim Fulton) за то, что терпеливо отвечал на шквал моих вопросов по использованию ZODB и buildout.
Особое спасибо Мартьяну Фассену (Martijn Fassen), который учил меня пользоваться такими продуктами, как ZODB и Grok. Если вам интересно заглянуть в будущее разработки веб-приложений на языке Python, обратите внимание на проект Grok: http://grok.zope.org/.
Спасибо сотрудникам журнала «Red Hat Magazine» – Джулии Брис (Julie Bryce), Джессике Гербер (Jessica Gerber), Баша Харрису (Bascha Harris) и Рут Сьюл (Ruth Suehle) за то, что позволили мне опробовать идеи, излагаемые в книге, в форме статей. Спасибо также Майку МакКрери (Mike McCrery) из IBM Developerworks за то, что предоставил мне возможность опубликовать в форме статей некоторые идеи из книги.
Я хочу поблагодарить множество людей, которые в разные моменты моей жизни говорили, что мне чтото не по силам. Почти на каждом
жизненном этапе я встречал людей, которые пытались отговорить меня: начиная с того, что я не смогу поступить в колледж, в который хотел бы поступить, и заканчивая тем, что я никогда не смогу изучать программирование. Спасибо вам за то, что давали мне дополнительный толчок к воплощению моих мечтаний. Люди способны выстроить свою жизнь, если они понастоящему верят в себя; я мог бы посоветовать каждому пытаться сделать то, что он действительно хочет сделать.
Наконец, спасибо издательству O’Reilly и Татьяне Апанди (Tatiana Apandi) за то, что верили в мою способность написать книгу о применении языка Python в системном администрировании. Вы рискнули, поверили в меня и в Джереми, и я благодарю вас за это. Пусть ближе к концу книги Татьяна оставила издательство, чтобы воплотить свои мечты, тем не менее, мы продолжали чувствовать ее присутствие. Я также хотел бы отметить нового редактора Джулию Стил (Jilie Steele), которая была благожелательна и отзывчива. Вы привнесли целое море спокойствия, что лично я ценил очень высоко. В будущем я надеюсь еще услышать приятные новости от Джулии и буду счастлив снова работать с ней.

**От Джереми**

Длинный список благодарностей от Ноа заставил меня почувствовать себя неблагодарным человеком, потому что мой список не получится таким длинным, и обескураженным, так как он поблагодарил почти
всех, кому мне тоже хотелось бы сказать спасибо.
В первую очередь я хотел бы вознести слова благодарности Господу Богу, c помощью которого я могу творить и без которого я ничего не смог
бы сделать.
А в земном смысле в первую очередь я хотел бы поблагодарить мою супругу Дебру (Debra). Ты занимала детей другими делами, пока я работал над книгой. Ты сделала законом фразу: «Не беспокойте папу, он
работает над своей книгой». Ты подбадривала меня, когда мне это было необходимо, и ты выделила мне пространство, которое мне так требовалось. Спасибо тебе. Я люблю тебя. Без тебя я не смог бы написать эту книгу.
Я также хотел поблагодарить моих славных детей, Зейна (Zane) и Юстуса (Justus) за их терпение по отношению к моей работе над книгой.
Я пропустил большое число поездок с вами в парк Каменная Гора.
Я по-прежнему укладывал вас спать, но я не оставался и не засыпал вместе с вами, как обычно. Последние несколько недель я пропускал шоу «Kid’s Rock», которое выходит вечером по средам. Я пропустил
так много, но вы терпеливо выдержали все это. Спасибо вам за ваше терпение. И спасибо вам за то, что радовались, когда услышали, что я почти закончил книгу. Я люблю вас обоих.
Я хочу поблагодарить своих родителей, Чарльза и Линду Джонс (Charles and Linda Jones), за их поддержку моей работы над этой книгой. Но больше всего я хочу сказать им спасибо за то, что были для меня примером этики, за то, что научили меня работать над собой и с умом тратить деньги. Надеюсь, что все это я смогу передать своим детям, Зейну и Юстусу.
Спасибо Ноа Гифту (Noah Gift), моему соавтору, за то, что втянул меня в это дело. Оно оказалось тяжелым, тяжелее, чем я думал, и определенно одно из самых тяжелых, которое мне когда-либо приходилось делать. Когда вы работаете с человеком над чем-то, подобным книге, и под конец попрежнему считаете его своим другом, я думаю, это достаточно характеризует его. Спасибо, Ноа. Эта книга не состоялась бы без тебя.
Я хочу поблагодарить нашу команду рецензентов. Ноа уже поблагодарил всех вас, но я хочу еще раз поблагодарить Дуга Хеллмана (Doug Hellman), Дженнифер Девис (Jennifer Davis), Шеннона Дж. Беренса
(Shannon J. Behrens), Криса МакДауэлла (Chris McDowell), Титуса Брауна (Titus Brown) и Скотта Лирсина (Scott Leerseen). Вы удивительные люди. Бывали моменты, когда я заходил в тупик, и вы направляли мои мысли в нужное русло. Вы привнесли свое видение и помогли мне увидеть книгу с разных точек зрения. (В основном это относится к вам, Дженнифер. Если глава, посвященная обработке текста, принесет пользу системным администраторам, то только благодаря вам.) Спасибо вам всем.
Я хотел бы сказать спасибо нашим редакторам, Татьяне Апанди (Tatiana Apandi) и Джулии Стил (Julie Steele). Вы взяли на себя рутинный труд, освободив нас для работы над книгой. Вы обе облегчили нашу
ношу.
Я также хочу выразить свою признательность Фернандо Перезу (Fernando Perez) и Вилле Вайнио (Villе Vainio) за потрясающие отзывы. Надеюсь, что мне удалось воздать должное IPython. И спасибо вам
за IPython. Без него моя жизнь оказалась бы труднее.
Спасибо вам, Дункан МакГреггор (Duncan McGreggor), за помощь с примерами использования платформы Twisted. Ваши комментарии были чрезвычайно полезны. И спасибо, что вы продолжаете работать над
этой замечательной платформой. Я надеюсь, что теперь буду использовать ее более широко.
Я благодарю Брема Мулинаара (Bram Moolenaar) и всех тех, кто когдалибо работал над редактором Vim. Почти все слова и теги XML, которые мне пришлось написать, были написаны с помощью Vim. В процессе работы над книгой я узнал несколько новых приемов и ввел их
в свой повседневный обиход. Редактор Vim позволил мне поднять мою производительность. Спасибо вам.
Я также хочу сказать спасибо Линусу Торвальдсу (Linus Torvalds), разработчикам Debian, разработчикам Ubuntu и всем тем, кто когда-либо работал над операционной системой Linux. Почти каждое слово,
которое я напечатал, было напечатано в Linux. Вы обеспечили невероятную простоту настройки новых окружений и проверку различных идей. Спасибо вам.
Наконец, но ни в коем случае не меньше других, я хочу поблагодарить Гвидо ван Россума (Guido van Rossum) и всех тех, кто когда-либо работал над языком программирования Python. Я извлекал выгоду из вашего труда на протяжении нескольких последних лет. Два своих последних места работы я получил благодаря знанию языка Python.
Язык Python и сообщество его поклонников не раз радовали меня с тех пор, как я начал использовать этот язык гдето в 2001–2002 годах.
Спасибо вам. Python пришелся мне по душе.


## Глава 6. Данные

**Введение**

Управление данными, файлами и каталогами – это одна из причин, по
которым ИТорганизациям необходимы системные администраторы.
У какого системного администратора не возникало необходимости об
рабатывать все файлы в дереве каталогов, отыскивать или заменять
некоторый текст, и если вам еще не пришлось писать сценарий, кото
рый переименовывает все файлы в дереве каталогов, скорее всего это
ожидает вас в будущем. Эти умения составляют суть деятельности сис
темного администратора или, по крайней мере, хорошего системного
администратора. В этой главе мы сосредоточим свое внимание на дан
ных, файлах и каталогах.

Сисадмины постоянно должны перегонять данные из одного места
в другое. Ежедневное перемещение данных у одних системных адми
нистраторов составляет большую часть их работы, у других меньшую.
В индустрии производства мультипликационных фильмов постоянная
«перегонка» данных из одного места в другое является необходимым
условием, потому что для производства цифровых фильмов требуются
терабайты и терабайты пространства. Различные требования предъяв
ляются к операциям ввода/вывода на дисковые накопители, исходя из
качества и разрешения изображения, просматриваемого в каждый
конкретный момент времени. Если данные необходимо «перегонять»
на жесткий диск для просмотра, чтобы к ним был постоянный доступ
в ходе оцифровки, то объектами перемещения будут «свежие» несжа
тые или с незначительной степенью сжатия файлы изображений с вы
соким разрешением. Необходимость перемещения файлов обусловле
на тем, что в анимационной индустрии вообще используются два типа
накопителей. Существуют недорогие, емкие, медленные, надежные
накопители и быстрые, дорогостоящие накопители, которые нередко
представляют собой JBOD («just a bunch of disks» – простой дисковый
массив), объединенные в массив RAID 0 для обеспечения большей про
изводительности. Системного администратора, которому прежде всего
приходится иметь дело с данными, в киноиндустрии часто называют
«погонщиком данных».
Погонщик данных должен постоянно перемещать и переносить новые
данные из одного места в другое. Часто для этого используются такие
утилиты, как rsync, scp или mv. Эти простые, но мощные инструмен
ты могут использоваться в сценариях на языке Python для выполне
ния самых невероятных действий.
С помощью стандартной библиотеки языка Python можно делать по
трясающие вещи без дополнительных затрат. Преимущества стан
дартной библиотеки состоят в том, что ваши сценарии перемещения
данных будут работать везде, независимо от наличия платформозави
симой версии, например, утилиты tar.
Кроме того, не забывайте про резервное копирование. Существует мас
са сценариев и приложений резервного копирования, для создания ко
торых требуется смехотворный объем программного кода на языке Py
thon. Мы хотим предупредить вас, что создание дополнительных тес
тов для проверки программного кода, выполняющего резервное копи
рование, не только желательно, но и необходимо. Вы обязательно
должны провести как модульное, так и функциональное тестирование,
если вы используете собственные сценарии резервного копирования.
Кроме того, часто бывает необходимо выполнить обработку данных до,
после или в процессе перемещения. Конечно, Python прекрасно подхо
дит для решения и таких задач. Инструмент дедупликации, то есть
инструмент, который отыскивает дубликаты файлов и выполняет не
которые действия над ними, очень полезно иметь под рукой, поэтому
мы покажем, как создать его. Это один из примеров работы с непре
кращающимся потоком данных, с чем часто приходится сталкиваться
системным администраторам.
```
**Использование модуля OS**

**для взаимодействия с данными**

```
Если вам когданибудь приходилось создавать кроссплатформенные
сценарии командной оболочки, вы по достоинству оцените то обстоя
тельство, что модуль OS предоставляет переносимый прикладной ин
терфейс доступа к системным службам. В Python 2.5 модуль OS содер
жит более 200 методов, многие из которых предназначены для работы
с данными. В этом разделе мы рассмотрим многие из методов этого мо
дуля, которые пригодятся системным администраторам, которым час
то приходится иметь дело с данными.
```

Использование модуля OS для взаимодействия с данными **223**

```
Всякий раз, когда приходится исследовать новый модуль, оболочка
IPython оказывается незаменимым инструментом для этого, поэтому
давайте начнем наше путешествие по модулю OS с помощью оболочки
IPython, в которой будем выполнять действия, наиболее часто встре
чающиеся в практике. В примере 6.1 показано, как это делается.
```
```
Пример 6.1. Исследование методов модуля OS, наиболее часто
используемых при работе с данными
In [1]: import os
```
```
In [2]: os.getcwd()
Out[2]: '/private/tmp'
```
```
In [3]: os.mkdir("/tmp/os_mod_explore")
In [4]: os.listdir("/tmp/os_mod_explore")
Out[4]: []
In [5]: os.mkdir("/tmp/os_mod_explore/test_dir1")
```
```
In [6]: os.listdir("/tmp/os_mod_explore")
Out[6]: ['test_dir1']
```
```
In [7]: os.stat("/tmp/os_mod_explore")
Out[7]: (16877, 6029306L, 234881026L, 3, 501, 0, 102L,
1207014425, 1207014398, 1207014398)
In [8]: os.rename("/tmp/os_mod_explore/test_dir1",
"/tmp/os_mod_explore/test_dir1_renamed")
In [9]: os.listdir("/tmp/os_mod_explore")
Out[9]: ['test_dir1_renamed']
In [10]: os.rmdir("/tmp/os_mod_explore/test_dir1_renamed")
```
```
In [11]: os.rmdir("/tmp/os_mod_explore/")
```
```
В этом примере, после того как был импортирован модуль OS, в строке
[2] мы получили имя текущего рабочего каталога, затем в строке [3]
создали новый каталог. После этого в строке [4] с помощью метода
os.listdir() было получено содержимое этого вновь созданного катало
га. Затем мы воспользовались методом os.stat(), который похож на ко
манду stat в Bash, а затем в строке [8] переименовали каталог. В строке
[9] мы убедились, что каталог был переименован, и после этого мы уда
лили все созданные нами каталоги с помощью метода os.rmdir().
Этот пример ни в коем случае нельзя считать исчерпывающим иссле
дованием модуля OS. Кроме этого существует большое число методов,
которые могут вам пригодиться при работе с данными, включая мето
ды изменения прав доступа и методы создания символических ссылок.
Чтобы познакомиться с перечнем доступных методов модуля OS, обра
щайтесь к документации для своей версии Python или воспользуйтесь
функцией дополнения по клавише табуляции в оболочке IPython.

### и удаление данных Копирование, перемещение, переименование и удаление данных

Во вводном разделе главы мы говорили о перегонке данных, кроме то
го у вас уже есть некоторое представление о том, как можно использо
вать модуль OS, поэтому теперь мы можем сразу перейти на более вы
сокий уровень – к модулю shutil, который предназначен для работы
с более крупномасштабными элементами данных. Модуль shutil со
держит методы копирования, перемещения, переименования и удале
ния данных, как и модуль OS, но эти действия могут выполняться над
целыми деревьями данных.
Исследование модуля shutil в оболочке IPython – это самый увлека
тельный способ знакомства с ним. В примере ниже мы будем использо
вать метод shutil.copytree(), но в этом модуле имеется множество дру
гих методов копирования, принцип действия которых несколько отли
чается. Чтобы увидеть, в чем заключается разница между различными
методами копирования, обращайтесь к документации по стандартной
библиотеке языка Python. Взгляните на пример 6.2.
```
```
Пример 6.2. Использование модуля shutil для копирования дерева данных
In [1]: import os
In [2]: os.chdir("/tmp")
In [3]: os.makedirs("test/test_subdir1/test_subdir2")
In [4]: lslR
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test/
```
```
./test:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./test/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
```
```
./test/test_subdir1/test_subdir2:
In [5]: import shutil
```
```
In [6]: shutil.copytree("test", "testcopy")
In [19]: lslR
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test/
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 testcopy/
./test:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./test/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
./test/test_subdir1/test_subdir2:
```
```
./testcopy:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./testcopy/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
```
```
./testcopy/test_subdir1/test_subdir2:
```
```
Очевидно, что это очень простые и, вместе с тем, невероятно полезные
действия, а кроме того, вы легко можете использовать подобный про
граммный код внутри более сложного, кроссплатформенного сцена
рия, выполняющего перемещение данных. Первое, что приходит в го
лову, – подобный программный код можно использовать для переме
щения данных из одной файловой системы в другую по определенному
событию. При производстве мультипликационных фильмов часто бы
вает необходимо дождаться завершения работы над последними кад
рами, чтобы потом преобразовать их в последовательность, пригодную
для редактирования.
Мы могли бы написать сценарий, который в качестве задания для пла
нировщика cron дожидается, пока в каталоге появится «x» кадров.
После того как сценарий обнаружит, что в каталоге находится необхо
димое число кадров, он мог бы переместить этот каталог в другой ката
лог, где эти кадры будут подвергнуты обработке, или просто перемес
тить их на другой накопитель, достаточно быстрый, чтобы иметь воз
можность воспроизводить несжатый фильм с высоким разрешением.
Однако модуль shutil может не только копировать файлы, в нем также
имеются методы для перемещения и удаления деревьев данных. В при
мере 6.3 демонстрируется возможность перемещения нашего дерева,
а в примере 6.4 – возможность его удаления.
```
```
Пример 6.3. Перемещение дерева данных с помощью модуля shutil
In [20]: shutil.move("testcopy", "testcopymoved")
```
```
In [21]: lslR
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test/
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 testcopymoved/
```
```
./test:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./test/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
```
```
./test/test_subdir1/test_subdir2:
./testcopymoved:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
```
```
./testcopymoved/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
./testcopymoved/test_subdir1/test_subdir2:
```
```
Пример 6.4. Удаление дерева данных с помощью модуля shutil
In [22]: shutil.rmtree("testcopymoved")
```
```
In [23]: shutil.rmtree("testcopy")
In [24]: ll
```

Перемещение дерева данных является более впечатляющей операци
ей, чем удаление, поскольку после удаления нам нечего демонстриро
вать. Многие из этих простых примеров можно было бы объединить
с другими действиями в более сложные сценарии. Одна из разновидно
стей сценариев, которая могла бы быть полезна на практике, – это сце
нарий резервного копирования, копирующий дерево каталогов на се
тевой диск и затем создающий архив, имя которого включает текущие
дату и время. К счастью, у нас имеется пример, реализующий на язы
ке Python именно эти действия, который приводится в разделе этой
главы, посвященном резервному копированию.

### Работа с путями, каталогами и файлами


Невозможно говорить о работе с данными, не принимая во внимание
пути, каталоги и файлы. Любой системный администратор должен
уметь написать сценарий, который производит обход каталога, выпол
няет поиск по условию и затем какимнибудь образом обрабатывает
результат. Мы опишем некоторые интересные способы, позволяющие
это сделать.
Как всегда, все необходимые для выполнения задания инструменты
можно найти в стандартной библиотеке языка Python. Язык Python не
зря пользуется репутацией «батарейки входят в комплект поставки».
В примере 6.5 демонстрируется, как создать сценарий обхода катало
га, содержащий функции, которые явно возвращают файлы, каталоги
и пути.

```
Пример 6.5. Сценарий обхода каталога
import os
path = "/tmp"
def enumeratepaths(path=path):
"""Возвращает пути ко всем файлам в каталоге в виде списка"""
path_collection = []
for dirpath, dirnames, filenames in os.walk(path):
for file in filenames:
fullpath = os.path.join(dirpath, file)
path_collection.append(fullpath)
return path_collection
```
```
def enumeratefiles(path=path):
"""Возвращает имена всех файлов в каталоге в виде списка"""
file_collection = []
for dirpath, dirnames, filenames in os.walk(path):
for file in filenames:
file_collection.append(file)
```
```
return file_collection
def enumeratedir(path=path):
"""Возвращает имена всех подкаталогов в каталоге в виде списка"""
dir_collection = []
for dirpath, dirnames, filenames in os.walk(path):
for dir in dirnames:
dir_collection.append(dir)
return dir_collection
```
```
if __name__ == "__main__":
print "\nRecursive listing of all paths in a dir:"
for path in enumeratepaths():
print path
```
```
print "\nRecursive listing of all files in dir:"
for file in enumeratefiles():
print file
print "\nRecursive listing of all dirs in dir:"
for dir in enumeratedir():
print dir
```
```
На ноутбуке, работающем под управлением Mac OS, вывод этого сце
нария выглядит, как показано ниже:
```
```
[ngift@Macintosh7][H:12022][J:0]# python enumarate_file_dir_path.py
Recursive listing of all paths in a dir:
/tmp/.aksusb
/tmp/ARD_ABJMMRT
/tmp/com.hp.launchport
/tmp/error.txt
/tmp/liten.py
/tmp/LitenDeplicationReport.csv
/tmp/ngift.liten.log
/tmp/hsperfdata_ngift/58920
/tmp/launchh36okI/Render
/tmp/launchqy1S9C/Listeners
/tmp/launchRTJzTw/:0
/tmp/launchd150.wDvODl/sock

Recursive listing of all files in dir:
.aksusb
ARD_ABJMMRT
com.hp.launchport
error.txt
liten.py
LitenDeplicationReport.csv
ngift.liten.log
58920
Render
Listeners
:0
sock
Recursive listing of all dirs in dir:
.X11unix
hsperfdata_ngift
launchh36okI
launchqy1S9C
launchRTJzTw
launchd150.wDvODl
sshYcE2t6PfnO
```
```
Небольшое примечание к предыдущему фрагменту программного ко
да: метод os.walk() возвращает объектгенератор, благодаря которому
вы сможете выполнить обход дерева каталогов самостоятельно:
```
```
In [2]: import os
In [3]: os.walk("/tmp")
Out[3]: [generator object at 0x508e18]
```
```
Вот как это выглядит при вызове метода в оболочке IPython. Вы може
те заметить, что наличие генератора дает нам возможность использо
вать его метод path.next(). Мы не будем углубляться в обсуждение ге
нераторов, но вы должны знать, что метод os.walk() возвращает объ
ектгенератор. Генераторы очень полезны для системного программи
рования. Все, что вам необходимо знать о генераторах, вы найдете на
сайте Дэвида Бизли (David Beazely) по адресу: http://www.dabeaz.com/
generators/.
In [2]: import os
```
```
In [3]: os.walk("/tmp")
Out[3]: [generator object at 0x508e18]
```
```
In [4]: path = os.walk("/tmp")
In [5]: path.

path.__class__ path.__init__ path.__repr__ path.gi_running
path.__delattr__ path.__iter__ path.__setattr__ path.next
path.__doc__ path.__new__ path.__str__ path.send
path.__getattribute__ path.__reduce__ path.close path.throw
path.__hash__ path.__reduce_ex__ path.gi_frame
In [5]: path.next()
Out[5]:
('/tmp',
['.X11unix',
'hsperfdata_ngift',
'launchh36okI',
'launchqy1S9C',
'launchRTJzTw',
'launchd150.wDvODl',
'sshYcE2t6PfnO'],
['.aksusb',
'ARD_ABJMMRT',
'com.hp.launchport',
'error.txt',
'liten.py',
'LitenDeplicationReport.csv',
'ngift.liten.log'])
```
```
Вскоре мы познакомимся с генераторами поближе, но сначала созда
дим модуль, обладающий прозрачным прикладным интерфейсом, с по
мощью которого можно будет получать файлы, каталоги и пути.
Теперь, когда мы выполнили основную реализацию задачи обхода ка
талога, попробуем создать объектноориентированный модуль, чтобы
впоследствии его легко можно было импортировать и использовать.
Модуль с жестко заданными исходными данными получился бы коро
че, но универсальный модуль, который потом можно будет использо
вать в разных сценариях, облегчит нам жизнь гораздо существеннее.
Взгляните на пример 6.6.
```
```
Пример 6.6. Модуль многократного использования для обхода каталога
import os
```
```
class diskwalk(object):
"""Интерфейс доступа к коллекциям, получаемым при обходе каталога """
def __init__(self, path):
self.path = path
```
```
def enumeratePaths(self):
"""Возвращает пути ко всем файлам в каталоге в виде списка"""
path_collection = []
for dirpath, dirnames, filenames in os.walk(self.path):
for file in filenames:
fullpath = os.path.join(dirpath, file)
path_collection.append(fullpath)
return path_collection

def enumerateFiles(self):
"""Возвращает имена всех файлов в каталоге в виде списка"""
file_collection = []
for dirpath, dirnames, filenames in os.walk(self.path):
for file in filenames:
file_collection.append(file)
```
```
return file_collection
def enumerateDir(self):
"""Возвращает имена всех подкаталогов в каталоге в виде списка"""
dir_collection = []
for dirpath, dirnames, filenames in os.walk(self.path):
for dir in dirnames:
dir_collection.append(dir)
return dir_collection
```
```
Как видите, внесением небольших изменений нам удалось создать от
личный интерфейс для модификаций в будущем. Главная прелесть
этого нового модуля заключается в том, что его можно импортировать
в другие сценарии.


### Сравнение данных.


Сравнение данных – очень важная операция для системного админи
стратора. Вы часто могли задавать себе вопросы: «Какие файлы в этих
двух каталогах различны? Сколько копий одного и того же файла су
ществует у меня в системе?» В этом разделе вы найдете способы, кото
рые позволят вам ответить на эти и другие вопросы.
Когда приходится иметь дело с огромными объемами важных данных,
часто бывает необходимо сравнить деревья каталогов и файлов, чтобы
узнать, какие изменения были внесены. Это становится еще более
важным, когда дело доходит до создания сценариев, перемещающих
данные. Судный день будет вам гарантирован, если ваш сценарий пе
ремещения больших объемов данных повредит какиелибо критиче
ски важные данные.
В этом разделе мы сначала исследуем несколько легковесных методов
сравнения файлов и каталогов, а затем перейдем к вычислению и срав
нению контрольных сумм файлов. В стандартной библиотеке языка
Python имеется несколько модулей, которые помогут выполнить срав
нение; мы рассмотрим filecmp и os.listdir.
```
**Использование модуля filecmp**

```
Модуль filecmp содержит функции для быстрого и эффективного срав
нения файлов и каталогов. Модуль filecmp вызывает функцию os.stat()
для двух файлов и возвращает значение True, если результаты вызова
os.stat() одни и те же для обоих файлов, и False, если полученные результаты отличаются. Обычно функция os.stat() вызывается, чтобы определить, не используют ли два файла одни и те же индексные узлы на диске и не имеют ли они одинаковые размеры, но сравнение содержимого файлов при этом не производится.
Чтобы полностью понять, как работает модуль filecmp, нам потребуется
создать три файла. Для этого перейдем в каталог /tmp , создадим файл
с именем file0.txt и запишем в него «0». Затем создадим файл с именем
file1.txt и запишем в него «1». Наконец, создадим файл с именем
file00.txt и запишем в него «0». Эти файлы будут использоваться в ка
честве объектов сравнения в следующем фрагменте:

```
In [1]: import filecmp
In [2]: filecmp.cmp("file0.txt", "file1.txt")
Out[2]: False
In [3]: filecmp.cmp("file0.txt", "file00.txt")
Out[3]: True
```

Как видите, функция cmp() вернула значение True при сравнении фай
лов file0.txt и file00.txt , и False при сравнении файлов file1.txt
и file0.txt.
Функция dircmp() имеет множество атрибутов, которые сообщают о раз
личиях между двумя деревьями каталогов. Мы не будем рассматри
вать каждый атрибут, но продемонстрируем несколько примеров вы
полнения действий, которые могут быть вам полезны. Для этого при
мера в каталоге /tmp были созданы два подкаталога, в каждый из ко
торых были скопированы файлы из предыдущего примера. В каталоге
dirB был создан дополнительный файл с именем file11.txt , в который
была записана строка «11»:
```
```
In [1]: import filecmp
In [2]: pwd
Out[2]: '/private/tmp'
In [3]: filecmp.dircmp("dirA", "dirB").diff_files
Out[3]: []
In [4]: filecmp.dircmp("dirA", "dirB").same_files
Out[4]: ['file1.txt', 'file00.txt', 'file0.txt']
In [5]: filecmp.dircmp("dirA", "dirB").report()
diff dirA dirB
Only in dirB : ['file11.txt']
Identical files : ['file0.txt', 'file00.txt', 'file1.txt']
```
```
Возможно, вас удивило, что атрибут diff_files не содержит ничего,
хотя мы создали файл file11.txt с уникальной информацией в нем. Де
ло в том, что атрибут diff_files выявляет различия только между од
ноименными файлами.
Затем взгляните на результат вывода атрибута same_files и обратите
внимание, что он сообщает об идентичных файлах в двух каталогах.
Наконец, в последнем примере был сгенерирован отчет. Он наглядно
сообщает о различиях между двумя файлами. Это был лишь очень
краткий обзор возможностей модуля filecmp, поэтому мы рекомендуем
обратиться к документации в стандартной библиотеке языка Python,
чтобы получить полное представление о имеющихся возможностях,
для описания которых мы не располагаем достаточным пространством
в книге.
```
**Использование os.listdir**

```
Еще один легковесный способ сравнения двух каталогов основан на
использовании метода os.listdir(). Метод os.listdir() можно пред
ставлять себе как аналог команды ls – он возвращает список обнару
женных файлов. Язык Python поддерживает множество интересных
способов работы со списками, поэтому вы можете использовать метод
os.listdir() для выявления различий между каталогами, просто пре
образуя списки во множества и затем вычитая одно множество из дру
гого. Ниже показано, как это делается в оболочке IPython:
```
```
In [1]: import os
In [2]: dirA = set(os.listdir("/tmp/dirA"))
```
```
In [3]: dirA
Out[3]: set(['file1.txt', 'file00.txt', 'file0.txt'])
```
```
In [4]: dirB = set(os.listdir("/tmp/dirB"))
In [5]: dirB
Out[5]: set(['file1.txt', 'file00.txt', 'file11.txt', 'file0.txt'])
In [6]: dirA dirB
Out[6]: set([])
In [7]: dirBdirA
Out[7]: set(['file11.txt'])
```
```
В этом примере можно видеть, что мы преобразовали два списка во
множества, а затем выполнили операцию вычитания, чтобы выявить
различия. Обратите внимание, что в строке [7] было получено имя
file11.txt, потому что dirB является надмножеством для dirA, но в стро
ке [6] был получен пустой результат, потому что множество dirA содер
жит элементы, которые содержатся в множестве dirB. При использова
нии множеств легко можно создать простое объединение двух струк
тур данных, вычитая полные пути в одном каталоге из путей в другом
каталоге, и копируя найденные различия. Объединение данных мы
рассмотрим в следующем разделе.
Однако этот подход имеет существенные ограничения. Фактическое
имя файла часто может вводить в заблуждение, поскольку ничто не мешает иметь файл с нулевым размером, имя которого совпадает с име
нем файла, имеющим размер 200 Гбайт. В следующем разделе мы
представим несколько лучший способ обнаружения различий между
каталогами и объединения их содержимого.
```
### Объединение данных

```
Как быть, когда необходимо не просто сравнить файлы с данными, но
еще и объединить два дерева каталогов в одно? Главная проблема со
стоит в том, чтобы объединить содержимое одного дерева с другим без
создания дубликатов файлов.
Вы могли бы просто вслепую скопировать файлы из одного каталога
в другой и затем удалить дубликаты файлов, но гораздо эффективнее
было бы вообще не создавать дубликаты. Достаточно простое решение
этой проблемы состоит в том, чтобы сравнить два каталога с помощью
функции dircmp() из модуля filecmp и затем скопировать уникальные
файлы с помощью приема, основанного на использовании os.listdir,
описанного выше. Наилучшее решение заключается в использовании
контрольных сумм MD5, о чем рассказывается в следующем разделе.
```
**Сравнение контрольных сумм MD5**

```
Вычисление контрольной суммы MD5 файла и сравнение ее с кон
трольной суммой другого файла напоминает стрельбу из гранатомета
по движущейся мишени. Такое мощное оружие вводится в действие,
когда требуется полная уверенность в своих действиях, хотя 100про
центную гарантию может дать только побайтовое сравнение файлов.
В примере 6.7 показана функция, которая принимает путь к файлу
и возвращает его контрольную сумму.
```
```
Пример 6.7. Вычисление контрольной суммы MD5 файла
import hashlib
def create_checksum(path):
"""
Читает файл. Вычисляет контрольную сумму файла, строку за строкой.
Возвращает полную контрольную сумму для всего файла.
"""
fp = open(path)
checksum = hashlib.md5()
while True:
buffer = fp.read(8192)
if not buffer: break
checksum.update(buffer)
fp.close()
checksum = checksum.digest()
return checksum
Ниже приводится пример использования этой функции в интерактив
ной оболочке IPython для сравнения двух файлов:
```
```
In [2]: from checksum import createChecksum
In [3]: if createChecksum("image1") == createChecksum("image2"):
...: print "True"
...:
...:
True
```
```
In [5]: if createChecksum("image1") == createChecksum("image_unique"):
print "True"
...:
...:
```
```
В этом примере контрольные суммы файлов сравниваются вручную, но
мы вполне можем использовать программный код, написанный ранее,
который возвращает список путей, для рекурсивного сравнивания де
рева каталогов и получить список дубликатов. Прелесть удобного API
состоит в том, что его теперь можно использовать в оболочке IPython
с целью тестирования наших решений в интерактивном режиме. За
тем, если решение работает, мы можем создать другой модуль. В при
мере 6.8 приводится программный код, который отыскивает дублика
ты файлов.
```
```
Пример 6.8. Вычисление контрольных сумм MD5 в дереве каталогов
с целью поиска дубликатов файлов
In [1]: from checksum import createChecksum
```
```
In [2]: from diskwalk_api import diskwalk
In [3]: d = diskwalk('/tmp/duplicates_directory')
```
```
In [4]: files = d.enumeratePaths()
In [5]: len(files)
Out[5]: 12
In [6]: dup = []
```
```
In [7]: record = {}
In [8]: for file in files:
compound_key = (getsize(file),create_checksum(file))
if compound_key in record:
dup.append(file)
else:
record[compound_key] = file
```
```
...:
...:
```
```
In [9]: print dup
['/tmp/duplicates_directory/image2']
Фрагмент программного кода, который еще не встречался нам в пре
дыдущих примерах, начинается в строке [7]. Здесь мы создали пустой
словарь, и затем сохраняем вычисленные контрольные суммы в виде
ключей. Благодаря этому легко можно определить, была ли ранее вы
числена та или иная контрольная сумма. Если была, мы помещаем
файл в список дубликатов. Теперь давайте выделим часть программ
ного кода, которую позднее мы сможем использовать в разных сцена
риях. В конце концов, это очень удобно. Как это сделать, показано
в примере 6.9.

```
Пример 6.9. Поиск дубликатов
from checksum import create_checksum
from diskwalk_api import diskwalk
from os.path import getsize
def findDupes(path = '/tmp'):
dup = []
record = {}
d = diskwalk(path)
files = d.enumeratePaths()
for file in files:
compound_key = (getsize(file),create_checksum(file))
if compound_key in record:
dup.append(file)
else:
#print "Creating compound key record:", compound_key
record[compound_key] = file
return dup
```
```
if __name__ == "__main__":
dupes = findDupes()
for dup in dupes:
print "Duplicate: %s" % dup
```
```
Запустив этот сценарий, мы получили следующий результат:
[ngift@Macintosh7][H:10157][J:0]# python find_dupes.py
Duplicate: /tmp/duplicates_directory/image2
```
```
Мы надеемся, вы заметили, что этот пример демонстрирует преиму
щества повторного использования существующего программного ко
да. Теперь у нас имеется универсальный модуль, получающий путь
к дереву каталогов и возвращающий список дубликатов файлов. Это
уже само по себе удобно, но мы можем пойти еще дальше и автомати
чески удалить дубликаты.
Удаление файлов в языке выполняется очень просто – с помощью ме
тода os.remove(). Для этого примера у нас имеется множество файлов
размером 10 Мбайт в нашем каталоге /tmp. Попробуем удалить один
из них, воспользовавшись методом os.remove():

```
In [1]: import os
In [2]: os.remove("10
10mbfile.0 10mbfile.1 10mbfile.2 10mbfile.3 10mbfile.4
10mbfile.5 10mbfile.6 10mbfile.7 10mbfile.8
```
```
In [2]: os.remove("10mbfile.1")
In [3]: os.remove("10
10mbfile.0 10mbfile.2 10mbfile.3 10mbfile.4 10mbfile.5
10mbfile.6 10mbfile.7 10mbfile.8
```
```
Обратите внимание, как функция дополнения по клавише табуляции
в оболочке IPython позволяет увидеть список соответствующих фай
лов. Вы должны знать, что метод os.remove() удаляет файлы, ничего не
сообщая и навсегда, что может не всегда соответствовать нашим жела
ниям. Учитывая это обстоятельство, мы можем реализовать простой
метод, который будет удалять дубликаты, и затем расширить его. По
скольку интерактивная оболочка IPython позволяет легко проверить
эту идею, мы напишем проверочную функцию прямо в ней и сразу же
проверим ее:
In [1]: from find_dupes import findDupes
```
```
In [2]: dupes = findDupes("/tmp")
In [3]: def delete(file):
import os
...: print "deleting %s" % file
...: os.remove(file)
...:
...:
In [4]: for dupe in dupes:
...: delete(dupe)
...:
...:
In [5]: for dupe in dupes:
delete(dupe)
...:
...:
deleting /tmp/10mbfile.2
deleting /tmp/10mbfile.3
deleting /tmp/10mbfile.4
deleting /tmp/10mbfile.5
deleting /tmp/10mbfile.6
deleting /tmp/10mbfile.7
deleting /tmp/10mbfile.8
```
```
В этом примере мы несколько усложнили свой метод удаления, доба
вив в него инструкцию print, которая выводит имена удаляемых фай
лов. Мы уже создали достаточно много программного кода, пригодного
для многократного использования, поэтому у нас нет никаких причин останавливаться на достигнутом. Мы можем создать еще один модуль,
который будет выполнять различные операции удаления, получая объ
ект типа file. Этот модуль даже не требуется привязывать к поиску
дубликатов, его можно использовать для удаления любых файлов. Ис
ходный текст модуля приводится в примере 6.10.

```
Пример 6.10. Модуль delete
#!/usr/bin/env python
import os
```
```
class Delete(object):
"""Методы удаления, работающие с объектами типа file"""
```
```
def __init__(self, file):
self.file = file
```
```
def interactive(self):
"""Интерактивный режим удаления"""
```
```
input = raw_input("Do you really want to delete %s [N]/Y" % self.file)
if input.upper() == "Y":
print "DELETING: %s" % self.file
status = os.remove(self.file)
else:
print "Skipping: %s" % self.file
return
def dryrun(self):
"""Имитация удаления"""
print "Dry Run: %s [NOT DELETED]" % self.file
return
def delete(self):
```
```
"""Удаляет файл без дополнительных условий"""
print "DELETING: %s" % self.file
try:
status = os.remove(self.file)
except Exception, err:
print err
return status
if __name__ == "__main__":
from find_dupes import findDupes
dupes = findDupes('/tmp')
for dupe in dupes:
delete = Delete(dupe)
#delete.dryrun()
#delete.delete()
#delete.interactive()
```
```
В этом модуле имеется три различных метода удаления. Метод удале
ния в интерактивном режиме запрашивает у пользователя подтверждение для каждого файла, который предполагается удалить. Это может
показаться раздражающим, но этот метод обеспечивает хорошую за
щиту для тех, кто впоследствии будет сопровождать или изменять этот
программный код.
Метод пробного режима всего лишь имитирует удаление. И, наконец,
имеется метод, который удаляет файлы безвозвратно. В конце модуля
можно увидеть закомментированные варианты использования каждо
го из трех методов. Ниже приводятся примеры каждого из методов
в действии:

**-** Пробный режим

```
ngift@Macintosh7][H:10197][J:0]# python delete.py
Dry Run: /tmp/10mbfile.1 [NOT DELETED]
Dry Run: /tmp/10mbfile.2 [NOT DELETED]
Dry Run: /tmp/10mbfile.3 [NOT DELETED]
Dry Run: /tmp/10mbfile.4 [NOT DELETED]
Dry Run: /tmp/10mbfile.5 [NOT DELETED]
Dry Run: /tmp/10mbfile.6 [NOT DELETED]
Dry Run: /tmp/10mbfile.7 [NOT DELETED]
Dry Run: /tmp/10mbfile.8 [NOT DELETED]
```
**-** Интерактивный режим

```
ngift@Macintosh7][H:10201][J:0]# python delete.py
Do you really want to delete /tmp/10mbfile.1 [N]/YY
DELETING: /tmp/10mbfile.1
Do you really want to delete /tmp/10mbfile.2 [N]/Y
Skipping: /tmp/10mbfile.2
Do you really want to delete /tmp/10mbfile.3 [N]/Y
```
**-** Удаление
    [ngift@Macintosh7][H:10203][J:0]# python delete.py
    DELETING: /tmp/10mbfile.1
    DELETING: /tmp/10mbfile.2
    DELETING: /tmp/10mbfile.3
    DELETING: /tmp/10mbfile.4
    DELETING: /tmp/10mbfile.5
    DELETING: /tmp/10mbfile.6
    DELETING: /tmp/10mbfile.7
    DELETING: /tmp/10mbfile.8

```
Вы можете согласиться, что приемы инкапсуляции, подобные тем, что
были продемонстрированы выше, очень удобны, когда приходится
иметь дело с данными, потому что вы можете предотвратить возникно
вение проблем в будущем, абстрагировавшись от конкретной ситуа
ции и решая универсальную задачу. В данном случае нам необходимо
было реализовать удаление дубликатов файлов, поэтому был создан
модуль, который универсальным способом отыскивает файлы и удаля
ет их. Мы могли бы создать еще один инструмент, который получает объект типа file и выполняет сжатие файла. И мы действительно вскоре подойдем к этому примеру.

### Поиск файлов и каталогов по шаблону.

До сих пор мы рассматривали способы обработки каталогов и файлов
и такие действия, как поиск дубликатов, удаление каталогов, переме
щение каталогов и так далее. Следующий шаг в освоении дерева ката
логов состоит в применении поиска по шаблону либо как самостоя
тельной операции, либо в комбинации с предыдущими приемами. Как
и все прочее в языке Python, реализация поиска по шаблону расшире
ния или имени файла выполняется очень просто. В этом разделе мы
продемонстрируем несколько общих проблем, связанных с поиском по
шаблону, и применим приемы, использовавшиеся ранее, для создания
простых, но мощных инструментов.
Очень часто системным администраторам приходится сталкиваться
с необходимостью отыскать и удалить, переместить, переименовать или
скопировать файлы определенных типов. Самый простой подход к ре
шению этой задачи в языке Python заключается в использовании моду
ля fnmatch или glob. Основное отличие между этими двумя модулями
заключается в том, что функция fnmatch() при сопоставлении имени
файла с шаблоном UNIX возвращает значение True или False, а функ
ция glob() возвращает список путей к файлам, имена которых соответ
ствуют шаблону. Для создания более сложных инструментов поиска по
шаблону можно использовать регулярные выражения. Об использова
нии регулярных выражений более подробно рассказывается в главе 3.
В примере 6.11 показано, как используются функции fnmatch() и glob().
Здесь мы снова повторно использовали программный код, созданный
нами ранее, импортировав класс diskwalk из модуля diskwalk_api.
```
```
Пример 6.11. Использование функций fnmatch() и glob()
в интерактивном режиме для поиска файлов
In [1]: from diskwalk_api import diskwalk
```
```
In [2]: files = diskwalk("/tmp")
In [3]: from fnmatch import fnmatch
```
```
In [4]: for file in files:
...: if fnmatch(file,"*.txt"):
...: print file
...:
...:
/tmp/file.txt
```
```
In [5]: from glob import glob
In [6]: import os
In [7]: os.chdir("/tmp")
In [8]: glob("*")
Out[8]: ['file.txt', 'image.iso', 'music.mp3']
```
```
В этом примере, после того как мы воспользовались нашим модулем
diskwalk_api, у нас появился список полных путей к файлам, находя
щимся в каталоге /tmp. После этого мы использовали функцию
fnmatch(), чтобы определить соответствие каждого файла шаблону
"*.txt". Функция glob() отличается тем, что она сразу выполняет со
поставление с шаблоном и возвращает список имен файлов. Функция
glob() является более высокоуровневой по отношению к функции
fnmatch(), но обе они являются незаменимыми инструментами при ре
шении немного разных задач.
Функцию fnmatch() особенно удобно использовать в комбинации с про
граммным кодом, создающим фильтр для поиска данных в дереве ка
талогов. Часто при работе с каталогами бывает необходимо работать
с файлами, имена которых соответствуют определенным шаблонам.
Чтобы увидеть этот прием в действии, мы попробуем решить классиче
скую задачу системного администрирования по переименованию всех
файлов в дереве каталогов, имена которых соответствуют заданному
шаблону. Имейте в виду, что переименовывать файлы так же просто,
как удалять, сжимать или обрабатывать их. Для решения подобных
задач используется простой алгоритм:

```
1. Получить путь к файлу в каталоге.
2. Выполнить дополнительную фильтрацию – в эту операцию может
    быть вовлечено несколько фильтров, таких как имя файла, расши
    рение, размер, уникальность и так далее.
3. Выполнить действие над файлом – скопировать, удалить, сжать,
    прочитать и так далее. Как это делается, показано в примере 6.12.

```
Пример 6.12. Переименование файлов с расширением .mp3 в файлы
с расширением .txt
In [1]: from diskwalk_api import diskwalk
In [2]: from shutil import move
```
```
In [3]: from fnmatch import fnmatch
In [4]: files = diskwalk("/tmp")
```
```
In [5]: for file in files:
if fnmatch(file, "*.mp3"):
#здесь можно сделать все, что угодно: удалить, переместить
#переименовать ...хмм, переименовать
move(file, "%s.txt" % file)
```
```
In [6]: lsl /tmp/
total 0
rwrr 1 ngift wheel 0 Apr 1 21:50 file.txt
rwrr 1 ngift wheel 0 Apr 1 21:50 image.iso
rwrr 1 ngift wheel 0 Apr 1 21:50 music.mp3.txt
rwrr 1 ngift wheel 0 Apr 1 22:45 music1.mp3.txt
rwrr 1 ngift wheel 0 Apr 1 22:45 music2.mp3.txt
rwrr 1 ngift wheel 0 Apr 1 22:45 music3.mp3.txt
```
```
При использовании программного кода, разработанного ранее, пере
именование всех файлов с расширением .mp3 в каталоге уложилось
в четыре строки легко читаемого программного кода на языке Python.
Если вы один из немногих системных администраторов, кто не прочи
тал ни одного эпизода из «BOFH» («Bastard Operator From Hell»), то
вам не сразу станет очевидно, что можно было бы дальше сделать
сэтим фрагментом кода.
Представьте, что у вас имеется технологический файловый сервер, ко
торый используется исключительно как высокопроизводительное
хранилище файлов с далеко не безграничной емкостью. Вы стали за
мечать, что диски сервера стали часто переполняться, потому что па
рочка недобросовестных пользователей принялись размещать на них
сотни гигабайтов файлов MP3. Конечно, вы могли бы ввести квотиро
вание дискового пространства для пользователей, но нередко квотиро
вание порождает больше проблем, чем решает. Одно из решений состо
ит в том, чтобы написать сценарий для запуска его из планировщика
cron каждую ночь, который будет отыскивать файлы MP3 и выпол
нять над ними «случайные» операции. По понедельникам он мог бы
давать этим файлам расширение .txt , по вторникам – сжимать их
в ZIPархивы, по средам – перемещать в каталог /tmp , по четвергам –
удалять их и отсылать владельцу полный список удаленных файлов
MP3 по электронной почте. Мы не можем советовать вам сделать это,
если, конечно, вы не являетесь владельцем компании, на которую ра
ботаете, но для настоящего «чертова ублюдка оператора» этот пример
можно считать воплощением мечты.

### Обертка для rsync

Как вы уже, наверное, знаете, rsync – это инструмент командной стро
ки, первоначально разрабатывавшийся Эндрю Триджеллом (Andrew
Tridgell) и Полом Маккерра (Paul Mackerra). В конце 2007 года стала
доступна для тестирования версия 3, включающая еще более широкий
перечень параметров, чем оригинальная версия.
За эти годы для нас rsync превратился в основной инструмент переме
щения данных из пункта А в пункт Б. Объем страницы справочного
руководства и количество возможных параметров просто поражают,
поэтому мы рекомендуем познакомиться с ними поближе. Без преуве
личения утилиту rsync можно считать уникальным, наиболее полез
ным инструментом командной строки, из всех, что когдалибо созда
вались для системных администраторов.
К этому стоит добавить, что язык Python предоставляет несколько спо
собов управления поведением rsync. Одна из проблем, с которой мы
столкнулись, состояла в том, чтобы обеспечить копирование данных
в запланированное время. Мы не раз попадали в ситуации, когда было
необходимо синхронизировать терабайты данных между двумя файло
выми серверами настолько быстро, насколько это возможно, но мы со
всем не хотели контролировать этот процесс вручную. Это как раз та си
туация, в которой Python действительно может сыграть значимую
роль.
С помощью языка Python можно придать утилите rsync немного искус
ственного интеллекта и настроить ее под свои нужды. В такой ситуа
ции сценарий на языке Python используется как связующий про
граммный код, который заставляет утилиты UNIX выполнять такие
вещи, для которых они никогда не предназначались, и благодаря это
му вы получаете возможность создавать очень гибкие и легко настраи
ваемые инструменты. Вы здесь действительно ограничены только ва
шим воображением. В примере 6.13. приводится очень простой сцена
рий, который представляет собой обертку для rsync.
```
```
Пример 6.13. Простая обертка для rsync
#!/usr/bin/env python
#обертка вокруг rsync для синхронизации содержимого двух каталогов
from subprocess import call
import sys
source = "/tmp/sync_dir_A/" #Обратите внимание на завершающий символ слеша
target = "/tmp/sync_dir_B"
rsync = "rsync"
arguments = "a"
cmd = "%s %s %s %s" % (rsync, arguments, source, target)
```
```
def sync():
```
```
ret = call(cmd, shell=True)
if ret != 0:
print "rsync failed"
sys.exit(1)
sync()
```
```
Этот пример жестко определяет синхронизацию двух каталогов и вы
водит сообщение об ошибке, если команда не сработала. Однако мы
могли бы реализовать нечто более интересное и решить проблему, с ко
торой часто приходится сталкиваться. Нас часто вызывали, чтобы
синхронизировать два очень больших каталога, но мы при этом не со
бирались следить за синхронизацией данных всю ночь. Но, если вы не
контролируете процесс синхронизации, вы можете обнаружить, что
процесс был прерван на полпути, при этом данные и целая ночь време
ни были потрачены впустую, а сам процесс синхронизации придется
```

Обертка для rsync **243**

```
опять запускать на следующий день. Используя Python, вы можете
создать более агрессивную, высокомотивированную команду rsync.
Что могла бы делать высокомотивированная команда rsync? Она могла
бы делать то же самое, что и вы, если бы контролировали процесс син
хронизации двух каталогов: она могла бы пытаться продолжать син
хронизацию до самого конца и затем посылала бы сообщение по элек
тронной почте с описанием того, что было сделано. В примере 6.14
приводится немного более продвинутый сценарийобертка для rsync.
```
```
Пример 6.14. Команда rsync, которая не завершается,
пока не выполнит задание
#!/usr/bin/env python
#обертка вокруг rsync для синхронизации содержимого двух каталогов
from subprocess import call
import sys
import time
"""эта мотивированная команда rsync будет пытаться синхронизировать
каталоги, пока не синхронизирует их"""
source = "/tmp/sync_dir_A/" #Note the trailing slash
target = "/tmp/sync_dir_B"
rsync = "rsync"
arguments = "av"
cmd = "%s %s %s %s" % (rsync, arguments, source, target)
```
```
def sync():
while True:
ret = call(cmd, shell=True)
if ret !=0:
print "resubmitting rsync"
time.sleep(30)
else:
print "rsync was succesful"
subprocess.call("mails 'jobs done' bofh@example.com",
shell=True)
sys.exit(0)
sync()
```
```
Этот сценарий максимально упрощен и содержит жестко определен
ные данные, но это – пример полезного инструмента, который можно
создать для автоматизации чегото, что вам обычно приходится кон
тролировать вручную. В этот сценарий можно добавить такие особен
ности, как возможность устанавливать интервал между попытками
и ограничивать количество попыток, проверять объем свободного дис
кового пространства на машине, с которой устанавливается соедине
ние, и так далее.
```

**244** Глава 6. Данные

### Метаданные: данные о данных.

```
Большинство системных администраторов начинают вникать в суть де
ла, когда принимаются интересоваться не только данными, но и дан
ными о данных. Метаданные, или данные о данных, часто могут иг
рать более важную роль, чем сами данные. Например, в кинопроиз
водстве и в телевидении одни и те же данные часто хранятся в несколь
ких каталогах внутри файловой системы или даже в разных файловых
системах. Слежение за такими данными часто приводит к созданию
своего рода системы управления метаданными.
Метаданные – это данные о том, как организованы и как используют
ся определенные файлы, что может быть очень важно для приложе
ния, для процесса производства мультипликационного фильма или
для процедуры восстановления из резервной копии. Python также
сможет помочь в этом, поскольку на этом языке легко можно реализо
вать как чтение, так и запись метаданных.
Рассмотрим использование популярного средства ORM (ObjectRelati
onal Mapping – объектнореляционная проекция) SQLAlchemy для соз
дания метаданных о файловой системе. К счастью, для SQLAlchemy
имеется очень качественная документация, а кроме того, этот продукт
работает с SQLite. На наш взгляд, это потрясающая комбинация, по
зволяющая разрабатывать собственные решения по управлению мета
данными.
В примерах выше мы выполняли обход файловой системы в режиме
реального времени, производили запросы и выполняли действия над
обнаруженными файлами. Это невероятно удобно, но поиск по круп
ным файловым системам, содержащим миллионы файлов, отнимет
слишком много времени иногда только для того, чтобы выполнить
единственную операцию. В примере 6.15 мы покажем, на что могут
быть похожи самые простые метаданные, объединив приемы обхода
каталогов со средством ORM.
```
```
Пример 6.15. Создание метаданных о файловой системе
с помощью SQLAlchemy
#!/usr/bin/env python
from sqlalchemy import create_engine
from sqlalchemy import Table, Column, Integer, String, MetaData, ForeignKey
from sqlalchemy.orm import mapper, sessionmaker
import os
#путь
path = " /tmp"
#Часть 1: Создание механизма
engine = create_engine('sqlite:///:memory:', echo=False)
#Часть 2: метаданные
metadata = MetaData()
```

Метаданные: данные о данных **245**

```
filesystem_table = Table('filesystem', metadata,
Column('id', Integer, primary_key=True),
Column('path', String(500)),
Column('file', String(255)),
)
metadata.create_all(engine)
```
```
#Часть 3: класс отображения
class Filesystem(object):
```
```
def __init__(self, path, file):
self.path = path
self.file = file
def __repr__(self):
return "[Filesystem('%s','%s')]" % (self.path, self.file)
#Часть 4: функция отображения
mapper(Filesystem, filesystem_table)
#Часть 5: создание сеанса
Session = sessionmaker(bind=engine, autoflush=True, transactional=True)
session = Session()
```
```
#Часть 6: обход файловой системы и заполнение базы данных результатами
for dirpath, dirnames, filenames in os.walk(path):
for file in filenames:
fullpath = os.path.join(dirpath, file)
record = Filesystem(fullpath, file)
session.save(record)
```
```
#Часть 7: подтверждение записи данных в базу
session.commit()
```
```
#Часть 8: запрос
for record in session.query(Filesystem):
print "Database Record Number: %s, Path: %s , File: %s " \
% (record.id,record.path, record.file)
```
```
Этот сценарий проще представлять себе как последовательность проце
дур, выполняемых одна за другой. В первой части создается механизм,
который в действительности является лишь несколько необычным
способом определения базы данных, которая будет использоваться для
хранения метаданных. Во второй части определяется экземпляр клас
са метаданных и создается таблица в базе данных. В третьей части оп
ределяется класс, который будет отображаться в только что созданную
таблицу базы данных. В четвертой части вызывается функция отобра
жения, которая производит объектнореляционную проекцию, а по
просту – отображает класс в таблицу. В пятой части создается сеанс
связи с базой данных. Обратите внимание, что здесь указано несколь
ко именованных аргументов, включая autoflush и transactional.
Теперь, когда создание объектнореляционной проекции закончено,
в шестой части мы выполняем уже знакомые нам действия – извлекаем
```

**246** Глава 6. Данные

```
имена файлов и полные пути при обходе дерева каталогов. Однако здесь
имеется пара интересных приемов. Обратите внимание, что для каждо
го пути и имени файла создается отдельная запись, которая затем со
храняется в базе данных. После этого – в седьмой части – мы подтвер
ждаем транзакцию в нашей базе данных, «расположенной в памяти».
Наконец, в восьмой части выполняется запрос – на языке Python, ко
нечно, возвращающий записи, которые мы поместили в базу данных.
Этот пример мог бы стать для вас прекрасной возможностью поэкспе
риментировать в создании собственных решений использования мета
данных с применением SQLAlchemy в вашей компании или у клиен
тов. Этот пример можно расширить такими дополнительными воз
можностями, как выполнение реляционных запросов или запись ре
зультатов в файл и так далее.
```
### Архивирование, сжатие, отображение и восстановление

**и восстановление**

```
Действия с большими объемами данных представляют собой пробле
му, с которой системные администраторы сталкиваются изо дня
в день. Для выполнения своей работы они часто используют tar, dd,
gzip, bzip, bzip2, hdiutil, asr и другие утилиты.
Хотите верьте, хотите нет, но и в этом случае «батарейки входят в ком
плект поставки» – стандартная библиотека языка Python имеет встро
енную поддержку TARфайлов, zlibфайлов и gzipфайлов. Если вам
требуется сжатие и архивирование, значит, у вас не будет никаких про
блем, т. к. язык Python предлагает богатый выбор необходимых инст
рументов. Давайте поближе посмотрим на дедушку всех архиваторов –
tar – и увидим, как стандартная библиотека реализует его поддержку.
```
### Использование модуля tarfile для создания архивов TAR

**архивов TAR**

```
Создать архив TAR очень просто, даже слишком просто. В примере 6.16
мы создаем очень большой файл. Обратите внимание, что синтаксис
создания архива намного более простой, чем даже синтаксис использо
вания самой команды tar.
```
```
Пример 6.16. Создание большого текстового файла
In [1]: f = open("largeFile.txt", "w")
```
```
In [2]: statement = "This is a big line that I intend to write over and over
again."
```
```
ln [3]: x = 0
In [4]: for x in xrange(20000):
...: x += 1
```

Использование модуля tarfile для создания архивов TAR **247**

```
...: f.write("%s\n" % statement)
...:
...:
In [4]: lsl
rwrr 1 root root 1236992 Oct 25 23:13 largeFile.txt
```
```
Теперь, когда у нас имеется большой файл, наполненный мусором, пе
редадим его архиватору TAR, как показано в примере 6.17.
```
```
Пример 6.17. Архивирование содержимого файла
In [1]: import tarfile
In [2]: tar = tarfile.open("largefile.tar", "w")
```
```
In [3]: tar.add("largeFile.txt")
In [4]: tar.close()
```
```
In [5]: ll
rwrr 1 root root 1236992 Oct 25 23:15 largeFile.txt
rwrr 1 root root 1236992 Oct 26 00:39 largefile.tar
```
```
Как видите, был создан обычный архив TAR, причем намного более
простым способом, чем с использованием команды tar. Этот пример оп
ределенно создает прецедент к использованию оболочки IPython для
выполнения повседневной работы по системному администрированию.
Несмотря на удобство создания архивов TAR с помощью Python, тем
не менее, практически бесполезно упаковывать в архив одинединст
венный файл. Используя тот же самый прием обхода каталогов, кото
рый мы уже столько раз применяли в этой главе, можно упаковать
вархив TAR весь каталог /tmp , для чего достаточно выполнить обход
дерева каталогов и добавить в архив каждый файл, находящийся в ка
талоге /tmp , как показано в примере 6.18.
```
```
Пример 6.18. Архивирование содержимого дерева каталогов
In [27]: import tarfile
```
```
In [28]: tar = tarfile.open("temp.tar", "w")
In [29]: import os
```
```
In [30]: for root, dir, files in os.walk("/tmp"):
....: for file in filenames:
....:
KeyboardInterrupt
```
```
In [30]: for root, dir, files in os.walk("/tmp"):
....: for file in files:
....: fullpath = os.path.join(root,file)
....: tar.add(fullpath)
....:
....:
```
```
In [33]: tar.close()
```

**248** Глава 6. Данные

```
В том, чтобы добавить в архив содержимое дерева каталогов при его
обходе, нет ничего сложного, и это очень неплохой прием, потому что
его можно объединить с другими приемами, рассматривавшимися
в этой главе. Представьте, что вы архивируете каталог, заполненный
мультимедийными файлами. Было бы неразумно архивировать дубли
каты, поэтому у вас вполне может появиться желание перед архивиро
ванием заменить дубликаты символическими ссылками. Обладая зна
ниями, полученными в этой главе, вы легко сможете написать сцена
рий, который сделает это и сэкономит вам немного дискового про
странства.
Поскольку создание простых архивов TAR – занятие довольно скуч
ное, давайте приправим его сжатием bzip2, что заставит ваш процес
сор скулить и жаловаться на то, как много выпало работы на его долю.
Алгоритм сжатия bzip2 иногда может оказаться отличной штукой.
Посмотрим, насколько впечатляющим он действительно может быть.
Создадим текстовый файл размером 60 Мбайт и сожмем его до 10 Кбайт,
как показано в примере 6.19!
```
```
Пример 6.19. Создание архива TAR, сжатого по алгоритму bzip2
In [1: tar = tarfile.open("largefilecompressed.tar.bzip2", "w|bz2")
In [2]: tar.add("largeFile.txt")
```
```
In [3]: lsh
foo1.txt fooDir1/ largeFile.txt largefilecompressed.tar.bzip2*
foo2.txt fooDir2/ largefile.tar
ln [4]: tar.close()
```
```
In [5]: lslh
rwrr 1 root root 61M Oct 25 23:15 largeFile.txt
rwrr 1 root root 61M Oct 26 00:39 largefile.tar
rwxrxrx 1 root root 10K Oct 26 01:02 largefilecompressed.tar.bzip2*
```
```
Что самое удивительное, алгоритму bzip2 удалось сжать текстовый
файл размером 61 Мбайт в 10 Кбайт, хотя мы и смошенничали, ис
пользуя одни и те же данные снова и снова. Конечно, этот эффект был
получен далеко не бесплатно, потому что в системе на базе двухъядер
ного процессора AMD на это потребовалось несколько минут.
Теперь попробуем двинуться дальше и создать сжатый архив другими
доступными способами, начав с gzip. Синтаксис при этом меняется
весьма незначительно, как показано в примере 6.20.
```
```
Пример 6.20. Создание архива TAR, сжатого по алгоритму gzip
In [10]: tar = tarfile.open("largefile.tar.gzip", "w|gz")
```
```
In [11]: tar.add("largeFile.txt")
ln [12]: tar.close()
```

Использование модуля tarfile для проверки содержимого файлов TAR **249**

```
In [13]: lslh
rwrr 1 root root 61M Oct 26 01:20 largeFile.txt
rwrr 1 root root 61M Oct 26 00:39 largefile.tar
rwxrxrx 1 root root 160K Oct 26 01:24 largefile.tar.gzip*
```
```
Архив gzip тоже отличается невероятно маленьким размером, уме
стившись в 160 Кбайт, причем на моей машине сжатый архив TAR
был создан за несколько секунд. В большинстве ситуаций это непло
хой компромисс.
```
### содержимого файлов TAR Использование модуля tarfile для проверки

**содержимого файлов TAR**

Теперь, когда у нас имеется инструмент создания файлов TAR, есть
смысл попробовать проверить содержимое файлов TAR. Создать файл
TAR – это лишь полдела. Если вы проработали системным админист
ратором достаточно продолжительное время, вам, вероятно, случалось
«погореть» с некачественной резервной копией или случалось быть об
виненным в создании некачественной резервной копии.
Чтобы воспроизвести эту ситуацию и подчеркнуть важность проверки
архивов TAR, мы поделимся историей о нашем вымышленном друге,
которую назовем «Проблема пропавшего архива TAR». Имена, назва
ния и факты являются вымышленными. Любые совпадения с действи
тельностью являются случайными.
Наш друг работал в крупной телестудии в качестве системного адми
нистратора и отвечал за поддержку отдела, во главе которого стоял по
настоящему невыдержанный человек. У этого руководителя была ре
путация неправдивого, импульсивного и невыдержанного человека.
Если возникала ситуация, когда этот сумасшедший совершал промах,
например не укладывался в оговоренные с клиентом сроки или выпол
нял свою часть программы не в соответствии с требуемыми характери
стиками, он с большим удовольствием лгал и перекладывал ответст
венность на когонибудь другого. Зачастую этим кемнибудь другим
оказывался наш друг, системный администратор.
К сожалению, наш друг отвечал за содержание резервных копий этого
сумасшедшего. Ему уже стало казаться, что настало время подыски
вать другую работу, но он работал в этой студии уже много лет, у него
было много друзей, и он не хотел потерять все изза этих временных
неурядиц. Ему требовалась система, позволяющая убедиться, что он
охватил резервированием все данные, и поэтому он ввел регистраци
онную систему, которая классифицировала содержимое всех архивов
TAR, которые автоматически создавались для этого сумасшедшего,
так как понимал, что может «погореть», и это лишь вопрос времени,
когда сумасшедший опять не уложится в сроки и ему потребуется при
чина для оправдания.
Однажды нашему другу Вильяму позвонил начальник и сказал:
«Вильям, зайдите ко мне немедленно, у нас неприятности с резервны
ми копиями». Вильям сразу же пошел к начальнику и узнал, что этот
сумасшедший, Алекс, обвинил Вильяма в повреждении архива со
съемкой телешоу, изза чего произошла задержка с передачей про
граммы клиенту. Срыв Алексом сроков сдачи совершенно вывел Боба,
начальника Алекса, из себя.
Начальник сказал Вильяму, что, по словам Алекса, резервная копия
содержала только поврежденные файлы и что изза этого были сорва
ны сроки подготовки шоу. В ответ Вильям сказал боссу, что был уве
рен в том, что рано или поздно его обвинят в порче архива и поэтому
втайне написал на языке Python сценарий, который проверяет содер
жимое всех создаваемых им архивов TAR и записывает расширенные
сведения об атрибутах файлов до и после резервного копирования.
Оказалось, что Алекс так и не приступал к работе над шоу и что в тече
ние нескольких месяцев архивировалась пустая папка.
Когда Алекс был поставлен перед фактами, он быстро пошел на попят
ную и попытался перевести внимание на другую проблему. К несча
стью для Алекса, этот случай стал последней каплей и пару месяцев
спустя он исчез с работы. Возможно, он уехал или был уволен, но это
уже не важно, наш друг успешно решил проблему пропавшего архива
TAR.
Мораль этой истории заключается в том, что, когда приходится иметь
дело с резервными копиями, с ними следует обращаться как с ядер
ным оружием, так как резервные копии могут хранить в себе такие
опасности, о которых вы даже не подозреваете.
Ниже демонстрируется несколько способов проверки содержимого
файла TAR, созданного ранее:

```
In [1]: import tarfile
In [2]: tar = tarfile.open("temp.tar","r")
```
```
In [3]: tar.list()
rwrr ngift/wheel 2 20080404 15:17:14 tmp/file00.txt
rwrr ngift/wheel 2 20080404 15:15:39 tmp/file1.txt
rwrr ngift/wheel 0 20080404 20:50:57 tmp/temp.tar
rwrr ngift/wheel 2 20080404 16:19:07 tmp/dirA/file0.txt
rwrr ngift/wheel 2 20080404 16:19:07 tmp/dirA/file00.txt
rwrr ngift/wheel 2 20080404 16:19:07 tmp/dirA/file1.txt
rwrr ngift/wheel 2 20080404 16:19:52 tmp/dirB/file0.txt
rwrr ngift/wheel 2 20080404 16:19:52 tmp/dirB/file00.txt
rwrr ngift/wheel 2 20080404 16:19:52 tmp/dirB/file1.txt
rwrr ngift/wheel 3 20080404 16:21:50 tmp/dirB/file11.txt
In [4]: tar.name
Out[4]: '/private/tmp/temp.tar'
In [5]: tar.getnames()
Out[5]:
['tmp/file00.txt',
'tmp/file1.txt',
'tmp/temp.tar',
'tmp/dirA/file0.txt',
'tmp/dirA/file00.txt',
'tmp/dirA/file1.txt',
'tmp/dirB/file0.txt',
'tmp/dirB/file00.txt',
'tmp/dirB/file1.txt',
'tmp/dirB/file11.txt']
In [10]: tar.members
Out[10]:
[<TarInfo 'tmp/file00.txt' at 0x109eff0>,
<TarInfo 'tmp/file1.txt' at 0x109ef30>,
<TarInfo 'tmp/temp.tar' at 0x10a4310>,
<TarInfo 'tmp/dirA/file0.txt' at 0x10a4350>,
<TarInfo 'tmp/dirA/file00.txt' at 0x10a43b0>,
<TarInfo 'tmp/dirA/file1.txt' at 0x10a4410>,
<TarInfo 'tmp/dirB/file0.txt' at 0x10a4470>,
<TarInfo 'tmp/dirB/file00.txt' at 0x10a44d0>,
<TarInfo 'tmp/dirB/file1.txt' at 0x10a4530>,
<TarInfo 'tmp/dirB/file11.txt' at 0x10a4590>]
```
```
Эти примеры показывают, как получить имена файлов, хранящиеся
в архиве TAR, чтобы впоследствии иметь возможность их проанализи
ровать в сценарии, проверяющем данные. Извлечение файлов из архи
вов выполняется ничуть не сложнее. Если вам потребуется извлечь все
файлы из архива TAR в текущий рабочий каталог, можно воспользо
ваться следующей функцией:
In [60]: tar.extractall()
```
```
drwxrwxrwx 7 ngift wheel 238 Apr 4 22:59 tmp/
```
```
Если вы чрезвычайно подозрительны, каковыми и должны быть, то
вы могли бы реализовать подсчет контрольных сумм MD5 случайных
файлов при извлечении их из архива и сравнивать их с соответствую
щими контрольными суммами, которые были сохранены до упаковки
файлов в архив. Это очень эффективный способ убедиться в том, что
целостность данных не нарушена.
Ни одно разумное решение не должно основываться на предположе
нии, что архив был создан без ошибок. По крайней мере, хотя бы выбо
рочная проверка архивов должна выполняться автоматически. Но
лучше, если сразу после создания каждый архив будет открываться
и проверяться.
```

## 7. SNMP

**Введение**

Протокол SNMP может изменить вашу жизнь системного администра
тора. Отдача от использования SNMP ощущается не так скоро, как от
нескольких строк программного кода на языке Python, выполняющих
анализ файла журнала, например, но когда инфраструктура SNMP бу
дет настроена, работа с ней начинает удивлять.

В этой главе мы рассмотрим следующие аспекты SNMP: автообнару
жение, опрос/мониторинг, создание агентов, управление устройства
ми и, наконец, интеграцию оборудования средствами SNMP. Безус
ловно, все это можно реализовать на языке Python.

Если вы не знакомы с SNMP или вам требуется освежить свои знания
о SNMP, мы настоятельно рекомендуем прочитать книгу «Essential
SNMP» Дугласа Мауро (Douglas Mauro) и Кевина Шмидта (Kevin
Schmidt) (O’Reilly) или хотя бы держать ее под рукой. Хороший спра
вочник является основой к истинному пониманию возможностей
SNMP. В следующем разделе мы рассмотрим основы SNMP, но глубо
кое изучение этого протокола выходит далеко за рамки этой книги.
В действительности тема использования Python в комплексе с SNMP
настолько обширна, что заслуживает отдельной книги.

### Краткое введение в SNMP

**Обзор SNMP**

С высоты 3000 метров SNMP – это протокол управления устройствами
в IPсетях. Как правило, этот протокол работает с портами UDP 161
и 162, хотя вполне возможно использовать и порты TCP. Практически
все современные устройства в центрах обработки данных поддержива


Краткое введение в SNMP **253**

```
ют работу с протоколом SNMP, а это означает, что имеется возмож
ность управлять не только коммутаторами и маршрутизаторами, но
также серверами, принтерами, блоками бесперебойного питания, на
копителями и другими устройствами.
Работа протокола SNMP основана на передаче хостам пакетов UDP
и ожидании ответов. Таким образом на самом простом уровне произво
дится мониторинг устройств. Тем не менее, протокол SNMP обладает
гораздо более широкими возможностями благодаря управляющим уст
ройствам и возможности создания агентов, отвечающих на запросы.
Наиболее типичными примерами того, что возможно с применением
SNMP, является мониторинг нагрузки на процессор, использования
диска и объема свободной памяти. Этот протокол может также исполь
зоваться для управления сетевыми коммутаторами, с его помощью
вполне возможно даже выполнять загрузку новых параметров на
стройки коммутатора. Мало кому известно, что точно так же можно
осуществлять мониторинг программного обеспечения, такого как веб
приложения и базы данных. Наконец, имеется поддержка RMON MIB
(Remote Monitoring Management Information Base – база управляющей
информации для удаленного мониторинга), которая обеспечивает мо
ниторинг «динамики», тогда как в обычном режиме SNMP применя
ется для мониторинга статических показателей.
Мы уже упомянули аббревиатуру MIB, поэтому сейчас объясним, что
это такое. SNMP – это всего лишь протокол, и он не делает никаких
предположений о данных. На подконтрольных устройствах выполняет
ся агент, snmpd, у которого имеется перечень объектов, подвергаемых
мониторингу. Фактически перечень представляет собой базу управ
ляющей информации, или MIB (Management Information Base). У каж
дого агента имеется, по крайней мере, одна база MIB, структура кото
рой соответствует спецификациям MIBII, определяемым в RFC 1213.
Базу MIB можно представить себе как файл, который используется
для трансляции имен в числа (чемто похоже на DNS), хотя на самом
деле все немного сложнее.
В этом файле находятся описания объектов управления. У каждого
объекта имеется три атрибута: имя, тип и синтаксис и данные для пе
редачи. Из них вам чаще всего придется работать с именами. Имена
часто еще называют идентификаторами объектов, или OID (Object
Identifier). Передавая этот OID агенту, вы тем самым сообщаете, что
именно хотели бы получить. Имена имеют две формы представления:
числовую и «удобочитаемую». Чаще используется удобочитаемая
форма имен, потому что числовые имена имеют большую длину и их
сложно запоминать. Одним из самых часто используемых OID являет
ся sysDescr. Если вы воспользуетесь инструментом командной строки
snmpwalk, чтобы получить значение идентификатора sysDescr, вы мо
жете использовать как удобочитаемую, так и числовую форму пред
ставления:
```

**254** Глава 7. SNMP

```
[root@rhel][H:4461]# snmpwalkv 2c c public localhost .1.3.6.1.2.1.1.1.0
SNMPv2MIB::sysDescr.0 = STRING: Linux localhost
2.6.188.1.15.el5 #1 SMP Mon Oct 22 08:32:04 EDT 2007 i686
[root@rhel][H:4461]# snmpwalkv 2c c public localhost sysDescr
SNMPv2MIB::sysDescr.0 = STRING: Linux localhost
2.6.188.1.15.el5 #1 SMP Mon Oct 22 08:32:04 EDT 2007 i686
```
```
К этому моменту мы нагрузили вас уймой аббревиатур и RFC, но при
зываем вас пересилить в себе желание встать и пойти спать. Мы обе
щаем, что очень скоро исправимся и приступим к разработке про
граммного кода.
```
**Установка и настройка SNMP**

```
Для упрощения дальнейшего повествования мы будем использовать
только пакет NetSNMP и соответствующее расширение Python к не
му. Но это не говорит о его большей ценности в сравнении с другими
библиотеками SNMP для Python, например PySNMP, используемой
в таких продуктах, как TwistwdSNMP и Zenoss. В Zenoss и в Twisted
SNMP библиотека PySNMP используется в асинхронном режиме. Это
очень правильный подход, который заслуживает рассмотрения, но у нас
просто нет места, чтобы описать оба эти продукта в данной главе.
Говоря в терминах NetSNMP, мы будем иметь дело с двумя различны
ми прикладными интерфейсами (API). Первый метод состоит в ис
пользовании модуля subprocess, чтобы «обернуть» инструменты ко
мандной строки из пакета NetSNMP, а второй – в использовании но
вых расширений для Python. Каждый из этих методов имеет свои пре
имущества и недостатки в зависимости от среды, в которой они
применяются.
В заключение мы также познакомимся с продуктом Zenoss, который
представляет собой весьма внушительное решение мониторинга сетей
посредством протокола SNMP, полностью реализованное на языке Py
thon и распространяемое с открытыми исходными текстами. При ис
пользовании Zenoss нам не придется писать средства управления SNMP
с чистого листа и вместо этого мы сможем взаимодействовать с ним по
средством его общедоступного API. Кроме того, проект Zenoss предос
тавляет нам возможность создавать собственные модули для этого про
дукта, вносить исправления и, наконец, расширять его функциональ
ность.
Чтобы добиться чегото полезного от SNMP, и в частности от NetSNMP,
его сначала нужно установить. К счастью, большинство операционных
систем UNIX и Linux устанавливаются вместе с пакетом NetSNMP, по
этому, если вам необходимо реализовать мониторинг устройства, для
этого достаточно будет выполнить необходимые настройки в конфигу
рационном файле snmpd.conf и запустить демон. Если вы предполагае
те разрабатывать на языке Python приложения, использующие пакет
```

Краткое введение в SNMP **255**

```
NetSNMP, о котором идет речь в этой главе, вам необходимо скомпи
лировать и установить расширения для Python. Если же вы предпола
гаете просто обертывать команды NetSNMP, такие как snmpget, snmp
walk, snmpdf и другие, тогда вам ничего не потребуется делать, если сам
пакет NetSNMP уже установлен.
Как вариант, вы можете загрузить виртуальную машину с исходными
текстами примеров для этой книги с сайта издательства http://www.ore>
illy.com/9780596515829. Вы можете также обращаться на сайт под
держки книги http://www.py4sa.com , где найдете последнюю информацию
о том, как можно опробовать примеры из этого раздела.
Кроме того, мы настроили эту виртуальную машину и с поддержкой
NetSNMP, и с необходимыми расширениями для Python. Вы можете
просто использовать эту виртуальную машину для запуска всех при
меров. Если мощность вашего компьютера позволяет, вы можете соз
дать несколько копий виртуальной машины и запускать под их управ
лением другие примеры из этой главы, чтобы имитировать взаимодей
ствия с несколькими компьютерами одновременно.
Если вы решите самостоятельно установить расширения для Python,
вам потребуется загрузить с сайта sourceforge.net NetSNMP вер
сии 5.4.x или выше. Расширения в этом пакете не скомпилированы
по умолчанию, поэтому вам придется самостоятельно собрать их, сле
дуя инструкциям в каталоге Python/README. В двух словах заметим,
что вам сначала надо будет скомпилировать эту версию NetSNMP,
а затем запустить сценарий setyp.py в каталоге Python. Мы считаем,
что процедура установки наименее утомительна в дистрибутиве Red
Hat Linux, где имеется пакет RPM с исходными текстами. Если вы ре
шили выполнить компиляцию, возможно, вам следует сначала попро
бовать сделать это в Red Hat, чтобы ознакомиться с самим процессом,
а затем приступать к установке в AIX, Solaris, OS X, HPUX и в других
операционных системах. Наконец, если столкнетесь с неприятностя
ми, то для запуска примеров просто воспользуйтесь виртуальной ма
шиной, а порядок компиляции и установки выясните позже.
И еще одно последнее замечание: обязательно выполните команду set
up.py build и затем setup.py test. Это сразу же позволит вам проверить
возможность работы с NetSNMP из Python. В качестве совета: если вы
столкнетесь с неприятностями во время компиляции, запустите ко
манду ldconfig, как показано ниже:
ldconfigv /usr/local/lib/
```
```
Если вам случится устанавливать пакет NetSNMP на стороне клиен
та, который предполагается подвергнуть мониторингу, вам следует
скомпилировать NetSNMP с параметром Host Resources MIB. Для
этого обычно достаточно выполнить следующую команду конфигури
рования процесса сборки:
./configurewithmibmodules=host
```

**256** Глава 7. SNMP

```
Обратите внимание, что при запуске сценария configure он попытается
запустить сценарий автоматической настройки. Но вам не обязатель
но делать это. Часто бывает проще вручную создать свой конфигура
ционный файл. В Red Hat настройки обычно сохраняются в файле
/etc/snmp/snmpd.conf и имеют примерно следующий вид:
syslocation "O'Reilly"
syscontact bofh@oreilly.com
rocommunity public
```
```
Этого простого файла будет вполне достаточно для опробования приме
ров в оставшейся части главы и запросов не для третьей версии SNMP.
Версия SNMPv3 имеет несколько более сложные настройки и не со
всем вписывается в тему данной главы, хотя при этом мы хотели бы
заметить, что в производстве лучше использовать SNMPv3, так как
версии 2 и 1 не имеют никакой защиты. Это значит, что никогда не
следует использовать SNMPv2 и SNMPv1 для передачи запросов через
Интернет, поскольку этот трафик может быть перехвачен. Известны
случаи высококлассных взломов, которые стали возможны благодаря
использованию этих версий.
```
### IPython и NetSNMP.

```
Если прежде вы никогда не занимались разработкой для SNMP, у вас
может возникнуть ощущение, что это не самая приятная работа. Чест
но говоря, это так и есть. Работа с SNMP чемто сродни головной бо
ли – изза высокой сложности протокола, изза необходимости читать
большое число RFC и изза высоких шансов допустить ошибку. Один
из способов попытаться ослабить эту боль состоит в том, чтобы для ис
следования SNMP и получения навыков обращения с API использо
вать оболочку IPython.
В примере 7.1 представлен очень короткий фрагмент программного
кода для запуска на локальной машине.
```
```
Пример 7.1. Использование IPython и Net>SNMP с расширениями Python
In [1]: import netsnmp
In [2]: oid = netsnmp.Varbind('sysDescr')
```
```
In [3]: result = netsnmp.snmpwalk(oid,
...: Version = 2,
...: DestHost="localhost",
...: Community="public")
```
```
Out[4]: ('Linux localhost 2.6.188.1.14.el5 #1 SMP Thu Aug 27 12:51:54 EDT
2008 i686',)
```
```
При исследовании библиотеки очень помогает использование функ
ции дополнения по нажатию клавиши табуляции. В этом примере мы
вовсю использовали функцию дополнения в IPython и с ее помощью
```

IPython и Net;SNMP **257**

```
создали очень простой запрос SNMPv2. В качестве общего примеча
ния: идентификатор sysDescr, о котором мы уже упоминали ранее,
представляет собой очень важный запрос, позволяющий получить ба
зовые характеристики машины. В выводе этого примера можно уви
деть нечто похожее, хотя и не идентичное, тому, что выводит команда
uname – a.
Как будет показано ниже в этой главе, анализ ответа на запрос sysDe
scr является важной частью исследования центров обработки данных.
К сожалению, как и многие составляющие SNMP, этот ответ не совсем
точен. Некоторые устройства могут не возвращать никакого ответа,
некоторые могут возвращать хоть и полезную, но неполную информа
цию, например: «Fibre Switch» (оптоволоконный коммутатор), неко
торые могут возвращать полную строку идентификации производите
ля. У нас недостаточно места, чтобы углубляться в детали решения
этой проблемы, но заметим, что умение анализировать все эти разли
чия как раз и есть то, на чем большие мальчики зарабатывают деньги.
Как вы уже знаете из главы 2 «IPython», существует возможность соз
дать определение класса или функции в виде отдельного файла прямо
из оболочки IPython, переключившись в редактор Vim, выполнив сле
дующую команду:
```
```
ed some_filename.py
```
```
После выхода из редактора вы получаете атрибуты созданного модуля
в своем пространстве имен и можете вывести их командой who. Этот
прием очень удобно использовать при работе с SNMP, так как итера
тивный стиль программирования естественным образом вписывается
в эту прикладную область. Давайте двинемся дальше и запишем сле
дующий ниже фрагмент программного кода в файл с именем snmp.py ,
выполнив команду:
```
```
ed snmp.py
```
```
В примере 7.2 приводится простой модуль, представляющий собой
шаблон создания сеанса с помощью NetSNMP.
```
```
Пример 7.2. Простой модуль создания сеанса с помощью Net>SNMP
#!/usr/bin/env python
import netsnmp
```
```
class Snmp(object):
"""Простой сеанс SNMP"""
def __init__(self,
oid = "sysDescr",
Version = 2,
DestHost = "localhost",
Community = "public"):
self.oid = oid
self.version = Version
```

**258** Глава 7. SNMP

```
self.destHost = DestHost
self.community = Community
```
```
def query(self):
"""Создает запрос SNMP"""
try:
result = netsnmp.snmpwalk(self.oid,
Version = self.version,
DestHost = self.destHost,
Community = self.community)
except Exception, err:
print err
result = None
return result
```
```
После того как вы сохраните этот файл и введете команду who, вы полу
чите следующее:
In [2]: who
Snmp netsnmp
```
```
Теперь, когда у нас имеется объектноориентированный интерфейс
к SNMP, можно воспользоваться им, чтобы выполнить запрос к ло
кальной машине:
```
```
In [3]: s = snmp()
In [4]: s.query()
Out[4]: ('Linux localhost 2.6.188.1.14.el5 #1 SMP Thu Sep 27 18:58:54 EDT
2007 i686',)
```
```
In [5]: result = s.query()
In [6]: len(result)
Out[6]: 1
```
```
Глядя на этот пример, можно сказать, что с помощью этого модуля
легко можно получать результаты, хотя в данном случае мы просто за
пустили сценарий, в котором жестко определили исходные данные;
поэтому теперь попробуем изменить значение объекта OID, чтобы вы
полнить обход всего поддерева системы:
```
```
In [7]: s.oid
Out[7]: 'sysDescr'
```
```
In [8]: s.oid = ".1.3.6.1.2.1.1"
In [9]: result = s.query()
```
```
In [10]: print result
('Linux localhost 2.6.188.1.14.el5 #1 SMP Thu Sep 27 18:58:54 EDT 2007 i686',
'.1.3.6.1.4.1.8072.3.2.10', '121219', 'me@localhost.com', 'localhost',
'"My Local Machine"', '0', '.1.3.6.1.6.3.10.3.1.1', '.1.3.6.1.6.3.11.3.1.1',
'.1.3.6.1.6.3.15.2.1.1', '.1.3.6.1.6.3.1',
'.1.3.6.1.2.1.49', '.1.3.6.1.2.1.4', '.1.3.6.1.2.1.50',
'.1.3.6.1.6.3.16.2.2.1', 'The SNMP Management Architecture MIB.',
```

IPython и Net;SNMP **259**

```
'The MIB for Message Processing and Dispatching.', 'The management information
definitions for the SNMP Userbased Security Model.',
'The MIB module for SNMPv2 entities', 'The MIB module for managing TCP
implementations', 'The MIB module for managing IP and ICMP implementations',
'The MIB module for managing UDP [snip]',
'Viewbased Access Control Model for SNMP.', '0', '0', '0', '0', '0', '0',
'0', '0')
```
```
Такой стиль интерактивного и исследовательского программирования
делает работу с SNMP более приятной. К этому моменту, если вы чув
ствуете в себе уверенность, можете приступить к выполнению запро
сов с другими значениями OID или даже выполнить обход всего дерева
MIB. Однако обход полного дерева MIB может занять некоторое время,
потому что потребуется выполнить запросы для множества значений
OID, поэтому на практике такой подход обычно не используется, так
как при этом будут потребляться ресурсы клиентской машины.
```
```
Не забывайте, что MIBII – это всего лишь файл со значениями
OID, который входит в состав большинства систем, обладающих
поддержкой SNMP. Другие MIB, уникальные для каждого про
изводителя, располагаются в отдельных файлах, к которым мо
жет обращаться агент, чтобы вернуть ответ на запрос. Если вы
захотите перейти на следующую ступень мастерства, вам при
дется найти специализированную документацию от производи
теля с описанием того, в какой базе MIB следует запрашивать
тот или иной OID.
```
```
Теперь перейдем к использованию особенности оболочки IPython, ко
торая позволяет запускать выполнение заданий в фоновом режиме:
```
```
In [11]: bg s.query()
Starting job # 0 in a separate thread.
```
```
In [12]: jobs[0].status
Out[12]: 'Completed'
```
```
In [16]: jobs[0].result
Out[16]:
('Linux localhost 2.6.188.1.14.el5 #1 SMP Thu Sep 27 18:58:54 EDT 2007 i686',
'.1.3.6.1.4.1.8072.3.2.10', '121219', 'me@localhost.com', 'localhost',
'"My Local Machine"',
'0', '.1.3.6.1.6.3.10.3.1.1', '.1.3.6.1.6.3.11.3.1.1',
'.1.3.6.1.6.3.15.2.1.1', '.1.3.6.1.6.3.1',
'.1.3.6.1.2.1.49', '.1.3.6.1.2.1.4', '.1.3.6.1.2.1.50',
'.1.3.6.1.6.3.16.2.2.1',
'The SNMP Management Architecture MIB.', 'The MIB for Message Processing and
Dispatching.',
'The management information definitions for the SNMP Userbased Security
Model.',
'The MIB module for SNMPv2 entities', 'The MIB module for managing TCP
implementations',
'The MIB module for managing IP and ICMP implementations', 'The MIB module for
```

**260** Глава 7. SNMP

```
managing UDP implementations',
'Viewbased Access Control Model for SNMP.', '0', '0', '0', '0', '0', '0',
'0', '0')
```
```
Прежде чем вы придете в восхищение, разрешите сообщить, что хотя
выполнение действий в фоновом режиме прекрасно реализовано в IPy
thon, тем не менее, этот режим может использоваться только при рабо
те с библиотеками, поддерживающими асинхронную модель выполне
ния. А расширения Python для NetSNMP работают в синхронном ре
жиме. В двух словах отметим, что вы не сможете писать многопоточ
ный программный код, ожидающий ответа, так как в основе лежат
блоки кода на языке C.
К счастью, как будет показано в главе, рассказывающей о процессах
и многозадачности, с помощью модуля обработки легко можно соз
давать дочерние процессы для параллельного выполнения запросов
SNMP. В следующем разделе мы рассмотрим проблему создания сце
нария, который будет автоматически исследовать центр обработки
данных.
```
### Исследование центра обработки данных.

```
Одна из наиболее полезных сторон SNMP заключается в использова
нии этого протокола для исследования центра обработки данных. Про
ще говоря, в ходе исследования составляется опись устройств, под
ключенных к сети, и производится сбор информации об этих устройст
вах. Более детальные виды исследований могут использоваться для
выявления связей между собранными данными, например, выяснение
точного MACадреса, под которым сервер известен коммутатору Cisco,
или схемы распределения памяти для оптоволоконного коммутатора
Brocade.
В этом разделе мы создадим простой сценарий, который будет отби
рать корректные IPадреса, MACадреса, основную информацию, по
ставляемую протоколом SNMP, и помещать ее в записи. Этот сценарий
может использоваться в вашей организации как основа для реализа
ции приложений, выполняющих исследование центра обработки дан
ных. При создании сценария мы будем использовать сведения, кото
рые рассматривались в других главах.
Существует несколько различных алгоритмов исследования, с кото
рыми нам приходилось сталкиваться, но только один из них мы пред
ставим вашему вниманию. Суть алгоритма состоит в следующем: по
слать серию запросов по протоколу ICMP; каждому ответившему уст
ройству послать простой запрос SNMP; проанализировать ответ; про
должить исследование на основе полученных данных. Другой алгоритм
подразумевает посылку серии запросов SNMP и сбор ответов с помо
щью другого процесса, но, как уже говорилось выше, мы сосредото
чимся на реализации первого алгоритма. Взгляните на пример 7.3.
```

Исследование центра обработки данных **261**

```
Небольшое замечание к программному коду ниже: поскольку
библиотека NetSNMP предусматривает возможность работы
только в синхронном режиме, мы создаем дочерние процессы
вызовом subprocess.call(). Это приводит к возможности появле
ния блокировок. В части использования утилиты ping мы могли
бы просто использовать subprocess.Popen, но чтобы сохранить
единообразие, мы используем один и тот же прием как для вы
полнения запросов SNMP, так и при использовании утилиты
ping.
```
```
Пример 7.3. Простой сценарий исследования центра обработки данных
#!/usr/bin/env python
from processing import Process, Queue, Pool
import time
import subprocess
import sys
from snmp import Snmp
```
```
q = Queue()
oq = Queue()
#ips = IP("10.0.1.0/24")
ips = ["192.19.101.250", "192.19.101.251", "192.19.101.252",
"192.19.101.253", "192.168.1.1"]
num_workers = 10
```
```
class HostRecord(object):
"""Записи с информацией о хостах"""
def __init__(self, ip=None, mac=None, snmp_response=None):
self.ip = ip
self.mac = mac
self.snmp_response = snmp_response
def __repr__(self):
return "[Host Record('%s','%s','%s')]" % (self.ip,
self.mac,
self.snmp_response)
```
```
def f(i,q,oq):
while True:
time.sleep(.1)
if q.empty():
sys.exit()
print "Process Number: %s Exit" % i
ip = q.get()
print "Process Number: %s" % i
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
oq.put(ip)
```

**262** Глава 7. SNMP

```
else:
print "Process Number: %s didn’t find a response for %s " % (i, ip)
pass
def snmp_query(i,out):
while True:
time.sleep(.1)
if out.empty():
sys.exit()
print "Process Number: %s" % i
ipaddr = out.get()
s = Snmp()
h = HostRecord()
h.ip = ipaddr
h.snmp_response = s.query()
print h
return h
try:
q.putmany(ips)
finally:
for i in range(num_workers):
p = Process(target=f, args=[i,q,oq])
p.start()
for i in range(num_workers):
pp = Process(target=snmp_query, args=[i,oq])
pp.start()
print "main process joins on queue"
p.join()
#while not oq.empty():
# print "Validated", oq.get()
print "Main Program finished"
```
```
Когда мы запустили этот сценарий, то получили следующий результат:
[root@giftcsllc02][H:4849][J:0]> python discover.py
Process Number: 0
192.19.101.250: is alive
Process Number: 1
192.19.101.251: is alive
Process Number: 2
Process Number: 3
Process Number: 4
main process joins on queue
192.19.101.252: is alive
192.19.101.253: is alive
Main Program finished
[Host Record('192.19.101.250','None','('Linux linux.host 2.6.188.1.15.el5
#1 SMP Mon Oct 22 08:32:04 EDT 2007 i686',)')]
[Host Record('192.19.101.252','None','('Linux linux.host 2.6.188.1.15.el5
#1 SMP Mon Oct 22 08:32:04 EDT 2007 i686',)')]
[Host Record('192.19.101.253','None','('Linux linux.host 2.6.188.1.15.el5
```

Получение множества значений с помощью SNMP **263**

```
#1 SMP Mon Oct 22 08:32:04 EDT 2007 i686',)')]
[Host Record('192.19.101.251','None','('Linux linux.host 2.6.188.1.15.el5
#1 SMP Mon Oct 22 08:32:04 EDT 2007 i686',)')]
Process Number: 4 didn't find a response for 192.168.1.1
```
```
Полученные результаты показывают, как работает этот интересный
алгоритм исследования центра обработки данных. В этом сценарии
можно было бы коечто исправить: например, добавить запись MAC
адреса в объект HostRecord, переписать программный код в более объ
ектноориентированном стиле, – дополнений хватило бы еще на одну
книгу, и разработок хватило бы на целую компанию. Понимая это, мы
переходим к другому разделу.
```
### Получение множества значений с помощью SNMP

```
Получение единственного значения не представляет большой сложно
сти, хотя иногда бывает желательно проверить ответы или выполнить
некоторое действие, основанное, например, на типе операционной сис
темы, под управлением которой работает компьютер. Чтобы сделать
чтото более значимое, бывает необходимо получить несколько значе
ний и выполнить какиелибо действия над ними.
Часто возникает задача произвести инвентаризацию центра обработки
данных или отдела и собрать сведения о некоторых параметрах всех
имеющихся машин. Представим такую гипотетическую ситуацию: вы
готовитесь к крупному обновлению программного обеспечения и вам
сказали, что каждая система должна иметь как минимум 1 Гбайт ОЗУ.
Вы помните, что на большинстве компьютеров установлено памяти не
менее 1 Гбайта, но среди тысяч поддерживаемых вами компьютеров
имеется несколько таких, где памяти меньше требуемого объема.
Очевидно, что у вас имеется несколько вариантов действий. Рассмот
рим каждый из них:
Вариант 1
Физически обойти все компьютеры и проверить объем ОЗУ на каж
дом из них, запустив некоторую команду или вскрыв корпус. Дос
таточно очевидно, что это не самый привлекательный вариант.
Вариант 2
Зайти по сети на каждый компьютер и выполнить команду, чтобы
определить объем ОЗУ. Этот подход обладает массой недостатков,
но его хотя бы теоретически можно реализовать в виде сценария,
выполняющего команду средствами ssh. Одна из основных проблем
состоит в том, что сценарий должен учитывать различия между
платформами, так как все операционные системы в чемто немного
отличаются. Другая проблема заключается в необходимости знать,
где все эти компьютеры располагаются.
```

**264** Глава 7. SNMP

```
Вариант 3
Написать небольшой сценарий, который опросит все устройства,
включенные в сеть, и определит объем памяти на каждом из них
с помощью SNMP.
Вариант 3, основанный на использовании SNMP, позволяет легко соз
дать опись, в которой будут присутствовать только компьютеры, имею
щие менее 1 Гбайта ОЗУ. Точный идентификатор OID, который потре
буется запросить, носит имя «hrMemorySize». Протокол SNMP отно
сится к разряду тех инструментов, которые всегда выгоднее использо
вать в многозадачном режиме, но всетаки подобной оптимизации
лучше избегать, если это не является абсолютно необходимым. Помня
об этом, перейдем непосредственно к деталям.
Чтобы быстро проверить нашу идею, воспользуемся программным ко
дом из предыдущего примера.
Получение объема памяти с помощью SNMP:
In [1]: run snmpinput
```
```
In [2]: who
netsnmp Snmp
```
```
In [3]: s = Snmp()
In [4]: s.DestHost = "10.0.1.2"
```
```
In [5]: s.Community = "public"
In [6]: s.oid = "hrMemorySize"
```
```
In [7]: result = int(s.query()[0])
hrMemorySize = None ( None )
```
```
In [27]: print result
2026124
```
```
Как видите, реализовать подобный сценарий достаточно просто. Ре
зультат возвращается в виде кортежа в строке [6], поэтому мы извле
каем элемент с индексом 0 и преобразуем его в целое число. Теперь мы
имеем целое число, соответствующее объему памяти в килобайтах.
Единственное, что следует иметь в виду, – на разных компьютерах
объем ОЗУ вычисляется поразному. Поэтому в таких случаях лучше
принимать решение на основе приближенных, а не точных значений.
Например, можно было бы искать компьютеры, объем ОЗУ в которых
немного меньше 1 Гбайта – скажем, 990 Мбайт.
В приведенном примере мы можем примерно оценить, что полученное
число примерно соответствует объему ОЗУ 2 Гбайта. Вы можете пола
гаться на эту информацию, отвечая на запрос своего руководителя
о наличии компьютеров с ОЗУ менее 2 Гбайт, если известно, что новое
приложение, которое требуется установить, требует наличия памяти
не менее 2 Гбайт.
```

Получение множества значений с помощью SNMP **265**

```
Теперь, проверив основную идею, мы можем автоматизировать проце
дуру определения памяти. Если говорить более определенно, следует
опросить все компьютеры, выяснить, в каких из них установлено па
мяти менее 2 Гбайт ОЗУ и затем записать полученную информацию
в файл формата CSV^1 , чтобы ее потом проще было импортировать в Ex
cel или OpenOffice Calc.
Далее можно написать инструмент командной строки, который прини
мает диапазон сетевых адресов в качестве входного аргумента и, до
полнительно, значение идентификатора OID, по умолчанию используя
идентификатор «hrMemorySize». При этом в сценарии нам необходимо
будет предусмотреть обход сетевых адресов из указанного диапазона.
Всякий раз, когда системный администратор пишет программный
код, он сталкивается с определенными ограничениями. В состоянии
ли вы потратить несколько часов или даже дней на создание большого
объектноориентированного сценария, который потом можно будет
использовать для решения других задач, или вам нужно быстро полу
чить хотя бы приблизительные результаты? На наш взгляд, в боль
шинстве случаев вполне можно выполнить обе реализации. При ис
пользовании IPython вы можете быстро создавать заготовки сценари
ев и затем доводить их до окончательного состояния. Вообще – это хо
рошая идея писать программный код многократного использования,
поскольку эта привычка, как снежный ком, быстро обретает инерцию
движения.
Надеемся, что теперь вы понимаете, в чем заключается сила SNMP.
Давайте приступим к созданию нашего сценария...
```
**Поиск объема памяти**

```
В этом следующем примере мы реализуем инструмент командной
строки, определяющий объем памяти, установленной в компьютерах,
с помощью SNMP:
#!/usr/bin/env python
#Инструмент командной строки, определяющий общий объем памяти в компьютере
import netsnmp
import optparse
from IPy import IP
```
```
class SnmpSession(object):
"""Простой сеанс SNMP"""
def __init__(self,
oid="hrMemorySize",
Version=2,
DestHost="localhost",
```
(^1) CSV, или Comma Separated Values, – значения, разделенные запятыми. –
_Прим. перев._


**266** Глава 7. SNMP

```
Community="public"):
self.oid = oid
self.Version = Version
self.DestHost = DestHost
self.Community = Community
def query(self):
"""Создает запрос SNMP"""
try:
result = netsnmp.snmpwalk(self.oid,
Version = self.Version,
DestHost = self.DestHost,
Community = self.Community)
except:
#Несмотря на то, что это всего лишь пример,
#тем не менее, выведем, какое исключение возникло
import sys
print sys.exc_info()
result = None
return result
class SnmpController(object):
"""Использует модуль optparse для управления сеансом SnmpSession"""
def run(self):
results = {} #Место сбора и хранения результатов snmp
p = optparse.OptionParser(description="A tool that determines
memory installed",
prog="memorator",
version="memorator 0.1.0a",
usage="%prog [subnet range] [options]")
p.add_option('community', 'c',help='community string',
default='public')
p.add_option('oid', 'o', help='object identifier',
default='hrMemorySize')
p.add_option('verbose', 'v', action=’store_true',
help='increase verbosity')
p.add_option('quiet', 'q', action=’store_true',help=’
suppresses most messages')
p.add_option('threshold', 't', action=’store', type="int",
help='a number to filter queries with')
```
```
options, arguments = p.parse_args()
if arguments:
for arg in arguments:
try:
ips = IP(arg) #Преобразовать аргумент в строку
except:
if not options.quiet:
print 'Ignoring %s, not a valid IP address' % arg
continue
for i in ips:
ipAddr = str(i)
```

Получение множества значений с помощью SNMP **267**

```
if not options.quiet:
print 'Running snmp query for: ', ipAddr
session = SnmpSession(options.oid,
DestHost = ipAddr,
Community = options.community)
if options.oid == "hrMemorySize":
try:
memory = int(session.query()[0])/1024
except:
memory = None
output = memory
else:
#Обработка результатов, не имеющих отношения
#к объему памяти
output = session.query()
if not options.quiet:
print "%s returns %s" % (ipAddr,output)
#Поместить полученные результаты в словарь,
#Но только если был получен корректный ответ
if output != None:
if options.threshold: #если порог обозначен
if output < options.threshold:
results[ipAddr] = output
#если разрешен вывод результатов
if not options.quiet:
print "%s returns %s" % (ipAddr,output)
else:
results[ipAddr] = output
if not options.quiet:
print output
```
```
print "Results from SNMP Query %s for %s:\n" % (options.oid,
arguments), results
```
```
else:
p.print_help() #при отсутствии аргументов командной строки
#вывести инструкцию об использовании
def _main():
"""
Запускает процесс сбора информации.
"""
start = SnmpController()
start.run()
if __name__ =='__main__':
try:
import IPy
except:
print "Please install the IPy module to use this tool"
_main()
```

**268** Глава 7. SNMP

```
Теперь пройдемся по этому сценарию и посмотрим, что он делает. Мы
взяли целый класс из предыдущего примера и поместили его в новый
модуль. Затем мы написали классконтроллер, который анализирует
аргументы командной строки с помощью модуля optparse. Модуль IPy,
к которому мы обращаемся снова и снова, используется для автомати
ческой обработки IPадресов. Благодаря этому можно указать несколь
ко IPадресов или диапазон адресов, и наш модуль будет отсылать за
просы SNMP и возвращать результаты в виде словаря, в котором роль
ключей будут играть IPадреса, а роль значений – ответы SNMP.
Единственная сложность, которая здесь реализована, – это логика об
работки пустых ответов и проверки порогового значения. То есть мо
дуль возвращает только значения ниже указанного порога. При ис
пользовании порога мы можем получать значимые для нас результаты
и учесть различия в том, как разные компьютеры вычисляют объем
памяти.
Посмотрим на вывод, полученный в результате работы этого модуля:
```
```
[ngift@ngleplap][H:6518][J:0]> ./memory_tool_netsnmp.py 10.0.1.2 10.0.1.20
Running snmp query for: 10.0.1.2
hrMemorySize = None ( None )
1978
Running snmp query for: 10.0.1.20
hrMemorySize = None ( None )
372
Results from SNMP Query hrMemorySize for ['10.0.1.2', '10.0.1.20']:
{'10.0.1.2': 1978, '10.0.1.20': 372}
```
```
Как видите, результаты были получены для компьютеров в подсети
10.0.1.0/24. Теперь воспользуемся флагом threshold (порог), чтобы
сымитировать поиск машин, объем ОЗУ в которых меньше 2 Гбайт.
Как уже упоминалось выше, разные компьютеры поразному вычис
ляют имеющийся объем ОЗУ, поэтому для пущей уверенности возь
мем в качестве порогового значения число 1800, что примерно должно
соответствовать объему ОЗУ 1800 Мбайт. То есть, если в компьютере
объем ОЗУ составляет менее 1800 Мбайт, или примерно 2 Гбайта, ин
формация о нем будет включена в наш отчет.
Ниже приводится результат выполнения такого запроса:
[ngift@ngleplap][H:6519][J:0]>
./memory_tool_netsnmp.pythreshold 1800 10.0.1.2 10.0.1.20
Running snmp query for: 10.0.1.2
hrMemorySize = None ( None )
Running snmp query for: 10.0.1.20
hrMemorySize = None ( None )
10.0.1.20 returns 372
Results from SNMP Query hrMemorySize for ['10.0.1.2', '10.0.1.20']:
{'10.0.1.20': 372}
```

Получение множества значений с помощью SNMP **269**

```
Наш сценарий прекрасно справился с заданием, однако мы можем
сделать еще коечто, чтобы оптимизировать его. Если вам потребует
ся опросить несколько тысяч машин, то для выполнения работы этому
сценарию может потребоваться целый день или даже больше. Это, мо
жет быть, и не страшно, но если вам требуется получить результаты
очень быстро, вам необходимо будет обеспечить возможность парал
лельного выполнения нескольких запросов одновременно и организо
вать ветвление для каждого запроса, используя для этого библиотеку
стороннего производителя. Еще одно усовершенствование, которое
можно было бы внести, – это автоматическое создание файла отчета
в формате CSV из нашего словаря.
Но прежде чем мы перейдем к реализации этих задач, позвольте обра
тить ваше внимание на один момент, который вы, возможно, не заме
тили. Сценарий написан так, что позволяет запрашивать любой OID,
а не только определять объем памяти. Это очень удобно, потому что
у нас теперь имеется как инструмент определения объемов памяти,
так и универсальный инструмент, позволяющий выполнять любые за
просы SNMP.
Рассмотрим пример, который наглядно демонстрирует, что мы имеем
в виду:
```
```
[ngift@ngleplap][H:6522][J:0]> ./memory_tool_netsnmp.pyo sysDescr
10.0.1.2 10.0.1.20
Running snmp query for: 10.0.1.2
sysDescr = None ( None )
10.0.1.2 returns ('Linux cent 2.6.188.1.14.el5 #1 SMP
Thu Sep 27 19:05:32 EDT 2007 x86_64',)
('Linux cent 2.6.188.1.14.el5 #1 SMP Thu Sep 27 19:05:32 EDT 2007 x86_64',)
Running snmp query for: 10.0.1.20
sysDescr = None ( None )
10.0.1.20 returns ('Linux localhost.localdomain 2.6.188.1.14.el5 #1 SMP
Thu Sep 27 19:05:32 EDT 2007 x86_64',)
('Linux localhost.localdomain 2.6.188.1.14.el5 #1 SMP
Thu Sep 27 19:05:32 EDT 2007 x86_64',)
Results from SNMP Query sysDescr for ['10.0.1.2', '10.0.1.20']:
{'10.0.1.2': ('Linux cent 2.6.188.1.14.el5 #1 SMP
Thu Sep 27 19:05:32 EDT 2007 x86_64',), '10.0.1.20':
('Linux localhost.localdomain 2.6.188.1.14.el5 #1 SMP
Thu Sep 27 19:05:32 EDT 2007 x86_64',)}
```
```
Совсем не лишне учитывать это, приступая к работе над «одноразо
вым» инструментом для конкретного случая. Почему бы не потратить
дополнительные 30 минут, чтобы придать ему универсальность? В ре
зультате у вас может получиться инструмент, который будет находить
применение снова и снова, и эти 30 минут превратятся в ничто по срав
нению с тем временем, которое вам удастся сэкономить в будущем.
```

**270** Глава 7. SNMP

### Создание гибридных инструментов SNMP.

```
Мы уже показали вам несколько отдельных инструментов и хотим от
метить, что использованные нами приемы можно объединить для соз
дания весьма сложных инструментов. Начнем с создания серии про
стых узкоспециализированных инструментов, на основе которых позд
нее мы сможем создавать большие сценарии.
Ниже приводится полезный сценарий с именем snmpstatus, который
получает несколько различных запросов snmp и комбинирует из них
«состояние» опрашиваемого узла:
import subprocess
```
```
class Snmpdf(object):
"""Инструмент командной строки snmpstatus"""
def __init__(self,
Version="v2c",
DestHost="localhost",
Community="public",
verbose=True):
self.Version = Version
self.DestHost = DestHost
self.Community = Community
self.verbose = verbose
def query(self):
"""Создает запрос для snmpstatus"""
Version = self.Version
DestHost = self.DestHost
Community = self.Community
verbose = self.verbose
try:
snmpstatus = "snmpstatus %sc %s %s" % (Version, Community,
DestHost)
if verbose:
print "Running: %s" % snmpstatus
p = subprocess.Popen(snmpstatus,
shell=True,
stdout=subprocess.PIPE)
out = p.stdout.read()
return out
except:
import sys
print >> sys.stderr, "error running %s" % snmpstatus
```
```
def _main():
snmpstatus = Snmpdf()
result = snmpstatus.query()
print result
```

Расширение возможностей Net;SNMP **271**

```
if __name__ == "__main__":
_main()
```
```
Мы надеемся, что вы обратили внимание на тот факт, что этот сцена
рий не сильно отличается от команды snmpdf, за исключением некото
рых имен. Это отличный пример, когда было бы желательно перейти
на более высокий уровень абстракции и затем повторно использовать
общие компоненты. Если бы мы создали модуль, вмещающий весь об
щий программный код, наш новый сценарий состоял бы всего из не
скольких строк. Имейте это в виду, мы еще вернемся к этому.
Другой инструмент, имеющий отношение к SNMP, – это ARP, кото
рый использует протокол ARP. С помощью протокола ARP можно по
лучить MACадреса устройств по их IPадресам, при условии, что они
находятся в одной и той же сети. Давайте напишем и этот узкоспециа
лизированный инструмент. Он пригодится нам немного позже.
Оформить действия с протоколом ARP в виде сценария не составит ни
какого труда; можно сразу продемонстрировать работу этого примера,
используя интерактивную оболочку IPython. Итак, запустите IPython
и введите следующее:
```
```
import re
import subprocess
#некоторые переменные
ARP = "arp"
IP = "10.0.1.1"
CMD = "%s %s " % (ARP, IP)
macPattern = re.compile(":")
def getMac():
p = subprocess.Popen(CMD, shell=True, stdout=subprocess.PIPE)
out = p.stdout.read()
results = out.split()
for chunk in results:
if re.search(macPattern, chunk):
return chunk
if __name__ == "__main__":
macAddr = getMac()
print macAddr
```
```
Этот фрагмент нельзя назвать инструментом многократного использо
вания, но вы легко можете взять эту идею за основу и использовать ее
как часть общей библиотеки получения сведений об устройствах в сети
центра обработки данных.
```
### Расширение возможностей NetSNMP

```
Как уже говорилось ранее, в большинстве операционных систем *nix
пакет NetSNMP установлен в виде агента. По умолчанию агент может
возвращать определенный перечень информации, однако существует
```

**272** Глава 7. SNMP

```
возможность расширять этот перечень. Можно было бы указать агенту
на необходимость собирать некоторые сведения и затем возвращать их
по протоколу SNMP.
Файл EXAMPLE.conf , поставляемый в составе NetSNMP, – это один
из лучших источников информации по расширению возможностей
NetSNMP. Нелишним будет обратиться к команде man snmpd.conf, ко
торая выводит более подробную информацию с описанием API. Если
вас интересуют вопросы расширения возможностей «родных» агентов
пакета, оба эти источника справочной информации могут стать для
вас незаменимыми.
С точки зрения программистов на языке Python, возможность расши
рения NetSNMP является одним из самых захватывающих аспектов
работы с SNMP, потому что позволяет разработчикам писать про
граммный код, выполняющий мониторинг всего, что они сочтут необ
ходимым, и дополнительно иметь внутреннего агента, отвечающего
предъявляемым условиям.
Пакет NetSNMP предлагает достаточно много способов расширения
возможностей агента, и для начала мы напишем программу «Hello
World», которая будет выполняться по запросу snmp. Первый шаг за
ключается в создании простого файла snmpd.conf , посредством которо
го будет запускаться наша программа «Hello World», написанная на
языке Python. В примере 7.4 показано, как выглядит этот файл в опе
рационной системе Red Hat.
```
```
Пример 7.4. Конфигурационный файл SNMP, предусматривающий вызов
программы «Hello World»
syslocation "O'Reilly"
syscontact bofh@oreilly.com
rocommunity public
exec helloworld /usr/bin/pythonc "print 'hello world from Python'"
```
```
После этого следует сообщить демону snmpd о необходимости перечи
тать конфигурационный файл. Сделать это можно тремя разными спо
собами. В Red Hat можно использовать такую команду:
```
```
service snmpd reload
```
```
или сначала выполнить такую команду:
```
```
psef | grep snmpd
root 12345 1 0 Apr14?
00:00:30 /usr/sbin/snmpdLsd Lf /dev/null /var/run/snmpd.pid –a
```
```
а затем послать демону сигнал:
```
```
killHUP 12345
```
```
Наконец, можно с помощью команды snmpset присвоить целое число
(1) параметру UCD–SNMPMIB::versionUpdateConfig.0 и тем самым вынудить
демон snmpd перечитать конфигурационный файл.
```

Расширение возможностей Net;SNMP **273**

```
Теперь, когда демон snmpd перечитал измененный файл snmpd.conf , мы
можем двинуться дальше и послать нашей машине запрос с помощью
команды snmpwalk или с помощью расширения NetSNMP из оболочки
IPython. Ниже показано, что возвращает команда snmpwalk:
```
```
[root@giftcsllc02][H:4904][J:0]> snmpwalkv 1 c public localhost
.1.3.6.1.4.1.2021.8
UCDSNMPMIB::extIndex.1 = INTEGER: 1
UCDSNMPMIB::extNames.1 = STRING: helloworld
UCDSNMPMIB::extCommand.1 = STRING: /usr/bin/python
c "print 'hello world from Python'"
UCDSNMPMIB::extResult.1 = INTEGER: 0
UCDSNMPMIB::extOutput.1 = STRING: hello world from Python
UCDSNMPMIB::extErrFix.1 = INTEGER: noError(0)
UCDSNMPMIB::extErrFixCmd.1 = STRING:
```
```
Этот запрос требует некоторых пояснений, так как наблюдательный чи
татель может задаться вопросом, откуда взялся OID 1.3.6.1.4.1.2021.8.
Этот OID соответствует идентификатору ucdavis.extTable. Когда созда
ется расширение в snmpd.conf , оно присваивается этому OID. Дело не
сколько осложняется, когда возникает потребность создать свой OID.
Для этого необходимо обратиться в организацию iana.org и получить
уникальный номер для своего предприятия. После этого можно будет
использовать полученный номер для создания специализированных
запросов агенту. Основная причина таких сложностей состоит в необ
ходимости сохранить однородность пространства имен и избежать
конфликтов с числами, которые, возможно, получат поставщики обо
рудования в будущем.
Истинная сила Python заключается вовсе не в том, чтобы получить вы
вод от единственной команды – это было бы слишком просто. Ниже
приводится пример сценария, который определяет общее число обра
щений к вебсерверу Apache из броузера Firefox, анализируя файл жур
нала, и возвращает результат под нестандартным OID предприятия.
Начнем рассмотрение с конца и сначала посмотрим на полученные ре
зультаты:
snmpwalkv 2c c public localhost .1.3.6.1.4.1.2021.28664.100
UCDSNMPMIB::ucdavis.28664.100.1.1 = INTEGER: 1
UCDSNMPMIB::ucdavis.28664.100.2.1 = STRING: "FirefoxHits"
UCDSNMPMIB::ucdavis.28664.100.3.1 = STRING:
"/usr/bin/python /opt/local/snmp_scripts/agent_ext_logs.py"
UCDSNMPMIB::ucdavis.28664.100.100.1 = INTEGER: 0
UCDSNMPMIB::ucdavis.28664.100.101.1 = STRING:
"Total number of Firefox Browser Hits: 15702"
UCDSNMPMIB::ucdavis.28664.100.102.1 = INTEGER: 0
UCDSNMPMIB::ucdavis.28664.100.103.1 = ""
```
```
Если отыскать строку со значением 100.101.1, можно увидеть вывод,
полученный от сценария, который анализирует файл журнала вебсер
вера Apache и отыскивает записи, свидетельствующие об обращениях
```

**274** Глава 7. SNMP

```
с помощью броузера Firefox. Затем сценарий суммирует их и возвраща
ет по протоколу SNMP. В примере 7.5 приводится исходный текст сце
нария, который запускается при выполнении запроса к данному OID.
```
```
Пример 7.5. Сценарий поиска числа обращений к веб>серверу Apache
из броузера Firefox
import re
```
```
"""Возвращает число обращений из броузера Firefox"""
def grep(lines,pattern="Firefox"):
pat = re.compile(pattern)
for line in lines:
if pat.search(line): yield line
def increment(lines):
num = 0
for line in lines:
num += 1
return num
```
```
wwwlog = open("/home/noahgift/logs/noahgift.comcombinedlog")
column = (line.rsplit(None,1)[1] for line in wwwlog)
match = grep(column)
count = increment(match)
print "Total Number of Firefox Hits: %s" % count
```
```
Чтобы заставить этот запрос работать, мы сначала должны добавить
вфайл snmpd.conf информацию об этом сценарии, как показано ниже:
syslocation “O Reilly”
syscontact bofh@oreilly.com
rocommunity public
exec helloworld /usr/bin/pythonc "print 'hello world from Python'"
exec .1.3.6.1.4.1.2021.28664.100 FirefoxHits /usr/bin/python
/opt/local/snmp_scripts/agent_ext_logs.py
```
```
Самая магическая часть здесь – последняя строка с идентификатором
.1.3.6.1.4.1.2021, где 28664 является числом нашего предприятия,
а число 100 – просто некоторое число, которое мы решили использо
вать для примера. Это очень важно – следовать общепринятым прави
лам и использовать свое число предприятия, если вы планируете зани
маться расширением возможностей SNMP. Благодаря этому вы сумее
те избежать конфликтов при использовании в команде snmpset чисел,
уже занятых кемто другим.
Мы склонны считать, что тема использования SNMP является одной
из самых захватывающих тем в книге и что при этом SNMP попреж
нему остается малоизведанной областью. Можно привести массу при
меров, когда расширение возможностей NetSNMP может быть полез
ным, а при аккуратном использовании SNMPv3 вы сможете делать
удивительные вещи, реализовать которые с помощью протокола SNMP
```

Управление устройствами через SNMP **275**

```
совсем несложно и для которых применение ssh и сокетов могло бы по
казаться естественным выбором.
```
### Управление устройствами через SNMP.

```
Одним из самых интересных аспектов применения SNMP является
возможность управления устройствами по этому протоколу. Очевид
но, что такой способ управления маршрутизатором обладает сущест
венными преимуществами перед использованием, например, модуля
Pexpect ( http://sourceforge.net/projects/pexpect/ ), потому что реализу
ется намного проще.
Для краткости мы в примере будем рассматривать только использова
ние SNMPv1, но, если вам предстоит взаимодействовать с устройства
ми через незащищенную сеть, вам следует использовать SNMPv3. Пе
ред прочтением этого раздела было бы неплохо ознакомиться с книга
ми «Essential SNMP» и «Cisco IOS Cookbook» Кевина Дули (Kevin
Dooley) и Яна Дж. Брауна ( Ian. J. Brown) (O’Reilly), если они у вас име
ются или у вас имеется учетная запись для доступа к службе Safari.
Они содержат обширую информацию как об основах настройки, так
и о способах взаимодействия с устройствами Cisco по протоколу SNMP.
Поскольку перезагрузка параметров настройки в устройствах Cisco
красиво реализуется через протокол SNMP, мы выбрали эту тему для
разговора об управлении устройствами. Для опробования этого приме
ра вам потребуется работающий сервер TFTP, откуда маршрутизатор
будет забирать файл IOS, и маршрутизатор с разрешенным доступом
для чтения/записи по протоколу SNMP. В примере 7.6 приводится
сценарий на языке Python.
```
```
Пример 7.6. Выгрузка новой конфигурации в маршрутизатор Cisco
import netsnmp
vars = netsnmp.Varbind(netsnmp.VarList(netsnmp.Varbind(
".1.2.6.1.4.1.9.2.10.6.0", "1"),
(netsnmp.Varbind("cisco.example.com.1.3.6.1.4.1.9.2.10.12.172.25.1.1",
"isoconfig.bin")
result = netsnmp.snmpset(vars,
Version = 1,
DestHost='cisco.example.com',
Community='readWrite')
```
```
В этом примере мы использовали метод VarList из модуля netsnmp, что
бы сначала выполнить инструкцию, которая стирает информацию во
флешпамяти коммутатора, а затем загрузить новый образ файла IOS.
Этот программный код мог бы послужить основой сценария, выпол
няющего обновление настроек всех коммутаторов в вычислительном
центре. Как и любой другой программный код в этой книге, он должен
```

**276** Глава 7. SNMP

```
быть опробован на оборудовании, не включенном в работу, и вы не ока
жетесь перед фактом, что чтото натворили,.
И последнее замечание: протокол SNMP редко рассматривается как
способ управления устройствами и, тем не менее, он предоставляет
широкие возможности по управлению устройствами в вычислитель
ном центре, поскольку является универсальной спецификацией для
устройств, выпускавшихся начиная с 1988 года. В будущем возможно
очень интересное развитие протокола SNMP v3.
```
### Интеграция SNMP в сеть предприятия с помощью Zenoss

**с помощью Zenoss**

```
Zenoss представляет собой замечательную систему управления ло
кальными сетями уровня предприятия. Мало того, что Zenoss являет
ся приложением, распространяемым с открытыми исходными текста
ми, но оно еще целиком написано на языке Python. Система Zenoss яв
ляется представителем нового поколения приложений уровня пред
приятия, обладающих большими возможностями и допускающих
расширение с использованием интерфейса XMLRPC или ReST. За до
полнительной информацией о ReST обращайтесь к книге Леонарда
Ричардсона (Leonard Richardson) и Сэма Руби (Sam Ruby) «RESTful
Web Services» (O’Reilly).
Наконец, если у вас появится желание участвовать в разработке Ze
noss, вы можете предлагать свои исправления.
```
**Прикладной интерфейс Zenoss**

```
За последней информацией о прикладном интерфейсе Zenoss обра
щайтесь на сайт http://www.zenoss.com/community/docs/howtos/send>
events/.
```
```
Использование Zendmd
Система Zendoss не только поставляется в комплекте с системой мони
торинга и исследования SNMP, но и включает в себя прикладной ин
терфейс высокого уровня с именем zendmd. Вы можете открыть на
строенную командную оболочку Python и выполнять команды Zenoss
непосредственно.
Пример использования zendmd:
```
```
>>> d = find('build.zenoss.loc')
>>> d.os.interfaces.objectIds()
['eth0', 'eth1', 'lo', 'sit0', 'vmnet1', 'vmnet8']
>>> for d in dmd.Devices.getSubDevices():
>>> print d.id, d.getManageIp()
```

Интеграция SNMP в сеть предприятия с помощью Zenoss **277**

```
Прикладной интерфейс доступа к устройствам
С системой Zenoss можно также взаимодействовать через интерфейс
XMLRPC и добавлять или удалять устройства. Ниже приводятся два
примера:
С использованием ReST:
```
```
[zenos@zenoss $]
wget 'http://admin:zenoss@MYHOST:8080/zport/dmd
/ZenEventManager/manage_addEvent?device=MYDEVICE&component="
MYCOMPONENT&summary="
MYSUMMARY&severity=4&eclass=EVENTCLASS&eventClassKey=EVENTCLASSKEY
```
```
C использованием XMLRPC:
```
```
>>> from xmlrpclib import ServerProxy
>>> serv = ServerProxy(
'http://admin:zenoss@MYHOST:8080/zport/dmd/ZenEventManager')
>>> evt = {'device':'mydevice', 'component':'eth0',
'summary':'eth0 is down','severity':4, 'eventClass':'/Net'}
>>> serv.sendEvent(evt)
```

**8**

### Окрошка из операционных систем

**Введение**

Быть системным администратором зачастую означает быть брошен
ным на съедение волкам. Правила, предварительное планирование
и даже выбор операционной системы часто находятся вне сферы ваше
го влияния. В настоящее время чтобы быть хотя бы маломальски эф
фективным системным администратором, вам необходимо знать их
все, мы имеем в виду все операционные системы. От Linux до Solaris,
Mac OS X и FreeBSD – все эти системы должны быть вам знакомы.
Только время покажет, продолжат ли свое существование такие па
тентованные операционные системы, как AIX или HPUX, но они все
еще необходимы многим людям.

К счастью, здесь нам на помощь опять приходит язык Python – мы на
деемся, что вы обратили внимание, что в состав языка входит полно
масштабная стандартная библиотека, которая способна удовлетворить
практически все потребности администраторов самых разнообразных
операционных систем. В составе стандартной библиотеки имеются мо
дули, которые позволят системному администратору реализовать все,
что ему необходимо, от архивирования каталогов и сравнения файлов
и каталогов до анализа конфигурационных файлов. Зрелость языка
Python вместе с его элегантностью и удобочитаемостью – причина то
го, что он не имеет себе равных в системном администрировании.

Во многих сложнейших областях человеческой деятельности, где тре
буются услуги системного администратора, таких как производство
мультипликационных фильмов или в вычислительных центрах, про
исходит отказ от применения языка Perl в пользу языка Python, пото
му что последний позволяет писать более элегантный и удобочитае
мый программный код. Язык Ruby – это достаточно интересный язык
программирования, в котором используются положительные особен


Кросс;платформенное программирование на языке Python в UNIX **279**

```
ности языка Python, но, тем не менее, мощность стандартной библио
теки и широта возможностей языка Python дает ему преимущества пе
ред языком Ruby при использовании в качестве языка системного ад
министрирования.
В этой главе будут рассматриваться несколько операционных систем,
поэтому у нас не будет времени исследовать какуюлибо из них доста
точно глубоко, но мы углубимся настолько, чтобы показать, что Python
может играть роль как универсального кроссплатформенного языка
сценариев, так и уникального средства администрирования каждой из
операционных систем. Кроме того, на горизонте замаячила «новая
операционная система», которая обретает форму центра обработки
данных. Эта новая платформа получила название «(за)облачная» обра
ботка данных (Cloud Computing), и мы поговорим о том, что предлага
ют компании Amazon и Google.
Но довольно бездельничать и балагурить. С кухни потянуло чемто
восхитительным... это что, окрошка из операционных систем?
```
**Кроссплатформенное программирование**

### на языке Python в UNIX Кроссплатформенное программирование

```
Хотя между разными UNIXподобными операционными системами
существуют некоторые значимые различия, но общего в них намного
больше. Один из способов примирить различные версии *nix состоит
в том, чтобы создавать кроссплатформенные инструменты и библио
теки, которые скрывают различия между операционными системами.
Основной способ добиться этого – использовать условные инструкции,
которые проверяют тип и версию операционной системы.
Язык Python неизменно следует философии «батарейки входят в ком
плект поставки» и предоставляет инструменты для решения практи
чески любой проблемы, с которой вы можете столкнуться. Для опреде
ления типа платформы, на которой выполняется ваш программный
код, существует модуль platform. Давайте поближе познакомимся с ос
новами использования этого модуля.
Самый простой способ познакомиться с возможностями модуля plat
form – написать сценарий, который будет выводить всю доступную ин
формацию о системе, как показано в примере 8.1.
```
```
Пример 8.1. Использование модуля platform для получения информации
о системе
#!/usr/bin/env python
import platform
```
```
profile = [
platform.architecture(),
platform.dist(),
```

**280** Глава 8. Окрошка из операционных систем

```
platform.libc_ver(),
platform.mac_ver(),
platform.machine(),
platform.node(),
platform.platform(),
platform.processor(),
platform.python_build(),
platform.python_compiler(),
platform.python_version(),
platform.system(),
platform.uname(),
platform.version(),
]
for item in profile:
print item
```
```
Ниже приводится результат работы этого сценария в операционной
системе OS X Leopard 10.5.2:
[ngift@Macintosh6][H:10879][J:0]% python cross_platform.py
('32bit', '')
('', '', '')
('', '')
('10.5.2', ('', '', ''), 'i386')
i386
Macintosh6.local
Darwin9.2.0i38632bit
i386
('r251:54863', 'Jan 17 2008 19:35:17')
GCC 4.0.1 (Apple Inc. build 5465)
2.5.1
Darwin
('Darwin', 'Macintosh6.local', '9.2.0', 'Darwin Kernel Version 9.2.0:
Tue Feb 5 16:13:22 PST 2008; root:xnu1228.3.13~1/
RELEASE_I386','i386','i386')
Darwin Kernel Version 9.2.0: Tue Feb 5 16:13:22 PST 2008;
root:xnu1228.3.13~1/RELEASE_I386
```
```
Этот пример позволяет получить представление о том, какого рода ин
формация об операционной системе нам доступна. Следующий шаг на
пути к созданию кроссплатформенного программного кода состоит
в необходимости создать модуль fingerprint, который будет «брать от
печатки пальцев», определяя, на какой платформе, с каким номером
версии он выполняется. В следующем примере мы «взяли отпечатки
пальцев» у следующих операционных систем: Mac OS X, Ubuntu, Red
Hat/CentOS, FreeBSD и SunOS. Взгляните на пример 8.2.
```
```
Пример 8.2. Определение типа операционной системы
#!/usr/bin/env python
import platform
```

Кросс;платформенное программирование на языке Python в UNIX **281**

```
"""
Определение принадлежности к одной из следующих операционных систем:
* Mac OS X
* Ubuntu
* Red Hat/Cent OS
* FreeBSD
* SunOS
"""
class OpSysType(object):
"""Определяет тип ОС с помощью модуля platform"""
def __getattr__(self, attr):
if attr == "osx":
return "osx"
elif attr == "rhel":
return "redhat"
elif attr == "ubu":
return "ubuntu"
elif attr == "fbsd":
return "FreeBSD"
elif attr == "sun":
return "SunOS"
elif attr == "unknown_linux":
return "unknown_linux"
elif attr == "unknown":
return "unknown"
else:
raise AttributeError, attr
def linuxType(self):
"""Определяет разновидность Linux с помощью различных методов"""
if platform.dist()[0] == self.rhel:
return self.rhel
elif platform.uname()[1] == self.ubu:
return self.ubu
else:
return self.unknown_linux
def queryOS(self):
if platform.system() == "Darwin":
return self.osx
elif platform.system() == "Linux":
return self.linuxType()
elif platform.system() == self.sun:
return self.sun
elif platform.system() == self.fbsd:
return self.fbsd
```
```
def fingerprint():
type = OpSysType()
print type.queryOS()
if __name__ == "__main__":
fingerprint()
```

**282** Глава 8. Окрошка из операционных систем

```
Теперь посмотрим, что выводит этот модуль при запуске на различных
платформах.
Red Hat:
[root@localhost]/# python fingerprint.py
redhat
```
```
Ubuntu:
```
```
root@ubuntu:/# python fingerprint.py
ubuntu
```
```
Solaris 10 или SunOS:
bash3.00# python fingerprint.py
SunOS
```
```
FreeBSD:
```
```
# python fingerprint.py
FreeBSD
```
```
Хотя в выводе этой команды не содержится ничего особенно интерес
ного, но в действительности она предоставляет нам очень мощный ин
струмент. Этот простой модуль позволит нам писать кроссплатфор
менный программный код, так как мы, например, можем определить
словарь с типами этих операционных систем и при нахождении соот
ветствия выполнять соответствующий платформозависимый про
граммный код. Одним из примеров получения самой ощутимой выго
ды от использования приемов кроссплатформенного программирова
ния могут служить сценарии, используемые для администрирования
сети посредством применения ssh с ключами. В этом случае программ
ный код может работать на многих платформах и давать непротиворе
чивые результаты.
```
**Использование SSH с ключами, каталога NFS**

**и кроссплатформенных сценариев Python**

**для управления системами**

```
Один из способов управления инфраструктурой из компьютеров, рабо
тающих под управлением разнотипных систем *nix, заключается в ис
пользовании ssh с ключами, общего каталога, монтируемого как том
NFS, и кроссплатформенного программного кода на языке Python.
Разобьем этот процесс на несколько шагов, чтобы было понятнее:
Шаг 1: создать открытый ключ ssh в системе, откуда будет выполнять
ся администрирование. Обратите внимание: для разных платформ эта
процедура может существенно отличаться. За подробностями обра
щайтесь к документации по операционной системе и к справочному
руководству по команде ssh. Создание ключа демонстрируется в при
мере 8.3.
```

Кросс;платформенное программирование на языке Python в UNIX **283**

```
Примечание к примеру ниже: с целью демонстрации мы созда
ли ключ для пользователя root, однако для обеспечения более
высокого уровня безопасности было бы лучше создать учетную
запись пользователя, для которого определить привилегии sudo
на запуск только этого сценария.
```
```
Пример 8.3. Создание открытого ключа ssh
[ngift@Macintosh6][H:11026][J:0]% sshkeygent rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
6c:2f:6e:f6:b7:b8:4d:17:05:99:67:26:1c:b9:74:11 root@localhost.localdomain
[ngift@Macintosh6][H:11026][J:0]%
```
```
Шаг 2: Скопировать открытый ключ на администрируемые машины
исоздать файл authorized_keys , как показано в примере 8.4.
```
```
Пример 8.4. Копирование открытого ключа ssh
[ngift@Macintosh6][H:11026][J:0]% scp id_leop_lap.pub root@10.0.1.51:~/
.ssh/
root@10.0.1.51’s password:
id_leop_lap.pub
100% 403 0.4KB/s 00:00
[ngift@Macintosh6][H:11027][J:0]% ssh root@10.0.1.51
root@10.0.1.51’s password:
Last login: Sun Mar 2 06:26:10 2008
[root@localhost]~# cd .ssh
[root@localhost]~/.ssh# ll
total 8
rwrr 1 root root 403 Mar 2 06:32 id_leop_lap.pub
rwrr 1 root root 2044 Feb 14 05:33 known_hosts
[root@localhost]~/.ssh# cat id_leop_lap.pub > authorized_keys
[root@localhost]~/.ssh# exit
```
```
Connection to 10.0.1.51 closed.
[ngift@Macintosh6][H:11028][J:0]% ssh root@10.0.1.51
Last login: Sun Mar 2 06:32:22 2008 from 10.0.1.3
[root@localhost]~#
```
```
Шаг 3: смонтировать общий каталог NFS, содержащий модули, кото
рые потребуется запускать на стороне клиентов. Часто самый простой
способ добиться этого заключается в использовании функции autofs
и в последующем создании символической ссылки. Однако то же са
мое можно реализовать на основе системы управления версиями, с по
мощью которой через ssh обновлять локальные репозитарии SVN
с программным кодом на администрируемых машинах. После таких
```

**284** Глава 8. Окрошка из операционных систем

```
обновлений сценарии будут использовать самые свежие версии моду
лей. Например, в системе на базе дистрибутива Red Hat можно было
бы выполнить, например, такую команду:
lns /net/nas/python/src /src
```
```
Шаг 4: написать сценарий, который будет запускать программный код
на удаленных машинах. Теперь, когда у нас имеются ключи ssh и смон
тированный каталог NFS (или каталог, находящийся под контролем
системы управления версиями), это достаточно простая задача. Как
обычно, начнем с примера наиболее простого сценария, выполняюще
го администрирование удаленных систем через ssh. Если ранее вам ни
когда не приходилось делать ничего подобного, вас наверняка удивит,
насколько просто можно выполнять достаточно сложные действия.
В примере 8.5 реализован запуск простой команды uname.
```
```
Пример 8.5. Простой управляющий сценарий
#!/usr/bin/env python
import subprocess
```
```
"""
Система управления на основе ssh
"""
machines = ["10.0.1.40",
"10.0.1.50",
"10.0.1.51",
"10.0.1.60",
"10.0.1.80"]
```
```
cmd = "uname"
for machine in machines:
subprocess.call("ssh root@%s %s" % (machine, cmd), shell=True)
```
```
Выполнив этот сценарий на пяти машинах с указанными IPадресами,
которые работают под управлением CentOS 5, FreeBSD 7, Ubuntu 7.1
и Solaris 10, мы получили следующие результаты:
```
```
[ngift@Macintosh6][H:11088][J:0]% python dispatch.py
Linux
Linux
Linux
SunOS
FreeBSD
```
```
Однако у нас имеется модуль, более точно определяющий тип опера
ционной системы, поэтому используем его для получения более точно
го описания машин, которым посылаются команды, для чего создадим
временный каталог src на каждой удаленной машине и скопируем ту
да наш программный код. Конечно, после создания управляющего
сценария становится очевидной потребность в устойчивом интерфейсе
командной строки к нему, так как в противном случае нам придется
```

Кросс;платформенное программирование на языке Python в UNIX **285**

```
изменять сам сценарий, чтобы выполнить какуюнибудь другую ко
манду, как показано ниже:
```
```
cmd = "mkdir /src"
```
```
или:
```
```
cmd = "python /src/fingerprint.py"
```
```
или даже:
```
```
subprocess.call("scp fingerprint.py root@%s:/src/" % machine, shell=True)
```
```
Мы сделаем это, как только запустим наш сценарий fingerprint.py, но
сначала посмотрим на новую команду:
#!/usr/bin/env python
import subprocess
"""
Система управления на основе ssh
"""
machines = ["10.0.1.40",
"10.0.1.50",
"10.0.1.51",
"10.0.1.60",
"10.0.1.80"]
cmd = "python /src/fingerprint.py"
for machine in machines:
subprocess.call("ssh root@%s %s" % (machine, cmd), shell=True)
```
```
А теперь посмотрим, что получилось:
[ngift@Macintosh6][H:11107][J:0]# python dispatch.py
redhat
ubuntu
redhat
SunOS
FreeBSD
```
```
Благодаря модулю fingerprint.py результаты выглядят намного луч
ше. Безусловно, несколько строк в нашем управляющем сценарии тре
буют кардинальной перестройки, потому что в противном случае нам
всякий раз будет необходимо редактировать его. Нам требуется более
удобный инструмент, поэтому давайте создадим его.
```
**Создание кроссплатформенного**

**инструмента управления**

```
Решение об использовании ключей ssh в соединении с простой систе
мой управления оказалось недостаточно удобным, потому что его
сложно расширять или повторно использовать. Попробуем определить
перечень проблем, характерных для предыдущего инструмента, а затем
```

**286** Глава 8. Окрошка из операционных систем

```
составим список требований, устраняющих эти проблемы. Проблемы:
список администрируемых машин определяется жестко, в самом сце
нарии; выполняемая команда жестко задана в сценарии; допускается
запуск только одной команды за раз; один и тот же набор команд вы
полняется на всех машинах, мы лишены возможности выбора; наш
управляющий сценарий ожидает, пока не будет получен ответ на каж
дую команду. Требования: нам необходим инструмент командной
строки, который будет получать IPадреса и команды, которые надле
жит выполнить, из конфигурационного файла; нам необходим интер
фейс командной строки с параметрами, чтобы можно было передавать
команды машинам; нам необходим инструмент управления, который
будет запускать команды в отдельных потоках выполнения, чтобы не
блокировать процесс.
Похоже, что нам необходимо выработать элементарный синтаксис
конфигурационного файла с разделом для машин и с разделом для ко
манд. Взгляните на пример 8.6.
```
```
Пример 8.6. Конфигурационный файл для управляющего сценария
[MACHINES]
CENTOS: 10.0.1.40
UBUNTU: 10.0.1.50
REDHAT: 10.0.1.51
SUN: 10.0.1.60
FREEBSD: 10.0.1.80
[COMMANDS]
FINGERPRINT : python /src/fingerprint.py
```
```
Теперь нам необходимо написать функцию, которая будет читать со
держимое конфигурационного файла и выделять разделы MACHINES
и COMMANDS, чтобы можно было выполнять обход этих разделов по
очереди, как показано в примере 8.7.
```
```
Следует заметить, что команды из конфигурационного файла
будут импортироваться в случайном порядке. В большинстве
случаев это может оказаться неприемлемым и, возможно, было
бы лучше просто написать модуль на языке Python, который бу
дет играть роль конфигурационного файла.
```
```
Пример 8.7. Улучшенный сценарий управления
#!/usr/bin/env python
import subprocess
import ConfigParser
```
```
"""
Система управления на основе ssh
"""
def readConfig(file="config.ini"):
"""
Извлекает IPадреса и команды из конфигурационного файла
```

Кросс;платформенное программирование на языке Python в UNIX **287**

```
и возвращает кортеж
"""
ips = []
cmds = []
Config = ConfigParser.ConfigParser()
Config.read(file)
machines = Config.items("MACHINES")
commands = Config.items("COMMANDS")
for ip in machines:
ips.append(ip[1])
for cmd in commands:
cmds.append(cmd[1])
return ips, cmds
ips, cmds = readConfig()
```
```
#Выполнить все команды для каждого IPадреса
for ip in ips:
for cmd in cmds:
subprocess.call("ssh root@%s %s" % (ip, cmd), shell=True)
```
```
Эти несложные изменения повысили удобство использования. Мы мо
жем произвольно изменять список команд и машин и выполнять сразу
все команды. Если теперь взглянуть на вывод сценария, можно убе
диться, что он не изменился:
```
```
[ngift@Macintosh6][H:11285][J:0]# python advanced_dispatch1.py
redhat
redhat
ubuntu
SunOS
FreeBSD
```
```
Хотя это весьма усовершенствованный инструмент, у нас попрежне
му отсутствует механизм выполнения команд в отдельных потоках,
наличие которого определено в нашей спецификации. К счастью, мы
можем воспользоваться некоторыми приемами, описанными в главе,
посвященной процессам, и легко реализовать многопоточный режим
выполнения. В примере 8.8 показано, что для этого можно сделать.
```
```
Пример 8.8. Многопоточный инструмент управления командами
#!/usr/bin/env python
import subprocess
import ConfigParser
from threading import Thread
from Queue import Queue
import time
"""
Многопоточная система управления на основе ssh
"""
start = time.time()
queue = Queue()
```

**288** Глава 8. Окрошка из операционных систем

```
def readConfig(file="config.ini"):
"""
Извлекает IPадреса и команды из конфигурационного файла
и возвращает кортеж
"""
ips = []
cmds = []
Config = ConfigParser.ConfigParser()
Config.read(file)
machines = Config.items("MACHINES")
commands = Config.items("COMMANDS")
for ip in machines:
ips.append(ip[1])
for cmd in commands:
cmds.append(cmd[1])
return ips, cmds
```
```
def launcher(i,q, cmd):
"""Запускает команды в потоке выполнения, отдельном для каждого IP"""
while True:
#Получить ip, cmd из очереди
ip = q.get()
print "Thread %s: Running %s to %s" % (i, cmd, ip)
subprocess.call("ssh root@%s %s" % (ip, cmd), shell=True)
q.task_done()
```
```
#Получить IPадреса и команды из конфигурационного файла
ips, cmds = readConfig()
```
```
#Определить количество используемых потоков, но не более 25
if len(ips) < 25:
num_threads = len(ips)
else:
num_threads = 25
#Запустить потоки
for i in range(num_threads):
for cmd in cmds:
worker = Thread(target=launcher, args=(i, queue,cmd))
worker.setDaemon(True)
worker.start()
print "Main Thread Waiting"
for ip in ips:
queue.put(ip)
queue.join()
end = time.time()
print "Dispatch Completed in %s seconds" % end – start
```
```
Если теперь взглянуть на вывод нового многопоточного механизма
управления, можно заметить, что на выполнение всех команд потребо
валось около 1,2 секунды. Чтобы увидеть различия в скорости выпол
```

Кросс;платформенное программирование на языке Python в UNIX **289**

```
нения, нам следует добавить измерение времени в оригинальный
управляющий сценарий и сравнить полученные результаты:
```
```
[ngift@Macintosh6][H:11296][J:0]# python threaded_dispatch.py
Main Thread Waiting
Thread 1: Running python /src/fingerprint.py to 10.0.1.51
Thread 2: Running python /src/fingerprint.py to 10.0.1.40
Thread 0: Running python /src/fingerprint.py to 10.0.1.50
Thread 4: Running python /src/fingerprint.py to 10.0.1.60
Thread 3: Running python /src/fingerprint.py to 10.0.1.80
redhat
redhat
ubuntu
SunOS
FreeBSD
Dispatch Completed in 1 seconds
```
```
После добавления в оригинальный управляющий сценарий простого
программного кода, выполняющего замер времени, мы получили сле
дующее:
```
```
[ngift@Macintosh6][H:11305][J:0]# python advanced_dispatch1.py
redhat
redhat
ubuntu
SunOS
FreeBSD
Dispatch Completed in 3 seconds
```
```
Исходя из этих результатов, можно сказать, что наша многопоточная
версия оказалась примерно в три раза быстрее. Если бы мы использова
ли этот инструмент для опроса сети, скажем, из 500 машин, а не из 5,
разница в производительности могла бы оказаться еще более сущест
венной. Пока разработка нашего кроссплатформенного инструмента
управления продвигается достаточно успешно, поэтому сделаем сле
дующий шаг и создадим кроссплатформенный инструмент сборки.
```
```
Следует заметить, что для реализации этого сценария, возмож
но, более удачным решением было бы использование многоза
дачной версии IPython. За подробностями обращайтесь по адре
су: http://ipython.scipy.org/moin/Parallel_Computing.
```
**Создание кроссплатформенного инструмента сборки**

```
Мы уже знаем, как распределять работу между несколькими машина
ми, как определять тип операционной системы, под управлением ко
торой выполняется сценарий, и, наконец, создавать универсальную
декларацию с помощью менеджера пакетов EPM, который способен
создавать специализированные пакеты в зависимости от типа опера
ционной системы. Почему бы нам не объединить все это вместе? Мы
```

**290** Глава 8. Окрошка из операционных систем

```
можем использовать эти три приема, чтобы создать кроссплатфор
менный инструмент сборки.
С появлением технологии виртуальных машин стало весьма просто
создавать виртуальные машины для любых свободно распространяе
мых UNIXподобных операционных систем, таких как Debian/Ubuntu,
Red Hat/CentOS, FreeBSD и Solaris. Теперь, создав инструмент, кото
рый вы хотите сделать доступным всему миру или просто коллегам
в вашей компании, вы легко и просто можете создать «сборочный цех»,
возможно даже на своем ноутбуке, где ведется разработка сценария,
и создавать специализированные пакеты сразу же с этим сценарием.
Как это будет работать? Самый простой способ достичь этого – создать
общее дерево сборки пакета на разделе NFS и предоставить доступ
к этой точке монтирования всем серверам сборки. После этого, исполь
зуя инструменты, созданные нами ранее, настроить серверы на сборку
пакетов в каталоге NFS. Менеджер пакетов EPM позволяет создавать
простые декларации, или «списки» файлов, кроме того, у нас имеется
модуль fingerprint, поэтому самое сложное уже позади. Осталось на
писать программный код, который делает только то, что осталось.
Ниже показано, как может выглядеть сценарий сборки:
#!/usr/bin/env python
from fingerprint import fingerprint
from subprocess import call
```
```
os = fingerprint()
#Получить корректный ключ для EPM
epm_keyword = {"ubuntu":"dpkg", "redhat":"rpm", "SunOS":"pkg", "osx":"osx"}
try:
epm_keyword[os]
except Exception, err:
print err
subprocess.call("epmf %s helloEPM hello_epm.list" %
platform_cmd,shell=True)
```
```
Теперь можно отредактировать конфигурационный файл config.ini , пе
реориентировав его на запуск нового сценария.
[MACHINES]
CENTOS: 10.0.1.40
UBUNTU: 10.0.1.50
REDHAT: 10.0.1.51
SUN: 10.0.1.60
FREEBSD: 10.0.1.80
[COMMANDS]
FINGERPRINT = python /src/create_package.py
```
```
Теперь осталось только запустить многопоточную версию инструмента
сборки и – эврика! – нам удалось создать пакеты для CentOS, Ubuntu,
```

PyInotify **291**

```
Red Hat, FreeBSD и Solaris за считанные секунды. Этот сценарий еще
нельзя рассматривать как окончательную рабочую версию программ
ного кода, так как в нем отсутствует обработка ошибок, но он прекрас
но демонстрирует, что позволяет сделать язык Python на скорую руку,
всего за несколько минут или часов.
```
**PyInotify**

```
Если вам выпадет честь работать с платформами GNU/Linux, вы по
достоинству оцените возможности PyInotify. Согласно документации
это: «модуль Python для обнаружения изменений в файловой систе
ме». Официальная страница проекта находится по адресу http://pyino>
tify.sourceforge.net.
В примере 8.9 показано, как работать с этим модулем.
```
```
Пример 8.9. Сценарий слежения за событиями с помощью модуля Pyinotify
import os
import sys
from pyinotify import WatchManager, Notifier, ProcessEvent, EventsCodes
```
```
class PClose(ProcessEvent):
"""
Обработка события закрытия
"""
def __init__(self, path):
self.path = path
self.file = file
def process_IN_CLOSE(self, event):
"""
Обработка событий 'IN_CLOSE_*'
может принимать функциюобработчик
"""
path = self.path
if event.name:
self.file = "%s" % os.path.join(event.path, event.name)
else:
self.file = "%s" % event.path
print "%s Closed" % self.file
print "Performing pretend action on %s...." % self.file
import time
time.sleep(2)
print "%s has been processed" % self.file
```
```
class Controller(object):
def __init__(self, path='/tmp'):
self.path = path
def run(self):
self.pclose = PClose(self.path)
```

**292** Глава 8. Окрошка из операционных систем

```
PC = self.pclose
# следить только за этими событиями
mask = EventsCodes.IN_CLOSE_WRITE | EventsCodes.IN_CLOSE_NOWRITE
# экземпляр менеджера слежения за событиями
wm = WatchManager()
notifier = Notifier(wm, PC)
```
```
print 'monitoring of %s started' % self.path
added_flag = False
# читать и обрабатывать события
while True:
try:
if not added_flag:
# на первой итерации добавить слежение за каталогом:
# обрабатываемые события определяются маской.
wm.add_watch(self.path, mask)
added_flag = True
notifier.process_events()
if notifier.check_events():
notifier.read_events()
except KeyboardInterrupt:
# ...пока не будет нажата комбинация CtrlC
print 'stop monitoring...'
# прекратить слежение за событиями
notifier.stop()
break
except Exception, err:
# продолжить слежение
print err
```
```
def main():
monitor = Controller()
monitor.run()
if __name__ == '__main__':
main()
```
```
Если запустить этот сценарий, он начнет выполнять «требуемые» дей
ствия при помещении чего бы то ни было в каталог /tmp. Этот пример
должен дать вам некоторое представление о том, как фактически сде
лать чтонибудь полезное, например, добавить функцию обратного вы
зова для выполнения требуемых действий. Здесь же можно было ис
пользовать часть программного кода из главы «Данные», например,
для автоматического поиска и удаления дубликатов или для архиви
рования файлов, если их имена соответствуют определяемому вами
критерию в функции fnmatch(). В общем, это интересный и полезный
модуль Python, который работает только в Linux.
```

#### OS X 293

### OS X.

```
OS X является довольно экзотической операционной системой, если не
сказать больше. С одной стороны, она обладает, пожалуй, самым луч
шим пользовательским интерфейсом Cocoa, а с другой, в версии Leo
pard, она является полностью POSIXсовместимой операционной сис
темой UNIX. Системе OS X удалось добиться того, чего не удалось ни
одному производителю операционных систем UNIX: она вывела UNIX
на уровень массового потребления. Версия OS X Leopard включает в се
бя Python 2.5.1, Twisted и многие другие замечательные программные
компоненты на языке Python.
Разработчики системы OS X следуют несколько странной парадигме,
предлагая операционную систему и в серверном, и в обычном исполне
нии. Хотя, безусловно, компания Apple имеет на это полное право,
возможно, ей стоит отказаться от такой архаичной идеи; мы же здесь
не будем обсуждать плюсы и минусы концепции единой ОС по единой
цене. Серверная версия операционной системы предлагает более пол
ный комплект инструментов командной строки для администрирова
ния, а также ряд компонентов, характерных для Apple, таких как воз
можность загрузки по сети, возможность работы с серверами катало
гов LDAP, и многие другие особенности.
```
**Взаимодействие с DSCL, утилитой службы каталогов**

```
Название DSCL происходит от Directory Services Command Line (ко
мандная строка службы каталогов) и представляет собой удобный спо
соб доступа к прикладному интерфейсу службы каталогов в OS X.
DSCL позволяет читать, создавать и удалять записи, что язык Python
позволяет делать естественным образом. В примере 8.10 демонстриру
ется взаимодействие с DSCL в оболочке IPython для чтения атрибутов
службы Open Directory и их значений.
```
```
Обратите внимание, что в этом примере мы только читаем зна
чения атрибутов, но точно так же, используя тот же прием,
можно было бы организовать и их изменение.
```
```
Пример 8.10. Получение записи пользователя в интерактивной оболочке
IPython с помощью DSCL
In [40]: import subprocess
```
```
In [41]: p = subprocess.Popen("dscl. read /Users/ngift",
shell=True,stdout=subprocess.PIPE)
```
```
In [42]: out = p.stdout.readlines()
In [43]: for line in out:
line.strip().split()
Out[46]: ['NFSHomeDirectory:', '/Users/ngift']
```

**294** Глава 8. Окрошка из операционных систем

```
Out[46]: ['Password:', '********']
Out[46]: ['Picture:']
Out[46]: ['/Library/User', 'Pictures/Flowers/Sunflower.tif']
Out[46]: ['PrimaryGroupID:', '20']
Out[46]: ['RealName:', 'ngift']
Out[46]: ['RecordName:', 'ngift']
Out[46]: ['RecordType:', 'dsRecTypeStandard:Users']
Out[46]: ['UniqueID:', '501']
Out[46]: ['UserShell:', '/bin/zsh']
```
```
Это замечательно, что в Apple организовали централизованное управле
ние локальными учетными записями и учетными записями LDAP/Ac
tive Directory с помощью команды dscl. Утилита dscl – это как глоток
свежего воздуха по сравнению с другими средствами управления LDAP,
даже если вынести использование Python за скобки. У нас недостаточно
места, чтобы углубляться в подробности. Тем не менее, заметим, что
с помощью языка Python и утилиты dscl можно очень легко организо
вать программное управление учетными записями как в локальной ба
зе данных, так и в базе данных LDAP, такой как Open Directory, а пре
дыдущий пример должен показать вам, с чего следует начинать.
```
**Взаимодействие с прикладным интерфейсом OS X**

```
Часто администратору OS X бывает необходимо знать, как организо
вать взаимодействие с фактическим интерфейсом пользователя. В OS X
Leopard для языков Python и Ruby предоставляется доступ к механиз
му Scripting Bridge. За дополнительной информацией по этому меха
низму обращайтесь по адресу http://developer.apple.com/documentation/
Cocoa/Conceptual/RubyPythonCocoa/Introduction/Introduction.html.
Как вариант, для доступа к OSA, или Open Scripting Architecture (от
крытая архитектура сценариев), можно использовать модуль py–app
script со страницей проекта по адресу http://sourceforge.net/projects/
appscript.
Работать с модулем py–appscript – одно удовольствие, так как он дает
возможность из языка Python взаимодействовать с очень богатой воз
можностями архитектурой OSA. Но прежде чем познакомится с ним
поближе, мы сначала воспользуемся простым инструментом команд
ной строки osascript, на примере которого продемонстрируем, как
можно организовать взаимодействие с прикладным интерфейсом сце
нариев. В OS X Leopard теперь имеется возможность писать инстру
менты командной строки, работающие под управлением osascript,
и выполнять их как обычные сценарии Bash или Python. Давайте на
пишем сценарий с именем bofh.osa, как показано ниже, и затем запус
тим его. Текст сценария приводится в примере 8.11.
```
```
Пример 8.11. Сценарий «Hello, Bastard Operator From Hell»
#!/usr/bin/osascript
say "Hello, Bastard Operator From Hell" using "Zarvox"
```

#### OS X 295

```
Если запустить этот сценарий из командной строки, механический го
лос поприветствует нас. Это немножко глупо, но это же Mac OS X; она
вполне допускает такие вещи.
А теперь погрузимся в использование модуля appscript для доступа
к тому же самому API из сценариев на языке Python, но сделаем это
в интерактивном режиме, в оболочке IPython. Ниже представлена инте
рактивная версия примера, включенного в исходные тексты appscript,
который выводит список всех запущенных процессов в алфавитном
порядке:
In [4]: from appscript import app
```
```
In [5]: sysevents = app('System Events')
In [6]: processnames = sysevents.application_processes.name.get()
```
```
In [7]: processnames.sort(lambda x, y: cmp(x.lower(), y.lower()))
In [8]: print '\n'.join(processnames)
Activity Monitor
AirPort Base Station Agent
AppleSpell
Camino
DashboardClient
DashboardClient
Dock
Finder
Folder Actions Dispatcher
GrowlHelperApp
GrowlMenu
iCal
iTunesHelper
JavaApplicationStub
loginwindow
mdworker
PandoraBoy
Python
quicklookd
Safari
Spotlight
System Events
SystemUIServer
Terminal
TextEdit
TextMate
```
```
Если вам придется решать задачи автоматизации с применением при
ложений OS X, модуль appscript окажется для вас удачной находкой,
так как с его помощью в языке Python можно реализовать такие дейст
вия, которые ранее были возможны только в языке Applescript. Ноа
Гифт (Noah Gift) написал статью, в которой немного рассказывается
```

**296** Глава 8. Окрошка из операционных систем

```
об этом: http://www.macdevcenter.com/pub/a/mac/2007/05/08/using>
python>and>applescript>to>get>the>most>out>of>your>mac.html.
Коечто системный администратор может выполнять с помощью Final
Cut Pro, создавая пакеты операций, взаимодействующих, например,
с Adobe After Effects. Кроме того, в OS X с помощью Applescript Studio
можно быстро создать графический интерфейс и вызывать из него сце
нарий на языке Python командой do shell script. Мало кому известно,
что оригинальная версия Carbon Copy Cloner была написана в App
lescript Studio. Если у вас есть свободное время, вам стоит познако
миться с этой средой поближе.
```
**Автоматическое восстановление системы**

```
ASR – это еще один революционный, опередивший время инструмент
командной строки, разработанный для OS X. Этот инструмент являет
ся ключевым компонентом очень популярной утилиты с именем Car
bon Copy Cloner и служит для автоматизации многих ситуаций. Ноа
(Noah) использовал утилиту asr в паре с Netboot для автоматического
восстановления – фактически он ввел полную автоматизацию этого
процесса в одном из мест, где он работал. Пользователю достаточно
было просто перезагрузить свою машину и удерживать клавишу «N»,
чтобы перейти в режим загрузки по сети, и в результате либо наступал
«конец игры», либо машина сама исправляла повреждения.
Пожалуйста, не рассказывайте об этом никому, потому что многие до
сих пор думают, что он все еще работает там. Ниже, в примере 8.12
приводится упрощенная версия сценария для автоматического восста
новления системы, который может быть запущен при загрузке по сети
или со второго раздела жесткого диска. С точки зрения настроек, ката
лог /Users , как и любой другой жизненно важный каталог, должен
быть символической ссылкой, ведущей в другой раздел, или должен
находиться в сети, что еще лучше. Смотрите пример 8.12.
```
```
Пример 8.12. Сценарий автоматического восстановления раздела жесткого
диска в OS X, демонстрирующий ход выполнения с помощью
виджета из библиотеки WXPython
#!/usr/bin/env pythonw
#автоматически восстанавливает раздел жесткого диска
```
```
import subprocess
import os
import sys
import time
from wx import PySimpleApp, ProgressDialog, PD_APP_MODAL, PD_ELAPSED_TIME
#команда пересоздания главного раздела с помощью утилиты asr
asr = '/usr/sbin/asrsource '
#переменные, содержащие различные пути
os_path = '/Volumes/main’
```

#### OS X 297

```
ipath = '/net/server/image.dmg '
dpath = 'target /Volumes/mainerase nopromptoverify &'
reimage_cmd = "%s%s%s" % (asr,ipath, dpath)
#Команды перезагрузки
reboot = 'reboot'
bless = '/usr/sbin/blessfolder /Volumes/main/System/Library/CoreServices
setOF'
#часть использования wxpython
application = PySimpleApp()
dialog = ProgressDialog ('Progress', 'Attempting Rebuild of Main Partition',
maximum = 100, style = PD_APP_MODAL | PD_ELAPSED_TIME)
def boot2main():
"""Делает новый раздел загружаемым и выполняет перезагрузку"""
subprocess.call(bless, shell=True)
subprocess.call(reboot, shell=True)
def rebuild():
"""Пересоздает раздел"""
try:
time.sleep(5) #Дать диалогу время на запуск
subprocess.call(reimage_cmd)
except OSError:
print "CMD: %s [ERROR: invalid path]" % reimage_cmd
sys.exit(1)
time.sleep(30)
while True:
if os.path.exists(os_path):
x = 0
wxSleep(1)
dialog.Update (x + 1,
"Rebuild is complete...\n rebooting to main partition\n
...in 5 seconds..")
wxSleep(5)
print "repaired volume.." + os_path
boot2main() #вызывает функции reboot/bless
break
else:
x = 0
wxSleep(1)
dialog.Update ( x + 1, 'Reimaging.... ')
def main():
if os.path.exists(os_path):
rebuild()
else:
print "Could not find valid path...FAILED.."
sys.exit(1)
if __name__ == "__main__":
main()
```

**298** Глава 8. Окрошка из операционных систем

```
Этот сценарий пытается пересоздать раздел и выводит средствами биб
лиотеки WXPython индикатор хода выполнения. Если путь указан
корректно и не обнаружено ошибок, выполняется пересоздание разде
ла жесткого диска с помощью команды asr, в процессе выполнения ко
торой выводится индикатор, показывающий ход выполнения опера
ции, затем новый раздел назначается загружаемым с помощью коман
ды bless, после чего выполняется перезагрузка машины.
Этот сценарий легко можно превратить в основу системы управления
и распространения дистрибутива системы уровня предприятия, по
скольку достаточно легко организовать установку различных образов,
основываясь на данных об аппаратной комплектации или даже считы
вая «старую» метку жесткого диска. После этого можно, например,
организовать программную установку пакетов программного обеспе
чения с помощью системы управления пакетами в OS X или с помо
щью свободно распространяемого инструмента radmind. Ноа (Noah)
реализовал один интересный сценарий, в котором сначала в автомати
ческом режиме развертывал базовую систему OS X, а затем завершал
установку остальных пакетов с помощью radmind.
Если вы всерьез собираетесь заниматься администрированием систем
OS X, то вам определенно стоило бы поближе познакомиться с radmind.
Radmind – это своего рода система автоматического обновления, кото
рая обнаруживает изменения в файловой системе и обеспечивает воз
можность восстановления машин на основе этих изменений. Дополни
тельную информацию о radmind вы найдете на странице http://
rsug.itd.umich.edu/software/radmind/. Несмотря на то, что программа
radmind написана не на языке Python, ее легко можно было бы пере
писать на этом языке.
```
### Управление DNS с помощью сценариев на языке Python

```
В главе 3 мы выполняли анализ потока информации в формате XML,
генерируемого утилитой system_profiler, используя для этого библио
теку ElementTree. Но в OS X в Python встроена поддержка библиотеки
plistlib, которая позволяет анализировать и создавать файлы Plist.
Сам модуль тоже называется plistlib. У нас нет возможности проде
монстрировать этот модуль на примерах, но вам стоит познакомиться
с ним поближе самостоятельно.
```
### Администрирование систем Red Hat Linux

```
В Red Hat язык Python используется очень широко – и в компании,
и в операционной системе. Некоторые из наиболее интересных новых
способов использования Python родились в группе Emerging Technolo
gies: http://et.redhat.com/page/Main_Page. Ниже приводится список
некоторых проектов, использующих язык Python:
```
**-** Libvert – API виртуализации менеджера виртуальных машин


Администрирование Ubuntu **299**

**-** VirtInst – приложение управления виртуальными машинами на ба
    зе библиотеки libvirt^1 , написанное на языке Python + PyGTK
**-** Библиотека Python, упрощающая инициализацию гостевых вирту
    альных машин на основе libvirt
**-** Cobbler – продукт, позволяющий создавать полностью автоматизи
    рованные серверы загрузки для нужд PXE и виртуализации
**-** VirtFactory: сетевая среда управления виртуальными приложе
    ниями
**-** FUNC (Fedora Unified Network Controller)

### Администрирование Ubuntu.

```
Можно сказать, что из всех основных дистрибутивов Linux Ubuntu яв
ляется одним из самых влюбленных в Python. Отчасти потому, что
Марк Шаттлворт (Mark Shuttleworth), создатель дистрибутива, долгое
время – с начала 90 годов – работал с языком Python. Одним из заме
чательных источников пакетов на языке Python для Ubuntu является
Launchpad: http://launchpad.net.
```
### Администрирование систем Solaris.

```
С конца 90х до начала 2000х годов операционная система Solaris за
нимала практически непоколебимое место в мире UNIX. В начале
2000х годов Linux подобно метеориту врезался в Solaris, в связи с чем
компании Sun пришлось испытать вполне реальные неприятности. Од
нако с недавнего времени все больше системных администраторов, раз
работчиков и предпринимателей снова начинают говорить о Solaris.
Из наиболее интересных нововведений, которые предполагает внести
Sun, можно назвать 6месячный цикл выпуска новых версий системы,
так же, как и в Ubuntu, с 18месячным периодом технической под
держки; отказ от создания объемного дистрибутива на DVDдиске
в пользу единственного CD, как в Ubuntu. Наконец, были заимствова
ны некоторые идеи из Red Hat и Fedora по созданию версии Solaris,
разрабатываемой сообществом. Загрузить или заказать загрузочный
CD можно по адресу: http://www.opensolaris.com.
Что все это означает для системного администратора, использующего
язык Python? Интерес к Sun быстро растет, и у нее имеется большое
количество весьма интересных технологий, начиная от ZFS и заканчи
вая контейнерами и LDOM, которые в некотором смысле можно срав
нить с виртуальными машинами VMware. Имеется даже связь с этой
книгой. Интерпретатор Python прекрасно работает в операционной
```
(^1) libvert и libvirt – это разные библиотеки! – _Прим. перев._


**300** Глава 8. Окрошка из операционных систем

```
системе Solaris и даже широко используется в разработке системы
управления пакетами для нее.
```
**Виртуализация**

```
14 августа 2007 года состоялось первое открытое размещение акций
компании VMware, которое принесло ей миллионы долларов и укре
пило позиции виртуализации как крупного направления в развитии
информационных технологий. Предсказание будущего всегда было
рискованным делом, однако все чаще в крупных компаниях слышны
слова «операционная система центра обработки данных», и все, от Mi
crosoft до Red Hat и Oracle, стремятся не опоздать сесть в поезд виртуа
лизации. Можно смело сказать, что со временем виртуализация пол
ностью изменит центры обработки данных и работу системных адми
нистраторов. Виртуализация – это элементарный пример действия
слишком частого использования фразы «прорывная технология».
Виртуализация – это обоюдоострое оружие для системных админист
раторов, так как, с одной стороны, позволяет легко тестировать систе
мы и приложения, но, с другой стороны, чрезвычайно увеличивает
сложность администрирования. Теперь на одной машине одновремен
но может работать сразу несколько операционных систем, здесь могут
находиться приложения для малого бизнеса или крупная часть вычис
лительного центра. За эффективность приходится платить, а обеспече
ние эффективности – прямая обязанность среднего системного адми
нистратора.
Возможно, прямо сейчас, читая эти строки, вы могли бы подумать: ка
кое отношение все это имеет к языку Python? Самое непосредственное.
В компании Racemi, где недавно работал Ноа (Noah), на языке Python
было написано полноценное приложение управления центром обра
ботки данных, которое имеет дело с виртуализацией. Python может
и действительно очень тесно взаимодействует с механизмами виртуа
лизации, начиная от управления виртуальными машинами и заканчи
вая перемещением систем с физических машин на виртуальные, ис
пользуя для этого Python API. В этом виртуализованном мире Python
чувствует себя как дома и можно смело утверждать, что он будет иг
рать далеко не последнюю роль в будущей операционной системе цен
тра обработки данных.
```
**VMware**

```
Как уже говорилось выше, компания VMware является лидером по
разработке технологий виртуализации. Наличие полного программно
го контроля над виртуальной машиной – это своего рода Чаша Грааля.
К счастью, существует несколько API на выбор: Perl, XMLRPC, Py
thon и C. К моменту написания этих строк некоторые реализации Py
thon имели определенные ограничения, но такое положение дел могло
```

Облачная обработка данных **301**

```
измениться. Похоже, что в VMware выбрали новое направление –
XMLRPC API.
Компания VMware выпускает несколько различных продуктов с раз
личными API. Из продуктов, с которыми вам может потребоваться
взаимодействовать, можно назвать VMware Site Recovery Manager,
VMware ESX Server, VMware Server и VMware Fusion.
У нас недостаточно места, чтобы охватить принципы взаимодействия
с этими технологиями, поскольку эта тема выходит далеко за рамки
данной книги, но они стоят того, чтобы следить за их развитием и за
тем, какую роль будет играть Python.
```
**Облачная обработка данных**

```
Толькотолько утихла шумиха вокруг виртуализации, как вдруг воз
ник шум об «облачной» обработке данных (cloud computing). Термин
«облачная обработка данных» обозначает технологию выделения вы
числительных ресурсов по требованию, в зависимости от величины ра
бочей нагрузки. В сфере развития технологии «облачной» обработки
данных присутствуют два крупных игрока – Amazon и Google. Бук
вально за несколько недель до передачи этой книги издателю компа
ния Google взорвала настоящую бомбу. Компания предложила инте
реснейшую «фишку», которая пока поддерживается только языком
Python. Поскольку эта книга посвящена языку Python, мы думаем,
что такое ограничение не слишком огорчит вас. В некотором смысле
такое предпочтение, отданное языку Python, напоминает нам рекламу
American Express.
В этом разделе мы пройдемся по некоторым имеющимся API, с кото
рыми вам придется столкнуться при работе с Amazon и с Google App
Engine. В заключение мы поговорим о том, как это может касаться
системных администраторов.
```
```
Вебслужбы Amazon на основе Boto
Отличную возможность для работы с инфраструктурой «облачной» об
работки данных Amazon предоставляет интерфейс Boto. Посредством
Boto обеспечивается доступ к таким службам, как Simple Storage Ser
vice, Simple Queue Service, Elastic Compute Cloud, Mechanical Turk,
SimpleDB. Это совершенно новый и очень мощный API, поэтому мы
рекомендуем заглянуть на домашнюю страницу проекта http://code.
google.com/p/boto/. Здесь вы сможете почерпнуть самую свежую ин
формацию, что лучше, чем приведение нами сведений, доступных на
данный момент.
Ниже приводится короткий пример взаимодействия со службой Sim
pleDB.
Соединение со службой:
```

**302** Глава 8. Окрошка из операционных систем

```
In [1]: import boto
In [2]: sdb = boto.connect_sdb()
```
```
Создание нового домена:
In [3]: domain = sdb.create_domain('my_domain')
```
```
Добавление нового элемента:
In [4]: item = domain.new_item('item')
```
```
Примерно так выглядит API в настоящее время, но, чтобы получить
полное представление, вам необходимо взглянуть на примеры в репо
зитарии svn: http://code.google.com/p/boto/source/browse. Заметим,
что изучение примеров – это один из лучших способов понять, как ра
ботает новая библиотека.
```
```
Google App Engine
Служба Google App Engine выпущена в состоянии бетаверсии и со дня
объявления была широко разрекламирована. Она позволяет свободно
запускать приложения в инфраструктуре Google. Приложения App
Engine имеют API пока только для Python, но со временем такое поло
жение дел может измениться. Одна из интереснейших особенностей
App Engine заключается в том, что она интегрирована с другими служ
бами Google.
Все более возможным становится перемещение большей части из того,
что находилось у вас в центре обработки данных, в другие центры, по
этому это все более затрагивает системных администраторов. Умение
взаимодействовать со службой Google App Engine может оказаться ка
```
```
ПОРТ РЕТ ЗНА МЕ НИ ТО СТИ: КО МАН ДА РАЗ РА БОТ ЧИ КОВ GOOGLE APP ENGINE
```
**Кевин Гиббс (Kevin Gibbs)**

```
Кевин Гиббс – технический лидер проекта Goo
gle App Engine. Кевин присоединился к Google
в 2004 году. До работы над Google App Engine
в течение ряда лет работал в группе разработки
инфраструктуры систем, где занимался система
ми управления кластерами, которые составляют
основу продуктов и служб компании Google. Кро
ме того, Кевин является автором Google Suggest, программного
продукта, обеспечивающего вывод интерактивных подсказок
в процессе ввода с клавиатуры. До присоединения к Google Ке
вин работал в группе передовых интернеттехнологий компании
IBM, где занимался созданием инструментов разработчика.
```

Облачная обработка данных **303**

```
чественно новым навыком для системного администратора, поэтому
есть смысл заняться ее исследованием.
Мы побеседовали с некоторыми специалистами из команды разработ
чиков App Engine и спросили их о том, что в первую очередь может
пригодиться системным администраторам. Они выделили следующие
задачи:
```
1. Выгрузка больших объемов данных: _[http://code.google.com/ap>](http://code.google.com/ap>)_
    _pengine/articles/bulkload.html_.
    Системным администраторам часто приходится перемещать огром
    ные объемы данных, и этот инструмент позволит решать эти про
    блемы в контексте приложений из Google App Engine.
2. Регистрация событий: _[http://code.google.com/appengine/articles/log>](http://code.google.com/appengine/articles/log>)_
    _ging.html_.
3. Интерфейс к электронной почте: функция send_mail_to_admin():
    _[http://code.google.com/appengine/docs/mail/functions.html](http://code.google.com/appengine/docs/mail/functions.html)_.
    C точки зрения системного администратора владение этим интер
    фейсом может оказаться полезным для организации мониторинга.
    В случае появления важных исключений или выполнения опера
    ций вы могли бы автоматически отправлять администраторам при
    ложений сообщения по электронной почте.
4. Выполнение периодических задач с помощью планировщика зада
    ний cron.
    Это не является непосредственной частью Google App Engine, но вы
    могли бы использовать планировщик заданий cron на своих серве
    рах для передачи запросов своим приложениям через определен
    ные интервалы времени. Например, можно было бы оформить зада
    ние для планировщика, согласно которому каждый час будет посы
    латься запрос по адресу _[http://yourapp.com/emailsummary](http://yourapp.com/emailsummary)_ , в ре
    зультате которого системному администратору будет высылаться
    сообщение электронной почты с описанием важных событий, про
    изошедших в течение последнего часа.
5. Управление версиями: _[http://code.google.com/appengine/docs/confi>](http://code.google.com/appengine/docs/confi>)_
    _guringa napp.html#Required_Elements_.
    Одно из обязательных полей, заполняемых для вашего приложе
    ния, – идентификатор версии. Каждый раз, когда выгружается
    приложение с тем же идентификатором версии, оно замещается но
    вым программным кодом. Изменяя идентификатор версии, вы по
    лучаете возможность иметь несколько версий приложения и с по
    мощью консоли администратора выбирать, какая из версий долж
    на быть включена в работу.

```
Создание примера приложения для Google App Engine
Прежде чем приступить к созданию приложения для Google App En
gine, вам потребуется загрузить пакет SDK для Google App Engine:
```

**304** Глава 8. Окрошка из операционных систем

```
http://code.google.com/appengine/downloads.html. Вы также можете
ознакомиться с замечательным учебным руководством по Google App
Engine: http://code.google.com/appengine/docs/gettingstarted/.
В этом разделе мы предлагаем обратное учебное руководство для Goo
gle App Engine, так как замечательное учебное руководство уже суще
ствует. Если вы перейдете по адресу http://greedycoin.appspot.com/ , то
сможете опробовать работающую версию приложения, которое описы
вается ниже, а также познакомиться с последней версией исходных
текстов. Приложение принимает сумму, введенную пользователем, со
храняет ее в базе данных и затем возвращает сумму в виде списка мо
нет определенного достоинства. Приложением также поддерживается
возможность регистрации посредством API аутентификации и возмож
ность получения информации о последних запросах. Исходный текст
приложения приводится в примере 8.13.
```
```
Пример 8.13. Веб>приложение Greedy Coin
#!/usr/bin/env python2.5
#Noah Gift
import decimal
import wsgiref.handlers
import os
```
```
from google.appengine.api import users
from google.appengine.ext import webapp
from google.appengine.ext import db
from google.appengine.ext.webapp import template
```
```
class ChangeModel(db.Model):
user = db.UserProperty()
input = db.IntegerProperty()
date = db.DateTimeProperty(auto_now_add=True)
```
```
class MainPage(webapp.RequestHandler):
"""Главная страница"""
```
```
def get(self):
user = users.get_current_user()
```
```
if users.get_current_user():
url = users.create_logout_url(self.request.uri)
url_linktext = 'Logout'
else:
url = users.create_login_url(self.request.uri)
url_linktext = 'Login'
```
```
template_values = {
'url': url,
'url_linktext': url_linktext,
}
path = os.path.join(os.path.dirname(__file__), 'index.html')
self.response.out.write(template.render(path, template_values))
```

Облачная обработка данных **305**

```
class Recent(webapp.RequestHandler):
"""Получение информации о 10 последних запросах"""
```
```
def get(self):
#коллекция
collection = []
#получить 10 последних записей из хранилища данных
query = ChangeModel.all().order('date')
records = query.fetch(limit=10)
```
```
#отформатировать дробные значения
for change in records:
collection.append(decimal.Decimal(change.input)/100)
template_values = {
'inputs': collection,
'records': records,
}
path = os.path.join(os.path.dirname(__file__), 'query.html')
self.response.out.write(template.render(path,template_values))
class Result(webapp.RequestHandler):
"""Возвращает страницу с результатами"""
def __init__(self):
self.coins = [1,5,10,25]
self.coin_lookup = {25: "quarters", 10: "dimes", 5: "nickels",
1: "pennies"}
def get(self):
#Просто получить последнее число
collection = {}
```
```
#выбрать последний ввод из хранилища данных
change = db.GqlQuery(
"SELECT * FROM ChangeModel ORDER BY date DESC LIMIT 1")
for c in change:
change_input = c.input
#логика размена суммы монетами
coin = self.coins.pop()
num, rem = divmod(change_input, coin)
if num:
collection[self.coin_lookup[coin]] = num
while rem > 0:
coin = self.coins.pop()
num, rem = divmod(rem, coin)
if num:
collection[self.coin_lookup[coin]] = num
template_values = {
'collection': collection,
'input': decimal.Decimal(change_input)/100,
}
```

**306** Глава 8. Окрошка из операционных систем

```
#шаблон отображения
path = os.path.join(os.path.dirname(__file__), 'result.html')
self.response.out.write(template.render(path, template_values))
class Change(webapp.RequestHandler):
```
```
def post(self):
"""метод вывода результатов"""
model = ChangeModel()
try:
change_input = decimal.Decimal(self.request.get('content'))
model.input = int(change_input*100)
model.put()
self.redirect('/result')
except decimal.InvalidOperation:
path = os.path.join(os.path.dirname(__file__),
'submit_error.html')
self.response.out.write(template.render(path,None))
```
```
def main():
application = webapp.WSGIApplication([('/', MainPage),
('/submit_form', Change),
('/result', Result),
('/recent', Recent)],
debug=True)
wsgiref.handlers.CGIHandler().run(application)
if __name__ == "__main__":
main()
```
```
Так как это обратное учебное руководство, начнем с рассмотрения вер
сии приложения, работающей по адресу http://greedycoin.appspot.com/ ,
или с вашей версии по адресу http://localhost:8080/. На главной стра
нице приложения на фоне цвета тыквы находятся две прямоугольные
области: область слева представляет собой форму, где вы можете вве
сти денежную сумму, а область справа содержит элементы навигации.
Эти приятные (или уродливые) цвета и схема размещения являются
комбинацией задействованного механизма шаблонов Django и CSS.
Шаблоны Django можно найти в главном каталоге, а используемые
CSS – в таблицах стилей. Механизм оформления не имеет никакого от
ношения к Google App Engine, поэтому за дополнительной информа
цией о механизме шаблонов Django мы просто отсылаем вас к руково
дству: http://www.djangoproject.com/documentation/templates/.
Теперь, когда мы познакомились с внешним видом приложения, да
вайте перейдем к изучению некоторых особенностей Google App En
gine. Обратите внимание на ссылку «Login» в правой области: она
обеспечивает возможность использовать прикладной интерфейс меха
низма аутентификации. Ниже показано, как это реализовано в про
граммном коде:
```

Облачная обработка данных **307**

```
class MainPage(webapp.RequestHandler):
"""Главная страница"""
```
```
def get(self):
user = users.get_current_user()
```
```
if users.get_current_user():
url = users.create_logout_url(self.request.uri)
url_linktext = 'Logout'
else:
url = users.create_login_url(self.request.uri)
url_linktext = 'Login'
```
```
template_values = {
'url': url,
'url_linktext': url_linktext,
}
path = os.path.join(os.path.dirname(__file__), 'index.html')
self.response.out.write(template.render(path, template_values))
```
```
Здесь представлен класс, наследующий свойства и методы класса
webapp.RequestHandler, и если вы определите метод get(), вы сможете
проверять, зарегистрировался ли пользователь. Если вы посмотрите на
несколько последних строк, то увидите, что информация о пользовате
ле помещается в шаблон, который затем используется механизмом
шаблонов Django для отображения страницы index.html. Это просто за
мечательно, что таким тривиальным способом можно задействовать
мощную базу учетных записей Google для обеспечения возможности
авторизации на страницах. В предыдущем фрагменте это взаимодейст
вие достигается всего двумя строчками:
```
```
user = users.get_current_user()
if users.get_current_user():
```
```
Здесь мы могли бы предложить вам поэкспериментировать с этим
фрагментом и попытаться изменить его так, чтобы приложение было
доступно только для зарегистрировавшихся пользователей. Для этого
вам даже не требуется понимать, как работает весь механизм, – доста
точно будет использовать уже имеющиеся условные инструкции.
Теперь, когда мы получили некоторое представление об аутентифика
ции, перейдем к вещам более сложным. Прикладной интерфейс к хра
нилищу данных позволяет сохранять данные и затем извлекать их в лю
бой части приложения. Для этого необходимо импортировать модуль
db, как показано в предыдущем примере, и определить модель:
```
```
class ChangeModel(db.Model):
user = db.UserProperty()
input = db.IntegerProperty()
date = db.DateTimeProperty(auto_now_add=True)
```

**308** Глава 8. Окрошка из операционных систем

```
С помощью этого простого класса мы можем создавать и использовать
хранимые данные. Ниже приводится класс, в котором используется
Python API для получения данных из хранилища и отображения 10 по
следних результатов:
```
```
class Recent(webapp.RequestHandler):
"""Получение информации о 10 последних запросах"""
```
```
def get(self):
#коллекция
collection = []
#получить 10 последних записей из хранилища данных
query = ChangeModel.all().order('date')
records = query.fetch(limit=10)
```
```
#отформатировать дробные значения
for change in records:
collection.append(decimal.Decimal(change.input)/100)
template_values = {
'inputs': collection,
'records': records,
}
path = os.path.join(os.path.dirname(__file__), 'query.html')
self.response.out.write(template.render(path,template_values))
```
```
Самые важные строки здесь:
```
```
query = ChangeModel.all().order('date')
records = query.fetch(limit=10)
```
```
Они выбирают результаты из хранилища данных и затем «извлекают»
(fetch) 10 последних записей в запросе. Здесь можно остановиться
и поэкспериментировать с этим фрагментов, попытавшись получить
большее число записей или отсортировать их в другом порядке. Это
должно дать вам прочувствовать взаимодействие с приложением.
Наконец, если внимательно посмотреть на фрагмент ниже, можно об
наружить, что каждому URL в списке соответствует свой класс, кото
рый определен в нашем файле change.py. Здесь мы могли бы пореко
мендовать вам поэкспериментировать с URL, изменяя соответствия
между ними и частями приложения – это должно дать представление
о том, как они задействуются.
def main():
application = webapp.WSGIApplication([('/', MainPage),
('/submit_form', Change),
('/result', Result),
('/recent', Recent)],
debug=True)
wsgiref.handlers.CGIHandler().run(application)
```

Использование Zenoss для управления серверами Windows из Linux **309**

```
На этом мы заканчиваем наше обратное учебное руководство по Google
App Engine, которое должно было дать вам некоторое представление
о том, как можно было бы реализовать собственный инструмент для
нужд системного администрирования. Если вам интересно будет озна
комиться с примерами других приложений, можете также познако
миться с исходными текстами приложения Google App Engine, напи
санного самим Гвидо ван Россумом (Guido van Rossum): http://code.
google.com/p/rietveld/source/browse.
```
**Использование Zenoss для управления**

**серверами Windows из Linux**

```
Если вы имеете несчастье заниматься администрированием одного
или нескольких серверов, работающих под управлением Windows, ва
ша работа может стать немного менее неприятной. В этом нам может
помочь такой удивительный инструмент, как Zenoss. Мы говорили
о Zenoss в главе 7 «SNMP». Помимо того, что он является инструмен
том SNMP, он к тому же обеспечивает возможность взаимодействовать
с серверами Windows через WMI (Windows Management Interface – ин
терфейс управления Windows) из Linux! Мы можем только посмеи
ваться и размышлять о практических применениях, полагаясь на эти
технологии. Из разговоров со специалистами проекта Zenoss мы выяс
нили, что они предлагают передавать сообщения WMI серверу Samba
(или CIFS) на машине, работающей под управлением Linux, и посы
лать их серверу Windows. И, пожалуй, самое интересное (по крайней
мере, для читателей этой книги) заключается в том, что имеется воз
можность организовать взаимодействие с соединением WMI из сцена
риев на языке Python.
```
```
Обсуждение синтаксиса и особенностей WMI выходит далеко за
рамки этой книги.
```
```
Существующая документация к Zenoss прекрасно освещает принципы
взаимодействия с WMI из Linux с помощью языка Python. Тем не ме
нее, примеры, которые мы собираемся представить вашему внима
нию, должны послужить хорошей основой для вашего дальнейшего
усовершенствования. Для начала рассмотрим применение инструмен
та wmic (не имеющего отношения к языку Python) для обеспечения
взаимодействия с сервером Windows через WMI из операционной сис
темы Linux. wmic – это простая утилита командной строки, которая
принимает в качестве аргументов командной строки имя пользовате
ля, пароль, адрес сервера и запрос WMI. Она выполняет подключение
к указанному серверу с заданными параметрами аутентификации, пе
редает запрос и отображает результаты на устройстве стандартного
```

**310** Глава 8. Окрошка из операционных систем

```
вывода. Синтаксис использования этой утилиты выглядит следую
щим образом:
```
```
wmicU username%password //SERVER_IP_ADDRESS_OR_HOSTNAME "some WMI query"
```
```
В следующем примере выполняется соединение с сервером, имеющим
IPадрес 192.168.1.3, с именем пользователя Administrator, и произво
дится запрос на получение записей из журнала событий:
```
```
wmicU Administrator%password //192.168.1.3 "SELECT * FROM Win32_NTLogEvent"
```
```
А ниже приводится часть результатов, полученных в ходе выполнения
этой команды:
CLASS: Win32_NTLogEvent
Category|CategoryString|ComputerName|Data|EventCode|EventIdentifier|
EventType|InsertionStrings|Logfile|Message|RecordNumber|SourceName|
TimeGenerated|TimeWritten|Type|User
...
|3|DCOM|20080320034341.000000+000|20080320034341.000000+000|Information|(null)
0|(null)|MACHINENAME|NULL|6005|2147489653|3|(,,,,14,0,0 )|System|The Event log
service was started.
|2|EventLog|20080320034341.000000+000|20080320034341.000000+000|Information|
(null)0|(null)|MACHINENAME|NULL|6009|2147489657|3|(5.02.,3790,Service Pack
2,Uniprocessor Free)|System|Microsoft (R) Windows (R) 5.02. 3790 Service Pack 2
Uniprocessor Free.
|1|EventLog|20080320034341.000000+000|20080320034341.000000+000|Information|
(null)
```
```
Чтобы выполнить аналогичный запрос из сценария на языке Python,
сначала необходимо настроить окружение. Для примеров, следующих
ниже, мы использовали комплекс Zenoss 2.1.3 VMware. В этом ком
плексе часть программного кода Zenoss располагается в домашнем ка
талоге пользователя zenoss. Самое сложное заключается в том, чтобы
добавить путь к каталогу, где находится модуль wmiclient.py, в пере
менную окружения PYTHONPATH. Мы добавили путь к каталогу в начало
уже существующей переменной PYTHONPATH, как показано ниже:
export PYTHONPATH=~/Products/ZenWin:$PYTHONPATH
```
```
Обеспечив возможность доступа к необходимым библиотекам, можно
попробовать запустить сценарий, исходный текст которого приводит
ся ниже:
#!/usr/bin/env python
```
```
from wmiclient import WMI
if __name__ == '__main__':
w = WMI('winserver', '192.168.1.3', 'Administrator', passwd='foo')
w.connect()
q = w.query('SELECT * FROM Win32_NTLogEvent')
for l in q:
```

Использование Zenoss для управления серверами Windows из Linux **311**

```
print "l.timewritten::", l.timewritten
print "l.message::", l.message
```
```
Вместо того чтобы выводить значения всех полей, как это сделано в при
мере с применением wmic, этот сценарий выводит только время и текст
сообщения из журнала. Данный сценарий соединяется с сервером
192.168.1.3 с привилегиями пользователя Administrator и с паролем foo.
Затем он выполняет запрос WMI 'SELECT * FROM Win32_NTLogEvent'. После
этого производится обход полученных результатов и вывод времени
и текста сообщения для каждой записи. Трудно придумать чтолибо
более простое, чем этот пример.
Ниже приводится часть вывода, полученного от этого сценария:
l.timewritten:: 20080320034359.000000+000
l.message:: While validating that \Device\Serial1 was really a serial port,
a fifo was detected. The fifo will be used.
```
```
l.timewritten:: 20080320034359.000000+000
l.message:: While validating that \Device\Serial0 was really a serial port,
a fifo was detected. The fifo will be used.
l.timewritten:: 20080320034341.000000+000
l.message:: The COM sub system is suppressing duplicate event log entries for
a duration of 86400 seconds. The suppression timeout can be controlled by
a REG_DWORD value named SuppressDuplicateDuration under the following registry
key: HKLM\Software\Microsoft\Ole\EventLog.
```
```
l.timewritten:: 20080320034341.000000+000
l.message:: The Event log service was started.
```
```
l.timewritten:: 20080320034341.000000+000
l.message:: Microsoft (R) Windows (R) 5.02. 3790 Service Pack 2 Uniprocessor
Free.
```
```
Но как мы узнали, что необходимо использовать атрибуты timewritten
и message? Чтобы найти эту информацию, потребовалось приложить
совсем немного усилий. Ниже приводится сценарий, который помога
ет отыскивать необходимые атрибуты:
#!/usr/bin/env python
```
```
from wmiclient import WMI
if __name__ == '__main__':
w = WMI('winserver', '192.168.1.3', 'Administrator', passwd='foo')
w.connect()
q = w.query('SELECT * FROM Win32_NTLogEvent')
for l in q:
print "result set fields::>", l.Properties_.set.keys()
break
```
```
Вы могли бы заметить, что этот сценарий очень похож на предыдущий
сценарий WMI. Между этими сценариями имеются два отличия – дан
ный сценарий вместо вывода значений времени и текста сообщения
```

**312** Глава 8. Окрошка из операционных систем

```
выводит результат метода l.Properties_.set.keys() и прерывает цикл
после вывода первого результата. Объект set, метод keys() которого мы
вызываем, в действительности является словарем. (Что сразу приобре
тает определенный смысл, потому что keys() является методом слова
ря.) Каждая запись в результатах, полученных по запросу WMI, долж
на иметь ряд атрибутов, имена которых соответствуют ключам этого
словаря. А теперь приведем результаты работы сценария, который мы
только что обсудили:
```
```
result set fields::> ['category', 'computername', 'categorystring',
'eventidentifier', 'timewritten', 'recordnumber', 'eventtype', 'eventcode',
'timegenerated', 'sourcename', 'insertionstrings', 'user', 'type',
'message',
'logfile', 'data']
```
```
Как видите, оба атрибута, timewritten и message, использованные нами
в первом сценарии WMI, присутствуют в списке ключей.
Мы не считаем себя большими поклонниками работы с операционной
системой Windows, но тем не менее, мы понимаем, что иногда для вы
полнения работы приходится использовать предопределенные техно
логии. Этот инструмент от Zenoss поможет сделать решение такого ро
да задач менее неприятным делом. К тому же этот инструмент облада
ет такими широкими возможностями, что позволяет выполнять за
просы WMI из Linux. Если вам приходится работать с операционной
системой Windows, то Zenoss с успехом может занять видное место
в вашем инструментарии.
```

**9**

## Глава 9. Управление пакетами

**Введение**

Управление пакетами является одной из наиболее важных составляю
щих успешного проектирования программного обеспечения. Управле
ние пакетами в разработке аналогично организации доставки в компа
ниях, занимающихся электронной торговлей, таких как Amazon. Ес
ли бы не было компаний, выполняющих доставку, то и существование
самой компании Amazon было бы невозможным. Точно так же, если
не будет простой, устойчивой и функциональной системы управления
пакетами для операционной системы или языка, то и разработка про
граммного обеспечения будет сталкиваться с определенными ограни
чениями.
Когда упоминается «управление пакетами», возможно, первое, о чем
вы вспоминаете, это о пакетах _.rpm_ и утилите yum или о пакетах _.deb_
и утилите apt, или о какихто других комплексах управления пакета
ми уровня операционной системы. Мы рассмотрим все это в данной
главе, но основное наше внимание будет уделено созданию и управле
нию пакетами модулей на языке Python и среде окружения языка Py
thon. При использовании Python всегда имелась возможность обеспе
чить доступ к программному коду на языке Python для всей системы.
Кроме того, недавно появилось несколько проектов, которые еще боль
ше улучшили гибкость, удобство и простоту создания пакетов с моду
лями на языке Python, управления ими и распространения.

```
Среди этих проектов можно назвать setuptools, Buildout и virtualenv.
Часто эти проекты используют в процессе разработки и для управле
ния средой разработки. Но по большей части они предназначены для
обеспечения развертывания программного кода на языке Python плат
форменнонезависимым способом. (Обратите внимание на оговорку
«по большей части».)
```

**314** Глава 9. Управление пакетами

```
Другой способ развертывания связан с созданием системнозависимых
пакетов и передачей их на компьютеры конечных пользователей. В не
которых случаях это два совершенно независимых подхода, хотя в них
имеется и чтото общее. В этой главе мы будем рассматривать свободно
распространяемый инструмент EPM, который способен создавать па
кеты для платформ AIX, Debian/Ubuntu, FreeBSD, HPUX, IRIX, Mac
OS X, NetBSD, OpenBSD, Red Hat, Slackware, Solaris и Tru64 Unix.
Знание принципов управления пакетами необходимо не только раз
работчикам программного обеспечения. Это совершенно необходимо
и системным администраторам. На практике нередко системный ад
министратор является тем человеком, на которого возлагаются задачи
управления пакетами. Понимание новейших приемов управления па
кетами для языка Python и для различных операционных систем яв
ляется одним из способов повысить свою ценность как специалиста.
Хотелось бы надеяться, что данная глава поможет вам в этом. Кроме
того, ценную информацию по темам, которые мы затронем здесь, мож
но найти по адресу http://wiki.python.org/moin/buildout/pycon2008_
tutorial.
```
**Setuptools и пакеты Python Eggs**

```
Согласно официальной документации «setuptools – это набор расши
рений к distutils языка Python (на большинстве платформ – для Py
thon 2.3.5, однако для 64битовых платформ требуется версия не ниже
Python 2.4), которые упрощают сборку и распространение пакетов,
особенно когда они имеют зависимости от других пакетов».
До появления setuptools комплект distutils был основным средством
создания установочных пакетов с модулями на языке Python. setup
tools – это библиотека, которая расширяет возможности distutils. На
звание «eggs» относится к окончательному комплекту пакетов и моду
лей на языке Python, напоминая файлы .rpm или .deb. Как правило,
они распространяются в формате архива ZIP и устанавливаются либо
в сжатом виде, либо распаковываются, чтобы иметь возможность пе
ремещаться по содержимому пакета. Создание пакетов «eggs» – это
особенность библиотеки setuptools, которая работает с easy_install.
Согласно официальной документации «Easy Install – это модуль на
языке Python (easy_install), связанный с библиотекой setuptools, ко
торая позволяет автоматически загружать, собирать, устанавливать
и управлять пакетами языка Python». Несмотря на то, что это модуль,
чаще его воспринимают и используют как инструмент командной
строки. В этом разделе мы расскажем о setuptools, easy_install и eggs
и разъясним, для чего каждый из этих инструментов используется.
В этой главе мы выделим наиболее полезные на наш взгляд особенности
setuptools и easy_install. Чтобы получить полный комплект документа
ции к ним, обращайтесь по адресам http://peak.telecommunity.com/
```

Использование easy_install **315**

```
DevCenter/setuptools и http://peak.telecommunity.com/DevCenter/Easy>
Install , соответственно.
Сложные инструменты, способные делать удивительные вещи, часто
бывает сложно понять. Инструмент setuptools сложно понять отчасти
потому, что он делает именно удивительные вещи. С помощью этого
раздела, который можно рассматривать как краткое руководство,
и с последующим изучением руководств вы получите возможность
научиться использовать setuptools, easy_install и пакеты Python как
пользователь и как разработчик.
```
**Использование easy_install**

```
Основные принципы использования easy_install понять очень легко.
Большинство читателей этой книги наверняка использовали rpm,
yum, aptget, fink или подобные им инструменты управления пакета
ми. Фраза «Easy Install» (простая установка) часто означает использо
вание инструмента командной строки с именем easy_install для вы
полнения задач, похожих на выполняемые утилитой yum в системах на
базе Red Hat или apt–get в системах на базе Debian, – для пакетов Py
thon.
Инструмент easy_install можно установить с помощью запуска сцена
рия «начальной установки» с именем ez_setup.py для версии Python,
с которой будет работать easy_install. Сценарий ez_setup.py загрузит
последнюю версию setuptools и автоматически установит easy_install
как сценарий в местоположение по умолчанию, которое в UNIXпо
добных системах обычно соответствует каталогу, где находится испол
няемый файл интерпретатора python. Давайте посмотрим, насколько
это «просто» в действительности. Взгляните на пример 9.1.
```
```
Пример 9.1. Загрузка и установка easy_install
$ curl http://peak.telecommunity.com/dist/ez_setup.py
> ez_setup.py
% Total % Received % Xferd Average Speed Time Time Time Current
Dload Upload Total Spent Left Speed
100 9419 100 9419 0 0 606 0 0:00:15 0:00:15:: 83353
$ ls
ez_setup.py
$ sudo python2.5 ez_setup.py
Password:
Searching for setuptools
Reading http://pypi.python.org/simple/setuptools/
Best match: setuptools 0.6c8
Processing setuptools0.6c8py2.5.egg
setuptools 0.6c8 is already the active version in easyinstall.pth
Installing easy_install script to /usr/local/bin
Installing easy_install2.5 script to /usr/local/bin
```

**316** Глава 9. Управление пакетами

```
Using /Library/Python/2.5/sitepackages/setuptools0.6c8py2.5.egg
Processing dependencies for setuptools
Finished processing dependencies for setuptools
$
```
```
В этом случае сценарий easy_install был помещен в каталог /usr/local/
bin под двумя различными именами.
```
```
$ lsl /usr/local/bin/easy_install*
rwxrxrx 1 root wheel 364 Mar 9 18:14 /usr/local/bin/easy_install
rwxrxrx 1 root wheel 372 Mar 9 18:14 /usr/local/bin/easy_install2.5
```
```
В соответствии с соглашениями, продолжительное время существую
щими в языке Python, при установке выполняемых файлов программ
один файл устанавливается под именем, содержащим номер версии
Python, и один – без номера версии. Это означает, что по умолчанию
будет использоваться файл, имя которого не содержит номер версии,
пока пользователь явно не укажет имя файла с номером версии. Это
также означает, что по умолчанию будет использоваться последняя
установленная версия. Это удобно еще и потому, что старая версия по
прежнему остается в файловой системе.
Ниже приводится содержимое вновь установленного файла /usr/local/
bin/easy_install :
```
```
#!/System/Library/Frameworks/Python.framework/Versions/2.5/Resources/
Python.app/Contents/MacOS/Python
# EASYINSTALLENTRYSCRIPT:
'setuptools==0.6c8','console_scripts','easy_install'
__requires__ = 'setuptools==0.6c8'
import sys
from pkg_resources import load_entry_point
sys.exit(
load_entry_point('setuptools==0.6c8', 'console_scripts', 'easy_install')()
)
```
```
Главное здесь то, что при установке setuptools устанавливается сцена
рий с именем easy_install, который может использоваться для уста
новки и управления программным кодом на языке Python. Второй по
важности момент, ради которого мы привели содержимое сценария
easy_install, заключается в том, что он относится к типу сценариев,
которые создаются автоматически при использовании «точек входа»,
когда определяются пакеты. Пока не надо беспокоиться о содержимом
этого сценария, о точках входа или о создании таких сценариев, как
этот. Мы подойдем к этой теме далее в этой главе.
Теперь, когда в нашем распоряжении имеется сценарий easy_install,
мы можем установить любой пакет, находящийся в центральном репо
зитарии модулей Python, который обычно называют PyPI (Python
```

Использование easy_install **317**

```
Package Index – каталог пакетов Python), или «Cheesshop»: http://py>
pi.python.org/pypi.
Чтобы установить IPython, оболочку, которая используется для де
монстрации примеров на протяжении всей книги, можно просто за
пустить следующую команду:
sudo easy_install ipython
```
```
Обратите внимание, что для выполнения своей работы сценарий
easy_install требует в данном случае привилегий суперпользователя,
так как пакеты устанавливаются в глобальный для Python каталог
site>packages. Он также помещает сценарии в каталог, по умолчанию
предназначенный операционной системой для сценариев, который
обычно является каталогом, где находится исполняемый файл python.
Для установки пакетов с помощью easy_install необходимо обладать
правом на запись в каталог site>packages и в каталог, куда был установ
лен Python. Если у вас это вызывает затруднения, обратитесь к разде
лу главы, где обсуждается использование virtualenv и setuptools. Как
вариант, можно было бы скомпилировать и установить Python в ката
лог по своему выбору: например, в свой домашний каталог.
Прежде чем мы перейдем к изучению дополнительных возможностей
инструмента easy_install, коротко вспомним основные моменты ис
пользования easy_install:
```
1. Загрузить сценарий начальной установки ez_setup.py.
2. Запустить ez_setup.py для версии Python, с которой будет работать
    easy_install.
3. Если в вашей системе установлено несколько версий Python, явно
    запускайте сценарий easy_install с требуемым номером версии.

```
ПОРТ РЕТ ЗНА МЕ НИ ТО СТИ: EASY INSTALL
```
**Филлип Дж. Эби (Phillip J. Eby)**

```
Филлип Дж. Эби отвечает за систему Python En
hancement Proposals (система приема предложе
ний по улучшению Python), поддержку стандарта
WSGI (Web Server Gateway Interface – интерфейс
взаимодействия с вебсервером), setuptools и мно
гое другое. О нем рассказывалось в книге «Dream
ing in Code» (Three Rivers Press). Вы можете посе
тить его блог, посвященный программированию: http://dirtsim>
ple.org/programming/.
```

**318** Глава 9. Управление пакетами

**Дополнительные особенности easy_install**

```
Для большинства тех, кто пользуется сценарием easy_install, вполне
достаточно вызывать его с единственным аргументом командной стро
ки, без дополнительных параметров. (К слову сказать, при использо
вании easy_install с единственным аргументом – именем пакета, этот
сценарий просто загрузит и установит этот пакет, как показано в пре
дыдущем примере с IPython.) Тем не менее, иногда бывают случаи, ко
гда неплохо было бы иметь возможности для выполнения дополни
тельных действий, помимо загрузки пакета из Python Package Index.
К счастью, easy_install имеет в запасе несколько оригинальных реше
ний и обладает достаточно высокой гибкостью, чтобы предоставить це
лый набор дополнительных возможностей.
```
**Поиск пакетов на вебстраницах**

```
Как было показано ранее, easy_install может отыскивать пакеты в цен
тральном репозитарии и автоматически устанавливать их. Но кроме
этого он имеет возможность устанавливать пакеты любыми другими
способами, которые только можно себе представить. Ниже приводится
пример того, как выполнить поиск пакета на вебстранице и устано
вить или обновить пакет по имени и номеру версии:
$ easy_installf http://code.google.com/p/liten/ liten
Searching for liten
Reading http://code.google.com/p/liten/
Best match: liten 0.1.3
Downloading http://liten.googlecode.com/files/liten0.1.3py2.4.egg
[обрезано]
```
```
В данной ситуации на странице http://code.google.com/p/liten/ имеет
ся пакет .egg для Python 2.4 и Python 2.5. Ключ –f сценария easy_in
stall определяет адрес страницы, где требуется отыскать пакет. Сце
нарий отыскал оба пакета и установил версию для Python 2.4, как наи
более соответствующую. Достаточно очевидно, что это очень мощная
особенность, так как easy_install не только отыскал ссылку на пакет,
но и обнаружил наиболее подходящую версию.
```
**Установка дистрибутива с исходными**

**текстами по заданному URL**

```
Теперь мы попробуем автоматически установить дистрибутив с исход
ными текстами по известному адресу URL:
```
```
% easy_install http://superbwest.dl.sourceforge.net/sourceforge
/sqlalchemy/SQLAlchemy0.4.3.tar.gz
```
```
Downloading http://superbwest.dl.sourceforge.net/sourceforge
/sqlalchemy/SQLAlchemy0.4.3.tar.gz
Processing SQLAlchemy0.4.3.tar.gz
```

Дополнительные особенности easy_install **319**

```
Running SQLAlchemy0.4.3/setup.pyq bdist_eggdistdir
/var/folders/LZ/LZFo5h8JEW4Jzr+ydkXfI++++TI/Tmp/
easy_installGw2Xq3/SQLAlchemy0.4.3/eggdisttmpMf4jir
zip_safe flag not set; analyzing archive contents...
sqlalchemy.util: module MAY be using inspect.stack
sqlalchemy.databases.mysql: module MAY be using inspect.stack
Adding SQLAlchemy 0.4.3 to easyinstall.pth file
Installed /Users/ngift/src/py24ENV/lib/python2.4/sitepackages/SQLAlchemy
0.4.3py2.4.egg
Processing dependencies for SQLAlchemy==0.4.3
Finished processing dependencies for SQLAlchemy==0.4.3
```
```
Мы передали сценарию easy_install адрес местоположения сжатого
тарболла. Он обнаружил, что должен установить дистрибутив с исход
ными текстами, причем нам не пришлось явно сообщать ему об этом.
Это очень интересный способ установки, но, чтобы он работал, в корне
вом каталоге дистрибутива должен иметься файл setup.py. Например,
к моменту написания этих строк, если разработчик создаст несколько
уровней вложенности каталогов, попытка выполнить установку тако
го пакета потерпит неудачу.
```
**Установка пакетов, расположенных в локальной**

**или в сетевой файловой системе**

```
Ниже приводится пример установки пакета .egg , находящегося в ло
кальной файловой системе или на смонтированном томе NFS:
easy_install /net/src/eggs/convertWindowsToMacOperatingSystempy2.5.egg
```
```
Кроме всего прочего существует возможность устанавливать пакеты,
находящиеся в смонтированном каталоге NFS или в локальном разде
ле. Это может быть очень удобно при распространении пакетов в окру
жении *nix, особенно когда имеется несколько машин, которые долж
ны быть синхронизированы друг с другом по версиям программного
кода, работающего на них. Некоторые другие сценарии, представлен
ные в этой книге, могли бы помочь в создании демона, выполняющего
опрос. Каждый клиент мог бы с помощью такого демона проверять на
личие обновлений в центральном репозитарии пакетов. При обнару
жении новой версии он мог бы автоматически выполнять обновление.
```
**Обновление пакетов**

```
Еще одна область применения easy_install – обновление пакетов. В сле
дующих нескольких примерах демонстрируется установка и обновле
ние пакета CherryPy.
Сначала устанавливается версия CherryPy 2.2.1:
$ easy_install cherrypy==2.2.1
Searching for cherrypy==2.2.1
Reading http://pypi.python.org/simple/cherrypy/
```

**320** Глава 9. Управление пакетами

```
....
Best match: CherryPy 2.2.1
Downloading http://download.cherrypy.org/cherrypy/2.2.1/CherryPy2.2.1.tar.gz
....
Processing dependencies for cherrypy==2.2.1
Finished processing dependencies for cherrypy==2.2.1
```
```
Теперь посмотрим, что произойдет, если предложить сценарию easy_in
stall попытаться установить пакет, который уже был установлен:
```
```
$ easy_install cherrypy
Searching for cherrypy
Best match: CherryPy 2.2.1
Processing CherryPy2.2.1py2.5.egg
CherryPy 2.2.1 is already the active version in easyinstall.pth
Using /Users/jmjones/python/cherrypy/lib/python2.5/sitepackages/CherryPy
2.2.1py2.5.egg
Processing dependencies for cherrypy
Finished processing dependencies for cherrypy
```
```
После установки некоторой версии пакета можно обновить его до бо
лее свежей версии, явно указав, какую версию нужно загрузить и ус
тановить:
```
```
$ easy_install cherrypy==2.3.0 Searching for
cherrypy==2.3.0
Reading http://pypi.python.org/simple/cherrypy/
....
Best match: CherryPy 2.3.0
Downloading http://download.cherrypy.org/cherrypy/2.3.0/CherryPy2.3.0.zip
....
Processing dependencies for cherrypy==2.3.0
Finished processing dependencies for cherrypy==2.3.0
```
```
Обратите внимание: в данном примере мы не использовали ключ
––upgrade. В действительности этот ключ необходим, только если у вас
уже установлена некоторая версия пакета и вы хотите обновить его до
самой последней версии.
Далее мы обновляем пакет до версии CherryPy 3.0.0, используя ключ
––upgrade. В данном случае использовать ключ ––upgrade было совер
шенно необязательно:
```
```
$ easy_installupgrade cherrypy==3.0.0
Searching for cherrypy==3.0.0
Reading http://pypi.python.org/simple/cherrypy/
....
Best match: CherryPy 3.0.0
Downloading http://download.cherrypy.org/cherrypy/3.0.0/CherryPy3.0.0.zip
....
Processing dependencies for cherrypy==3.0.0
Finished processing dependencies for cherrypy==3.0.0
```

Дополнительные особенности easy_install **321**

```
Если использовать ключ ––upgrade, не указывая номер версии, обновле
ние будет выполнено до самой последней версии пакета. Обратите вни
мание: действие команды в этом случае отличается от действия коман
ды easy_install cherrypy. Команда easy_install cherrypy обнаружит, что
ранее уже была установлена некоторая версия пакета и поэтому ника
ких действий предпринимать не будет. В следующем примере про
изойдет обновление пакета CherryPy до самой последней версии:
$ easy_installupgrade cherrypy
Searching for cherrypy
Reading http://pypi.python.org/simple/cherrypy/
....
Best match: CherryPy 3.1.0beta3
Downloading http://download.cherrypy.org/cherrypy/3.1.0beta3/CherryPy
3.1.0beta3.zip
....
Processing dependencies for cherrypy
Finished processing dependencies for cherrypy
```
```
Теперь у нас установлена версия CherryPy 3.1.0b3. Если теперь попро
бовать выполнить обновление до версии, больше чем 3.0.0, никаких
действий предприниматься не будет, так как у нас уже установлена та
кая версия:
$ easy_installupgrade cherrypy>3.0.0
$
```
**Установка распакованного дистрибутива с исходными**

**текстами в текущем рабочем каталоге**

```
Несмотря на всю свою тривиальность, такой способ установки может
оказаться полезным. Вместо того чтобы следовать через процедуру py
thon setup.py install, вы можете просто ввести следующую команду
(для этого требуется меньше вводить с клавиатуры, поэтому это будет
ценный совет для ленивых):
```
```
easy_install
```
**Извлечение дистрибутива с исходными текстами**

**в заданный каталог**

```
Следующий пример может использоваться для поиска дистрибутива
с исходными текстами или пакета по указанному URL с последующей
распаковкой его в заданный каталог:
```
```
easy_installeditablebuilddirectory ~/sandbox liten
```
```
Это достаточно удобный прием, так как он позволяет с помощью
easy_install поместить дистрибутив с исходными текстами в требуемый
каталог. Так как в процессе установки пакета с помощью сценария
easy_install не всегда устанавливается все его содержимое (например,
```

**322** Глава 9. Управление пакетами

```
документация или примеры программного кода), это отличный способ
узнать, что входит в состав дистрибутива. В этом случае easy_install
только лишь скопирует файлы из дистрибутива. Если вам потребуется
установить пакет, вам нужно будет запустить сценарий easy_install
еще раз.
```
**Изменение активной версии пакета**

```
В этом примере предполагается, что у вас уже установлен пакет liten
версии 0.1.3 и при этом была установлена некоторая другая версия
liten. Кроме того, предполагается, что «активной» является эта дру
гая версия. Ниже показано, как можно активировать версию:
```
```
easy_install liten=0.1.3
```
```
Этот прием работает как в случае перехода к использованию более ста
рой версии, так и в случае возврата к более новой версии пакета.
```
**Преобразование отдельного файла .py в пакет .egg**

```
Ниже показано, как преобразовать обычный пакет Python в пакет .egg
(обратите внимание на ключ –f):
```
```
easy_installf "http://svn.colorstudy.com/virtualenv/
trunk/virtualenv.py#egg=virtualenv1.0" virtualenv
```
```
Этот прием пригодится, когда необходимо упаковать единственный
файл .py в пакет .egg. Иногда этот метод может оказаться лучшим спо
собом, когда необходимо обеспечить доступ к ранее распакованному
отдельному файлу из любой точки файловой системы. Как вариант,
можно было бы добавить путь к требуемому файлу в переменную окру
жения PYTHONPATH. В этом примере мы получаем из основного каталога
проекта сценарий virtualenv.py, упаковываем его и указываем нашу
собственную версию и метку к ней. В строке URL подстрока #egg=vir
tualenv–1.0 просто определяет имя пакета и номер версии, выбранные
нами для этого сценария. Аргумент, который следует за строкой URL,
определяет имя создаваемого пакета. В этом аргументе желательно ис
пользовать имена, которые не противоречили бы строке URL, потому
что мы предписываем easy_install установить пакет с тем же именем,
что и созданный. Даже при том, что было бы желательно указывать
непротиворечивые имена, вы не должны чувствовать себя обязанными
сохранять название пакета в соответствии с названием модуля. На
пример:
easy_installf "http://svn.colorstudy.com/virtualenv/
trunk/virtualenv.py#egg=foofoo1.0" foofoo
```
```
Эта команда делает в точности то же самое, что и предыдущий пример,
только в этом случае создается пакет с именем foofoo, а не virtualenv.
Какое имя вы выберете для своего пакета – полностью ваше дело.
```

Дополнительные особенности easy_install **323**

**Аутентификация на сайтах, доступ к которым**

**защищен паролем**

```
В практике может возникнуть ситуация, когда вам потребуется уста
новить пакет .egg с вебсайта, где требуется пройти аутентификацию,
прежде чем будет разрешено загружать с него какиелибо файлы. В та
ком случае можно указать имя пользователя и пароль прямо в строке
URL, как показано ниже:
easy_installf http://uid:passwd@example.com/packages
```
```
Вы можете заниматься на работе своим собственным проектом, и вам
не хотелось бы, чтобы ваши коллеги узнали о нем. (Разве не все занима
ются этим?) Один из способов передать свои пакеты коллегам «изпод
полы» заключается в том, чтобы создать простой файл .htaccess и за
тем выполнять процедуру аутентификации в сценарии easy_install.
```
### Интеграция конфигурационных файлов

```
Для опытных пользователей в арсенале easy_install имеется еще один
прием. Значения параметров по умолчанию можно задать с помощью
конфигурационного файла, который имеет формат iniфайлов. Для
системного администратора это особенно удачная возможность, так
как позволяет определять настройки клиентов, использующих сцена
рий easy_install. Параметры конфигурации будут отыскиваться сце
нарием easy_install в следующих файлах и в следующем порядке: те>
кущий_рабочий_каталог/setup.cfg , ~/.pydistutils.cfg и в файле distu>
tils.cfg , в каталоге пакета distutils.
Что можно добавить в этот конфигурационный файл? Обычно здесь
определяются два параметра: сайт(ы) в локальной сети, откуда можно
загружать пакеты, и нестандартный каталог установки пакетов. Ниже
показано, как может выглядеть файл конфигурации для easy_install:
[easy_install]
```
```
#Где искать пакеты
find_links = http://code.example.com/downloads
```
```
#Ограничить возможности поиска этими доменами
allow_hosts = *.example.com
```
```
#Куда устанавливать пакеты. Обратите внимание: этот каталог должен
#находиться в PYTHONPATH
install_dir = /src/lib/python
```
```
В этом конфигурационном файле, который мы могли бы назвать, на
пример, ~/.pydistutils.cfg , определяется адрес URL для поиска паке
тов, разрешается искать пакеты только в домене example.com (и в под
доменах) и, наконец, указывается, куда должны помещаться пакеты
при установке.
```

**324** Глава 9. Управление пакетами

**Коротко о дополнительных особенностях easy_install**

```
Этот раздел не может служить заменой всеобъемлющей официальной
документации с описанием сценария easy_install, его цель состояла
лишь в том, чтобы обозначить некоторые основные особенности, кото
рые могут использоваться опытными пользователями. Сценарий
easy_install продолжает активно разрабатываться, поэтому будет не
лишним чаще обращаться на страницу http://peak.telecommunity.com/
DevCenter/EasyInstall за обновлениями в документации. Кроме того,
существует почтовая рассылка, она называется distutilssig (где sig про
исходит от special interest group – группа с особыми интересами), где
обсуждаются все проблемы, связанные с распространением программ
ного кода. Подпишитесь на рассылку по адресу http://mail.python.org/
mailman/listinfo/distutils>sig , и вы сможете посылать свои сообщения
об обнаруженных ошибках и получать помощь, касающуюся исполь
зования easy_install.
Наконец, выполнив команду easy_install ––help, вы обнаружите еще
большее число параметров, о которых мы даже не упоминали здесь.
Весьма вероятно, что какаялибо особенность, которая вам необходи
ма, уже реализована в easy_install.
```
**Создание пакетов**

```
Ранее мы уже упоминали, что пакеты с расширением .egg – это пакеты
модулей на языке Python, но мы не давали определения пакетам луч
ше, чем это. Ниже приводится определение «пакета egg», взятое с веб
сайта проекта setuptools:
```
```
Пакеты в формате .egg – это предпочтительный двоичный формат ди
стрибутивов для EasyInstall, потому что являются кроссплатфор
менными (для пакетов с модулями исключительно на языке Python),
могут импортироваться непосредственно и содержат метаданные
проекта, включая сценарии и информацию о зависимостях проекта.
Они могут просто загружаться и добавляться в значение атрибута
sys.path или помещаться в каталог, который уже имеется в sys.path,
после чего они автоматически будут обнаруживаться системой
управления пакетами во время выполнения.
```
```
Мы не приводили причины, по которым системный администратор
мог бы быть заинтересован в создании пакетов. Если ваша деятель
ность ограничивается созданием одноразовых сценариев, эти знания
не окажутся вам особенно полезными. Но когда вы начнете выделять
общие шаблоны и задачи, вы обнаружите, что пакеты помогут вам из
бежать многих неприятностей. Если вы создадите небольшую библио
теку сценариев, предназначенных для решения наиболее часто встре
чающихся задач, вы сможете оформить ее в виде пакета. А если вы
сделаете это, то вы не только сэкономите время на написании про
```

Создание пакетов **325**

```
граммного кода, но облегчите себе процедуру их установки на несколь
ких машинах.
Создание пакетов Python представляет собой чрезвычайно простой
процесс, состоящий из четырех этапов:
```
1. Установить setuptools.
2. Создать файлы, которые необходимо поместить в пакет.
3. Создать файл _setup.py_.
4. Запустить.
    python setup.py bdist_egg

```
Инструмент setuptools у нас уже установлен, поэтому мы можем дви
нуться дальше и создать файлы для помещения в пакет:
$ cd /tmp
$ mkdir eggexample
$ cd eggexample
$ touch helloegg.py
```
```
В данном случае пакет будет содержать пустой модуль на языке Py
thon с именем hello–egg.py.
Далее создадим простейший файл setup.py :
```
```
from setuptools import setup, find_packages
setup(
name = "HelloWorld",
version = "0.1",
packages = find_packages(),
)
```
```
Теперь создадим пакет:
$ python setup.py bdist_egg
running bdist_egg
running egg_info
creating HelloWorld.egginfo
writing HelloWorld.egginfo/PKGINFO
writing toplevel names to HelloWorld.egginfo/top_level.txt
writing dependency_links to HelloWorld.egginfo/dependency_links.txt
writing manifest file 'HelloWorld.egginfo/SOURCES.txt'
reading manifest file 'HelloWorld.egginfo/SOURCES.txt'
writing manifest file 'HelloWorld.egginfo/SOURCES.txt'
installing library code to build/bdist.macosx10.5i386/egg
running install_lib
warning: install_lib: 'build/lib' does not exist no Python modules to
install
creating build
creating build/bdist.macosx10.5i386
creating build/bdist.macosx10.5i386/egg
creating build/bdist.macosx10.5i386/egg/EGGINFO
```

**326** Глава 9. Управление пакетами

```
copying HelloWorld.egginfo/PKGINFO> build/bdist.macosx10.5i386/egg/
EGGINFO
copying HelloWorld.egginfo/SOURCES.txt> build/bdist.macosx10.5i386/egg/
EGGINFO
copying HelloWorld.egginfo/dependency_links.txt> build/bdist.macosx10.5
i386/egg/EGGINFO
copying HelloWorld.egginfo/top_level.txt> build/bdist.macosx10.5i386/
egg/EGGINFO
zip_safe flag not set; analyzing archive contents...
creating dist
creating 'dist/HelloWorld0.1py2.5.egg' and adding 'build/bdist.macosx
10.5i386/egg' to it
removing 'build/bdist.macosx10.5i386/egg' (and everything under it)
$ ll
total 8
drwxrxrx 6 ngift wheel 204 Mar 10 06:53 HelloWorld.egginfo
drwxrxrx 3 ngift wheel 102 Mar 10 06:53 build
drwxrxrx 3 ngift wheel 102 Mar 10 06:53 dist
rwrr 1 ngift wheel 0 Mar 10 06:50 helloegg.py
rwrr 1 ngift wheel 131 Mar 10 06:52 setup.py
```
```
Установим пакет:
$ sudo easy_install HelloWorld0.1py2.5.egg
sudo easy_install HelloWorld0.1py2.5.egg
Password:
Processing HelloWorld0.1py2.5.egg
Removing /Library/Python/2.5/sitepackages/HelloWorld0.1py2.5.egg
Copying HelloWorld0.1py2.5.egg to /Library/Python/2.5/sitepackages
Adding HelloWorld 0.1 to easyinstall.pth file
```
```
Installed /Library/Python/2.5/sitepackages/HelloWorld0.1py2.5.egg
Processing dependencies for HelloWorld==0.1
Finished processing dependencies for HelloWorld==0.1
```
```
Как видите, пакеты создаются чрезвычайно просто. Однако созданный
пакет в действительности был пустым файлом, поэтому мы создадим
другой сценарий на языке Python и рассмотрим процедуру создания
пакета более подробно.
Ниже приводится очень простой сценарий на языке Python, который
отображает файлы в каталоге, являющиеся символическими ссылками,
показывает местоположение, где находятся соответствующие им на
стоящие файлы, и выясняет, существуют ли эти файлы на самом деле:
#!/usr/bin/env python
```
```
import os
import sys
```
```
def get_dir_tuple(filename, directory):
abspath = os.path.join(directory, filename)
realpath = os.path.realpath(abspath)
exists = os.path.exists(abspath)
```

Создание пакетов **327**

```
return (filename, realpath, exists)
def get_links(directory):
file_list = [get_dir_tuple(f, directory) for f in os.listdir(directory)
if os.path.islink(os.path.join(directory, f))]
return file_list
def main():
if not len(sys.argv) == 2:
print 'USAGE: %s directory' % sys.argv[0]
sys.exit(1)
directory = sys.argv[1]
print get_links(directory)
if __name__ == '__main__':
main()
```
```
Затем мы создадим сценарий setup.py, который будет использоваться
инструментом setuptools. Это еще один минимально возможный файл
setup.py , как и в предыдущем примере:
```
```
from setuptools import setup, find_packages
setup(
name = "symlinkator",
version = "0.1",
packages = find_packages(),
entry_points = {
'console_scripts': [
'linkator = symlinkator.symlinkator:main',
],
},
)
```
```
Здесь объявляется имя пакета – «symlinkator», номер версии 0.1 и ука
зывается, что инструмент setuptools будет пытаться отыскать любые
подходящие файлы для включения. Раздел entry_points пока просто
игнорируйте.
Теперь соберем пакет, запустив команду python setup.py bdist_egg:
```
```
$ python setup.py bdist_egg
running bdist_egg
running egg_info
creating symlinkator.egginfo
writing symlinkator.egginfo/PKGINFO
writing toplevel names to symlinkator.egginfo/top_level.txt
writing dependency_links to symlinkator.egginfo/dependency_links.txt
writing manifest file 'symlinkator.egginfo/SOURCES.txt'
writing manifest file 'symlinkator.egginfo/SOURCES.txt'
installing library code to build/bdist.linuxx86_64/egg
running install_lib
warning: install_lib: 'build/lib' does not exist no Python modules
to install
creating build
```

**328** Глава 9. Управление пакетами

```
creating build/bdist.linuxx86_64
creating build/bdist.linuxx86_64/egg
creating build/bdist.linuxx86_64/egg/EGGINFO
copying symlinkator.egginfo/PKGINFO> build/bdist.linuxx86_64/egg/EGG
INFO
copying symlinkator.egginfo/SOURCES.txt> build/bdist.linuxx86_64/egg/
EGGINFO
copying symlinkator.egginfo/dependency_links.txt> build/bdist.linux
x86_64/egg/EGGINFO
copying symlinkator.egginfo/top_level.txt> build/bdist.linuxx86_64/egg/
EGGINFO
zip_safe flag not set; analyzing archive contents...
creating dist
creating 'dist/symlinkator0.1py2.5.egg' and adding 'build/bdist.linux
x86_64/egg' to it
removing 'build/bdist.linuxx86_64/egg' (and everything under it)
```
```
Проверим содержимое пакета. Для этого перейдем в предварительно
созданный каталог dist и проверим наличие пакета в этом каталоге:
```
```
$ lsl dist
total 4
rwrr 1 jmjones jmjones 825 20080503 15:34 symlinkator0.1py2.5.egg
```
```
Теперь установим пакет:
```
```
$ easy_install dist/symlinkator0.1py2.5.egg
Processing symlinkator0.1py2.5.egg
....
Processing dependencies for symlinkator==0.1
Finished processing dependencies for symlinkator==0.1
```
```
Затем запустим оболочку IPython, импортируем модуль и попробуем
им воспользоваться:
In [1]: from symlinkator.symlinkator import get_links
```
```
In [2]: get_links('/home/jmjones/logs/')
Out[2]: [('fetchmail.log.old', '/home/jmjones/logs/fetchmail.log.3', False),
('fetchmail.log', '/home/jmjones/logs/fetchmail.log.0', True)]
```
```
На всякий случай проверим содержимое каталога, который был пере
дан функции get_links():
$ lsl ~/logs/
total 0
lrwxrwxrwx 1 jmjones jmjones 15 20080503 15:11 fetchmail.log>
fetchmail.log.0
rwrr 1 jmjones jmjones 0 20080503 15:09 fetchmail.log.0
rwrr 1 jmjones jmjones 0 20080503 15:09 fetchmail.log.1
lrwxrwxrwx 1 jmjones jmjones 15 20080503 15:11 fetchmail.log.old>
fetchmail.log.3
```

Точки входа и сценарии консоли **329**

**Точки входа и сценарии консоли**

```
Со страницы документации проекта setuptools:
```
```
Точки входа используются для поддержки динамического обнару
жения служб или расширений, предоставляемых проектом. За до
полнительной информацией и примерами представления аргумен
тов обращайтесь к разделу «Dynamic Discovery of Services and Plu
gins». Кроме того, это ключевое слово (entry_points) используется
для поддержки автоматического создания сценариев.
```
```
В этой книге мы рассмотрим единственную разновидность точек вхо
да – различные сценарии консоли. setuptools автоматически создает
сценарий консоли, исходя из двух частей информации, которую вы
поместите в свой сценарий setup.py. Ниже приводится интересующий
нас раздел в файле setup.py из предыдущего примера:
entry_points = {
'console_scripts': [
'linkator = symlinkator.symlinkator:main',
],
},
```
```
В этом примере мы указали, что хотели бы получить сценарий linkator
и что при исполнении сценария он должен вызывать функцию main()
из модуля symlinkator.symlinkator. Во время установки пакета сцена
рий linkator был помещен в тот же каталог, где находится исполняе
мый файл python:
#!/home/jmjones/local/python/scratch/bin/python
# EASYINSTALLENTRYSCRIPT: 'symlinkator==0.1','console_scripts','linkator'
__requires__ = 'symlinkator==0.1'
import sys
from pkg_resources import load_entry_point
```
```
sys.exit(
load_entry_point('symlinkator==0.1', 'console_scripts', 'linkator')()
)
```
```
Все, что вы видите, было создано инструментом setuptools. Совершенно
необязательно понимать все, что находится в этом сценарии. В действи
тельности, вообще необязательно понимать хоть чтонибудь в этом
сценарии. Важно лишь знать, что, когда вы определяете в файле set
up.py точку входа console_scripts, setuptools создаст сценарий, который
будет вызывать ваш программный код, расположенный там, где вы
укажете. Ниже показано, что произошло, когда мы вызвали этот сце
нарий примерно так, как вызывали функцию в предыдущем примере:
$ linkator ~/logs/
[('fetchmail.log.old', '/home/jmjones/logs/fetchmail.log.3', False),
('fetchmail.log', '/home/jmjones/logs/fetchmail.log.0', True)]
```

**330** Глава 9. Управление пакетами

```
С точками входа связано несколько достаточно сложных аспектов, но
на верхнем уровне достаточно знать, что точки входа используются
для установки ваших сценариев, играющих роль инструментов ко
мандной строки, в каталог, доступный для пользователя. Для этого
вам необходимо следовать синтаксису, описанному выше, и опреде
лить функцию, которая должна вызываться вашим инструментом ко
мандной строки.
```
**Регистрация пакета в Python Package Index**

```
Если вы напишете действительно полезный модуль, вполне естествен
но, что вы захотите поделиться им с другими людьми. Это одна из са
мых приятных сторон в разработке открытого программного обеспече
ния. К счастью, выгрузить пакет в Python Package Index (каталог па
кетов Python) совсем несложно.
Этот процесс лишь немного отличается от процесса создания пакета.
При этом следует обратить внимание на две вещи: не забыть включить
описание в формате ReST (reStructuredText) в атрибут long_description
и подставить значение download_url. О формате ReST мы уже упомина
ли в главе 4.
Несмотря на то, что формат ReST уже обсуждался ранее, мы должны
здесь подчеркнуть, что применение формата ReST для оформления до
кументации необходимо потому, что она будет преобразована в формат
HTML после выгрузки пакета в Python Package Index. Вы можете вос
пользоваться инструментом ReSTless, созданным Аароном Хиллегас
сом (Aaron Hillegass), для предварительного просмотра форматирован
ного текста, чтобы убедиться, что он отформатирован должным обра
зом. Обязательно просматривайте документацию, чтобы убедиться в от
сутствии нарушений форматирования. Если текст не будет должным
образом отформатирован в формате ReST, после выгрузки модуля
текст будет отображаться как обычный текст, а не как HTML.
В примере 9.2 приводится содержимое файла setup.py для инструмен
та командной строки и библиотеки, созданной Ноа (Noah).
```
```
Пример 9.2. Пример файла setup.py для выгрузки модуля
в Python Package Index
#!/usr/bin/env python
```
```
# liten 0.1.4.2 deduplication commandline tool
#
# Author: Noah Gift
try:
from setuptools import setup, find_packages
except ImportError:
from ez_setup import use_setuptools
use_setuptools()
from setuptools import setup, find_packages
```

Регистрация пакета в Python Package Index **331**

```
import os,sys
version = '0.1.4.2'
f = open(os.path.join(os.path.dirname(__file__), 'docs', 'index.txt'))
long_description = f.read().strip()
f.close()
setup(
name='liten',
version='0.1.4.2',
description='a deduplication command line tool',
long_description=long_description,
classifiers=[
'Development Status :: 4 Beta',
'Intended Audience :: Developers',
'License :: OSI Approved :: MIT License',
],
author='Noah Gift',
author_email='noah.gift@gmail.com',
url='http://pypi.python.org/pypi/liten',
download_url="http://code.google.com/p/liten/downloads/list",
license='MIT',
py_modules=['virtualenv'],
zip_safe=False,
py_modules=['liten'],
entry_points="""
[console_scripts]
liten = liten:main
""",
)
```
```
C помощью этого файла setup.py теперь можно «автоматически» заре
гистрировать пакет в Python Package Index, используя следующую ко
манду:
$ python setup.py register
running register
running egg_info
writing liten.egginfo/PKGINFO
writing toplevel names to liten.egginfo/top_level.txt
writing dependency_links to liten.egginfo/dependency_links.txt
writing entry points to liten.egginfo/entry_points.txt
writing manifest file 'liten.egginfo/SOURCES.txt'
Using PyPI login from /Users/ngift/.pypirc
Server response (200): OK
```
```
В этом файле setup.py появились новые дополнительные поля, если
сравнивать его с предыдущим примером symlinkator. В число дополни
тельных полей входят description, long_description, classifiers, author
и download_url. Точка входа, обсуждавшаяся выше, позволяет запус
кать инструмент из командной строки и устанавливать его в каталог,
по умолчанию предназначенный для сценариев.
```

**332** Глава 9. Управление пакетами

```
Атрибут download_url имеет особо важное значение, потому что он сооб
щает сценарию easy_install, где искать ваш пакет. Сюда можно вклю
чить ссылку на страницу, и тогда сценарий easy_install самостоятель
но отыщет дистрибутив с исходными текстами или пакет в формате
.egg , но можно также указать прямую ссылку на пакет.
В атрибут long_description записывается существующее описание, ко
торое хранится в созданном нами файле index.txt в подкаталоге docs.
Файл index.txt содержит текст в формате ReST, а сценарий setup.py
в процессе регистрации пакета в Python Package Index читает эту ин
формацию и помещает ее в атрибут long_description.
```
**Где можно получить дополнительную информацию...**

```
Ниже приводится несколько важных ресурсов:
Easy install
http://peak.telecommunity.com/DevCenter/EasyInstall
Пакеты Python в формате .egg
http://peak.telecommunity.com/DevCenter/PythonEggs
Модуль setuptools
http://peak.telecommunity.com/DevCenter/setuptools
Модуль pkg_resources
http://peak.telecommunity.com/DevCenter/PkgResources
Обзор архитектуры модуля pkg_resources и формата Python egg в об>
щих чертах
Обзор архитектуры модуля pkg_resources и формата Python egg
вобщих чертах
И не забудьте про почтовую рассылку по языку Python http://mail.py>
thon.org/pipermail/distutilssig/.
```
**Distutils**

```
К моменту написания этих строк инструмент setuptools считался пред
почтительным способом создания и распространения пакетов и похо
же, что части библиотеки setuptools войдут в стандартную библиотеку
языка Python. Но при этом попрежнему важно знать, как работает па
кет distutils, возможности которого расширяет библиотека setuptools,
и какие возможности в нем отсутствуют.
Когда пакет создается с помощью distutils, обычно установка такого
пакета выполняется командой:
python setup.py install
```
```
Что касается вопроса сборки пакетов, готовых для распространения,
мы рассмотрим четыре следующие темы:
```

Distutils **333**

**-** Как написать сценарий установки, то есть файл _setup.py_
**-** Основные параметры настройки в файле _setup.py_
**-** Как собрать дистрибутив с исходными текстами
**-** Создание двоичных пакетов, например, в формате rpm для Red Hat,
    pkgtool для Solaris и swinstall для HPUX
Лучший способ продемонстрировать, как работает пакет distutils, –
это встать на ноги и приготовиться.
Шаг 1: создать некоторый программный код. Воспользуемся следую
щим сценарием, на примере которого продемонстрируем, как органи
зовать его распространение:

```
#!/usr/bin/env python
#A simple python script we will package
#Distutils Example. Version 0.1
class DistutilsClass(object):
"""Этот класс выводит информацию о самом себе."""
def __init__(self):
print "Hello, I am a distutils distributed script." \
"All I do is print this message."
if __name__ == '__main__':
DistutilsClass()
```
```
Шаг 2: создать файл setup.py в каталоге со сценарием.
#Installer for distutils example script
from distutils.core import setup
setup(name="distutils_example",
version="0.1",
description="A Completely Useless Script That Prints",
author="Joe Blow",
author_email = "joe.blow@pyatl.org",
url = "http://www.pyatl.org")
```
```
Обратите внимание: мы передали функции setup() несколько имено
ванных аргументов, значения которых позднее будут использоваться
как метаданные для идентификации пакета. Учтите, что это очень
простой пример и на самом деле эта функция имеет гораздо большее
число аргументов, которые, например, позволяют разрешать пробле
мы с зависимостями и другие. Мы не будем углубляться в исследова
ние дополнительных параметров настройки, но рекомендуем ознако
миться с ними в официальной электронной документации Python.
Шаг 3: создать дистрибутив.
Теперь, когда у нас имеется простенький сценарий setup.py, можно
создать пакет дистрибутива с исходными текстами, просто запустив
следующую команду в том же каталоге, где находится ваш сценарий
ифайлы README и setup.py :
```

**334** Глава 9. Управление пакетами

```
python setup.py sdist
```
```
Вы должны получить следующий вывод:
```
```
running sdist
warning: sdist: manifest template 'MANIFEST.in' does not exist
(using default file list)
writing manifest file 'MANIFEST'
creating distutils_example0.1
making hard links in distutils_example0.1...
hard linking README.txt distutils_example0.1
hard linking setup.py distutils_example0.1
creating dist
tarcf dist/distutils_example0.1.tar distutils_example0.1
gzipf9 dist/distutils_example0.1.tar
removing 'distutils_example0.1' (and everything under it)
```
```
Теперь все, что необходимо сделать для установки такого пакета, – это
распаковать его и выполнить команду:
```
```
python setup.py install
```
```
Ниже приводятся несколько примеров, которые пригодятся, если воз
никнет необходимость создать пакет в двоичном формате. Обратите
внимание, что эти способы тесно связаны с типом операционной систе
мы, поэтому вы не сможете собрать пакет в формате rpm, например,
в операционной системе OS X. Однако, учитывая изобилие продуктов
виртуализации, это не должно быть для вас большой проблемой. Дос
таточно хранить под рукой несколько виртуальных машин, которыми
можно было бы воспользоваться для сборки пакетов.
Чтобы собрать пакет rpm:
```
```
python setup.py bdist_rpm
```
```
Чтобы собрать пакет в формате pkgtool для Solaris:
```
```
python setup.py bdist_pkgtool
```
```
Чтобы собрать пакет в формате swinstall для HPUX:
```
```
python setup.py bdist_sdux
```
```
Наконец, когда вы выполняете компиляцию полученного пакета, вы
можете настроить каталог, где должна происходить сборка. Обычно
процессы компиляции и установки выполняются одновременно, но вы
можете выбрать для сборки свой каталог, как показано ниже:
python setup.py buildbuildbase=/mnt/python_src/ascript.py
```
```
Когда вы запустите команду install, она скопирует все, что находится
в каталоге сборки, в каталог установки. По умолчанию каталог уста
новки соответствует каталогу site>packages в каталоге установки ин
терпретатора Python, под управлением которого выполняется коман
```

Buildout **335**

```
да, но вы можете указать свой каталог установки , например, смонти
рованный каталог NFS, как в примере выше.
```
**Buildout**

```
Инструмент Buildout был создан Джимом Фултоном (Jim Fulton) из
корпорации Zope Corporation и предназначен для «сборки» новых при
ложений. Этими приложениями могут быть программы на языке Py
thon или другие программы, такие как Apache. Одна из основных це
лей Buildout состоит в том, чтобы обеспечить возможность установки
приложений на разных платформах. Одним из первых экспериментов,
которые провел автор с помощью Buildout, был эксперимент по раз
вертыванию сайта Plone 3.x. С тех пор он понял, что это была всего
лишь вершина айсберга.
Buildout – это один из наиболее интересных новых инструментов
управления пакетами, которые может предложить Python, так как он
позволяет сложным приложениям со сложными зависимостями раз
вертывать самих себя, если в дистрибутиве имеются файл bootstrap.py
и файл с настройками. В следующих разделах мы поделим наше обсу
ждение на две части: использование Buildout и разработка с примене
нием Buildout. Мы также рекомендовали бы вам прочитать руково
дство по Buildout по адресу: http://pypi.python.org/pypi/zc.buildout ,
так как этот неоценимый ресурс содержит самую свежую информацию
о Buildout. Эта документация настолько полная, насколько это воз
можно, и ее обязательно должен прочитать каждый пользователь
Buildout.
```
**Использование Buildout**

```
Несмотря на то, что многие, кто имел дело с технологиями Zope, знали
о существовании Buildout, это оставалось тайной для остальной части
пользователей Python. Buildout – это рекомендуемый механизм раз
вертывания Plone. Для тех, кто не знаком с Plone: это система управ
```
```
ПОРТ РЕТ ЗНА МЕ НИ ТО СТИ: BUILDOUT
```
**Джим Фултон (Jim Fulton)**

```
Джим Фултон – создатель и один из членов проекта Zope Object
Database. Джим также является одним из создателей Zope Object
Publishing Environment и техническим директором Zope Corpo
ration.
```

**336** Глава 9. Управление пакетами

```
ления содержимым для сайтов уровня предприятия, за которой стоит
огромное сообщество разработчиков. Система Plone была чрезвычайно
сложна в установке, пока не появился инструмент Buildout. Теперь
благодаря Buildout установка Plone выполняется тривиально просто.
Многие даже не подозревают, что Buildout можно использовать даже
для управления окружением Python. Buildout – это весьма интеллекту
альное программное обеспечение, которому требуется всего две вещи:
```
**-** Последняя версия _bootstrap.py_. Загрузить ее всегда можно по адресу
    _[http://svn.zope.org/*checkout*/zc.buildout/trunk/bootstrap/bootst>](http://svn.zope.org/*checkout*/zc.buildout/trunk/bootstrap/bootst>)_
    _rap.py_.
**-** Файл _buildout.cfg_ с именами пакетов для установки.
Лучший способ продемонстрировать возможности Buildout состоит
в том, чтобы установить чтонибудь с его помощью. Ноа (Noah) напи
сал инструмент командной строки для удаления дубликатов файлов,
который можно найти в центральном репозитарии Python, PyPI. Мы
попробуем с помощью Buildout развернуть среду Python для запуска
этого инструмента.
Шаг 1: загруить сценарий buildout.py:

```
mkdirp ~/src/buildout_demo
curl http://svn.zope.org/*checkout*/zc.buildout/trunk/
bootstrap/bootstrap.py > ~/src/buildout_demo/bootstrap.py
```
```
Шаг 2: написать простой файл buildout.cfg. Как уже говорилось выше,
Buildout требует для своей работы файл buildout.cfg. Если попытаться
запустить сценарий buildout.py без файла buildout.cfg , будет получено
следующее сообщение:
$ python bootstrap.py
While:
Initializing.
Error: Couldn't open /Users/ngift/src/buildout_demo/buildout.cfg
```
```
Для примера создадим конфигурационный файл, как показано в при
мере 9.3.
```
```
Пример 9.3. Пример конфигурационного файла Buildout
[buildout]
parts = mypython
[mypython]
recipe = zc.recipe.egg
interpreter = mypython
eggs = liten
```
```
Если сохранить этот файл с именем buildout.cfg и затем снова запус
тить сценарий buildout.py, будет получен вывод, как показано в при
мере 9.4.
```

Использование Buildout **337**

```
Пример 9.4. Создание окружения buildout
$ python bootstrap.py
Creating directory '/Users/ngift/src/buildout_demo/bin'.
Creating directory '/Users/ngift/src/buildout_demo/parts'.
Creating directory '/Users/ngift/src/buildout_demo/eggs'.
Creating directory '/Users/ngift/src/buildout_demo/developeggs'.
Generated script '/Users/ngift/src/buildout_demo/bin/buildout'.
```
```
Если заглянуть в эти вновь созданные каталоги, мы найдем выполняе
мые программы, включая отдельный интерпретатор Python в каталоге
bin :
```
```
$ lsl bin
total 24
rwxrxrx 1 ngift staff 362 Mar 4 22:17 buildout
rwxrxrx 1 ngift staff 651 Mar 4 22:23 mypython
```
```
Теперь, когда была выполнена установка инструмента Buildout, мож
но запустить его и пакет, который мы определили ранее, будет рабо
тать, как показано в примере 9.5.
```
```
Пример 9.5. Запуск Buildout и тестирование установки
$ bin/buildout
Getting distribution for 'zc.recipe.egg'.
Got zc.recipe.egg 1.0.0.
Installing mypython.
Getting distribution for 'liten'.
Got liten 0.1.3.
Generated script '/Users/ngift/src/buildout_demo/bin/liten'.
Generated interpreter '/Users/ngift/src/buildout_demo/bin/mypython'.
$ bin/mypython
>>>
$ lsl bin
total 24
rwxrxrx 1 ngift staff 362 Mar 4 22:17 buildout
rwxrxrx 1 ngift staff 258 Mar 4 22:23 liten
rwxrxrx 1 ngift staff 651 Mar 4 22:23 mypython
$ bin/mypython
```
```
>>> import liten
```
```
Наконец, т. к. сценарий «liten» был создан с использованием точки
входа, которые обсуждались ранее в этой главе, то при установке паке
та формата egg помимо модуля автоматически был установлен кон
сольный сценарий в локальный каталог bin в окружении Buildout. Ес
ли попробовать запустить этот сценарий, будет получен вывод, как по
казано ниже:
$ bin/liten
Usage: liten [starting directory] [options]
```

**338** Глава 9. Управление пакетами

```
A commandline tool for detecting duplicates using md5 checksums.
Options:
version show program's version number and exit
h,help show this help message and exit
c,config Path to read in config file
s SIZE,size=SIZE File Size Example: 10bytes, 10KB, 10MB,10GB,10TB, or
plain number defaults to MB (1 = 1MB)
q,quiet Suppresses all STDOUT.
r REPORT,report=REPORT
Path to store duplication report. Default CWD
t,test Runs doctest.
$ pwd
/Users/ngift/src/buildout_demo
```
```
Это очень простой и яркий пример, демонстрирующий, как можно ис
пользовать Buildout для создания изолированной среды и автоматиче
ски развертывать все необходимые зависимости проекта и самой сре
ды. Тем не менее, чтобы продемонстрировать истинную мощь Build
out, нам необходимо рассмотреть еще один аспект этого инструмента.
Buildout обладает полным «контролем» над каталогом, в котором он
выполняется, и при каждом запуске он читает файл buildout.cfg в по
исках инструкций. Это означает, что если удалить пакет egg из спи
ска, это приведет к удалению инструмента командной строки и биб
лиотеки, как показано в примере 9.6.
```
```
Пример 9.6. Удаление записей из конфигурационного файла Buildout
[buildout]
parts =
```
```
Ниже приводится результат повторного запуска Buildout после удале
ния пакетов и интерпретатора из списка. Обратите внимание, что
у Buildout имеется множество параметров командной строки и в дан
ном случае мы указали ключ –N, который всего лишь модифицирует
измененные файлы. Обычно, на каждом перезапуске Buildout пере
страивает полностью свою среду.
```
```
$ bin/buildoutN
Uninstalling mypython.
```
```
Если теперь заглянуть в каталог bin , можно будет убедиться, что ин
терпретатор и инструмент командной строки исчезли. Единственное,
что осталось в нем, это сам инструмент командной строки Buildout:
$ lsl bin/
total 8
rwxrxrx 1 ngift staff 362 Mar 4 22:17 buildout
```
```
Однако, если заглянуть в каталог eggs , можно увидеть, что пакет уста
новлен, но неактивен. Мы не сможем запустить его, так как интерпре
татор отсутствует:
```

Разработка с использованием Buildout **339**

```
$ lsl eggs
total 640
drwxrxrx 7 ngift staff 238 Mar 4 22:54 liten0.1.3py2.5.egg
rwrr 1 ngift staff 324858 Feb 16 23:47 setuptools0.6c8py2.5.egg
drwxrxrx 5 ngift staff 170 Mar 4 22:17 zc.buildout1.0.0py2.5.egg
drwxrxrx 4 ngift staff 136 Mar 4 22:23 zc.recipe.egg1.0.0py2.5.egg
```
**Разработка с использованием Buildout**

```
Теперь, когда мы рассмотрели простой пример создания и удаления
среды, управляемой инструментом Buildout, мы можем двинуться
дальше и создать среду разработки, управляемую Buildout.
Один из наиболее типичных сценариев, когда используется Buildout,
выглядит очень просто. Разработчик может работать над отдельным
пакетом, который находится в репозитарии системы управления вер
сиями. Разработчик извлекает свой проект в каталог верхнего уровня
src. Внутри этого каталога он запускает Buildout, как было описано
выше, примерно с таким конфигурационным файлом:
```
```
[buildout]
develop =.
parts = test
[python]
recipe = zc.recipe.egg
interpreter = python
eggs = ${config:mypkgs}
[scripts]
recipe = zc.recipe.egg:scripts
eggs = ${config:mypkgs}
```
```
[test]
recipe = zc.recipe.testrunner
eggs = ${config:mypkgs}
```
**virtualenv**

```
Согласно описанию на странице в Python Package Index: «virtualenv –
это инструмент создания изолированной среды Python». Основная за
дача, которую решает virtualenv, состоит в устранении конфликтов
между пакетами. Часто один инструмент требует одну версию некото
рого пакета, а другой инструмент – другую версию того же пакета. Это
может породить ситуацию, когда будет нарушена работоспособность
рабочего вебприложения, потому что ктото «случайно» изменит со
держимое глобального каталога site>packages , обновив пакет, чтобы
получить возможность пользоваться другим инструментом.
С другой стороны, разработчик может не иметь права на запись в гло
бальный каталог site>packages , и тогда он может с помощью virtualenv
```

**340** Глава 9. Управление пакетами

```
создать виртуальную среду, изолированную от системной среды Py
thon. Инструмент virtualenv предоставляет отличный способ ликвиди
ровать проблемы еще до того, как они появятся, так как он позволяет
создать новую среду, частично или полностью изолированную от гло
бального каталога site>packages.
Инструмент virtualenv также может «развертывать» виртуальную
среду, позволяя разработчикам наполнять ее только требуемыми па
кетами. По своему действию он очень напоминает Buildout, но в отли
чие от последнего не использует декларативный конфигурационный
файл. Следует заметить, что оба инструмента, Buildout и virtualenv,
очень широко используют библиотеку setuptools, сопровождением ко
торой в настоящее время занимается Филлип Дж. Эби (Phillip J. Eby).
```
```
Так как же пользоваться инструментом virtualenv? Самый простой
способ – установить его с помощью easy_install:
```
```
sudo easy_install virtualenv
```
```
Если вы планируете использовать virtualenv только с одной версией
Python, такой подход вполне оправдывает себя. Если у вас установле
но несколько версий Python, например, Python 2.4, Python 2.5, Python
2.6 и, возможно, Python 3000, и при этом они установлены в один и тот
же каталог bin , такой как /usr/bin , тогда лучше будет использовать
иной подход, поскольку в один и тот же каталог можно установить
только один сценарий virtualenv.
Один из способов получить несколько сценариев virtualenv, работаю
щих с разными версиями Python, состоит в том, чтобы просто загру
зить последнюю версию virtualenv и создать псевдонимы для каждой
версии Python. Ниже описывается, как это сделать:
```
1. curl _[http://svn.colorstudy.com/virtualenv/trunk/virtualenv.py](http://svn.colorstudy.com/virtualenv/trunk/virtualenv.py) > virtu>_
    _alenv.py_
2. sudo cp _virtualenv.py /usr/local/bin/virtualenv.py_

```
ПОРТ РЕТ ЗНА МЕ НИ ТО СТИ: VIRTUALENV
```
**Ян Бикинг (Ian Bicking)**

```
Ян Бикинг отвечает за такое количество пакетов
Python, что ему часто бывает сложно уследить за
всем. Им был написан пакет Webob, являющийся
частью Google App Engine, Paste, virtualenv, SQL
Object и многие другие пакеты. Вы можете посе
тить его блог по адресу: http://blog.ianbicking.org/.
```

virtualenv **341**

3. Создать два псевдонима в командной оболочке Bash или zsh:
    alias virtualenvpy24="/usr/bin/python2.4 /usr/local/bin/virtualenv.py"
    alias virtualenvpy25="/usr/bin/python2.5 /usr/local/bin/virtualenv.py"
    alias virtualenvpy26="/usr/bin/python2.6 /usr/local/bin/virtualenv.py"

```
Создав среду с несколькими сценариями, можно двинуться дальше
и создать несколько контейнеров virtualenv, по одному для каждой
версии Python, которые нам потребуются. Ниже показано, как это де
лается.
Создание виртуальной среды Python 2.4:
$ virtualenvpy24 /tmp/sandbox/py24ENV
New python executable in /tmp/sandbox/py24ENV/bin/python
Installing setuptools.................done.
$ /tmp/sandbox/py24ENV/bin/python
Python 2.4.4 (#1, Dec 24 2007, 15:02:49)
[GCC 4.0.1 (Apple Inc. build 5465)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>>
$ ls /tmp/sandbox/py24ENV/
bin/ lib/
$ ls /tmp/sandbox/py24ENV/bin/
activate easy_install* easy_install2.4* python* python2.4@
```
```
Создание виртуальной среды Python 2.5:
```
```
$ virtualenvpy25 /tmp/sandbox/py25ENV
New python executable in /tmp/sandbox/py25ENV/bin/python
Installing setuptools..........................done.
$ /tmp/sandbox/py25ENV/bin/python
Python 2.5.1 (r251:54863, Jan 17 2008, 19:35:17)
[GCC 4.0.1 (Apple Inc. build 5465)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>>
$ ls /tmp/sandbox/py25ENV/
bin/ lib/
$ ls /tmp/sandbox/py25ENV/bin/
activate easy_install* easy_install2.5* python* python2.5@
```
```
Если внимательно взглянуть на вывод команд, можно заметить, что
virtualenv создал каталоги bin и lib. Внутри каталога bin находится ин
терпретатор python, который использует каталог lib как собственный
локальный каталог site>packages. Другой заметной особенностью яв
ляется наличие предустановленного сценария easy_install, что позво
ляет устанавливать пакеты в виртуальную среду.
Наконец, важно отметить, что существует два способа работы с создан
ной виртуальной средой. Можно запустить виртуальную среду, явно
указав полный путь к интерпретатору:
$ /src/virtualenvpy24/bin/python2.4
```

**342** Глава 9. Управление пакетами

```
Или можно использовать сценарий activate, находящийся в каталоге
bin требуемой виртуальной среды, чтобы активировать эту среду без
ввода полного пути. Это дополнительный способ, который вы можете
использовать, но он не является обязательным, так как вы всегда мо
жете ввести полный путь к требуемой виртуальной среде. Дуг Хелл
манн (Doug Hellmann), один из рецензентов этой книги, написал инте
ресный сценарий, доступный по адресу: http://www.doughellmann.com
/projects/virtualenvwrapper/. Он использует сценарий activate и меню
на языке Bash, которое позволяет выбирать, какая среда должна быть
запущена.
```
**Создание собственных виртуальных окружений**

```
Версия virtualenv 1.0, которая была текущей на момент написания
этой книги, включает поддержку создания сценариев развертывания
собственных виртуальных окружений. Добиться этого можно с помо
щью функции virtualenv.create_bootstrap_script(text). Эта функция
создает сценарий развертывания, который по своему действию напо
минает virtualenv, но обладает расширенными возможностями анали
за параметров с помощью функций, определяемых пользователем,
extend_parser() и adjust_options(), и позволяет выполнять действия по
сле установки с помощью функции after_install().
Давайте посмотрим, насколько просто создать собственный сценарий
развертывания, который установит virualenv и заданный набор паке
тов в новую среду. Возьмем опять в качестве примера пакет liten. Мы
можем с помощью virtualenv создать совершенно новую виртуальную
среду и установить в нее пакет liten. В примере 9.7 показано, как соз
дается сценария развертывания собственной виртуальной среды, кото
рый устанавливает пакет liten.
```
```
Пример 9.7. Пример сценария, развертывающего новую виртуальную среду
import virtualenv, textwrap
output = virtualenv.create_bootstrap_script(textwrap.dedent("""
import os, subprocess
def after_install(options, home_dir):
etc = join(home_dir, 'etc')
if not os.path.exists(etc):
os.makedirs(etc)
subprocess.call([join(home_dir, 'bin', 'easy_install'),
'liten'])
"""))
f = open('litenbootstrap.py', 'w').write(output)
```
```
Этот сценарий является измененной версией примера из документа
ции к virtualenv и здесь особое внимание следует обратить на послед
ние две строки:
```
```
subprocess.call([join(home_dir, 'bin', 'easy_install'),
'liten'])
```

virtualenv **343**

```
"""))
f = open('litenbootstrap.py', 'w').write(output)
```
```
В двух словах, эти строки предписывают функции after_install() вы
полнить запись в новый файл с именем liten>bootstrap.py , расположен
ный в текущем рабочем каталоге, и затем с помощью easy_install уста
новить модуль liten. Важно отметить, что этот фрагмент программного
кода создаст файл bootstrap.py , который затем будет использоваться
при запуске. После запуска этого сценария мы получим файл liten>
bootstrap.py , который потом можно передать разработчику или конеч
ному пользователю.
Если запустить сценарий liten–bootstrap.py без параметров, от него бу
дет получен следующий вывод:
```
```
$ python litenbootstrap.py
You must provide a DEST_DIR
Usage: litenbootstrap.py [OPTIONS] DEST_DIR
Options:
version show program's version number and exit
h,help show this help message and exit
v,verbose Increase verbosity
q,quiet Decrease verbosity
clear Clear out the nonroot install and start from scratch
nositepackages Don't give access to the global sitepackages dir to the
virtual environment
```
```
Если запустить этот сценарий, указав ему каталог назначения, будет
получен следующий вывод:
$ python litenbootstrap.pynositepackages /tmp/litenENV
New python executable in /tmp/litenENV/bin/python
Installing setuptools..........................done.
Searching for liten
Best match: liten 0.1.3
Processing liten0.1.3py2.5.egg
Adding liten 0.1.3 to easyinstall.pth file
Installing liten script to /tmp/litenENV/bin
Using /Library/Python/2.5/sitepackages/liten0.1.3py2.5.egg
Processing dependencies for liten
Finished processing dependencies for liten
```
```
Наш интеллектуальный сценарий автоматически создал среду с на
шим модулем. Если теперь запустить инструмент liten с полным путем
к виртуальной среде, мы получим следующее:
$ /tmp/litenENV/bin/liten
Usage: liten [starting directory] [options]
A commandline tool for detecting duplicates using md5 checksums.
```
```
Options:
```

**344** Глава 9. Управление пакетами

```
version show program's version number and exit
h,help show this help message and exit
c,config Path to read in config file
s SIZE,size=SIZE File Size Example: 10bytes, 10KB, 10MB,10GB,10TB, or
plain number defaults to MB (1 = 1MB)
q,quiet Suppresses all STDOUT.
r REPORT,report=REPORT
Path to store duplication report. Default CWD
t,test Runs doctest.
```
```
Этот прием стоит того, чтобы знать о нем, так как он позволяет созда
вать полностью изолированную и развернутую виртуальную среду.
Мы надеемся, что в этом разделе нам удалось показать одно из основ
ных преимуществ virutalenv – его простоту в использовании и изуче
нии. Больше, чем что бы то ни было, virtualenv почитает священное
правило KISS (keep its syntax simple – сохраняй синтаксис как можно
проще), и одной этой причины уже достаточно, чтобы подумать об ис
пользовании этого инструмента для управления изолированными сре
дами разработки. Если у вас имеются дополнительные вопросы, касаю
щиеся этого инструмента, обязательно посетите почтовую рассылку
virtualenv по адресу http://groups.google.com/group/python>virtualenv/.
```
**Менеджер пакетов EPM**

```
Менеджер пакетов EPM создает «родные» пакеты для каждой опера
ционной системы, поэтому он должен присутствовать в любой систе
ме, где производится «сборка» пакетов. Благодаря невероятным успе
хам технологий виртуализации за последние несколько лет не состав
ляет никакого труда установить и настроить несколько виртуальных
машин. Я создал маленький кластер виртуальных машин (с мини
мальным потреблением памяти), которые загружаются в режиме, эк
вивалентном уровню 3 в Red Hat, – чтобы проверить примеры про
граммного кода, которые приводятся в этой книге.
Впервые возможности EPM продемонстрировал мне мой коллега, ко
торый одновременно является одним из разработчиков EPM. Я тогда
искал инструмент, который позволил бы мне создавать пакеты про
граммного обеспечения, которое я разрабатывал, в зависимости от ти
па операционной системы, и он назвал EPM. После прочтения некото
рой документации на сайте http://www.epmhome.org/epm>book.html
я был приятно удивлен, насколько простым и безболезненным оказал
ся процесс создания пакетов. В этом разделе мы пройдем все этапы
создания пакета программного обеспечения, готового к установке на
самых разных платформах: Ubuntu, OS X, Red Hat, Solaris и FreeBSD.
Эти шаги легко могут быть применены к другим системам, поддержи
вающим EPM, таким как AIX или HPUX.
```

Менеджер пакетов EPM **345**

```
Прежде чем перейти к изучению, приведу некоторые начальные сведе
ния о EPM. Согласно официальной документации, этот менеджер па
кетов изначально предусматривал сборку дистрибутивов программно
го обеспечения в двоичном формате, на основе общей спецификации
формата. Благодаря такой постановке задачи одни и те же файлы ди
стрибутивов могли использоваться в любых операционных системах
идля всех форматов.
```
**Требования и установка менеджера пакетов EPM**

```
Для установки EPM требуется только командная оболочка типа
Bourne shell, компилятор языка C и программы make и gzip. Все эти
утилиты легко получить практически в любой UNIXподобной систе
ме, если они уже не установлены. После того как исходные тексты
EPM будут загружены, необходимо выполнить следующую последова
тельность команд:
```
```
./configure
make
make install
```
**Создание дистрибутива Hello World с инструментом**

**командной строки**

```
Прежде чем приступать к созданию пакетов для любой UNIXподобной
системы, необходимо иметь чтолибо, что требуется упаковать. В духе
сложившихся традиций мы сначала создадим простой инструмент ко
мандной строки с именем hello_epm.py, как показано в примере 9.8.
```
```
Пример 9.8. Инструмент командной строки Hello EPM
#!/usr/bin/env python
import optparse
```
```
def main():
p = optparse.OptionParser()
p.add_option('os', 'o', default="*NIX")
options, arguments = p.parse_args()
print 'Hello EPM, I like to make packages on %s' % options.os
if __name__ == '__main__':
main()
```
```
Если запустить этот сценарий, будет получен следующий вывод:
```
```
$ python hello_epm.py
Hello EPM, I like to make packages on *NIX
```
```
$ python hello_epm.pyos RedHat
Hello EPM, I like to make packages on RedHat
```

**346** Глава 9. Управление пакетами

**Создание платформозависимых пакетов**

**с помощью EPM**

```
«Основы» использования настолько просты, что может вызвать у вас
недоумение, почему раньше вы никогда не пользовались EPM для упа
ковки кроссплатформенного программного обеспечения. EPM читает
файл(ы) с «перечнем», описывающим ваш пакет с программным обес
печением. Комментарии в этом «перечне» начинаются с символа #, ди
рективы – с символа %, переменные – с символа $ и, наконец, строки
с именами файлов, каталогов, сценариев инициализации и символи
ческих ссылок начинаются с алфавитного символа.
С помощью EPM можно создавать как универсальные кроссплатфор
менные сценарии установки, так и платформозависимые пакеты. Мы
сосредоточимся на создании платформозависимых файлов пакетов.
Следующий шаг на пути к созданию платформозависимого пакета за
ключается в создании манифеста, или «перечня», описывающего па
кет. В примере 9.9 приводится шаблон манифеста, использовавшийся
нами для создания пакета с нашим инструментом командной строки
hello_epm. Вообще, этот шаблон является настолько универсальным,
что вы можете использовать его с незначительными изменениями для
создания своих собственных инструментов.
```
```
Пример 9.9. Шаблон «перечня» для EPM
#Файл перечня для EPM может использоваться для создания пакетов под
#любую из следующих платформ
#epmf format foo bar.list ENTER
#Параметр format может быть одним из следующих ключевых слов:
#aix пакеты с программным обеспечением для AIX.
#bsd пакеты с программным обеспечением для FreeBSD, NetBSD или OpenBSD.
#depot или swinstall пакеты с программным обеспечением для HPUX.
#dpkg пакеты с программным обеспечением для Debian.
#inst или tardist пакеты с программным обеспечением для IRIX.
#native "родные" для текущей платформы пакеты (RPM, INST, DEPOT, PKG, ...).
#osx пакеты с программным обеспечением для MacOS X.
#pkg пакеты с программным обеспечением для Solaris.
#portable переносимые пакеты с программным обеспечением (по умолчанию).
#rpm пакеты с программным обеспечением для Red Hat.
#setld пакеты с программным обеспечением для Tru64 (setld).
#slackware пакеты с программным обеспечением для Slackware.
# Раздел с информацией о продукте
```
```
%product hello_epm
%copyright 2008 Py4SA
%vendor O’Reilly
%license COPYING
%readme README
%description Command Line Hello World Tool
%version 0.1
```

Менеджер пакетов EPM **347**

```
# Переменные для сценария автоматической конфигурации
$prefix=/usr
$exec_prefix=/usr
$bindir=${exec_prefix}/bin
$datadir=/usr/share
$docdir=${datadir}/doc/
$libdir=/usr/lib
$mandir=/usr/share/man
$srcdir=.
# Выполняемые файлы
```
```
%system all
f 0555 root sys ${bindir}/hello_epm hello_epm.py
```
```
# Документация
%subpackage documentation
f 0444 root sys ${docdir}/README $srcdir/README
f 0444 root sys ${docdir}/COPYING $srcdir/COPYING
f 0444 root sys ${docdir}/hello_epm.html $srcdir/doc/hello_epm.html
# Файлы страниц справочного руководства (man)
```
```
%subpackage man
%description Man pages for hello_epm
f 0444 root sys ${mandir}/man1/hello_epm.1 $srcdir/doc/hello_epm.man
```
```
Если заглянуть внутрь файла, который мы назвали hello_epm.list ,
можно заметить, что мы определили переменную $srcdir, значение ко
торой соответствует текущему рабочему каталогу. Чтобы создать па
кет для любой из возможных платформ, нам необходимо создать в те
кущем рабочем каталоге следующие файлы и каталоги: README ,
COPYING , doc/hello_epm.html и doc/hello_epm.man. В этом же катало
ге должен находиться и наш сценарий hello_epm.py.
При желании мы можем «обмануть» EPM, просто поместив пустые
файлы в каталог, который предполагается упаковать, выполнив сле
дующие команды:
$ pwd
/tmp/release/hello_epm
$ touch README
$ touch COPYING
$ mkdir doc
$ touch doc/hello_epm.html
$ touch doc/hello_epm.man
```
```
Если теперь заглянуть в наш каталог, можно увидеть следующее его
содержимое:
```
```
$ lslR
total 16
rwrr 1 ngift wheel 0 Mar 10 04:45 COPYING
```

**348** Глава 9. Управление пакетами

```
rwrr 1 ngift wheel 0 Mar 10 04:45 README
drwxrxrx 4 ngift wheel 136 Mar 10 04:45 doc
rwrr 1 ngift wheel 1495 Mar 10 04:44 hello_epm.list
rwrr@ 1 ngift wheel 278 Mar 10 04:10 hello_epm.py
```
```
./doc:
total 0
rwrr 1 ngift wheel 0 Mar 10 04:45 hello_epm.html
rwrr 1 ngift wheel 0 Mar 10 04:45 hello_epm.man
```
**Создание пакета**

```
Теперь у нас имеется каталог с файлом «перечня», содержащий дирек
тивы, которые могут быть выполнены на любой платформе, где имеет
ся поддержка EPM. Теперь все, что осталось сделать, это запустить ко
манду epm – f, добавив к ней название платформы и имя файла перечня.
В примере 9.10 показано, как это выглядит в OS X.
```
```
Пример 9.10. Создание «родного» для OS X инсталлятора с помощью EPM
$ epmf osx hello_epm hello_epm.list
epm: Product names should only contain letters and numbers!
^C
$ epmf osx helloEPM hello_epm.list
$ ll
total 16
rwrr 1 ngift wheel 0 Mar 10 04:45 COPYING
rwrr 1 ngift wheel 0 Mar 10 04:45 README
drwxrxrx 4 ngift wheel 136 Mar 10 04:45 doc
rwrr 1 ngift wheel 1495 Mar 10 04:44 hello_epm.list
rwrr@ 1 ngift wheel 278 Mar 10 04:10 hello_epm.py
drwxrwxrwx 6 ngift staff 204 Mar 10 04:52 macosx10.5intel
```
```
Обратите внимание на предупреждение, которое было получено при
попытке использовать символ подчеркивания в имени пакета. По этой
причине мы дали пакету другое название и повторно запустили коман
ду. В результате был создан каталог macosx>10.5>intel со следующим
содержимым:
```
```
$ lsla macosx10.5intel
total 56
drwxrwxrwx 4 ngift staff 136 Mar 10 04:54.
drwxrxrx 8 ngift wheel 272 Mar 10 04:54 ..
rwrr@ 1 ngift staff 23329 Mar 10 04:54 helloEPM0.1macosx10.5
intel.dmg
drwxrxrx 3 ngift wheel 102 Mar 10 04:54 helloEPM.mpkg
```
```
Это очень удобно, так как был создан файл архива .dmg , который явля
ется «родным» форматом для OS X, содержащий наш инсталлятор
и инсталлятор, «родной» для OS X.
Если теперь запустить установку, можно заметить, что OS X установит
пустые файлы со страницей справочного руководства и с документа
```

Менеджер пакетов EPM **349**

```
цией и выведет содержимое пустого файла с лицензионным соглаше
нием. В конечном итоге наш инструмент будет помещен точно туда,
куда было указано, и ему будет присвоено заданное нами имя:
$ which hello_epm
/usr/bin/hello_epm
$ hello_epm
Hello EPM, I like to make packages on *NIX
$ hello_epmh
Usage: hello_epm [options]
Options:
h,help show this help message and exit
o OS,os=OS
$
```
**Вывод: EPM действительно прост в использовании**

```
Если с помощью команды scp – r скопировать каталог /tmp/release/hel
lo_epm в Red Hat, Ubuntu или Solaris, мы сможем выполнить одну и ту
же команду создания пакета, за исключением названия платформы,
и она «просто будет работать». В главе 8 мы узнали, как создать «фер
му» для сборки, чтобы вы могли моментально создавать кроссплат
форменные пакеты. Обратите внимание, что все представленные ис
ходные тексты примеров наряду с созданным пакетом, доступны для
загрузки. Теперь у вас есть все необходимые знания, чтобы за несколь
ко минут, немного изменив пример, начать создавать свои собствен
ные кроссплатформенные пакеты.
Менеджер пакетов EPM в состоянии предложить еще целый ряд допол
нительных особенностей, но они выходят далеко за рамки этой книги.
Если вам интересно узнать о том, как создавать пакеты с учетом зави
симостей, как запускать пред и постустановочные сценарии и так да
лее, то вам следует обратиться непосредственно к официальной доку
ментации EPM, где описываются все эти случаи и многое другое.
```

**10**

### 10. Процессы и многозадачность

**Введение**

Обращение с процессами для системного администратора UNIX/Linux –
это реалии жизни. Вы должны знать о сценариях запуска системных
служб, уровнях запуска, демонах, о заданиях планировщика cron,
о долгоживущих процессах, о многозадачности и о массе других про
блем. К счастью, язык Python делает работу с процессами удивительно
простым делом. Начиная с версии Python 2.4, появился универсаль
ный модуль subprocess, позволяющий порождать новые процессы
и обмениваться информацией с ними через устройства стандартного
ввода, стандартного вывода и стандартного вывода сообщений об ошиб
ках. Обмен информацией с процессами – это лишь один из аспектов ра
боты с ними; не менее важно понимать, как развертывать и управлять
процессами, работающими продолжительное время.

**Модуль subprocess**

```
В версии Python 2.4 появился новый модуль subprocess, занявший ме
сто нескольких старых модулей: os.system, os.spawn, os.popen и popen2.
Модуль subprocess принес революционные изменения в жизнь систем
ных администраторов и разработчиков, которым приходится иметь
дело с процессами и постоянно прибегать к командам оболочки. Те
перь имеется универсальный модуль для работы с процессами, кото
рый, в конечном счете, может использоваться для управления группа
ми процессов.
Модуль subprocess можно считать самым важным для системного ад
министратора модулем, потому что он обеспечивает унифицирован
ный интерфейс к системе. Модуль subprocess отвечает в языке Python
за выполнение следующих действий: порождение новых процессов,
```

Модуль subprocess **351**

```
соединение с потоками стандартного ввода, стандартного вывода,
стандартного вывода сообщений об ошибках и получение кодов воз
врата от этих процессов.
Чтобы подогреть ваш интерес, будем следовать принципу KISS (Keep
Its Syntax Simple – сохраняй синтаксис как можно проще) и с помо
щью модуля subprocess выполним простейший вызов системной ути
литы, как показано в примере 10.1.
```
```
Пример 10.1. Простейший пример использования модуля subprocess
In [4]: subprocess.call('dfk', shell=True)
Filesystem 1024blocks Used Available Capacity Mounted on
/dev/disk0s2 97349872 80043824 17050048 83% /
devfs 106 106 0 100% /dev
fdesc 1 1 0 100% /dev
maphosts 0 0 0 100% /net
map auto_home 0 0 0 100% /home
Out[4]: 0
```
```
Используя тот же простой синтаксис, можно использовать перемен
ные окружения. В примере 10.2 показано, как можно получить объем
дискового пространства, занимаемого домашним каталогом.
```
```
Пример 10.2. Объем используемого дискового пространства
In [7]: subprocess.call('duhs $HOME', shell=True)
28G /Users/ngift
Out[7]: 0
```
```
Следует отметить один интересный прием, позволяющий при исполь
зовании модуля subprocess подавить вывод в поток стандартного выво
да. Многие интересуются только возможностью запускать команды
системы, но никак не беспокоятся о стандартном выводе. Часто в та
ких случаях бывает необходимо подавить стандартный вывод вызова
subprocess.call(). К счастью, сделать это очень просто, как показано
в примере 10.3.
```
```
Пример 10.3. Подавление стандартного вывода вызова subprocess.call()
In [3]: import subprocess
```
```
In [4]: ret = subprocess.call("pingc 1 10.0.1.1",
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
```
```
По поводу этих двух примеров и вызова subprocess.call() имеется не
сколько общих примечаний. Обычно при использовании функции sub
process.call() необходимо просто запустить команду, а вывод от нее
сохранять не требуется. Если же необходимо захватить вывод коман
ды, то следует использовать функцию subprocess.Popen(). Между функ
циями subprocess.call() и subprocess.Popen() существует еще одно су
```

**352** Глава 10. Процессы и многозадачность

```
щественное отличие. Функция subprocess.call() блокирует выполне
ние сценария до получения ответа, в то время как функция subpro
cess.Popen() – нет.
```
**Использование кодов возврата с помощью**

**модуля subprocess**

```
Интересно заметить, что при использовании subprocess.call() можно
получать коды возврата, чтобы определить, насколько успешно была
выполнена команда. Если у вас есть опыт программирования на языке
C или Bash, вы должны быть близко знакомы с кодами возврата. Часто
взаимозаменяемые фразы «код выхода» или «код возврата» использу
ются для обозначения кода состояния системного процесса.
Каждый процесс возвращает код возврата при выходе, и значение ко
да возврата может использоваться, чтобы определить, какие действия
должна предпринять программа. Вообще, если программа возвращает
значение, отличное от нуля, это свидетельствует об ошибке. Самое оче
видное для разработчика использование кода возврата – определить,
какие действия выполнять, если процесс вернул значение кода, отлич
ное от нуля, свидетельствующее об ошибке. Но существует множество
более интересных, хотя и не таких очевидных способов использования
кодов возврата. Существуют специальные значения кодов возврата,
которые свидетельствуют о том, что искомый объект не найден, что
файл не является исполняемой программой или программа была за
вершена комбинацией клавиш CtrlC. В этом разделе мы будем исполь
зовать все эти коды возвратов в программах на языке Python.
В следующем списке приводятся наиболее распространенные коды
возврата с их назначением:
0 Успешное завершение
1 Общая ошибка
2 Неправильное использование встроенных команд оболочки
126 Вызываемая команда не может быть выполнена
127 Команда не найдена
128 Неверный аргумент команды exit
128+n Фатальная ошибка по сигналу «n»
130 Сценарий был завершен нажатием комбинации клавиш CtrlC
255 Указан код завершения за пределами допустимого диапазона
Наиболее практичный пример, где эти сведения могли бы применять
ся, – это использование кодов 0 и 1, которые просто свидетельствуют об
успешном или неудачном завершении только что выполненной коман
ды. Рассмотрим несколько простых примеров использования кодов,
возвращаемых функцией subprocess.call(). Взгляните на пример 10.4.
```

Модуль subprocess **353**

```
Пример 10.4. Код, возвращаемый функцией subprocess.call() в случае неудачи
In [16]: subprocess.call("ls /foo", shell=True)
ls: /foo: No such file or directory
Out[16]: 1
```
```
Поскольку этот каталог отсутствует, мы получили код возврата 1, сви
детельствующий об ошибке. Мы можем записывать код возврата в пе
ременную и затем использовать его в условных инструкциях, как по
казано в примере 10.5.
```
```
Пример 10.5. Условные инструкции, проверяющие код возврата,
получаемый от функции subprocess.call()
In [25]: ret = subprocess.call("ls /foo", shell=True)
ls: /foo: No such file or directory
In [26]: if ret == 0:
....: print "success"
....: else:
....: print "failure"
....:
....:
failure
```
```
Ниже приводится пример получения кода возврата «команда не най
дена», который имеет значение 127. Это может быть полезно для соз
дания инструмента, который может пытаться запускать различные
похожие команды оболочки на основе информации об их доступности.
Например, можно было бы сначала попробовать запустить команду
rsync, и если будет получен код возврата 127, попытаться выполнить
команду scp – r, как показано в примере 10.6.
```
```
Пример 10.6. Код 127, возвращаемый функцией subprocess.call()
In [28]: subprocess.call("rsync /foo /bar", shell=True)
/bin/sh: rsync: command not found
Out[28]: 127
```
```
Возьмем предыдущий пример и сделаем его менее абстрактным. Часто
при создании кроссплатформенного программного кода, который дол
жен работать в различных UNIXподобных системах, вы можете столк
нуться с ситуацией, когда для достижения определенного результата
необходимо использовать различные системные программы в зависи
мости от того, в какой операционной системе выполняется сценарий.
Каждая из систем HPUX, AIX, Solars, FreeBSD и Red Hat может
иметь разные утилиты, которые делают то, что вам требуется. Сцена
рий мог бы попытаться выполнить с помощью модуля subprocess сна
чала одну команду, а получив код возврата 127, попытаться выпол
нить другую команду, и так далее.
К сожалению, значения кодов возврата могут изменяться от системы
к системе, поэтому, если вы пишете кроссплатформенный сценарий,
возможно, желательнее будет анализировать лишь нулевое и ненуле
```

**354** Глава 10. Процессы и многозадачность

```
вое значение кода выхода. Ради примера, ниже показан код возврата,
который был получен в Solaris 10 при выполнении той же команды,
что раньше выполнялась в Red Hat Enterprise Linux 5:
ash3.00# python
Python 2.4.4 (#1, Jan 9 2007, 23:31:33) [C] on sunos5
Type "help", "copyright", "credits" or "license" for more information.
>>> import subprocess
>>> subprocess.call("rsync", shell=True)
/bin/sh: rsync: not found
1
```
```
Мы попрежнему можем использовать определенные коды возврата,
предварительно определив тип операционной системы. После опреде
ления типа системы можно было бы проверить наличие определенной
команды. Если вы предполагаете писать такой программный код, тогда
для вас будет совсем нелишним познакомиться поближе с модулем
platform. О работе с этим модулем подробно рассказывалось в главе 8,
поэтому вы можете обращаться к ней за дополнительной информацией.
Взгляните на пример 10.7, в котором модуль platform используется
в интерактивном режиме в оболочке IPython, чтобы определить, ка
кую команду передать функции subprocess.call().
```
```
Пример 10.7. Использование модулей platform и subprocess, чтобы убедиться,
что команда выполняется в Solaris 10
In [1]: import platform
In [2]: import subprocess
In [3]: platform?
Namespace: Interactive
File: /usr/lib/python2.4/platform.py
Docstring:
This module tries to retrieve as much platformidentifying data as
possible. It makes this information available via function APIs.
(Этот модуль пытается получить максимально возможный объем информации,
идентифицирующей операционную систему, и обеспечивает доступ к этой
информации через функции API.)
If called from the command line, it prints the platform
information concatenated as single string to stdout. The output
format is useable as part of a filename.
(При вызове из командной строки выводит на устройство stdout информацию
о платформе в виде единой строки. Строка имеет такой формат, что может
использоваться как имя файла.)
In [4]: if platform.system() == 'SunOS':
....: print "yes"
....:
yes
In [5]: if platform.release() == '5.10':
....: print "yes"
```

Модуль subprocess **355**

```
....:
yes
```
```
In [6]: if platform.system() == 'SunOS':
...: ret = subprocess.call('cp /tmp/foo.txt /tmp/bar.txt', shell=True)
...: if ret == 0:
...: print "Success, the copy was made on %s %s " %
(platform.system(), platform.release())
...:
Success, the copy was made on SunOS 5.10
```
```
Как видите, модуль platform в соединении с функцией subprocess.call()
может оказаться эффективным средством в создании кроссплатфор
менного программного кода. За подробной информацией об использо
вании модуля platform при создании кроссплатформенного про
граммного кода для UNIXподобных систем обращайтесь к главе 8.
Взгляните на пример 10.8.
```
```
Пример 10.8. Захват вывода от команды средствами модуля subprocess
In [1]: import subprocess
In [2]: p = subprocess.Popen("dfh", shell=True, stdout=subprocess.PIPE)
In [3]: out = p.stdout.readlines()
In [4]: for line in out:
...: print line.strip()
...:
...:
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 78Gi 15Gi 85% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
```
```
Обратите внимание, что метод readlines() возвращает список, в кото
ром строки завершаются символом новой строки. Для их удаления мы
использовали вызов метода line.strip(). Кроме того, модуль subprocess
поддерживает возможность взаимодействия с устройствами стандарт
ного ввода и стандартного вывода для создания каналов (или цепочек
команд). Ниже приводится простой пример взаимодействия с устройст
вом стандартного вывода процесса. На языке Python можно реализо
вать такую интересную вещь, как «фабрику» цепочек команд, которая
выглядела бы на на языке Bash устрашающе. Всего несколько строк
простого программного кода, и мы можем выполнять и выводить ре
зультаты последовательности команд, число которых определяется
числом аргументов, как показано в примере 10.9.
```
```
Пример 10.9. «Фабрика» команд с использованием модуля subprocess
def multi(*args):
for cmd in args:
```

**356** Глава 10. Процессы и многозадачность

```
p = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE)
out = p.stdout.read()
print out
```
```
Ниже приводится пример этой простой функции в действии:
```
```
In [28]: multi("dfh", "ls l /tmp", "tail /var/log/system.log")
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 80Gi 13Gi 87% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
lrwxrxrx@ 1 root admin 11 Nov 24 23:37 /tmp> private/tmp
```
```
Feb 21 07:18:50 dhcp126 /usr/sbin/ocspd[65145]: starting
Feb 21 07:19:09 dhcp126 login[65151]: USER_PROCESS: 65151 ttys000
Feb 21 07:41:05 dhcp126 login[65197]: USER_PROCESS: 65197 ttys001
Feb 21 07:44:24 dhcp126 login[65229]: USER_PROCESS: 65229 ttys002
```
```
Благодаря мощи языка Python и синтаксической конструкции *args
мы можем запускать последовательности из произвольного числа ко
манд, используя нашу функцию в качестве фабрики. Каждая команда
извлекается из начала списка методом args.pop(0).^1 Если бы мы ис
пользовали вызов метода без аргумента args.pop(), команды извлека
лись бы в обратном порядке. Поскольку такой способ извлечения ко
манд может приводить к путанице, мы переписали функцию, реализо
вав ее на основе простого цикла for:^2
```
```
def multi(*args):
for cmd in args:
p = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE)
out = p.stdout.read()
print out
```
(^1) Метод pop() в приведенном примере не используется, кроме того, args – это
кортеж, а у кортежей нет метода pop(). Вероятно, раньше, в черновом вари
анте книги, этот пример был реализован иначе, с преобразованием кортежа
аргументов в список аргументов. Такая функция могла бы выглядеть при
мерно так:
def multi(*args):
cmd = list(args)
while len(cmd) > 0:
p = subprocess.Popen(cmd.pop(0), shell=True,
stdout = subprocess.PIPE)
out = p.stdout.read()
print out
_Прим. перев._
(^2) Этот пример полностью повторяет предыдущий... См. сноску 1. – _Прим. пе>
рев._


Модуль subprocess **357**

```
Системным администраторам часто приходится запускать последова
тельности команд, поэтому определенно имеет смысл создать модуль,
который упростил бы эту возможность. Давайте посмотрим, как мож
но было бы реализовать такой модуль с применением механизма на
следования. Исходный текст модуля приводится в примере 10.10.
```
```
Пример 10.10. Модуль>обертка вокруг модуля subprocess
#!/usr/bin/env python
from subprocess import call
import time
import sys
```
```
"""
subtube – это модуль, упрощающий и автоматизирующий некоторые аспекты
применения subprocess
"""
```
```
class BaseArgs(object):
"""Основной класс, выполняющий разбор именованных аргументов"""
```
```
def __init__(self, *args, **kwargs):
self.args = args
self.kwargs = kwargs
if self.kwargs.has_key("delay"):
self.delay = self.kwargs["delay"]
else:
self.delay = 0
if self.kwargs.has_key("verbose"):
self.verbose = self.kwargs["verbose"]
else:
self.verbose = False
def run (self):
"""Вы должны реализовать метод run"""
raise NotImplementedError
```
```
class Runner(BaseArgs):
"""
Упрощает вызов subprocess.call и запускает последовательность команд.
Конструктор класса Runner принимает N позиционных аргументов
и следующие необязательные аргументы:
[необязательные именованные аргументы]
delay=1, задержка в секундах
verbose=True, подробный отчет о выполняемых действиях
```
```
Порядок использования:
cmd = Runner("lsl", "df h", verbose=True, delay=3)
cmd.run()
"""
```
```
def run(self):
for cmd in self.args:
```

**358** Глава 10. Процессы и многозадачность

```
if self.verbose:
print "Running %s with delay=%s" % (cmd, self.delay)
time.sleep(self.delay)
call(cmd, shell=True)
```
```
А теперь посмотрим, как пользоваться нашим новым модулем:
In [8]: from subtube import Runner
In [9]: r = Runner("dfh", "du h /tmp")
In [10]: r.run()
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 80Gi 13Gi 87% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
4.0K /tmp
In [11]: r = Runner("dfh", "du h /tmp", verbose=True)
```
```
In [12]: r.run()
Running dfh with delay=0
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 80Gi 13Gi 87% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
Running duh /tmp with delay=0
4.0K /tmp
```
```
Если представить, что у нас настроен доступ через ssh ко всем нашим
машинам, мы легко могли бы выполнить, например, такое действие:
```
```
machines = ['homer', 'marge','lisa', 'bart']
for machine in machines:
r = Runner("ssh " + machine + "dfh", "ssh " + machine + "du h /tmp")
r.run()
```
```
Это топорный пример запуска команд на удаленной машине, но сама
идея достойна более пристального внимания, потому что в группе Red
Hat Emerging Technology разрабатывается проект, упрощающий
управление крупными кластерами компьютеров из сценариев на языке
Python. Согласно информации, которая приводится на вебсайте Func,
«Ниже приводится интересный, хотя и искусственный пример выпол
нения перезагрузки всех систем, где запущен демон httpd. Искусст
венный, да, но реализовать не составляет труда, благодаря Func».
О Func (FUNC) упоминалось в главе 8, где рассматривалась собствен
ная система «управления», способная работать в любой UNIXподоб
ной системе.
results = fc.Client("*").service.status("httpd")
for (host, returns) in results.iteritems():
```

Модуль subprocess **359**

```
if returns == 0:
fc.Client(host).reboot.reboot()
```
```
Модуль subprocess обеспечивает унифицированный интерфейс взаи
модействия с системой, с его помощью достаточно легко организовать
запись данных в поток стандартного ввода. В примере 10.11 мы запус
каем утилиту подсчета числа слов, предлагая ей подсчитать количест
во символов, и записываем в ее поток стандартного ввода строку сим
волов.
```
```
Пример 10.11. Организация связи с потоком стандартного ввода
через модуль subprocess
In [35]: p = subprocess.Popen("wcc", shell=True, stdin=subprocess.PIPE)
In [36]: p.communicate("charactersinword")
16
```
```
Эквивалентная команда на языке Bash выглядит, как показано ниже:
```
```
> echo charactersinword | wcc
```
```
Попробуем на этот раз сымитировать поведение Bash и перенаправить
файл в поток стандартного ввода. Для начала нам необходимо запи
сать чтонибудь в файл; сделаем это с использованием нового синтак
сиса Python 2.6. Запомните, что при использовании Python 2.5 необхо
димо использовать идиому импорта будущих возможностей:
```
```
In [5]: from __future__ import with_statement
In [6]: with open('temp.txt', 'w') as file:
...: file.write('charactersinword')
```
```
Теперь можно повторно открыть файл привычным способом и прочи
тать его содержимое в виде строки, присвоив полученное значение пе
ременной f:
```
```
In [7]: file = open('temp.txt')
In [8]: f = file.read()
```
```
После этого можно «перенаправить» файл на вход ожидающего про
цесса:
```
```
In [9]: p = subprocess.Popen("wcc", shell=True, stdin=subprocess.PIPE)
In [10]: p.communicate(f)
```
```
In [11]: p.communicate(f)
16
```
```
В командной оболочке Bash эквивалентная последовательность ко
манд выглядит, как показано ниже:
```
```
% echo charactersinword > temp.txt
% wcc < temp.txt
16
```

**360** Глава 10. Процессы и многозадачность

```
Теперь посмотрим, как реализовать конвейерную обработку с приме
нением нескольких команд, которая часто используется в сценариях
на языке командной оболочки. Посмотрим сначала, как выглядит по
следовательность команд, объединенных в конвейер, на языке Bash,
а затем реализуем ту же самую последовательность на языке Python.
На практике нам очень часто приходится иметь дело с файлами жур
налов. В примере 10.12 мы определяем, какая командная оболочка ис
пользуется суперпользователем root на ноутбуке Macintosh.
```
```
Пример 10.12. Объединение команд в цепочку с помощью модуля subprocess
На языке Bash это действие выполняется следующей простой це
почкой команд:
[ngift@Macintosh6][H:10014]> cat /etc/passwd | grep 0:0 | cutd ':' f 7
/bin/sh
Аналогичная последовательность на языке Python:
In [7]: p1 = subprocess.Popen("cat /etc/passwd", shell=True,
stdout=subprocess.PIPE)
In [8]: p2 = subprocess.Popen("grep 0:0", shell=True, stdin=p1.stdout,
stdout=subprocess.PIPE)
In [9]: p3 = subprocess.Popen("cutd ': ' f 7", shell=True,
stdin=p2.stdout,
stdout=subprocess.PIPE)
In [10]: print p3.stdout.read()
/bin/sh
```
```
Тем не менее, хотя мы можем реализовать некоторое действие с помо
щью модуля subprocess, организовав каналы, но это еще не означает, что
только так и следовало действовать. В предыдущем примере мы получи
ли имя командной оболочки пользователя root, объединив в конвейер
последовательность команд. Но для выполнения подобных действий
в языке Python имеется встроенный модуль, поэтому очень важно знать,
когда можно избежать использования модуля subprocess – язык Python
может содержать встроенный модуль, который способен выполнить не
обходимое действие. Многое из того, что можно сделать в командной
оболочке, например, создать архив в формате tar или zip, можно реали
зовать и на языке Python без использования команд системы. Поэтому,
когда вы обнаруживаете, что приходится реализовывать очень сложную
конвейерную обработку с использованием модуля subprocess, поищите
встроенный эквивалент в языке Python. Взгляните на пример 10.13.
```
```
Пример 10.13. Использование модуля pwd для работы с базой данных
паролей вместо subprocess
In [1]: import pwd
```
```
In [2]: pwd.getpwnam('root')
Out[2]: ('root', '********', 0, 0, 'System Administrator', '/var/root',
'/bin/sh')
```

Использование программы Supervisor для управления процессами **361**

```
In [3]: shell = pwd.getpwnam('root')[1]
In [4]: shell
Out[4]: '/bin/sh'
```
```
Модуль subprocess позволяет одновременно передавать данные в поток
стандартного ввода и принимать данные из потока стандартного выво
да процесса, а также получать данные из потока стандартного вывода
сообщений об ошибках. Рассмотрим пример, демонстрирующий это.
Обратите внимание, что мы используем команду ed upper.py для авто
матического переключения в редактор Vim из интерактивной оболоч
ки IPython, когда нам необходимо написать фрагмент программного
кода, который может представлять собой блок, аналогичный приве
денному в примере 10.14.
```
```
Пример 10.14. Передача данных в поток стандартного ввода и прием данных
из потока стандартного вывода и из потока стандартного
вывода сообщений об ошибках
import subprocess
```
```
p = subprocess.Popen("tr az AZ", shell=True, stdin=subprocess.PIPE,
stdout=subprocess.PIPE)
output, error = p.communicate("translatetoupper")
print output
```
```
Когда происходит возврат из редактора в оболочку IPython, она авто
матически выполняет фрагмент программного кода, и мы получаем
следующий результат:
done. Executing edited code...
TRANSLATETOUPPER
```
**Использование программы Supervisor**

**для управления процессами**

```
Системному администратору часто приходится управлять процесса
ми. Когда вебразработчики узнают, что их системный администратор
является специалистом в языке Python, они очень удивляются, пото
му что очень немногие вебплатформы на языке Python предлагают
элегантные способы управления долгоживущими процессами. Про
грамма Supervisor поможет в ситуациях, когда необходимо организо
вать управление долгоживущими процессами, и обеспечит их повтор
ный запуск после перезагрузки системы.
В действительности программа Supervisor может значительно больше,
чем просто оказывать помощь в развертывании вебприложений, – у нее
есть масса применений общего характера. Supervisor может использо
ваться как кроссплатформенный контроллер управления процессами
и взаимодействия с ними. Supervisor может запускать, останавливать
и перезапускать другие программы в UNIXподобных системах. Кроме
```

**362** Глава 10. Процессы и многозадачность

```
того, Supervisor может выполнять перезапуск «обрушившихся» про
цессов, что может оказаться очень удобным. Соавтор программы Su
pervisor, Крис Макдоног (Chris McDonough), сообщил нам, что она мо
жет также использоваться для управления «плохими» процессами, то
есть процессами, потребляющими, например, слишком много памяти
или процессорного времени. Supervisor обеспечивает возможность
удаленного управления посредством XMLRPC Interface Extensions
Event Notification System.
Основной интерес для большинства администраторов UNIXподобных
систем будут представлять программы supervisord– демон, который
запускает программы как дочерние процессы, и supervisorctl – кли
ентская программа, позволяющая просматривать файлы журналов
и управлять процессами. Кроме того, существует и вебинтерфейс, но,
поскольку эта книга о UNIXподобных системах, двинемся дальше.
К моменту написания этих строк последней была версия программы
Supervisor 3.0.x. Последнюю версию руководства к программе всегда
можно получить по адресу http://supervisord.org/manual/current/. Ус
тановка программы Supervisor не вызывает никаких сложностей – ее
можно установить с помощью утилиты easy_install. Предположим,
что мы с помощью virtualenv создали отдельный каталог для изолиро
ванной среды Python, в этом случае установить программу Supervisor
можно с помощью следующей команды:
```
```
bin/easy_install supervisor
```
```
Она установит Supervisor в каталог bin. Если воспользоваться утили
той easy_install в системной среде Python, то установка будет выпол
нена в каталог, например, /usr/local/bin или в каталог по умолчанию
для сценариев.
Следующий этап, который следует выполнить перед запуском демона
программы Supervisor, заключается в создании простого сценария,
который, как в следующем примере, выводит текст, ожидает 3 секун
ды и завершает свою работу. Такой сценарий, конечно, нельзя назвать
долгоживущим процессом, но с его помощью мы продемонстрируем
одну из самых сильных сторон программы Supervisor – способность
автоматически перезапускать программы, превращая их в некоторое
подобие демонов. Теперь можно заполнить файл supervisord.conf , ис
пользуя для этого специальную команду echo_supervisord_conf. В этом
примере мы просто заполняем файл /etc/supervisord.conf. Следует от
метить, что конфигурационный файл программы Supervisor может на
ходиться в любом месте, потому что демон supervisord можно запус
кать с параметром, указывающим его местоположение.
```
```
echo_supervisord_conf > /etc/supervisord.conf
```
```
Выполнив эти подготовительные действия, мы готовы приступить к соз
данию очень простого примера процесса, который будет завершаться
через несколько секунд после запуска. Чтобы обеспечить непрерыв
```

Использование программы Supervisor для управления процессами **363**

```
ную работу процесса, мы воспользуемся возможностью программы Su
pervisor перезапускать процессы, как показано в примере 10.15.
```
```
Пример 10.15. Простой пример перезапуска процесса с помощью программы
Supervisor
#!/usr/bin/env python
import time
print "Daemon runs for 3 seconds, then dies"
time.sleep(3)
print "Daemons dies"
```
```
Как уже упоминалось ранее, чтобы обеспечить запуск дочерних про
цессов под управлением supervisord, нам необходимо отредактировать
конфигурационный файл и добавить в него наше приложение. Давай
те двинемся дальше и добавим в файл /etc/supervisord.conf пару строк:
[program:daemon]
command=/root/daemon.py ; программа (можно указывать относительные пути
; с учетом переменной PATH и передавать аргументы)
autorestart=true ; перезапускать при необходимости (по умолчанию:
true)
```
```
Теперь можно запустить демон supervisord и затем с помощью про
граммы supervisorctl запускать процессы и следить за ними:
```
```
[root@localhost]~# supervisord
[root@localhost]~# supervisorctl
daemon RUNNING pid 32243, uptime 0:00:02
supervisor>
```
```
Здесь мы можем воспользоваться командой help, чтобы ознакомиться
с доступными параметрами программы supervisorctl:
```
```
supervisor> help
Documented commands (type help topic):
========================================
EOF exit maintail quit restart start stop version
clear help open reload shutdown status tail
```
```
Теперь запустим наш процесс, которому в конфигурационном файле
мы дали имя daemon, и затем будем следить за его работой, пока он не
завершится, после чего он волшебным образом будет перезапущен,
почти как Франкенштейн. Процесс живет, умирает и снова оживает.
supervisor> stop daemon
daemon: stopped
supervisor> start daemon
daemon: started
```
```
И в заключение нашей игры мы можем в интерактивном режиме про
сматривать, что выводится этой программой в поток стандартного вы
вода:
```

**364** Глава 10. Процессы и многозадачность

```
supervisor> tailf daemon
== Press CtrlC to exit ==
for 3 seconds, then die
Daemon died
Daemon runs for 3 seconds, then dies
```
**Использование программы screen**

**для управления процессами**

```
Альтернативный подход к управлению процессами заключается в ис
пользовании программы GNU screen. Как системному администрато
ру вам необходимо умение работать с программой screen, даже если вы
не собираетесь управлять программами из сценариев на языке Python.
Одна из основных особенностей программы screen заключается в том,
что она позволяет отсоединяться от долгоживущего процесса и вновь
возвращаться к нему. Это настолько полезная возможность, что на
наш взгляд владение этой программой можно рассматривать как один
из основных навыков работы с системой UNIX.
Рассмотрим типичную ситуацию, когда могло бы потребоваться отсо
единиться от долгоживущего вебприложения, такого как trac. Суще
ствует несколько способов настройки trac, но самый простой состоит
в том, чтобы отсоединиться от отдельного процесса trac с помощью
программы screen.
Все, что необходимо для запуска процесса под управлением програм
мы screen, – это поместить команду screen перед командой запуска
долгоживущего процесса, а затем нажать комбинации клавиш CtrlA
иCtrlD, чтобы отсоединиться от сеанса. Чтобы вновь подключиться
к этому процессу, вам достаточно просто снова ввести команду screen
и нажать клавишу CtrlA еще раз.
В примере 10.16 производится запуск программы tracd внутри сеанса
screen. Как только процесс запустится, мы можем просто отсоединить
ся от сеанса, нажав комбинации клавиш CtrlA и CtrlD, если, конечно,
предполагается, что позднее мы вновь будем подключаться к сеансу.
```
```
Пример 10.16. Запуск программ на языке Python под управлением
программы screen
screen python2.4 /usr/bin/tracdhostname=trac.example.comport 8888
rsingleenvauth=*,/home/noahgift/tracinstance/conf/
password,tracadminaccount /home/example/tracinstance/
```
```
Чтобы опять подключиться к этому сеансу, можно ввести команду:
[root@cent ~]# screenr
There are several suitable screens on:
4797.pts0.cent (Detached)
24145.pts0.cent (Detached)
Type "screen [d]r [pid.]tty.host" to resume one of them.
```

Потоки выполнения в Python **365**

```
Возможно, это не самый лучший подход для использования в рабочей
среде, но для нужд разработки или личного использования он облада
ет определенными достоинствами.
```
**Потоки выполнения в Python**

```
Потоки выполнения нередко рассматриваются как необходимое зло.
Несмотря на то, что многим потоки не нравятся, тем не менее, они по
зволяют решать задачи, когда приходится одновременно иметь дело
сразу с несколькими вещами. Потоки выполнения – это не процессы,
потому что они выполняются в пределах одного и того же процесса
и совместно используют память процесса. Это одно из самых больших
преимуществ и одновременно самый большой недостаток потоков.
Преимущество заключается в том, что можно создавать в памяти
структуры данных, которые будут доступны всем потокам выполнения
без использования механизмов межпроцессных взаимодействий (IPC).
Но при работе с потоками имеются свои подводные камни. Часто три
виальная программа, состоящая из нескольких десятков строк про
граммного кода, с введением потоков выполнения может стать чрез
вычайно сложной. Многопоточные программы сложно отлаживать без
использования всеобъемлющей трассировки, но и в этом случае отлад
ка остается очень сложной процедурой, потому что вывод трассиро
вочной информации может оказаться слишком объемным и запутан
ным. Один из авторов создал систему исследования центров обработки
данных с помощью протокола SNMP, но реализовать в ней полную
поддержку потоков выполнения оказалось очень непросто.
Однако существуют определенные стратегии, упрощающие создание
многопоточных приложений, и реализация надежной библиотеки трас
сировки – одна из таких стратегий. При этом они могут оказаться
очень удобным инструментом в решении сложных задач.
Знание основ программирования многопоточных приложений может
оказаться полезным для системного администратора. Вот несколько
примеров, когда потоки выполнения могут пригодиться в повседнев
ной практике системного администратора: исследование локальной
сети в автоматическом режиме, извлечение нескольких вебстраниц
одновременно, нагрузочное тестирование сервера и выполнение сете
вых операций.
Сохраняя верность принципу KISS, рассмотрим один из самых про
стых примеров использования нескольких потоков выполнения. Сле
дует заметить, что для использования модуля threading необходимо по
нимание объектноориентированного программирования. Если у вас
недостаточный опыт объектноориентированного программирования
(ООП) или вообще его нет, тогда этот пример может оказаться непо
нятным для вас. В этом случае мы могли бы порекомендовать приобре
```

**366** Глава 10. Процессы и многозадачность

```
сти книгу Марка Лутца (Mark Lutz) «Learning Python» (O’Reilly)^1 и по
знакомиться с некоторыми основами ООП, однако можно обратиться
к главе 1 «Введение» в этой книге и попрактиковаться на некоторых
примерах, которые там приводятся. В конечном счете, объектноори
ентированное программирование достойно того, чтобы изучать его.
Поскольку эта книга посвящена практическому применению языка
Python, давайте перейдем непосредственно к примеру многопоточного
приложения, где используются самые простые приемы многопоточно
го программирования. В этом простом многопоточном сценарии ис
пользуется модуль threading. В сценарии устанавливается значение
глобальной переменной, и затем переопределяется метод run() потока
выполнения. Наконец, запускается пять потоков выполнения, каж
дый из которых выводит свой номер.
Во многих отношениях этот пример чрезмерно упрощен и имеет пло
хой дизайн, потому что в нем сразу несколько потоков используют од
ну и ту же глобальную переменную. Часто совместно с потоками луч
ше использовать очереди, так как они могут принять на себя всю
сложность организации доступа к совместно используемым данным.
Исходный текст сценария приводится в примере 10.17.
```
```
Пример 10.17. Простейший многопоточный сценарий
#не совсем правильно организован доступ к совместно используемым данным
import threading
import time
count = 1
class KissThread(threading.Thread):
def run(self):
global count
print "Thread # %s: Pretending to do stuff" % count
count += 1
time.sleep(2)
print "done with stuff"
for t in range(5):
KissThread().start()
[ngift@Macintosh6][H:10464][J:0]> python thread1.py
Thread # 1: Pretending to do stuff
Thread # 2: Pretending to do stuff
Thread # 3: Pretending to do stuff
Thread # 4: Pretending to do stuff
Thread # 5: Pretending to do stuff
done with stuff
done with stuff
done with stuff
```
(^1) Марк Лутц. «Изучаем Python» – Пер. с англ. – СПб.: СимволПлюс, 2009. –
_Прим. перев._


Потоки выполнения в Python **367**

```
done with stuff
done with stuff
```
```
#common.py
import subprocess
import time
IP_LIST = [ 'google.com',
'yahoo.com',
'yelp.com',
'amazon.com',
'freebase.com',
'clearink.com',
'ironport.com' ]
```
```
cmd_stub = 'pingc 5 %s'
def do_ping(addr):
print time.asctime(), "DOING PING FOR", addr
cmd = cmd_stub % (addr,)
return subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
from common import IP_LIST, do_ping
import time
z = []
#for i in range(0, len(IP_LIST)):
for ip in IP_LIST:
p = do_ping(ip)
z.append((p, ip))
```
```
for p, ip in z:
print time.asctime(), "WAITING FOR", ip
p.wait()
print time.asctime(), ip, "RETURNED", p.returncode
```
```
jmjones@dinkgutsy:thread_discuss$ python nothread.py
Sat Apr 19 06:45:43 2008 DOING PING FOR google.com
Sat Apr 19 06:45:43 2008 DOING PING FOR yahoo.com
Sat Apr 19 06:45:43 2008 DOING PING FOR yelp.com
Sat Apr 19 06:45:43 2008 DOING PING FOR amazon.com
Sat Apr 19 06:45:43 2008 DOING PING FOR freebase.com
Sat Apr 19 06:45:43 2008 DOING PING FOR clearink.com
Sat Apr 19 06:45:43 2008 DOING PING FOR ironport.com
Sat Apr 19 06:45:43 2008 WAITING FOR google.com
Sat Apr 19 06:45:47 2008 google.com RETURNED 0
Sat Apr 19 06:45:47 2008 WAITING FOR yahoo.com
Sat Apr 19 06:45:47 2008 yahoo.com RETURNED 0
Sat Apr 19 06:45:47 2008 WAITING FOR yelp.com
Sat Apr 19 06:45:47 2008 yelp.com RETURNED 0
Sat Apr 19 06:45:47 2008 WAITING FOR amazon.com
Sat Apr 19 06:45:57 2008 amazon.com RETURNED 1
Sat Apr 19 06:45:57 2008 WAITING FOR freebase.com
Sat Apr 19 06:45:57 2008 freebase.com RETURNED 0
```

**368** Глава 10. Процессы и многозадачность

```
Sat Apr 19 06:45:57 2008 WAITING FOR clearink.com
Sat Apr 19 06:45:57 2008 clearink.com RETURNED 0
Sat Apr 19 06:45:57 2008 WAITING FOR ironport.com
Sat Apr 19 06:46:58 2008 ironport.com RETURNED 0
```
```
В качестве оговорки к следующим примерам многопоточных
сценариев следует заметить, что они являются достаточно
сложными примерами и те же самые действия могут быть реа
лизованы на основе применения функции subprocess.Popen().
Эта функция является лучшим выбором, когда требуется запус
тить группу процессов и дождаться их завершения. Если вам
необходимо организовать взаимодействие с каждым процессом,
то можно использовать функцию subprocess.Popen() в комплексе
с потоками выполнения. Основная цель этих примеров – проде
монстрировать, что многозадачность нередко требует уступок
и компромиссов. Часто бывает очень трудно определить, какая
модель лучше отвечает требованиям – потоки выполнения, про
цессы или асинхронные библиотеки, такие как stackless или
twisted. Ниже приводится пример опроса с помощью утилиты
ping большого массива IPадресов.
```
```
Теперь, когда у нас имеется своеобразная программа «Hello World» для
потоков выполнения, можно перейти к реализации сценария, кото
рый оценит любой системный администратор. Возьмем за основу наш
сценарий и изменим его так, чтобы он опрашивал узлы в сети. Это
можно считать начальным этапом на пути создания универсального
инструмента для работы с сетью. Программный код сценария приво
дится в примере 10.18.
```
```
Пример 10.18. Многопоточная версия утилиты ping
#!/usr/bin/env python
from threading import Thread
import subprocess
from Queue import Queue
num_threads = 3
queue = Queue()
ips = ["10.0.1.1", "10.0.1.3", "10.0.1.11", "10.0.1.51"]
def pinger(i, q):
"""опрос подсети"""
while True:
ip = q.get()
print "Thread %s: Pinging %s" % (i, ip)
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
else:
print "%s: did not respond" % ip
```

Потоки выполнения в Python **369**

```
q.task_done()
for i in range(num_threads):
```
```
worker = Thread(target=pinger, args=(i, queue))
worker.setDaemon(True)
worker.start()
for ip in ips:
queue.put(ip)
print "Main Thread Waiting"
queue.join()
print "Done"
```
```
Когда мы запустили этот, достаточно простой фрагмент программного
кода, мы получили следующий результат:
```
```
[ngift@Macintosh6][H:10432][J:0]# python ping_thread_basic.py
Thread 0: Pinging 10.0.1.1
Thread 1: Pinging 10.0.1.3
Thread 2: Pinging 10.0.1.11
Main Thread Waiting
10.0.1.1: is alive
Thread 0: Pinging 10.0.1.51
10.0.1.3: is alive
10.0.1.51: is alive
10.0.1.11: did not respond
Done
```
```
Этот пример заслуживает того, чтобы разобрать его на понятные час
ти, но сначала – небольшое пояснение. Пример разработки многопо
точной версии утилиты ping с целью опроса подсети – это отличный
способ продемонстрировать применение потоков. «Обычная» програм
ма на языке Python, не использующая потоки выполнения, потребова
ла бы времени для своего выполнения N * (среднее время ожидания от
вета на каждый запрос ping). Утилита ping может возвращать один из
двух вариантов ответа: время отклика хоста и сообщение об истечении
предельного времени ожидания. В типичной сети можно столкнуться
с обоими вариантами.
Это означает, что на выполнение приложения, использующего утилиту
ping для опроса хостов сети класса C, состоящей из 254 адресов, может
потребоваться до 254 * (~ 3 секунды), что может составить до 12.7 ми
нут. При использовании потоков это время можно уменьшить до не
скольких секунд. Именно поэтому потоки имеют важное значение для
разработки сетевых приложений. Теперь сделаем еще шаг и подума
ем, какие условия могут встретиться в действительности. Сколько
подсетей может существовать в типичном центре обработки данных?
20? 30? 50? Очевидно, что программа, выполняющая опрос последова
тельным способом, быстро теряет свою практическую ценность, и мно
гопоточная версия становится идеальным выбором.
```

**370** Глава 10. Процессы и многозадачность

```
Теперь вернемся к нашему простому сценарию и рассмотрим некото
рые особенности реализации. Первое, на что следует обратить внима
ние, – это импортируемые модули, в частности, наибольший интерес
для нас представляют модули threading и Queue. Как уже отмечалось
выше, разработка многопоточных приложений без использования оче
редей намного сложнее, и многим оказывается не под силу. Всякий
раз, когда вам требуется прибегнуть к использованию потоков, жела
тельно использовать модуль Queue. Почему? Этот модуль снижает по
требность в явной реализации защиты данных с помощью мьютексов,
потому что внутренние механизмы самих очередей обеспечивают необ
ходимую защиту данных.
Представьте, что вы фермер/ученый, живущий в Средние века, и вы
заметили, что вороны, которых часто называют «убийцами» (если ин
тересно узнать, почему, обращайтесь в Википедию), атакуют ваши по
ля с зерновыми стаями по 20 или более особей.
Это очень умные птицы и их невозможно испугать, бросая камни, так
как вы сможете бросать не чаще, чем один камень каждые 3 секунды,
а численность стаи может достигать 50 особей. Чтобы отпугнуть всех
ворон, может потребоваться до нескольких минут, но за этот промежу
ток времени урожаю может быть нанесен существенный ущерб. Как
ученый, знающий математику, вы понимаете, что эта проблема легко
разрешима. Вам нужно лишь набрать кучу камней и затем расставить
работников, чтобы они могли одновременно брать камни из кучи и бро
сать в ворон.
Если следовать этой стратегии, 30 работников, выбирая камни из кучи,
могли бы закидать камнями 50 ворон менее чем за 10 секунд. Это осно
ва использования потоков и очередей в сценариях на языке Python. Вы
нанимаете группу работников для выполнения какойлибо работы,
и когда очередь опустеет, задание можно считать выполненным.
Очереди обеспечивают способ передачи заданий «группе» работников
централизованным образом. Один из самых важных элементов нашей
простой программы – это вызов метода join(). Описание метода
queue.join() гласит следующее:
Namespace: Interactive
File: /System/Library/Frameworks/Python.framework/Versions/2.5/lib/
python2.5/
Queue.py
Definition: Queue.Queue.join(self)
Docstring:
Blocks until all items in the Queue have been gotten and processed.
(Блокирует выполнение вызывающей программы, пока не будут обработаны
все элементы очереди)
```
```
The count of unfinished tasks goes up whenever an item is added to the
queue. The count goes down whenever a consumer thread calls task_done()
to indicate the item was retrieved and all work on it is complete.
```

Потоки выполнения в Python **371**

```
(Всякий раз, когда в очередь добавляется новый элемент, увеличивается счетчик
невыполненных задач. Всякий раз, когда пользовательский поток вызывает метод
task_done(), чтобы показать, что изъятый из очереди элемент обработан,
счетчик уменьшается.)
```
```
When the count of unfinished tasks drops to zero, join() unblocks.
(Когда счетчик заданий уменьшается до нуля, метод join() возвращает
управление вызывающей программе.)
```
```
Метод join() представляет собой простой способ предотвратить завер
шение выполнения главного потока программы до того, как остальные
потоки выполнения получат шанс завершить обработку элементов
очереди. Возвращаясь к метафоре с фермером, главный поток можно
сравнить с фермером, который собирает кучу камней и уходит, а ра
ботники выстраиваются в линию, готовясь бросать камни. Если в на
шем примере закомментировать вызов метода queue.join(), отрица
тельные последствия этого не замедлят сказаться. Попробуем заком
ментировать вызов queue.join():
```
```
print "Main Thread Waiting"
#Если закомментировать вызов метода join, главная программа завершится
#до того, как потоки получат возможность выполнить свою работу
#queue.join()
print "Done"
```
```
Теперь посмотрим, что выдаст наш замечательный сценарий. Взгля
ните на пример 10.19.
```
```
Пример 10.19. Пример, когда главный поток выполнения программы
завершает работу раньше других потоков
[ngift@Macintosh6][H:10189][J:0]# python ping_thread_basic.py
Main Thread Waiting
Done
Unhandled exception in thread started by
Error in sys.excepthook:
```
```
Original exception was:
```
```
Теперь, ознакомившись с теорией применения в сценариях потоков вы
полнения и очередей, пройдемся по программному коду шаг за шагом.
В самом начале мы жестко определили несколько значений, которые
в более универсальных программах обычно передаются в виде аргумен
тов командной строки. Переменная num_threads содержит число рабо
чих потоков, переменная queue– это экземпляр очереди и, наконец,
ips – это список IPадресов, которые мы должны поместить в очередь:
```
```
num_threads = 3
queue = Queue()
ips = ["10.0.1.1", "10.0.1.3", "10.0.1.11", "10.0.1.51"]
```
```
Следующая функция выполняет основную работу в программе. Она вы
зывается каждым потоком и извлекает очередной IPадрес из очереди.
```

**372** Глава 10. Процессы и многозадачность

```
Примечательно, что адреса выталкиваются из очереди в том же поряд
ке, в каком они находятся в списке. Такая реализация позволяет из
влекать элементы, пока очередь не опустеет. В конце цикла while вы
зывается метод q.task_done() – это имеет важное значение, потому что
он сообщает методу join() о том, что был обработан очередной элемент,
извлеченный из очереди. Или, говоря простым языком, он сообщает
о том, что задание выполнено. Посмотрим, что говорится в описании
метода Queue.Queue.task_done():
```
```
File: /System/Library/Frameworks/Python.framework/Versions/2.5/lib/
python2.5/
Queue.py
Definition: Queue.Queue.task_done(self)
Docstring:
Indicate that a formerly enqueued task is complete.
(Свидетельствует о том, что очередное задание в очереди было выполнено.)
Used by Queue consumer threads. For each get() used to fetch a task,
a subsequent call to task_done() tells the queue that the processing
on the task is complete.
(Вызывается потокомпотребителем. Каждому вызову метода get(), используемому
для извлечения задания, должен соответствовать вызов метода task_done(),
который сообщает очереди, что задание выполнено.)
If a join() is currently blocking, it will resume when all items
have been processed (meaning that a task_done() call was received
for every item that had been put() into the queue).
(Метод join() вернет управление вызывающей программе, когда будут обработаны
все элементы (то есть для каждого элемента, помещенного в очередь вызовом
метода put(), будет вызван метод task_done()))
Raises a ValueError if called more times than there were items
placed in the queue.
(При вызове большее число раз, чем имелось элементов в очереди, возбуждает
исключение ValueError)
```
```
Из описания видно, что между методами q.get() и q.task_done() суще
ствует взаимосвязь и в конечном счете они связаны с методом q.join().
Это практически начало, середина и конец истории:
```
```
def pinger(i, q):
"""опрос подсети"""
while True:
ip = q.get()
print "Thread %s: Pinging %s" % (i, ip)
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
else:
```

Потоки выполнения в Python **373**

```
print "%s: did not respond" % ip
q.task_done()
```
```
Ниже мы используем простой цикл for, который управляет созданием
группы потоков выполнения. Примечательно, что эта группа просто
«сидит и ждет», пока чтонибудь не появится в очереди. В программе
ничего не происходит, пока управление не достигнет следующего раз
дела.
В нашей программе кроется одна малозаметная хитрость, которая пре
дохраняет программу от попадания в ловушку. Обратите внимание на
вызов метода setDaemon(True). Если этого не сделать перед вызовом ме
тода start() потока, программа зависнет на неопределенный срок.
Причина практически незаметна на первый взгляд и заключается в том,
что программа может завершить свою работу, только если потоки вы
полняются в режиме демонов. Вы могли заметить, что в функции
pinger() используется бесконечный цикл. Поскольку поток, вызвав
ший такую функцию, никогда сам не завершится, нам пришлось объя
вить их потокамидемонами. Чтобы убедиться в справедливости вы
шесказанного, просто закомментируйте строку worker.setDaemon(True)
и запустите программу. Заметим лишь, что без вызова этого метода
программа будет крутиться вхолостую неопределенно продолжитель
ное время. Обязательно проверьте это у себя, так как это поможет вам
частично снять с процесса покров таинственности:
```
```
for i in range(num_threads):
worker = Thread(target=pinger, args=(i, queue))
worker.setDaemon(True)
worker.start()
```
```
К этому моменту в нашей программе имеется группа готовых к работе
потоков, ожидающих, пока мы дадим им задание. Как только мы по
местим элементы в очередь, нашим потокам тут же будет послан сиг
нал, что можно извлечь задание из очереди, которое в данном случае
заключается в том, чтобы опросить указанный IPадрес:
for ip in ips:
queue.put(ip)
```
```
Наконец, мы достигли критической строки, зажатой между двумя ин
струкциями print, которая в конечном счете управляет программой.
Как уже говорилось ранее, вызвав метод очереди join(), главный по
ток программы становится в ожидание, пока не опустеет очередь зада
ний. Именно поэтому потоки и очередь напоминают шоколад с арахи
совым маслом. Каждый из них обладает своей прелестью, но вместе
они создают особый вкус.
```
```
print "Main Thread Waiting"
queue.join()
print "Done"
```

**374** Глава 10. Процессы и многозадачность

```
Чтобы лучше понять принципы использования потоков и очередей,
нам нужно сделать еще один шаг вперед и добавить в наш пример еще
одну группу потоков и еще одну очередь. В первом примере мы опра
шивали с помощью утилиты ping список IPадресов, которые извлека
ли из очереди. В следующем примере мы заставим первую группу по
токов помещать IPадреса, от которых был получен ответ, во вторую
очередь.
После этого вторая группа потоков будет извлекать IPадреса из вто
рой очереди, производить опрос с помощью утилиты arping и возвра
щать IPадреса вместе с MACадресами. Исходный текст примера при
водится в примере 10.20.
```
```
Пример 10.20. Несколько очередей и несколько групп потоков
#!/usr/bin/env python
#Требуется Python2.5 или выше
from threading import Thread
import subprocess
from Queue import Queue
import re
```
```
num_ping_threads = 3
num_arp_threads = 3
in_queue = Queue()
out_queue = Queue()
ips = ["10.0.1.1", "10.0.1.3", "10.0.1.11", "10.0.1.51"]
def pinger(i, iq, oq):
"""опрос подсети"""
while True:
ip = iq.get()
print "Thread %s: Pinging %s" % (i, ip)
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
#print "%s: is alive" % ip
#поместить ответившие IPадреса во вторую очередь
oq.put(ip)
else:
print "%s: did not respond" % ip
iq.task_done()
def arping(i, oq):
"""извлекает ответивший IPадрес из очереди и получает MACадрес"""
while True:
ip = oq.get()
p = subprocess.Popen("arpingc 1 %s" % ip,
shell=True,
stdout=subprocess.PIPE)
out = p.stdout.read()
```

Потоки выполнения в Python **375**

```
#отыскать и извлечь MACадрес из потока стандартного вывода
result = out.split()
pattern = re.compile(":")
macaddr = None
for item in result:
if re.search(pattern, item):
macaddr = item
print "IP Address: %s | Mac Address: %s " % (ip, macaddr)
oq.task_done()
#Поместить IPадреса в очередь
for ip in ips:
in_queue.put(ip)
```
```
#Породить группу потоков, вызывающих утилиту ping
for i in range(num_ping_threads):
```
```
worker = Thread(target=pinger, args=(i, in_queue, out_queue))
worker.setDaemon(True)
worker.start()
#Породить группу потоков, вызывающих утилиту arping
for i in range(num_arp_threads):
worker = Thread(target=arping, args=(i, out_queue))
worker.setDaemon(True)
worker.start()
```
```
print "Main Thread Waiting"
#Гарантировать, что программа не завершит работу,
#пока не опустеют обе очереди
in_queue.join()
out_queue.join()
print "Done"
```
```
После запуска этого сценария мы получили следующие результаты:
python2.5 ping_thread_basic_2.py
Main Thread Waiting
Thread 0: Pinging 10.0.1.1
Thread 1: Pinging 10.0.1.3
Thread 2: Pinging 10.0.1.11
Thread 0: Pinging 10.0.1.51
IP Address: 10.0.1.1 | Mac Address: [00:00:00:00:00:01]
IP Address: 10.0.1.51 | Mac Address: [00:00:00:80:E8:02]
IP Address: 10.0.1.3 | Mac Address: [00:00:00:07:E4:03]
10.0.1.11: did not respond
Done
```
```
Для реализации этого решения мы лишь немного расширили преды
дущий пример, добавив в него еще одну группу потоков и еще одну
очередь. Это достаточно важный прием, чтобы поместить его в свой ар
сенал, потому что модуль queue делает использование потоков более
```

**376** Глава 10. Процессы и многозадачность

```
простым и более безопасным делом. Можно даже сказать, что этот
прием относится к разряду обязательных к применению.
```
**Задержка выполнения потоков с помощью**

**threading.Timer**

```
В языке Python имеется еще одна особенность, имеющая отношение
к потокам, которая может оказаться удобной при решении задач сис
темного администрирования. Она существенно упрощает запуск функ
ции с задержкой по времени, как показано в примере 10.21.
```
```
Пример 10.21. Таймер внутри потока
#!/usr/bin/env python
from threading import Timer
import sys
import time
import copy
```
```
#простейшая обработка ошибок
if len(sys.argv) != 2:
print "Must enter an interval"
sys.exit(1)
```
```
#функция, которая будет вызываться с задержкой по времени
def hello():
print "Hello, I just got called after a %s sec delay" % call_time
#поток, который реализует задержку по времени
delay = sys.argv[1]
call_time = copy.copy(delay) #копирование задержки для использования позднее
t = Timer(int(delay), hello)
t.start()
```
```
#показать, что программа не блокируется и продолжает работать
print "waiting %s seconds to run function" % delay
for x in range(int(delay)):
print "Main program is still running for %s more sec" % delay
delay = int(delay) 1
time.sleep(1)
```
```
Если запустить этот фрагмент, можно увидеть, что главный поток про
граммы продолжает работу и при этом происходит отложенный вызов
функции:
[ngift@Macintosh6][H:10468][J:0]# python thread_timer.py 5
waiting 5 seconds to run function
Main program is still running for 5 more sec
Main program is still running for 4 more sec
Main program is still running for 3 more sec
Main program is still running for 2 more sec
Main program is still running for 1 more sec
Hello, I just got called after a 5 sec delay
```

Потоки выполнения в Python **377**

**Обработка событий в потоке**

```
Эта книга предназначена для системных администраторов, поэтому
давайте применим описанную выше методику для решения более
практичной задачи. В этом примере мы возьмем на вооружение прием
с отложенным запуском и объединим его с циклом ожидания событий,
в котором будем проверять наличие расхождений в именах файлов ме
жду двумя каталогами. Мы могли бы пойти дальше и проверять время
последнего изменения файлов, но, следуя принципу сохранения мак
симальной простоты примеров, мы посмотрим, как в этом цикле про
веряется ожидаемое событие и как, в случае его появления, вызывает
ся метод обработки.
Этот модуль легко можно преобразовать в более универсальный инст
румент, но пока в примере 10.22 жестко определены каталоги, кото
рые будут синхронизироваться с задержкой с помощью команды rsync
```
- av ––delete, если между ними будут обнаружены различия.

```
Пример 10.22. Инструмент синхронизации каталогов
#!/usr/bin/env python
from threading import Timer
import sys
import time
import copy
import os
from subprocess import call
class EventLoopDelaySpawn(object):
"""Класс обработки события, который запускает метод из потока задержки"""
def __init__(self, poll=10,
wait=1,
verbose=True,
dir1="/tmp/dir1",
dir2="/tmp/dir2"):
```
```
self.poll = int(poll)
self.wait = int(wait)
self.verbose = verbose
self.dir1 = dir1
self.dir2 = dir2
def poller(self):
"""Интервал опроса"""
time.sleep(self.poll)
if self.verbose:
print "Polling at %s sec interval" % self.poll
```
```
def action(self):
if self.verbose:
print "waiting %s seconds to run Action" % self.wait
```

**378** Глава 10. Процессы и многозадачность

```
ret = call("rsyncavdelete %s/ %s" % (self.dir1, self.dir2),
shell=True)
```
```
def eventHandler(self):
#Если в каталогах имеются файлы с разными именами
if os.listdir(self.dir1) != os.listdir(self.dir2):
print os.listdir(self.dir1)
t = Timer((self.wait), self.action)
t.start()
if self.verbose:
print "Event Registered"
else:
if self.verbose:
print "No Event Registered"
def run(self):
"""Цикл проверки события с отложенным запуском обработчика"""
try:
while True:
self.eventHandler()
self.poller()
except Exception, err:
print "Error: %s " % err
finally:
sys.exit(0)
E = EventLoopDelaySpawn()
E.run()
```
```
Внимательные читатели могут заметить, что строго говоря, задержка
здесь не является строго необходимой, и это действительно так. Но
как бы то ни было, задержка может дать дополнительное преимущест
во. Если добавить задержку, скажем, на 5 секунд, можно было бы пре
рвать выполнение потока в случае наступления другого события, на
пример, в случае неожиданного удаления основного каталога. Задерж
ка, реализованная в виде потока, представляет собой замечательный
механизм создания операций с отложенным выполнением, которые
можно отменить.
```
**Процессы**

```
Потоки – это не единственный способ использования многозадачности
в языке Python. В действительности процессы обладают некоторыми
преимуществами перед потоками, т. к. они, в отличие от потоков в язы
ке Python, могут выполняться на разных процессорах. На самом деле,
изза наличия глобальной блокировки интерпретатора (Global Inter
preter Lock, GIL) в каждый момент времени может выполняться толь
ко один поток управления и только на одном процессоре. Поэтому для
решения «тяжеловесных» задач на языке Python потоки являются не
```

Модуль processing **379**

```
лучшим выбором. В таких случаях обработку лучше производить
в разных процессах.
Процессы будут лучшим выбором, если для решения задачи потребу
ется задействовать несколько процессоров. Кроме того, существует
множество библиотек, которые просто не могут работать с потоками
управления. Например, текущая реализация библиотеки NetSNMP
для языка Python не является асинхронной, поэтому при необходимо
сти выполнения параллельной обработки следует использовать ветв
ление процессов.
Потоки в приложении совместно используют одну и ту же область па
мяти, в то время как процессы полностью независимы друг от друга
и для организации взаимодействия с процессом требуется приложить
больше усилий. Обмен информацией с процессами с помощью каналов
может оказаться непростым делом, но, к счастью, существует библио
тека processing, которую мы здесь подробно рассмотрим. Идут разго
воры о включении библиотеки processing в стандартную библиотеку
языка Python, поэтому будет совсем нелишним познакомиться с ней
поближе.
Ранее мы упоминали альтернативный метод создания множества про
цессов, основанный на использовании функции subprocess.Popen(). Во
многих случаях это отличный выбор для организации параллельного
выполнения программного кода. В главе 13 вы найдете пример, где
этот прием используется для создания множества процессов dd.
```
```
Как упоминалось ранее, реализация параллельной обработки
данных никогда не отличалась простотой. Этот пример можно
было счесть неэффективным, потому что в нем используется
функция subprocess.Popen(), вместо того чтобы с помощью моду
ля processing создавать дочерние процессы, в которых вызывать
функцию subprocess.call(). Однако с точки зрения крупного
приложения использование прикладного интерфейса, напоми
нающего очереди, имеет свои преимущества и сравнимо с при
мером многопоточного приложения, приведенного выше. В на
стоящее время идут разговоры об объединении модулей process
ing и Subprocess, потому что модулю Subprocess недостает воз
можности управления группой процессов, которая присутствует
в модуле processing. Этот запрос был сделан в системе PEP (Py
thon Enhancement Proposal – система приема предложений по
улучшению Python) для модуля Subprocess: http://www.py>
thon.org/dev/peps/pep>0324/.
```
**Модуль processing**

```
Так что же это за модуль processing, о котором мы упомянули выше?
На момент написания книги «processing – это пакет для языка Python,
который поддерживает возможность порождения процессов с помо
щью API модуля threading из стандартной библиотеки...». Одна из за
```

**380** Глава 10. Процессы и многозадачность

```
мечательных особенностей модуля processing заключается в том, что
он до определенной степени соответствует прикладному интерфейсу
модуля threading. Это означает, что вам не придется изучать новый
API, чтобы порождать новые процессы вместо потоков. Подробнее о мо
дуле processing можно прочитать по адресу: http://pypi.python.org/py>
pi/processing.
Теперь, когда мы получили некоторые сведения о модуле processing,
рассмотрим пример 10.23.
```
```
Пример 10.23. Введение в модуль processing
#!/usr/bin/env python
from processing import Process, Queue
import time
```
```
def f(q):
x = q.get()
print "Process number %s, sleeps for %s seconds" % (x,x)
time.sleep(x)
print "Process number %s finished" % x
q = Queue()
```
```
for i in range(10):
q.put(i)
i = Process(target=f, args=[q])
i.start()
```
```
print "main process joins on queue"
i.join()
print "Main Program finished"
```
```
Запустив этот фрагмент, мы получили следующее:
```
```
[ngift@Macintosh7][H:11199][J:0]# python processing1.py
Process number 0, sleeps for 0 seconds
Process number 0 finished
Process number 1, sleeps for 1 seconds
Process number 2, sleeps for 2 seconds
Process number 3, sleeps for 3 seconds
Process number 4, sleeps for 4 seconds
main process joins on queue
Process number 5, sleeps for 5 seconds
Process number 6, sleeps for 6 seconds
Process number 8, sleeps for 8 seconds
Process number 7, sleeps for 7 seconds
Process number 9, sleeps for 9 seconds
Process number 1 finished
Process number 2 finished
Process number 3 finished
Process number 4 finished
Process number 5 finished
Process number 6 finished
```

Модуль processing **381**

```
Process number 7 finished
Process number 8 finished
Process number 9 finished
Main Program finished
```
```
Все, что делает эта программа, это предписывает каждому процессу
приостановиться на количество секунд, соответствующее порядково
му номеру процесса. Как видите, интерфейс модуля прост и понятен.
Теперь, когда у нас имеется своего рода программа «Hello World», де
монстрирующая использование модуля processing, можно создать что
нибудь более интересное. Если вы помните, в разделе с описанием по
токов управления мы создали простой многопоточный сценарий, вы
полняющий опрос подсети. Поскольку прикладной интерфейс модуля
processing очень напоминает интерфейс модуля threading, мы можем
реализовать практически идентичный сценарий, используя процессы
вместо потоков управления, как показано в примере 10.24.
```
```
Пример 10.24. Утилита ping на основе процессов
#!/usr/bin/env python
from processing import Process, Queue, Pool
import time
import subprocess
from IPy import IP
import sys
```
```
q = Queue()
ips = IP("10.0.1.0/24")
def f(i,q):
while True:
if q.empty():
sys.exit()
print "Process Number: %s" % i
ip = q.get()
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
else:
print "Process Number: %s didn’t find a response for %s " % (i, ip)
```
```
for ip in ips:
q.put(ip)
```
```
#q.put("192.168.1.1")
for i in range(50):
p = Process(target=f, args=[i,q])
p.start()
```
```
print "main process joins on queue"
```

**382** Глава 10. Процессы и многозадачность

```
p.join()
print "Main Program finished"
```
```
Этот сценарий удивительно похож на многопоточную версию, которая
рассматривалась ранее. Если запустить этот сценарий, мы увидим
примерно следующее:
[обрезано]
10.0.1.255: is alive
Process Number: 48 didn't find a response for 10.0.1.216
Process Number: 47 didn't find a response for 10.0.1.217
Process Number: 49 didn't find a response for 10.0.1.218
Process Number: 46 didn't find a response for 10.0.1.219
Main Program finished
[обрезано]
[ngift@Macintosh7][H:11205][J:0]#
```
```
Этот пример требует дополнительных пояснений. Хотя прикладные
интерфейсы модулей очень похожи, между ними всетаки есть некото
рые отличия. Обратите внимание, что каждый из процессов запускает
ся внутри бесконечного цикла, где выполняется извлечение элементов
из очереди. Чтобы сообщить процессу о том, что он должен завершить
работу, мы добавили условную инструкцию, которая проверяет, не
опустела ли очередь. Каждый из 50 дочерних процессов сначала про
веряет, не опустела ли очередь, и если в очереди нет элементов, про
цесс сам «убивает» себя, вызывая функцию sys.exit().
Если в очереди еще имеются элементы, то процесс благополучно из
влекает очередной элемент, в данном случае – IPадрес, и приступает
к выполнению своего задания, то есть выполняет опрос заданного IP
адреса с помощью утилиты ping. Главная программа использует метод
join(), точно так же, как и версия сценария, реализованная на основе
потоков, и ожидает, пока очередь не опустеет. После того как все рабо
чие процессы завершатся, и очередь опустеет, следующая ниже инст
рукция print сообщит о завершении программы.
Благодаря похожести прикладного интерфейса модуль processing ис
пользовать так же просто, как и модуль threading. В главе 7 мы обсуж
дали практическую реализацию на основе модуля processing сцена
рия, использующего библиотеку NetSNMP, которая по своей природе
не является асинхронным расширением для языка Python.
```
**Планирование запуска процессов Python**

```
Теперь, когда мы рассмотрели разнообразные способы работы с про
цессами в языке Python, нам следует поговорить о способах планиро
вания выполнения этих процессов. Для запуска программ, написан
ных на языке Python, вполне подходит старый добрый планировщик
cron.
```

Планирование запуска процессов Python **383**

```
Одна из новых замечательных особенностей планировщика cron, имею
щегося в большинстве POSIXсовместимых систем, заключается во вве
дении каталогов планирования. Это и есть то, изза чего мы используем
cron, так как достаточно просто скопировать сценарий на языке Python
в один из четырех каталогов по умолчанию: /etc/cron.daily , /etc/cron.ho>
urly , /etc/cron.monthly и /etc/cron.weekly.
Достаточно много системных администраторов хотя бы раз в своей
жизни обеспечивали возможность отправки отчета об использовании
дискового пространства по электронной почте. Для этого вы просто по
мещаете в каталог /etc/cron.daily сценарий на языке Bash, который со
держит примерно следующее:
dfh | mail s "Nightly Disk Usage Report" staff@example.com
```
```
Сохранив сценарий под именем /etc/cron.daily/diskusage.sh , вы начи
наете каждый день получать по электронной почте отчеты, имеющие
примерно такой вид:
From: gurupythonsysadmin@example.com
Subject: Nightly Disk Usage Report
Date: February 24, 2029 10:18:57 PM EST
To: staff@example.com
Filesystem Size Used Avail Use% Mounted on
/dev/hda3 72G 16G 52G 24% /
/dev/hda1 99M 20M 75M 21% /boot
tmpfs 1010M 0 1010M 0% /dev/shm
```
```
Но существует лучший путь. Даже для реализации заданий планиров
щика cron можно использовать преимущества языка Python вместо
Bash или Perl. В действительности планировщик cron и Python прекрас
но работают вместе. Давайте возьмем сценарий на языке Bash и реали
зуем его на языке Python, как показано в примере 10.25.
```
```
Пример 10.25. Отсылка ежедневного отчета об использовании дискового
пространства по электронной почте
import smtplib
import subprocess
import string
p = subprocess.Popen("dfh", shell=True, stdout=subprocess.PIPE)
MSG = p.stdout.read()
FROM = "gurupythonsysadmin@example.com"
TO = "staff@example.com"
SUBJECT = "Nightly Disk Usage Report"
msg = string.join((
"From: %s" % FROM,
"To: %s" % TO,
"Subject: %s" % SUBJECT,
"",
MSG), "\r\n")
```

**384** Глава 10. Процессы и многозадачность

```
server = smtplib.SMTP('localhost')
server.sendmail(FROM, TO, msg)
server.quit()
```
```
Это тривиальный рецепт создания автоматизированного отчета об ис
пользовании дискового пространства на базе cron, но он прекрасно по
дойдет для решения множества задач. Теперь подробнее рассмотрим,
что делает этот небольшой фрагмент программного кода на языке Py
thon. В первую очередь, с помощью subprocess.Popen() выполняется
чтение потока стандартного вывода команды df. Затем создаются пе
ременные для заполнения полей From, To и Subject. Затем объединени
ем всех строк создается сообщение. Это самая сложная часть сцена
рия. В заключение мы указываем имя localhost в качестве имени сер
вера исходящей почты и передаем переменные, созданные ранее,
функции server.sendmail().
Для того чтобы использовать такой сценарий, его обычно помещают
вфайл /etc/cron.daily/nightly_disk_report.py.
Если вы еще только начинаете знакомиться с языком Python, можете
использовать этот программный код как шаблон для быстрого созда
ния работающих сценариев. В главе 4 мы немного подробнее обсужда
ли вопрос создания сообщений электронной почты, поэтому за допол
нительной информацией вы можете обращаться к этой главе.
```
**Запуск демона**

```
Работа с демонами – это данность для любого, кто потратил на опера
ционную систему UNIX больше времени, чем необходимо для беглого
знакомства. Демоны выполняют практически любые операции – от об
работки запросов до пересылки файлов на принтер (например, lpd),
приема запросов HTTP и передачи файлов (например, демон httpd веб
сервера Apache).
Так что же такое демон? Часто под демоном понимают выполняющий
ся в фоновом режиме процесс, который не имеет управляющего терми
нала. Если вы знакомы с механизмом управления заданиями в UNIX,
у вас может сложиться мнение, что добавление символа & в конце ко
манды создаст демона. Или нажатие комбинации CtrlZ после запуска
процесса с последующей командой bg создаст демона. В обоих случаях
вы получите фоновые процессы, но ни один из этих способов не отры
вает процесс от командной оболочки и не лишает его управляющего
терминала (возможно, принадлежащего процессу командной оболоч
ки). Итак, три основных признака демона: выполнение в фоновом ре
жиме, отсутствие связи с процессом, запустившим его, и отсутствие
управляющего терминала. Процесс, запущенный в фоновом режиме
при помощи механизма управления заданиями, отвечает только пер
вому требованию.
```

Запуск демона **385**

```
Ниже приводится фрагмент программного кода, в котором определя
ется функция daemonize(). Она превращает вызывающий ее процесс
в демона – в том смысле, в каком говорилось в предыдущем парагра
фе. Эта функция была взята из рецепта «Forking a Daemon Process on
Unix», который приводится во втором издании книги Дэвида Ашера
(David Asher) «Python Cookbook» (O’Reilly) на страницах 388389.
Этот программный код достаточно близко следует рекомендациям, ко
торые предлагает Ричард Стивенс (Richard Stevens) в своей книге
«UNIX Network Programming: The Sockets Networking API» (O’Reilly)
в качестве «правильного» способа создания демона. Для тех, кто не
знаком с книгой Стивенса, заметим, что она обычно рассматривается
как справочник по сетевому программированию, а также как руково
дство по созданию демонов в UNIX. Исходный текст функции приво
дится в примере 10.26.
```
```
Пример 10.26. Функция daemonize
import sys, os
def daemonize (stdin='/dev/null', stdout='/dev/null', stderr='/dev/null'):
# Выполнить первое ветвление процесса.
try:
pid = os.fork()
if pid > 0:
sys.exit(0) # Первый родительский процесс завершает работу.
except OSError, e:
sys.stderr.write("fork #1 failed: (%d) %s\n" % (e.errno, e.strerror))
sys.exit(1)
# Отключиться от родительского окружения.
os.chdir("/")
os.umask(0)
os.setsid()
# Выполнить второе ветвление.
try:
pid = os.fork()
if pid > 0:
sys.exit(0) # Второй родительский процесс завершает работу.
except OSError, e:
sys.stderr.write("fork #2 failed: (%d) %s\n" % (e.errno, e.strerror))
sys.exit(1)
# Теперь процесс стал демоном,
# выполнить перенаправление стандартных дескрипторов.
for f in sys.stdout, sys.stderr: f.flush()
si = file(stdin, 'r')
so = file(stdout, 'a+')
se = file(stderr, 'a+', 0)
os.dup2(si.fileno(), sys.stdin.fileno())
os.dup2(so.fileno(), sys.stdout.fileno())
os.dup2(se.fileno(), sys.stderr.fileno())
```
```
Первое, что делает эта функция, – с помощью функции fork() произво
дит ветвление процесса. В этом случае создается копия работающего
```

**386** Глава 10. Процессы и многозадачность

```
процесса, и эта копия рассматривается как «дочерний» процесс, а ори
гинал – как «родительский» процесс. После создания копии родитель
ский процесс может завершить свою работу. Для этого проверяется
идентификатор процесса pid после ветвления. Если идентификатор
представлен положительным числом, это означает, что выполняется
родительский процесс. Если вы никогда не программировали ветвле
ние процессов с помощью функции fork(), это может показаться вам
странным. После возврата из функции os.fork() в системе появляется
две копии одного и того же работающего процесса. Обе они проверяют
код, возвращаемый функцией fork(), который в дочернем процессе бу
дет иметь значение 0, а в родительском процессе – соответствовать иден
тификатору процесса. Любое ненулевое значение возвращается только
родительскому процессу, который должен завершить работу. Если
здесь возникло исключение, процесс просто завершается. Если этот
сценарий вызывается из интерактивной командной оболочки (такой
как Bash), вы в этот момент вернетесь в строку приглашения к вводу,
потому что тот процесс, который вы запускали, только что завершил
работу. Но дочерний процесс продолжает свою работу.
Затем процесс изменяет рабочий каталог на / (os.chdir("/"), устанав
ливает маску в значение 0 (os.umask(0)) и создает новый сеанс (os.set
sid()). Изменение каталога на / переводит процесс демона в каталог,
который всегда существует. Дополнительное преимущество, которое
дает операция перехода в каталог /, заключается в том, что долгожи
вущий процесс не будет препятствовать возможности отмонтировать
файловую систему, если получилось, что он был запущен из каталога
в файловой системе, которую вы пожелаете отмонтировать. Затем про
цесс изменяет свою маску режима создания файлов на маску с более
широкими правами. Если демон должен создавать файлы с правами
доступа для группы, унаследованная маска с более ограниченными
правами может давать отрицательный эффект. Последнее из этих трех
действий (os.setsid()), пожалуй, наименее знакомо большинству чи
тателей. Функция setsid() выполняет множество действий. Вопер
вых, она делает процесс лидером нового сеанса. Далее, она делает про
цесс лидером новой группы процессов. Наконец, пожалуй, самое важ
ное для демонов – она лишает процесс управляющего терминала.
Факт отсутствия управляющего терминала означает, что процесс не
может пасть жертвой неумышленных (или преднамеренных) опера
ций с механизмом управления заданиями с какоголибо терминала.
Для долгоживущих процессов, таких как демоны, очень важно ис
ключить возможность прерывания работы.
Но самое интересное на этом не заканчивается. После вызова функции
os.setsid() производится повторное ветвление. Первое ветвление про
цесса и вызов функции setsid() лишь готовят почву для второго ветв
ления – они отсоединяют процесс от какоголибо управляющего тер
минала и делают его лидером сеанса. Второе ветвление означает, что
получившийся процесс не может быть лидером сеанса, а также то, что
```

Запуск демона **387**

```
процесс не может приобрести управляющий терминал. Второе ветвле
ние не является обязательной процедурой и выполняется больше из
предосторожности. Без второго ветвления процесс мог бы приобрести
управляющий терминал, открыв любое терминальное устройство без
флага O_NOCTTY.
Последнее, что делает функция, – выполняет очистку файлов и произ
водит их реорганизацию. Выталкивается информация в стандартных
потоках вывода и вывода сообщений об ошибках (sys.stdout и sys.
stderr). Тем самым гарантируется вывод информации, которая еще не
была выведена. Функция daemonize() позволяет вызывающей програм
ме определять файлы, которые будут играть роль потоков stdin, stdout
иstderr. По умолчанию в качестве всех трех файлов используется уст
ройство /dev/null. В этом месте функция принимает либо указанные
пользователем файлы, либо значения по умолчанию и устанавливает
стандартный ввод, стандартный вывод и стандартный вывод сообще
ний об ошибках в соответствие этим файлам.
Как можно использовать функцию daemonize()? Предположим, что
у нас имеется программный код демона в виде сценария daemonize.py.
В примере 10.27 приводится пример сценария, использующего эту
функцию.
```
```
Пример 10.27. Использование функции daemonize()
from daemonize import daemonize
import time
import sys
```
```
def mod_5_watcher():
start_time = time.time()
end_time = start_time + 20
while time.time() < end_time:
now = time.time()
if int(now) % 5 == 0:
sys.stderr.write('Mod 5 at %s\n' % now)
else:
sys.stdout.write('No mod 5 at %s\n' % now)
time.sleep(1)
```
```
if __name__ == '__main__':
daemonize(stdout='/tmp/stdout.log', stderr='/tmp/stderr.log')
mod_5_watcher()
```
```
Этот сценарий сначала переходит в режим демона, определяя при
этом, что в качестве стандартного вывода будет использоваться файл
/tmp/stdout.log , а в качестве стандартного вывода сообщений об ошиб
ках будет использоваться файл /tmp/stderr.log. Затем в течение 20 се
кунд, с интервалами в 1 секунду между проверками, он отслеживает
текущее время. Если время, выраженное в секундах, делится на пять
без остатка, производится запись сообщения в поток стандартного вы
вода сообщений об ошибках. Если время не делится на пять, произво
```

**388** Глава 10. Процессы и многозадачность

```
дится запись сообщения в поток стандартного вывода. Так как процесс
использует файлы /tmp/stdout.log и /tmp/stderr.log в качестве стан
дартного вывода и стандартного вывода сообщений об ошибках, соот
ветственно, то мы имеем возможность наблюдать эти сообщения после
запуска этого примера...
Сразу же после запуска сценария происходит возврат в строку пригла
шения к вводу:
jmjones@dinkgutsy:code$ python use_daemonize.py
jmjones@dinkgutsy:code$
```
```
И ниже приводится результат работы примера:
```
```
jmjones@dinkgutsy:code$ cat /tmp/stdout.log
No mod 5 at 1207272453.18
No mod 5 at 1207272454.18
No mod 5 at 1207272456.18
No mod 5 at 1207272457.19
No mod 5 at 1207272458.19
No mod 5 at 1207272459.19
No mod 5 at 1207272461.2
No mod 5 at 1207272462.2
No mod 5 at 1207272463.2
No mod 5 at 1207272464.2
No mod 5 at 1207272466.2
No mod 5 at 1207272467.2
No mod 5 at 1207272468.2
No mod 5 at 1207272469.2
No mod 5 at 1207272471.2
No mod 5 at 1207272472.2
jmjones@dinkgutsy:code$ cat /tmp/stderr.log
Mod 5 at 1207272455.18
Mod 5 at 1207272460.2
Mod 5 at 1207272465.2
Mod 5 at 1207272470.2
```
```
Это действительно очень простой пример написания демона, но мы на
деемся, что он наглядно демонстрирует некоторые базовые понятия.
Вы можете использовать функцию daemonize() для создания демона,
который следит за состоянием каталога, выполняет мониторинг сети,
сетевых серверов и всего, что угодно, и работает продолжительное
(или неопределенно продолжительное) время.
```
### В заключение.

```
Хотелось бы надеяться, что эта глава продемонстрировала, насколько
широкими и мощными возможностями обладает язык Python для ра
боты с процессами. В языке Python реализован весьма изящный
и сложный прикладной интерфейс для работы с потоками выполне
ния, но при этом всегда полезно помнить о существовании GIL. Если
```

В заключение **389**

```
вы связаны с вводомвыводом, тогда зачастую эта блокировка не явля
ется проблемой, но если вам требуется загрузить работой несколько
процессоров, то лучше будет использовать несколько процессов. Неко
торые считают, что процессы предпочтительнее, чем потоки, даже ес
ли бы не было блокировки GIL. Главная причина появления такого
мнения состоит в том, что отладка многопоточного программного кода
может превратиться в кошмар.
Наконец, будет совсем не лишним поближе познакомиться с модулем
subprocess, если вы с ним еще не знакомы. Subprocess – это универ
сальный модуль, построенный по принципу «все в одном», предназна
ченный для работы с... ну. пусть будет, с подпроцессами.
```

**11**

### 11. Создание графического интерфейса

```
Когда информированные люди перечисляют обязанности системного
администратора, разработка программ с графическим интерфейсом
пользователя (ГИП) обычно не входит в их число. Тем не менее, быва
ют моменты, когда администратору просто необходимо создать прило
жение с графическим интерфейсом или создание такого приложения
сможет существенно облегчить ему жизнь. Здесь мы рассматриваем
идею графического интерфейса в широком смысле, подразумевая как
традиционные приложения – с графическим интерфейсом на базе та
ких библиотек, как GTK или Qt, так и приложения с вебинтерфейсом.
В этой главе все наше внимание будет сосредоточено на использовании
библиотек PyGTK, curses и вебплатформы Django. Для начала мы
рассмотрим основы создания графического интерфейса, затем перей
дем к исследованию очень простого приложения, использующего биб
лиотеку PyGTK, а потом напишем то же самое приложение с использо
ванием curses и Django. Наконец, разберем, как с помощью Django
и небольшого объема программного кода можно написать приложение
для работы с базой данных, имеющее привлекательный интерфейс.
```
**Теория создания графического интерфейса**

Когда создается консольная утилита, предполагается, что она будет вы
полнять все необходимые действия без вмешательства пользователя.
Такое положение дел имеет место, когда сценарии запускаются с помо
щью таких планировщиков заданий, как cron и at. Но когда создается
утилита с графическим интерфейсом, предполагается, что пользова
тель должен будет чтото вводить, чтобы эта утилита могла выполнить
свою работу. Вспомните свой опыт работы с графическими приложе
ниями, такими как вебброузеры, клиенты электронной почты и тек
стовые процессоры. Вы _запускаете_ приложение некоторым способом.


Теория создания графического интерфейса **391**

```
Приложение выполняет некоторые действия по инициализации, воз
можно, загружает какиенибудь конфигурационные файлы и перево
дит себя в некоторое определенное состояние. Но после этого приложе
ние просто ждет, пока пользователь сделает чтонибудь. Конечно, су
ществуют примеры приложений, выполняющих некоторые действия
самостоятельно, как, например, Firefox автоматически проверяет на
личие обновлений без явного требования или согласия пользователя,
но это уже другая история.
Чего ожидает приложение? Как оно узнает, что делать, когда пользо
ватель предпримет какоелибо действие? Приложение ожидает, пока
произойдет событие. Событие – это то, что происходит в пределах при
ложения с одним из визуальных элементов управления, например на
жатие кнопки или выбор флажка. И приложение «знает», что делать,
когда происходят такие события, потому что программист связывает
определенные события с определенными фрагментами программного
кода. «Фрагменты программного кода», связанные с определенными
событиями, называют обработчиками событий. Одно из предназначе
ний библиотек, на базе которых создается графический интерфейс, за
ключается в том, чтобы вызвать правильный обработчик события, ко
гда происходит некоторое событие. Если быть более точным, библиоте
ка графического интерфейса реализует «цикл событий», в пределах
которого выполняется проверка поступления новых событий, и, когда
события происходят, обрабатывает их соответствующим способом.
Поведение приложения управляется событиями. Когда вы пишете
приложение с графическим интерфейсом, вы сами решаете, как при
ложение должно реагировать на те или иные действия пользователя.
Вы создаете обработчики событий, которые будут вызываться библио
текой графического интерфейса при возбуждении событий пользова
телем.
Это описание соответствует приложениям, а как сформировать сам ин
терфейс? То есть как создавать кнопки, текстовые поля ввода, метки
и флажки в приложении? Ответ на этот вопрос зависит от используе
мого инструментария. Графический интерфейс можно создать с помо
щью специальной программыпостроителя графического интерфейса,
входящей в состав выбранной вами библиотеки. Построитель графиче
ского интерфейса позволяет разместить в форме будущего приложе
ния различные визуальные компоненты, такие как кнопки, метки,
флажки и другие. Например, если вы работаете в операционной систе
ме Mac OS X и выбрали в качестве основы библиотеку Cocoa, то для раз
мещения графических компонентов можно воспользоваться програм
мой Interface Builder. Или, если вы выбрали PyGTK в Linux, можно
воспользоваться программой Glade. Или, если вы выбрали PyQt, мож
но прибегнуть к помощи программы Qt Designer.
Построители графического интерфейса удобны в использовании, но
иногда у вас может появиться желание иметь более полный контроль
```

**392** Глава 11. Создание графического интерфейса

```
над графическим интерфейсом, чем может предложить программапо
строитель. В таких случаях будет совсем несложно создать графический
интерфейс «вручную», написав немного программного кода. В библио
теке PyGTK каждому типу графических элементов соответствует свой
класс на языке Python. Например, окно – это объект класса gtk.Window.
Кнопка – это объект класса gtk.Button. Чтобы создать простое прило
жение с графическим интерфесом, которое имеет окно и кнопку, вы
создаете экземпляры классов gtk.Window и gtk.Button и добавляете
кнопку в окно. Если необходимо, чтобы по щелчку на кнопке выпол
нялись некоторые действия, вы должны определить обработчик собы
тия «щелчка» на кнопке.
```
**Создание простого приложения PyGTK**

```
Мы создадим простой сценарий, использующий уже упоминавшиеся
классы gtk.Window и gtk.Button. Ниже приводится исходный текст про
стого приложения с графическим интерфейсом, которое не делает ни
чего полезного, но демонстрирует некоторые основные принципы соз
дания программ с графическим интерфейсом.
Прежде чем можно будет опробовать этот пример или написать свое
собственное приложение на базе библиотеки PyGTK, вам необходимо
установить ее. В современных дистрибутивах Linux установка выпол
няется достаточно просто. Она выполняется просто даже для Windows.
Если вы пользуетесь дистрибутивом Ubuntu, эта библиотека должна
быть уже установлена. Если для вашей платформы нет готового двоич
ного дистрибутива, то установка может оказаться достаточно слож
ной. Исходный текст приложения приводится в примере 11.1.
```
```
Пример 11.1. Простое приложение PyGTK с одним окном и с одной кнопкой
#!/usr/bin/env python
import pygtk
import gtk
import time
```
```
class SimpleButtonApp(object):
"""Это простое приложение PyGTK с одним окном и с одной кнопкой.
После щелчка на кнопке на ней отображается текущее время.
"""
```
```
def __init__(self):
#Главное окно приложения
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
#Так "регистрируется" обработчик события. Этот вызов
#предписывает главному циклу gtk вызвать self.quit(),
#когда окно "посылает" сигнал "destroy".
self.window.connect("destroy", self.quit)
```

Создание простого приложения PyGTK **393**

```
#Надпись на кнопке "Click Me"
self.button = gtk.Button("Click Me")
```
```
#Регистрация другого обработчика события. На этот раз, когда
#кнопка "посылает" сигнал "clicked", будет вызываться метод
#'update_button_label'.
self.button.connect("clicked", self.update_button_label, None)
```
```
#Окно – это контейнер. Метод "add" вставляет кнопку в окно.
self.window.add(self.button)
```
```
#Этот вызов делает кнопку видимой, но она не станет видимой,
#пока не станет видимым содержащий ее контейнер.
self.button.show()
#Сделать контейнер видимым
self.window.show()
def update_button_label(self, widget, data=None):
"""Помещает на кнопку надпись с текущим временем
Это обработчик события 'clicked' кнопки
"""
self.button.set_label(time.asctime())
```
```
def quit(self, widget, data=None):
"""Останавливает главный цикл событий gtk
Когда пользователь закрывает окно, оно исчезнет, но,
если не остановить главный цикл событий gtk, приложение
продолжит работу, хотя все будет выглядеть так, как будто
ничего не происходит
"""
gtk.main_quit()
```
```
def main(self):
"""Запуск главного цикла событий gtk"""
gtk.main()
if __name__ == "__main__":
s = SimpleButtonApp()
s.main()
```
```
Самое первое, на что вы наверняка обратили внимание в этом приме
ре, это то, что главный класс приложения наследует класс object, а не
какойнибудь класс GTK. Приложение с графическим интерфейсом на
базе PyGTK не обязательно должно быть реализовано в объектноори
ентированном стиле. Безусловно, вам придется создавать экземпляры
классов, но вы не обязаны создавать собственные классы. Однако для
чегото большего, чем тривиальный пример, такой как этот, мы на
стоятельно рекомендуем создавать собственные классы. Главное пре
имущество такого подхода к созданию приложений с графическим ин
терфейсом заключается в том, что все визуальные компоненты (окна,
кнопки, флажки) будут прикреплены к одному и тому же объекту, что
обеспечит прямой доступ к ним из любой части приложения.
```

**394** Глава 11. Создание графического интерфейса

```
Т. к. мы предпочли создать свой собственный класс, то сразу же нач
нем с того, что происходит в конструкторе (метод __init__()). Фактиче
ски, почти все, что делает это приложение, сосредоточено в конструк
торе. Этот пример содержит подробные комментарии, поэтому мы не
будем дублировать все пояснения здесь, а отметим наиболее важные
моменты. В конструкторе создаются два объекта графического интер
фейса: gtk.Window и gtk.Button. Затем кнопка помещается в окно, так
как окно – это контейнерный объект. Мы также создали обработчики
событий destroy и clicked, порождаемых окном и кнопкой соответст
венно. После запуска приложения на экране появляется окно с кноп
кой, имеющей надпись «Click Me» (щелкни здесь). Каждый раз, когда
производится щелчок на кнопке, надпись на кнопке обновляется и ото
бражает текущее время. На рис. 11.1 и 11.2 приводится внешний вид
приложения до и после щелчка на кнопке.
```
**Создание приложения PyGTK для просмотра**

**файла журнала вебсервера Apache**

```
Теперь, когда мы рассмотрели основы создания графического интер
фейса в общем и с использованием PyGTK, перейдем к примеру, кото
рый с помощью PyGTK реализует нечто более полезное – рассмотрим
создание приложения для просмотра содержимого файла журнала
вебсервера Apache. Это приложение будет обладать следующими
функциональными возможностями:
```
**-** Позволит выбирать и открывать требуемый файл журнала
**-** Будет отображать номер строки, имя удаленного хоста, код состоя
    ния и количество переданных байтов
**-** Позволит сортировать строки по их номерам, по именам удаленных
    хостов, коду состояния или количеству переданных байтов

```
Рис. 11.1. Простое приложение PyGTK – до щелчка на кнопке
```
```
Рис. 11.2. Простое приложение PyGTK – после щелчка на кнопке
```

Создание приложения PyGTK для просмотра файла журнала Apache **395**

```
Этот пример основан на программном коде, выполняющем анализ фай
ла журнала Apache, который мы написали в главе 3. Исходный текст
приложения приводится в примере 11.2.
```
```
Пример 11.2. Приложение PyGTK для просмотра файла журнала
веб>сервера Apache
#!/usr/bin/env python
import gtk
from apache_log_parser_regex import dictify_logline
class ApacheLogViewer(object):
"""Программа просмотра файла журнала вебсервера Apache, которая
позволяет сортировать информацию по разным полям данных"""
def __init__(self):
#Главное окно приложения
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
self.window.set_size_request(640, 480)
self.window.maximize()
```
```
#Остановить цикл событий при закрытии окна
self.window.connect("destroy", self.quit)
```
```
#VBox – это контейнер, позволяющий добавлять в него визуальные
#компоненты. Используется в первую очередь для обеспечения
#определенного порядка расположения компонентов
self.outer_vbox = gtk.VBox()
```
```
#Панель инструментов с кнопками открытия журнала
#и завершения приложения
self.toolbar = gtk.Toolbar()
#Создать кнопки открытия файла и завершения приложения
#и пиктограммы добавить кнопки на панель инструментов
#связать кнопки с соответствующими обработчиками событий
open_icon = gtk.Image()
quit_icon = gtk.Image()
open_icon.set_from_stock(gtk.STOCK_OPEN, gtk.ICON_SIZE_LARGE_TOOLBAR)
quit_icon.set_from_stock(gtk.STOCK_QUIT, gtk.ICON_SIZE_LARGE_TOOLBAR)
self.open_button = gtk.ToolButton(icon_widget=open_icon)
self.quit_button = gtk.ToolButton(icon_widget=quit_icon)
self.open_button.connect("clicked", self.show_file_chooser)
self.quit_button.connect("clicked", self.quit)
self.toolbar.insert(self.open_button, 0)
self.toolbar.insert(self.quit_button, 1)
```
```
#Элемент управления для выбора открываемого файла
self.file_chooser = gtk.FileChooserWidget()
self.file_chooser.connect("file_activated", self.load_logfile)
#ListStore используется для представления данных, имеющих вид
#списка. Элемент ListStore будет хранить табличные данные в виде:
#номер_строки, имя_хоста, статус, переданные_байты, текст_записи
self.loglines_store = gtk.ListStore(int, str, str, int, str)
```

**396** Глава 11. Создание графического интерфейса

```
#связать дерево с данными...
self.loglines_tree = gtk.TreeView(model=self.loglines_store)
#...и добавить надписи в заголовки колонок
self.add_column(self.loglines_tree, 'Line Number', 0)
self.add_column(self.loglines_tree, 'Remote Host', 1)
self.add_column(self.loglines_tree, 'Status', 2)
self.add_column(self.loglines_tree, 'Bytes Sent', 3)
self.add_column(self.loglines_tree, 'Logline', 4)
#определить прокручиваемую область для отображения файла журнала
self.loglines_window = gtk.ScrolledWindow()
#объединить все вместе
self.window.add(self.outer_vbox)
self.outer_vbox.pack_start(self.toolbar, False, False)
self.outer_vbox.pack_start(self.file_chooser)
self.outer_vbox.pack_start(self.loglines_window)
self.loglines_window.add(self.loglines_tree)
#сделать элементы видимыми
self.window.show_all()
```
```
#при этом элемент выбора файла должен оставаться невидимым
self.file_chooser.hide()
```
```
def add_column(self, tree_view, title, columnId, sortable=True):
column = gtk.TreeViewColumn(title, gtk.CellRendererText() ,
text=columnId)
column.set_resizable(True)
column.set_sort_column_id(columnId)
tree_view.append_column(column)
```
```
def show_file_chooser(self, widget, data=None):
"""делает видимым диалог выбора файла"""
self.file_chooser.show()
def load_logfile(self, widget, data=None):
"""загружает данные в визуальный компонент"""
filename = widget.get_filename()
print "FILE>", filename
self.file_chooser.hide()
self.loglines_store.clear()
logfile = open(filename, 'r')
for i, line in enumerate(logfile):
line_dict = dictify_logline(line)
self.loglines_store.append([i + 1, line_dict['remote_host'],
line_dict['status'], int(line_dict['bytes_sent']), line])
logfile.close()
def quit(self, widget, data=None):
"""останавливает главный цикл событий gtk"""
gtk.main_quit()
```
```
def main(self):
"""запускает главный цикл событий gtk"""
```

Создание приложения PyGTK для просмотра файла журнала Apache **397**

```
gtk.main()
if __name__ == "__main__":
l = ApacheLogViewer()
l.main()
```
```
В примере приложения просмотра файла журнала вебсервера Apache
главный класс приложения называется ApacheLogViewer и наследует
класс object. В нашем главном объекте нет ничего особенного, он про
сто объединяет в себе все части графического интерфейса.
Далее в методе __init__() создается объект окна. В этом примере данная
операция отличается от аналогичной операции в предыдущем, «про
стом», примере тем, что здесь указаны размеры окна. Мы сначала ука
зываем, что окно должно иметь размеры 640×480, а затем предписыва
ем максимизировать его. Такая двойная установка размеров была вы
полнена преднамеренно. 640×480 – это довольно разумные начальные
размеры, поэтому это очень неплохие значения по умолчанию. Хотя
размеры 640×480 достаточно хороши, но чем окно больше, тем лучше,
поэтому мы максимизируем окно. Оказывается, что первоначальная
установка размеров 640×480 (или любых других размеров) считается
хорошей практикой. Согласно документации к PyGTK менеджер окон
может не поддерживать запрос maximize(). Кроме того, пользователю
может понадобиться снова уменьшить размеры окна после его увеличе
ния, поэтому есть смысл задать исходные размеры окна.
После создания окна и определения его размеров мы создаем элемент
VBox. Это область, или ящик, с «вертикальным размещением», пред
ставляющая собой контейнерный объект. В библиотеке GTK использу
ется концепция использования областей с вертикальным (VBox) и гори
зонтальным (HBox) размещением визуальных компонентов (виджетов)
в окне. Основное предназначение этих областей состоит в том, чтобы
вы могли «наполнять» их виджетами, помещая их в начало (сверху
для VBox и слева для HBox) или в конец области. Под термином «вид
жет» подразумеваются обычные элементы графического интерфейса,
такие как кнопки или текстовые поля. При использовании этих облас
тей вы можете расположить виджеты в окне практически любым тре
буемым вам способом. Поскольку области являются контейнерами,
они могут вмещать другие области, поэтому вы спокойно можете встав
лять одни области в другие.
После добавления области VBox в окно мы добавляем панель инстру
ментов и кнопки. Сама по себе панель инструментов – это еще одна
разновидность контейнеров, и она предоставляет методы для добавле
ния в нее компонентов. Далее мы создаем пиктограммы для кнопок,
сами кнопки и подключаем к кнопкам обработчики событий. Нако
нец, мы добавляем кнопки на панель инструментов. Для добавления
виджетов на панель инструментов Toolbar используется метод insert(),
играющий ту же роль, что и метод pack_start() области VBox.
```

**398** Глава 11. Создание графического интерфейса

```
Далее мы создаем виджет выбора файлов, который позволит отыски
вать файлы журналов для просмотра, и связываем его с обработчиком
события. В этой части нет ничего сложного, но мы вскоре еще вернем
ся к ней.
После создания виджета выбора файлов мы создаем компонент спи
ска, который будет содержать строки из файла журнала. Этот компо
нент состоит из двух частей: объект хранения данных (с именем List
Store) и визуальный компонент (TreeView), с которым пользователь бу
дет взаимодействовать. Компонент хранения данных создается пер
вым, путем определения типов данных для каждой колонки. Затем мы
создаем визуальный компонент и связываем с ним компонент хране
ния данных.
Вслед за компонентом списка создается последний контейнер – про
кручиваемая область окна, после чего все виджеты объединяются вме
сте. Мы помещаем в созданную ранее область VBox панель инструмен
тов, виджет выбора файлов и прокручиваемую область. Список, содер
жащий строки из файла журнала, мы добавляем в прокручиваемую
область, благодаря чему при большом количестве строк мы сможем
прокручивать их.
В заключение мы делаем одни виджеты видимыми, а другие – невиди
мыми. Главное окно делается видимым с помощью метода show_all().
Этот метод делает видимыми и все вложенные компоненты. Учиты
вая, что мы создаем приложение с графическим интерфейсом, нам не
обходимо, чтобы виджет выбора файлов оставался невидимым, пока
пользователь не щелкнет на кнопке «open» (открыть). Поэтому этот
виджет после его создания мы делаем невидимым.
Запустив это приложение, вы сможете убедиться, что оно соответству
ет нашим первоначальным требованиям. Мы можем выбирать и от
крывать нужный нам файл журнала. Каждому полю – номер строки,
имя хоста, код состояния и количество переданных байтов – соответ
ствует своя колонка в компоненте списка, поэтому мы легко можем
идентифицировать данные, просто взглянув на строку. Кроме того, мы
можем выполнять сортировку по любому столбцу, просто щелкнув на
соответствующем заголовке.
```
**Создание приложения для просмотра файла**

**журнала вебсервера Apache с помощью curses**

```
curses – это библиотека, облегчающая создание интерактивных прило
жений с текстовым интерфейсом. В отличие от библиотек графическо
го интерфейса curses не поддерживает модель обработки событий
функциями обратного вызова. Вы сами отвечаете за получение ввода
от пользователя и за его обработку, тогда как в GTK задача получения
ввода от пользователя обрабатывается виджетами, и библиотека сама
```

Создание приложения для Apache с использованием curses **399**

```
вызывает функцииобработчики при возникновении событий. Еще од
но различие между curses и библиотеками создания графического ин
терфейса заключается в том, что при использовании библиотек графи
ческого интерфейса вы добавляете виджеты в некоторый контейнер
и позволяете библиотеке самой заниматься отображением и обновле
нием экрана. При использовании библиотеки curses вам обычно самим
придется заниматься выводом текста на экран.
В примере 11.3 приводится еще одна версия программы просмотра фай
ла журнала вебсервера Apache, реализованная с использованием моду
ля curses, входящего в состав стандартной библиотеки языка Python.
```
```
Пример 11.3. Приложение curses для просмотра файла журнала
веб>сервера Apache
#!/usr/bin/env python
"""
```
```
Программа просмотра файла журнала вебсервера Apache, реализованная на основе
библиотеки curses
```
```
Порядок использования:
curses_log_viewer.py logfile
```
```
Этой командой будет запущено интерактивное, управляемое с клавиатуры
приложение просмотра файла журнала. Ниже приводится перечень горячих клавиш
с описанием выполняемых ими функций:
u/d прокрутка вверх/вниз
t перейти в начало файла
q завершить работу
b/h/s – сортировать по количеству байтов/имени хоста/коду состояния
r восстановить первоначальный порядок сортировки
```
```
"""
import curses
from apache_log_parser_regex import dictify_logline
import sys
import operator
class CursesLogViewer(object):
def __init__(self, logfile=None):
self.screen = curses.initscr()
self.curr_topline = 0
self.logfile = logfile
self.loglines = []
def page_up(self):
self.curr_topline = self.curr_topline (2 * curses.LINES)
if self.curr_topline < 0:
self.curr_topline = 0
self.draw_loglines()
```

**400** Глава 11. Создание графического интерфейса

```
def page_down(self):
self.draw_loglines()
```
```
def top(self):
self.curr_topline = 0
self.draw_loglines()
def sortby(self, field):
#self.loglines = sorted(self.loglines, key=operator.itemgetter(field))
self.loglines.sort(key=operator.itemgetter(field))
self.top()
def set_logfile(self, logfile):
self.logfile = logfile
self.load_loglines()
```
```
def load_loglines(self):
self.loglines = []
logfile = open(self.logfile, 'r')
for i, line in enumerate(logfile):
line_dict = dictify_logline(line)
self.loglines.append((i + 1, line_dict['remote_host'],
line_dict['status'], int(line_dict['bytes_sent']), line.rstrip()))
logfile.close()
self.draw_loglines()
def draw_loglines(self):
self.screen.clear()
status_col = 4
bytes_col = 6
remote_host_col = 16
status_start = 0
bytes_start = 4
remote_host_start = 10
line_start = 26
logline_cols = curses.COLSstatus_colbytes_colremote_host_col1
for i in range(curses.LINES):
c = self.curr_topline
try:
curr_line = self.loglines[c]
except IndexError:
break
self.screen.addstr(i, status_start, str(curr_line[2]))
self.screen.addstr(i, bytes_start, str(curr_line[3]))
self.screen.addstr(i, remote_host_start, str(curr_line[1]))
#self.screen.addstr(i, line_start,
str(curr_line[4])[logline_cols])
self.screen.addstr(i, line_start, str(curr_line[4]), logline_cols)
self.curr_topline += 1
self.screen.refresh()
def main_loop(self, stdscr):
stdscr.clear()
self.load_loglines()
```

Создание приложения для Apache с использованием curses **401**

```
while True:
c = self.screen.getch()
try:
c = chr(c)
except ValueError:
continue
if c == 'd':
self.page_down()
elif c == 'u':
self.page_up()
elif c == 't':
self.top()
elif c == 'b':
self.sortby(3)
elif c == 'h':
self.sortby(1)
elif c == 's':
self.sortby(2)
elif c == 'r':
self.sortby(0)
elif c == 'q':
break
```
```
if __name__ == '__main__':
infile = sys.argv[1]
c = CursesLogViewer(infile)
curses.wrapper(c.main_loop)
```
```
В примере 11.3 мы создали единственный класс, CursesLogViewer, с це
лью организации программного кода. В конструкторе создается экран
curses и инициализируется несколько переменных. Экземпляр класса
CursesLogViewer создается в разделе «main» программы, при этом ему
передается имя файла журнала, который требуется просмотреть. Мы
могли бы реализовать в приложении возможность поиска и выбора
файла, но для этого пришлось бы приложить больше усилий, чем
в приложении PyGTK. Кроме того, поскольку приложение будет за
пускаться пользователем из командной оболочки, вполне естествен
ным будет ожидать, что пользователь сначала отыщет требуемый файл
в командной строке, а затем укажет его при запуске приложения. По
сле создания экземпляра класса CursesLogViewer мы передаем метод
main_loop() функции wrapper() из библиотеки curses. Функция wrapper()
переводит терминал в состояние, пригодное для работы приложения
на базе curses, вызывает указанную ей функцию, а затем, перед воз
вратом, возвращает терминал в нормальное состояние.
Метод main_loop() действует как элементарный цикл обработки собы
тий. Он ожидает, пока пользователь нажмет какуюлибо клавишу на
клавиатуре. После этого в соответствии с введенным символом цикл
переходит к соответствующему методу (или, по крайней мере, к реали
зации требуемого поведения). Нажатие клавиш u и d вызывает про
```

**402** Глава 11. Создание графического интерфейса

```
крутку вверх и вниз – за счет вызова методов page_up() и page_down(), со
ответственно. Метод page_down() просто вызывает метод draw_loglines(),
который выводит строки на терминал, начиная с текущей строки
и с верхней позиции на экране. При выводе каждой строки текущей
становится следующая строка. Метод draw_loglines() выводит столько
строк, сколько поместится на экране, а при следующем вызове он
вновь начнет вывод очередной текущей строки с верхней позиции на
экране. Поэтому многократный вызов draw_loglines() создает визуаль
ный эффект прокрутки вниз по содержимому файла журнала. Метод
page_up() сначала назначает текущей строку, расположенную на две
страницы выше, и затем производит вывод строк вызовом метода
draw_loglines(). Это создает визуальный эффект прокрутки вверх по
содержимому файла журнала. Причина, по которой в методе page_up()
текущей назначается строка, расположенная на две страницы выше,
состоит в том, что после вывода строк текущей становится строка, рас
положенная внизу экрана. Такой порядок был выбран для упрежде
ния прокрутки вниз.
Следующий метод нашего класса реализует сортировку. Мы преду
смотрели сортировку по имени хоста, коду состояния и количеству
байтов, отправленных в ответ на запрос. Любая попытка сортировки
приводит к вызову метода sortby(). Метод sortby() сортирует список
строк объекта CursesLogViewer по указанному полю, после чего вызыва
ет метод top(). Метод top() назначает текущей первую строку в списке
и затем выводит очередную страницу строк (которая будет первой
страницей).
Последний обработчик события в нашем приложении выполняет за
вершение работы приложения. В этом случае просто происходит пре
рывание «цикла обработки событий», что позволяет методу main_loop()
вернуть управление функции wrapper(), которая в свою очередь произ
водит восстановление режима работы терминала.
Несмотря на то, что по числу строк программного кода обе версии при
ложения вполне сопоставимы, тем не менее, для реализации приложе
ния на базе библиотеки curses пришлось приложить больше усилий.
Возможно, это обусловлено необходимостью создавать свой собствен
ный цикл обработки событий. Или, может быть, изза необходимости
создавать некоторое подобие графических элементов. Или, возможно,
изза того, что пришлось «рисовать» текст непосредственно на экране
терминала, у нас сложилось ощущение, что пришлось выполнить
больше работы. Как бы то ни было, иногда знание того, как создавать
приложения на базе curses, может оказаться полезным.
На рис. 11.3 показан внешний вид приложения просмотра файла жур
нала, в котором строки отсортированы по количеству отправленных
байтов.
Одно из улучшений, которое можно было бы внести в это приложение, –
это реализовать сортировку в порядке, обратном текущему. Сделать
```

Веб;приложения **403**

```
это достаточно просто, но мы оставим реализацию этой возможности
читателям. Как еще одно улучшение можно было бы организовать
просмотр всей информационной части строки журнала. Это тоже не
очень сложно, но реализацию этой возможности мы также оставим за
читателями в качестве упражнения.
```
**Вебприложения**

```
Сказать, что Сеть огромна, значит преуменьшить ее истинные разме
ры. Сеть изобилует приложениями, которые люди используют еже
дневно. Почему в Сети так много приложений? Вопервых, вебприло
жения отличаются широтой доступности. Это означает, что после раз
вертывания вебприложения любой, кто обладает доступом к нему,
может просто указать адрес URL в своем броузере и пользоваться им.
Пользователям не требуется ничего загружать и устанавливать, разве
только дополнения к броузеру (который сам по себе уже установлен),
такие как Flash. Эта особенность особенно привлекательна для пользо
вателей. Вовторых, вебприложения могут подвергаться модерниза
ции в одностороннем порядке, причем сразу для всех пользователей.
Это означает, что одна сторона (владелец приложения) может выпол
нить модернизацию приложения без какоголибо участия другой сто
роны (пользователя). Хотя в действительности это справедливо, толь
ко если вы не опираетесь на функциональные возможности, которые
могут отсутствовать у пользователя. Например, если ваше модернизи
рованное приложение опирается на новейшую версию Flash, это мо
жет потребовать от пользователей установить новую версию расшире
```
```
Рис. 11.3. Содержимое файла журнала веб>сервера Apache
```

**404** Глава 11. Создание графического интерфейса

```
ния, и все ваши преимущества могут «вылететь в трубу». Если же это
го не требуется, то возможность модернизации вебприложений стано
вится привлекательной для обеих сторон, хотя пользователи, скорее
всего, осознают это не так явно. Втретьих, броузер представляет собой
в значительной степени универсальную платформу. Конечно, имеются
определенные проблемы с обеспечением совместимости между броузе
рами, но в большинстве случаев, если вы не будете использовать спе
циальные расширения, то вебприложение, работающее в одном бро
узере и в одной операционной системе, практически наверняка будет
работать в другом броузере и в другой операционной системе. Эта осо
бенность также является привлекательной для обеих сторон. Просто
со стороны разработчика придется приложить немного больше уси
лий, чтобы обеспечить работоспособность приложения в различных
броузерах. А пользователи любят пользоваться приложениями, остав
ляющими за ними право выбора.
Насколько это важно для вас, как для системного администратора?
Все причины, которые приводились в пользу создания приложений
с графическим интерфейсом, в равной степени относятся и к вебприло
жениям. Одно из преимуществ вебприложений для системных адми
нистраторов состоит в том, что вебприложения имеют доступ к файло
вой системе и таблице процессов на той машине, на которой они вы
полняются. Эта особенность вебприложений делает их прекрасным
решением для осуществления мониторинга системы, приложений
и пользователей, а также отличным механизмом предоставления отче
тов. А этот класс задач находится в области ведения системного адми
нистратора.
Хотелось бы надеяться, что вы сможете воспользоваться этими преиму
ществами, хотя совсем не все вебприложения, которые вы создаете для
себя или для ваших пользователей, могут давать такой эффект. Итак,
какие инструменты вы можете использовать для создания вебприло
жений? Поскольку эта книга о языке Python, мы, конечно же, реко
мендуем использовать решения, основанные на языке Python. Но что
из них выбрать? Одна из проблем состоит в том, что существует столько
же платформ для разработки вебприложений на языке Python, сколь
ко дней в году. В настоящее время доминирующее положение занима
ют четыре из них – TurboGears, Django, Pylons и Zope. У каждой из
этих четырех платформ имеются свои достоинства, но на наш взгляд,
платформа Django лучше других соответствует теме этой книги.
```
**Django**

```
Django – это полнофункциональная платформа для разработки веб
приложений. Она содержит систему управления шаблонами, механиз
мы соединения с базами данных посредством объектнореляционной
проекции и, конечно же, сам язык Python для реализации логики при
ложений. Будучи «полнофункциональной» платформой, Django также
```

Django **405**

```
использует подход MVT (ModelViewTemplate – модельпредставление
шаблон). Подход модельпредставлениешаблон похож, если не иден
тичен, более общему подходу MVC (ModelViewController – модель
представлениеконтроллер). Оба способа позволяют разрабатывать веб
приложения так, чтобы не смешивать части приложений. Программ
ный код взаимодействия с базой данных в обоих случаях представляет
собой отдельную область, которая называется «моделью». Бизнесло
гика выделяется в область, которая называется «представлением»
в MVT и «контроллером» в MVC. А внешний интерфейс выделяется
в область, которая называется «шаблоном» в MVT и «представлени
ем» в MVC.
```
**Приложение для просмотра файла журнала**

**вебсервера Apache**

```
В следующем примере, состоящем из нескольких фрагментов про
граммного кода, мы создадим еще одно приложение для просмотра
файла журнала вебсервера Apache, аналогичное тому, что было реали
зовано на базе библиотеки PyGTK. Так как мы собираемся открывать
файлы журналов, чтобы позволить пользователям просматривать и сор
тировать их, то нам не потребуется обращаться к базе данных и наш
пример будет лишен какихлибо средств подключения к базам дан
ных. Прежде чем приступить к обсуждению примера, мы покажем
вам, как создать проект и приложение в Django.
Загрузить Django можно по адресу: http://www.djangoproject.com/.
К моменту написания этих строк последней была версия 0.96. Однако
мы рекомендуем устанавливать версию из дерева разработки. После
загрузки платформа устанавливается обычной командой python set
up.py install. После установки в каталоге site>packages появятся до
полнительные библиотеки платформы Django и сценарий django–ad
min.py в каталоге для сценариев. Обычно в UNIXподобных системах
сценарии по умолчанию устанавливаются в тот же каталог, где нахо
дится выполняемый файл python.
После установки Django необходимо создать проект и приложение. Про
екты содержат по одному или более приложений. Кроме того, они игра
ют роль центров конфигурации для всего вебприложения (не путайте
с приложением Django), которое вы создаете. Приложения Django –
это небольшие фрагменты, которые могут многократно использовать
ся в разных проектах. Для нашего приложения просмотра файла жу
ранала вебсервера Apache мы создали проект с именем «dj_apache»,
выполнив команду django–admin.py startproject dj_apache. Эта команда
создала каталог и несколько файлов. В примере 11.4 приводится дере
во каталогов нового проекта.
```
```
Пример 11.4. Дерево каталогов проекта Django
jmjones@dinkbuntu:~/code$ tree dj_apache
```

**406** Глава 11. Создание графического интерфейса

```
dj_apache
| __init__.py
| manage.py
| settings.py
` urls.py
0 directories, 4 files
```
```
Теперь, когда у нас имеется проект, мы можем в рамках этого проекта
создать приложение. Для этого сначала следует перейти в каталог
dj_apache , а затем создать приложение, выполнив команду django–ad
min.py startapp logview. В результате в каталоге dj_apache будет создан
каталог logview и несколько файлов. В примере 11.5 показаны все фай
лы и каталоги, которые теперь имеются в нашем распоряжении.
```
```
Пример 11.5. Дерево каталогов приложения Django
jmjones@dinkbuntu:~/tmp$ tree dj_apache/
dj_apache/
| __init__.py
| logview
| | __init__.py
| | models.py
| ` views.py
| manage.py
| settings.py
` urls.py
```
```
Как видите, каталог приложения (logview) содержит файлы models.py
иviews.py. Платформа Django следует соглашениям MVT, поэтому эти
файлы помогут разделить все приложение на компоненты, соответст
вующие именам файлов. Файл models.py содержит схему базы данных,
поэтому он представляет компонент Model (модель) в аббревиатуре
MVT. Файл views.py содержит реализацию логики приложения, по
этому он представляет компонент View (представление) в этой аббре
виатуре.
Здесь отсутствует компонент Template (шаблон). Компонент шаблона
содержит уровень представления всего приложения. Существует не
сколько способов заставить платформу Django увидеть наши шаблоны.
Так, в примере 11.6 показано, что мы создали подкаталог templates
в каталоге logview.
```
```
Пример 11.6. Добавление каталога templates
jmjones@dinkbuntu:~/code$ mkdir dj_apache/logview/templates
jmjones@dinkbuntu:~/code$ tree dj_apache/
dj_apache/
| __init__.py
| logview
| | __init__.py
| | models.py
| | templates
```

Django **407**

```
| ` views.py
| manage.py
| settings.py
` urls.py
```
```
2 directories, 7 files
```
```
Теперь мы готовы к воплощению нашего приложения. В первую оче
редь мы должны решить, как будут работать наши URL. Это очень про
стое приложение, поэтому адреса URL должны быть очень простыми.
Нам потребуется выводить список файлов журналов, доступных для
просмотра. Поскольку приложение обладает простой и ограниченной
функциональностью, мы будем использовать адрес URL «/» для дос
тупа к списку файлов и строку URL вида "/viewlog/some_sort_method/
some_log_file" для указания имени файла и метода сортировки. Чтобы
связать URL с определенным действием, нам необходимо обновить
файл urls.py в корневом каталоге проекта. Содержимое файла urls.py
для нашего проекта приводится в примере 11.7.
```
```
Пример 11.7. Конфигурация URL для проекта Django (urls.py)
from django.conf.urls.defaults import *
```
```
urlpatterns = patterns('',
(r'^$', 'dj_apache.logview.views.list_files'),
(r'^viewlog/(?P<sortmethod>.*?)/(?P<filename>.*?)/$',
'dj_apache.logview.views.view_log'),
)
```
```
Файл с настройками URL достаточно прост и понятен. Этот файл опира
ется на использование регулярных выражений: строки URL, соответст
вующие регулярному выражению, отображаются на функцию пред
ставления, задаваемую явно строкой. Здесь мы отображаем URL «/» на
функцию "dj_apache.logview.views.list_files". Все остальные URL, со
ответствующие регулярному выражению '^viewlog/(?P<sortmethod>.*?)/
(?P<filename>.*?)/$', – на функцию "dj_apache.logview.views.view_log".
Когда броузер соединяется с вебприложением Django и отсылает за
прос на доступ к определенному ресурсу, Django просматривает urls.py
в поисках элемента, регулярное выражение которого соответствует
URL, и затем направляет запрос соответствующей функции.
В примере 11.8 представлен исходный текст функций представления
для данного приложения, а также вспомогательной функции.
```
```
Пример 11.8. Модуль представления Django (views.py)
# Создайте свои представления здесь.
```
```
from django.shortcuts import render_to_response
import os
from apache_log_parser_regex import dictify_logline
import operator
```

**408** Глава 11. Создание графического интерфейса

```
log_dir = '/var/log/apache2'
def get_log_dict(logline):
l = dictify_logline(logline)
try:
l['bytes_sent'] = int(l['bytes_sent'])
except ValueError:
bytes_sent = 0
l['logline'] = logline
return l
def list_files(request):
file_list = [f for f in os.listdir(log_dir) if
os.path.isfile(os.path.join(log_dir, f))]
return render_to_response('list_files.html', {'file_list': file_list})
def view_log(request, sortmethod, filename):
logfile = open(os.path.join(log_dir, filename), 'r')
loglines = [get_log_dict(l) for l in logfile]
logfile.close()
try:
loglines.sort(key=operator.itemgetter(sortmethod))
except KeyError:
pass
return render_to_response('view_logfile.html', {'loglines': loglines,
'filename': filename})
```
```
Функция list_files() получает список всех файлов, находящихся в ка
талоге, заданном переменной log_dir, и передает этот список шаблону
list_files.html. Это все, что происходит в функции list_files(). Дан
ная функция настраивается изменением значения переменной log_dir.
Другой способ влияния на работу этой функции мог бы заключаться
в хранении имени каталога журналов в базе данных. Если бы имя ка
талога хранилось в базе данных, мы могли бы изменять это значение
без необходимости перезапускать приложение.
Функция view_log() принимает в качестве аргументов метод сортиров
ки и имя файла журнала. Значения для обоих этих аргументов извле
каются из URL посредством регулярного выражения, заданного в фай
ле urls.py. Для задания метода сортировки и имени файла мы использо
вали именованные группы в регулярном выражении в файле urls.py,
но это не является обязательным. Аргументы, извлеченные из URL,
передаются функции представления в том же порядке, в каком они
были найдены в соответствующих группах. Это распространенная
практика, когда в регулярном выражении разбора URL используются
именованные группы, потому что благодаря такому подходу вы легко
можете сказать, какие параметры извлекаются из URL, а также – как
должна выглядеть строка URL.
Функция view_log() открывает файл журнала с именем, полученным
из URL. Затем выполняется его анализ с помощью библиотеки анализа
файлов журналов Apache из приведенных ранее примеров, чтобы пре
```

Django **409**

```
образовать каждую строку в кортеж, в формате: статус, удаленный_хост,
количество_байтов и остаток строки журнала. Затем функция view_log()
сортирует список кортежей, который был получен из URL, с учетом
указанного метода сортировки. В заключение функция view_log() пере
дает полученный список шаблону view_logfile.html для отображения.
Единственное, что осталось сделать, это создать шаблоны, которые ис
пользуются функциями представления для отображения информа
ции. Шаблоны в платформе Django могут наследовать другие шабло
ны, благодаря чему повышается уровень многократного использова
ния кода и обеспечивается единообразие внешнего вида страниц. Пер
вым мы создадим шаблон, который является родительским для двух
других шаблонов. Этот шаблон будет определять общий внешний вид
для других двух шаблонов в приложении. Именно поэтому мы и нач
нем с него. Это шаблон base.html, исходный код которого приводится
в примере 11.9.
```
```
Пример 11.9. Базовый шаблон Django (base.html)
<html>
<head>
<title>
{% block title %}Apache Logviewer File Listing{% endblock %}
</title>
</head>
<body>
<div><a href="/">Log Directory</a></div>
{% block content %}Empty Content Block{% endblock %}
</body>
</html>
```
```
Это очень простой базовый шаблон. Возможно, это самая простая стра
ница HTML, которую только можно получить. Единственные элемен
ты, которые представляют здесь интерес, – это два раздела «block»:
«title» и «content». Когда в родительском шаблоне определяется раз
дел «block», дочерний шаблон получает возможность заменить его сво
им собственным содержимым. Это позволяет задавать содержимое по
умолчанию, которое может быть замещено в дочернем шаблоне. Блок
«title» позволяет дочерним страницам определять значение, которое
будет отображаться в теге <title>. Блок «content» – это типичный при
ем обновления «главного» раздела страницы без внесения изменений
в остальную часть страницы.
В примере 11.10 приводится шаблон, с помощью которого выводится
список файлов в указанном каталоге.
```
```
Пример 11.10. Шаблон Django для вывода списка файлов (list_files.html)
{% extends "base.html" %}
```
```
{% block title %}Apache Logviewer File Listing{% endblock %}
```

**410** Глава 11. Создание графического интерфейса

```
{% block content %}
<ul>
{% for f in file_list %}
<li><a href="/viewlog/linesort/{{ f }}/" >{{ f }}</a></li>
{% endfor %}
</ul>
{% endblock %}
```
```
На рис. 11.4 показано, как выглядит страница со списком файлов.
В этом шаблоне мы указываем, что расширяем шаблон «base.html».
Это позволяет использовать все, что определено в базовом шаблоне,
включать свой код в любые блоки, которые были определены, и пере
определять их поведение. Именно это мы и делаем с блоками «title»
и «content». В блоке «content» в цикле выполняется обход содержимо
го переменной file_list, которая была передана шаблону. Для каждо
го элемента в списке file_list создается ссылка, в результате щелчка
на которой будет открыт соответствующий файл журнала.
Шаблон в примере 11.11 отвечает за создание страниц, на которые
указывают ссылки из шаблона в предыдущем примере 11.10. Он ото
бражает содержимое выбранного файла журнала.
```
```
Пример 11.11. Шаблон Django для вывода содержимого файлов
(view_logfile.html)
{% extends "base.html" %}
```
```
{% block title %}Apache Logviewer File Viewer{% endblock %}
{% block content %}
<table border="1">
<tr>
<td><a href="/viewlog/status/{{ filename }}/">Status</a></td>
<td><a href="/viewlog/remote_host/{{ filename }}/">
Remote Host</a></td>
```
```
Рис. 11.4. Список файлов журналов веб>сервера Apache
```

Django **411**

```
<td><a href="/viewlog/bytes_sent/{{ filename }}/">Bytes Sent</a></td>
<td><a href="/viewlog/linesort/{{ filename }}/">Line</a></td>
</tr>
{% for l in loglines %}
<tr>
<td>{{ l.status }}</td>
<td>{{ l.remote_host }}</td>
<td>{{ l.bytes_sent }}</td>
<td><pre>{{ l.logline }}</pre></td>
</tr>
{% endfor %}
</table>
{% endblock %}
```
```
Шаблон в примере 11.11 наследует базовый шаблон, упоминавшийся
выше, и создает таблицу в области «content». Заголовок таблицы опи
сывает содержимое каждого столбца: код состояния, удаленный хост,
количество отправленных байтов и остаток строки из файла журнала.
Помимо описания содержимого, заголовки столбцов дают пользовате
лю возможность выполнять сортировку по тому или иному столбцу.
Например, если пользователь щелкнет на заголовке столбца «Bytes
Sent» (передано байтов) (который является обычной ссылкой), страни
ца будет перезагружена и программный код в сценарии представления
отсортирует строки по столбцу «Bytes Sent». Щелчок на заголовке лю
бого столбца, за исключением «Line», будет приводить к выполнению
сортировки по этому столбцу в порядке возрастания. Щелчок на заго
ловке «Line» приведет к возврату к первоначальному порядку следо
вания строк.
На рис. 11.5 показано, как выглядит страница приложения с ориги
нальным порядком следования строк, а на рис. 11.6 – как выглядит
страница после выполнения сортировки по столбцу «Bytes Sent».
Это было очень простое вебприложение, построенное на базе платфор
мы Django. В действительности это не совсем типичное приложение.
Большинство приложений Django выполняют операции с некоторыми
базами данных. Данное приложение можно было бы усовершенство
вать, добавив сортировку по всем столбцам в обратном порядке,
фильтрацию по некоторому значению кода состояния или удаленному
хосту, фильтрацию на основе критерия сравнения количества отправ
ленных байтов с некоторым числом, возможность комбинировать раз
личные фильтры друг с другом и дополнить их возможностями техно
логии AJAX. Но мы не будем выполнять все эти усовершенствования
и оставим их читателю в качестве самостоятельного упражнения.
```

**412** Глава 11. Создание графического интерфейса

```
Рис. 11.5. Просмотр содержимого файла журнала веб>сервера Apache –
сортировка по номерам строк
```
```
Рис. 11.6. Просмотр содержимого файла журнала веб>сервера Apache –
сортировка по количеству отправленных байтов
```

Django **413**

**Простое приложение базы данных**

```
Выше мы уже говорили, что предыдущее приложение на платформе
Django является не совсем типичным примером ее использования, так
как оно не использует базу данных. Следующий пример больше соот
ветствует типичному использованию Django, поэтому основное внима
ние мы сосредоточим в несколько иной области. При использовании
Django для создания приложения, которое будет подключаться к базе
данных, часто создаются шаблоны для отображения данных, храня
щихся в базе данных, а также формы, выполняющие проверку и обра
ботку данных, введенных пользователем. В этом примере будет пока
зано, как создается модель базы данных с использованием объектно
реляционных проекций платформы Django, а также – как создаются
шаблоны и сценарии для отображения данных, но ввод данных будет
опираться на встроенный административный интерфейс платформы
Django. Цель такого подхода состоит в том, чтобы показать вам, как
легко и быстро можно создать интерфейс для работы с базой данных,
который позволит вводить и администрировать данные.
Приложение, которое мы создадим, представляет собой приложение
инвентаризации компьютерных систем. В частности, это приложение
будет позволять вносить в базу данных компьютеры с их описанием,
присвоенными им IPадресами, с перечислением служб, которые вы
полняются на них, перечень аппаратного обеспечения, составляющего
сервер, и многое другое.
Как и в предыдущем примере, мы выполним те же самые действия,
чтобы создать проект и приложение Django. Ниже приводятся коман
ды обращения к инструменту командной строки django–admin, создаю
щие проект и приложение:
jmjones@dinkbuntu:~/code$ djangoadmin startproject sysmanage
jmjones@dinkbuntu:~/code$ cd sysmanage
jmjones@dinkbuntu:~/code/sysmanage$ djangoadmin startapp inventory
jmjones@dinkbuntu:~/code/sysmanage$
```
```
Эти команды создали аналогичное дерево каталогов, как и в предыду
щем примере приложения для просмотра файла журнала вебсервера
Apache. Ниже приводится дерево каталогов и файлов, которые были
созданы:
jmjones@dinkbuntu:~/code/sysmanage$ cd ../
jmjones@dinkbuntu:~/code$ tree sysmanage/
sysmanage/
| __init__.py
| inventory
| | __init__.py
| | models.py
| ` views.py
| manage.py
```

**414** Глава 11. Создание графического интерфейса

```
| settings.py
` urls.py
```
```
Создав проект и приложение, нам необходимо настроить базу данных,
с которой мы будем работать. База данных SQLite предоставляет пре
красные возможности, особенно для нужд тестирования и разработки,
при условии, что она не будет использоваться в рабочем окружении.
Если приложение предусматривает работу более чем с одним пользова
телем одновременно, мы рекомендуем использовать более надежную
базу данных, такую как PostgreSQL. Для настройки приложения на
использование базы данных SQLite мы изменим пару строк в файле
settings.py , расположенном в корневом каталоге проекта. Ниже пока
заны строки, которые мы изменили:
```
```
DATABASE_ENGINE = 'sqlite3'
DATABASE_NAME = os.path.join(os.path.dirname(__file__), 'dev.db')
```
```
В качестве механизма базы данных мы указали «sqlite3». Строка, опре
деляющая местоположение базы данных (параметр DATABASE_NAME), тре
бует дополнительных пояснений. Вместо того чтобы указать абсолют
ный путь к файлу базы данных, мы определили, что он всегда будет
находиться в том же каталоге, что и файл settings.py. Атрибут __file__
всегда хранит абсолютный путь к файлу settings.py. Вызов метода
os.path.dirname(__file__) возвращает каталог, в котором находится
файл settings.py. Полученное имя каталога и имя файла базы данных,
который мы предполагаем создать, передается методу os.path.join(),
возвращающему абсолютный путь к файлу базы данных, который за
висит от каталога с приложением. Это полезный прием, который вы
можете взять на вооружение при настройке параметров, связанных
с местоположением файлов.
В дополнение к настройкам базы данных нам необходимо включить
административный интерфейс платформы Django и наше приложение
инвентаризации, наряду с другими приложениями в этом проекте.
Ниже приводится соответствующий фрагмент файла settings.py :
INSTALLED_APPS = (
'django.contrib.admin',
'django.contrib.auth',
'django.contrib.contenttypes',
'django.contrib.sessions',
'django.contrib.sites',
'sysmanage.inventory',
)
```
```
Мы добавили в список установленных приложений django.contrib.admin
и sysmanage.inventory. Это означает, что, когда мы потребуем от плат
формы Django создать базу данных, она создаст таблицы для всех уста
новленных приложений.
```

Django **415**

```
Далее нам необходимо настроить отображение URL, так чтобы этот
проект включал административный интерфейс. Ниже приводится со
ответствующая строка из файла настройки URL:
# Раскомментируйте следующую строку для включения административного интерфейса
(r'^admin/', include('django.contrib.admin.urls')),
```
```
Инструмент, создавший файл urls.py , поместил в него строку, которая
подключает административный интерфейс, но эту строку требуется
раскомментировать. Как видите, чтобы подключить административ
ный интерфейс, мы просто убрали символ #, стоявший в начале строки.
Теперь, когда мы настроили базу данных, добавили приложения адми
нистративного интерфейса и инвентаризации и добавили администра
тивный интерфейс в конфигурационный файл urls.py , можно присту
пать к определению схемы базы данных. При использовании платфор
мы Django для каждого приложения определяется своя собственная
схема. В каталоге каждого приложения, в данном случае «inventory»,
присутствует файл с именем models.py , содержащий определения таб
лиц и столбцов, которые будут использоваться приложением. В Django,
как и в других платформах разработки вебприложений, опирающихся
на использование объектнореляционных проекций (ObjectRelation
Mapping, ORM), вполне возможно создавать и использовать базы дан
ных, не написав ни одного SQLвыражения. Механизм ORM платфор
мы Django превращает классы в таблицы, а атрибуты классов в столб
цы этих таблиц. Например, следующий фрагмент программного кода
является определением таблицы настроенной базы данных (этот фраг
мент является частью более крупного сценария, к которому мы вскоре
подойдем):
```
```
class HardwareComponent(models.Model):
manufacturer = models.CharField(max_length=50)
#в число типов входят видеокарта, сетевая карта...
type = models.CharField(max_length=50)
model = models.CharField(max_length=50, blank=True, null=True)
vendor_part_number = models.CharField(max_length=50,
blank=True, null=True)
description = models.TextField(blank=True, null=True)
```
```
Обратите внимание, что класс HardwareComponent наследует класс Model
платформы Django. Это означает, что класс HardwareComponent относит
ся к типу Model и обладает соответствующим поведением. Каждому ап
паратному компоненту мы придали несколько атрибутов: manufacturer
(производитель), type (тип), model (модель), vendor_part_number (серий
ный номер) и description (описание). Реализация этих атрибутов нахо
дится в самой платформе Django. Нет, платформа не предоставляет ка
койлибо перечень производителей, но она реализует тип CharField.
Такое определение класса в приложении inventory создаст таблицу
inventory_hardwarecomponent с шестью столбцами: id, manufacturer, type,
model, vendor_part_number и description. Что практически в точности со
```

**416** Глава 11. Создание графического интерфейса

```
ответствует определению класса для ORM. Фактически такое объяв
ление полностью соответствует определению класса для ORM. Когда
определяется класс модели, платформа Django создает соответствую
щую таблицу с именем, состоящим из имени приложения (все симво
лы в нижнем регистре), за которым следуют символ подчеркивания и
имя класса (все символы также в нижнем регистре). Кроме того, если
не определено иное, платформа создаст в вашей таблице дополнитель
ный столбец id, который будет играть роль первичного ключа. Ниже
приводится код на языке SQL, создающий таблицу, которая полно
стью соответствует модели HardwareComponent:
```
```
CREATE TABLE "inventory_hardwarecomponent" (
"id" integer NOT NULL PRIMARY KEY,
"manufacturer" varchar(50) NOT NULL,
"type" varchar(50) NOT NULL,
"model" varchar(50) NULL,
"vendor_part_number" varchar(50) NULL,
"description" text NULL
)
```
```
Если вам когданибудь потребуется увидеть код на языке SQL, кото
рый платформа использует для создания базы данных, просто запус
тите в каталоге проекта команду python manage.py sql myapp, где аргу
мент myapp соответствует имени приложения.
Теперь, когда вы познакомились с ORM платформы Django, мы прой
дем через создание модели базы данных для нашего приложения
инвентаризации. В примере 11.12 приводится содержимое файла
model.py для приложения inventory.
```
```
Пример 11.12. Схема базы данных (models.py)
from django.db import models
```
```
# Создайте здесь свои модели.
class OperatingSystem(models.Model):
name = models.CharField(max_length=50)
description = models.TextField(blank=True, null=True)
```
```
def __str__(self):
return self.name
```
```
class Admin:
pass
```
```
class Service(models.Model):
name = models.CharField(max_length=50)
description = models.TextField(blank=True, null=True)
def __str__(self):
return self.name
class Admin:
pass
```

Django **417**

```
class HardwareComponent(models.Model):
manufacturer = models.CharField(max_length=50)
#в число типов входят видеокарта, сетевая карта...
type = models.CharField(max_length=50)
model = models.CharField(max_length=50, blank=True, null=True)
vendor_part_number = models.CharField(max_length=50,
blank=True, null=True)
description = models.TextField(blank=True, null=True)
```
```
def __str__(self):
return self.manufacturer
```
```
class Admin:
pass
```
```
class Server(models.Model):
name = models.CharField(max_length=50)
description = models.TextField(blank=True, null=True)
os = models.ForeignKey(OperatingSystem)
services = models.ManyToManyField(Service)
hardware_component = models.ManyToManyField(HardwareComponent)
```
```
def __str__(self):
return self.name
```
```
class Admin:
pass
class IPAddress(models.Model):
address = models.TextField(blank=True, null=True)
server = models.ForeignKey(Server)
def __str__(self):
return self.address
class Admin:
pass
```
```
Для нашей модели мы определили пять классов: OperatingSystem, Ser
vice, HardwareComponent, Server и IPAddress. Класс OperatingSystem позволя
ет нам определять различные операционные системы для серверов, ко
торые будут учитываться приложением инвентаризации. В этом классе
мы определили два атрибута: name и description, которые действительно
будут необходимы нам. Можно было бы создать класс OperatingSystem
Vendor и определить ссылку на него в классе OperatingSystem, но в инте
ресах сохранения простоты и понятности мы опустим упоминание
о производителе операционной системы. Каждому серверу будет соот
ветствовать единственная операционная система. Мы покажем это от
ношение между сервером и операционной системой, когда будем рас
сматривать класс Server.
Класс Service позволяет перечислить все службы, которые могут вы
полняться на сервере. В качестве примеров таких служб можно на
звать вебсервер Apache, сервер электронной почты Postfix, сервер
```

**418** Глава 11. Создание графического интерфейса

```
DNS Bind и сервер OpenSSH. Как и класс OperatingSystem, этот класс
имеет два атрибута: name и description. Каждый сервер может иметь
множество служб. Мы покажем отношения между этими классами,
когда будем рассматривать класс Server.
Класс HerdwareComponent представляет список всех аппаратных компо
нентов, которые могут содержаться в сервере. Этот список будет пред
ставлять интерес, только если вы сами добавляли аппаратные компо
ненты в приобретенную систему и в случае, если вы собирали сервер из
отдельных компонентов. В классе HardwareComponent мы определили пять
атрибутов: manufacturer, type, model, vendor_part_number и description. Как
и в случае с изготовителем операционной системы, можно было бы соз
дать отдельные классы для описания производителей и типов аппарат
ного обеспечения, а затем связать их отношениями. Но опять же, ради
сохранения простоты мы предпочли не создавать такие отношения.
Класс Server – это основа системы инвентаризации. Каждый экземп
ляр класса Server – это отдельный сервер, информацию о котором мы
собираем. Класс Server – это место, где сходятся все связи и устанав
ливаются отношения с тремя предыдущими классами. Прежде всего,
мы дали каждому серверу атрибуты name и description. Они идентичны
одноименным атрибутам в других классах. Чтобы установить отноше
ния с другими классами, нам необходимо указать в классе Server, ка
кого типа будут эти отношения. Каждый сервер будет иметь только од
ну операционную систему, поэтому мы создаем отношение с классом
OperatingSystem по внешнему ключу (foreign key). Поскольку виртуали
зация становится все более распространенным явлением, отношение
такого типа со временем потеряет свой смысл, но пока оно вполне
удовлетворяет нашим потребностям. На сервере может выполняться
множество служб, и служба одного и того же типа может выполняться
на многих серверах, поэтому между классами Server и Service мы созда
ли отношение типа «многие ко многим». Точно так же каждый сервер
может содержать множество аппаратных компонентов, а один и тот же
тип аппаратного компонента может быть установлен на множестве
серверов. Поэтому классы Server и HardwareComponent мы также связали
отношением типа «многие ко многим».
Наконец, класс IPAddress – это список всех IPадресов всех серверов,
которые должны быть учтены. Мы определили эту модель последней,
чтобы подчеркнуть отношения между IPадресами и серверами. Класс
IPAddress имеет один атрибут и одно отношение. Атрибут address содер
жит IPадрес в формате XXX.XXX.XXX.XXX. Между классами IPAdd
ress и Server мы определили отношение по внешнему ключу, потому
что один IPадрес может принадлежать только одному серверу. Да, это
выглядит слишком упрощенно, но это удовлетворяет целям демонстра
ции установления отношений между компонентами данных в Django.
Теперь все готово к созданию файла базы данных sqlite. Если запустить
команду python manage.py syncdb в каталоге проекта, она создаст все от
```

Django **419**

```
сутствующие таблицы для приложений, включенных в файл settings.py.
Она также предложит создать в базе данных учетную запись суперполь
зователя, если предусмотрено создание таблиц аутентификации. Ниже
приводится (усеченный) вывод команды python manage.py syncdb:
```
```
jmjones@dinkbuntu:~/code/sysmanage$ python manage.py syncdb
Creating table django_admin_log
Creating table auth_message
```
...
Creating manytomany tables for Server model
Adding permission 'log entry | Can add log entry'
Adding permission 'log entry | Can change log entry'
Adding permission 'log entry | Can delete log entry'
You just installed Django's auth system, which means you don't have any
superusers defined.
Would you like to create one now? (yes/no): yes
Username (Leave blank to use 'jmjones'): Email address: none@none.com
Password:
Password (again): Superuser created successfully.
Adding permission 'message | Can add message'
...
Adding permission 'service | Can change service'
Adding permission 'service | Can delete service'
Adding permission 'server | Can add server'
Adding permission 'server | Can change server'
Adding permission 'server | Can delete server'

```
Теперь можно запустить сервер разработки Django и заняться исследо
ванием административного интерфейса. Ниже приводится команда
запуска сервера разработки Django и вывод, полученный в ходе ее вы
полнения:
jmjones@dinkbuntu:~/code/sysmanage$ python manage.py runserver 0.0.0.0:8080
Validating models...
0 errors found
```
```
Django version 0.97preSVNunknown, using settings 'sysmanage.settings'
Development server is running at http://0.0.0.0:8080/
Quit the server with CONTROLC.
```
```
На рис. 11.7 показана форма регистрации. Пройдя процедуру аутенти
фикации, мы сможем добавлять серверы, аппаратные компоненты,
операционные системы и прочие данные. На рис. 11.8 показана глав
ная страница административного интерфейса Django, а на рис. 11.9 –
форма добавления нового аппаратного компонента. Полезно иметь ин
струмент, позволяющий сохранять и просматривать данные непроти
воречивым, простым и удобным способом! Платформа Django удиви
тельно легко справляется с реализацией простого и удобного интер
фейса доступа к данным. И если это все, что вам необходимо, такой ин
струмент станет полезным для вас. Но это только самая верхушка
возможностей платформы Django. Придумав вид отображения данных
```

**420** Глава 11. Создание графического интерфейса

```
в броузере, вы наверняка сможете реализовать его с помощью Django.
И, как правило, это будет не очень сложно.
Например, если бы нам потребовалось получить отдельную страницу
для каждого типа операционной системы, аппаратного компонента,
службы и так далее, мы могли бы это реализовать. Если бы нам потре
бовалось иметь возможность щелкнуть на любом из этих элементов
и получить список серверов, обладающих этой характеристикой, мы
также могли бы реализовать это. И если бы нам потребовалось иметь
возможность щелкнуть на любом из серверов и получить подробную
информацию о нем, мы смогли бы реализовать и это. Давайте теперь это
сделаем. Добавим эти «потребности» к первоначальным требованиям.
```
```
Рис. 11.7. Страница регистрации при входе в административный
интерфейс Django
```
```
Рис. 11.8. Главная страница административного интерфейса Django
```

Django **421**

```
Для начала в примере 11.13 приводится дополненный файл urls.py.
```
```
Пример 11.13. Отображение адресов URL (urls.py)
from django.conf.urls.defaults import *
urlpatterns = patterns('',
# Пример:
# (r'^sysmanage/', include('sysmanage.foo.urls')),
```
```
# Раскомментируйте для включения административного интерфейса
(r'^admin/', include('django.contrib.admin.urls')),
(r'^$', 'sysmanage.inventory.views.main'),
(r'^categorized/(?P<category>.*?)/(?P<category_id>.*?)/$',
'sysmanage.inventory.views.categorized'),
(r'^server_detail/(?P<server_id>.*?)/$',
'sysmanage.inventory.views.server_detail'),
)
```
```
Мы добавили три новые строки для отображения трех адресов URL на
функции. Здесь нет ничего необычного по сравнению с приложением
просмотра файла журнала вебсервера Apache. Мы отобразили адреса
URL, соответствующие регулярным выражениям, на функции, при
этом мы использовали в регулярных выражениях именованную груп
пировку.
```
```
Рис. 11.9. Форма добавления аппаратного компонента
в административном интерфейсе Django
```

**422** Глава 11. Создание графического интерфейса

```
Следующее, что мы сделаем, это добавим в модуль views функции, ко
торые были объявлены в файле отображения адресов URL. В приме
ре 11.14 приводится содержимое модуля views.
```
```
Пример 11.14. Функции представления приложения инвентаризации
(views.py)
# Создайте здесь свои представления.
from django.shortcuts import render_to_response
import models
```
```
def main(request):
os_list = models.OperatingSystem.objects.all()
svc_list = models.Service.objects.all()
hardware_list = models.HardwareComponent.objects.all()
return render_to_response('main.html', {'os_list': os_list,
'svc_list': svc_list, 'hardware_list': hardware_list})
def categorized(request, category, category_id):
category_dict = {'os': 'Operating System',
'svc': 'Service', 'hw': 'Hardware'}
if category == 'os':
server_list = models.Server.objects.filter(os__exact=category_id)
category_name = models.OperatingSystem.objects.get(id=category_id)
elif category == 'svc':
server_list = \
models.Server.objects.filter(services__exact=category_id)
category_name = models.Service.objects.get(id=category_id)
elif category == 'hw':
server_list = \
models.Server.objects.filter(hardware_component__exact=category_id)
category_name = models.HardwareComponent.objects.get(id=category_id)
else:
server_list = []
return render_to_response('categorized.html', {'server_list': server_list,
'category': category_dict[category], 'category_name': category_name})
def server_detail(request, server_id):
server = models.Server.objects.get(id=server_id)
return render_to_response('server_detail.html', {'server': server})
```
```
В файл urls.py мы добавили три отображения адресов URL, поэтому
мы добавили три функции в файл views.py. Первая функция – main().
Она просто получает списки всех типов операционных систем, аппа
ратных компонентов и служб и передает их шаблону main.html.
В примере 11.6 мы уже создавали подкаталог templates в каталоге
приложения. Теперь сделаем то же самое и здесь:
jmjones@dinkbuntu:~/code/sysmanage/inventory$ mkdir templates
jmjones@dinkbuntu:~/code/sysmanage/inventory$
```
```
В примере 11.15 приводится содержимое шаблона «main.html», кото
рому функция main() передает данные для отображения.
```

Django **423**

```
Пример 11.15. Главный шаблон (main.html)
{% extends "base.html" %}
{% block title %}Server Inventory Category View{% endblock %}
{% block content %}
<div>
<h2>Operating Systems</h2>
<ul>
{% for o in os_list %}
<li><a href="/categorized/os/{{ o.id }}/" >{{ o.name }}</a></li>
{% endfor %}
</ul>
</div>
<div>
<h2>Services</h2>
<ul>
{% for s in svc_list %}
<li><a href="/categorized/svc/{{ s.id }}/" >{{ s.name }}</a></li>
{% endfor %}
</ul>
</div>
<div>
<h2>Hardware Components</h2>
<ul>
{% for h in hardware_list %}
<li>
<a href="/categorized/hw/{{ h.id }}/" >{{ h.manufacturer }}</a>
</li>
{% endfor %}
</ul>
</div>
{% endblock %}
```
```
Этот шаблон не содержит ничего сложного. Он делит страницу на три
части, по одной для каждой категории, которая должна отображаться.
В каждой категории выводится список элементов со ссылками, щел
кая на которых, можно получить список всех серверов, которые содер
жат указанный элемент.
Когда пользователь щелкает на одной из таких ссылок, вызывается
следующая функция представления categorized().
Главный шаблон передает функции представления categorized() кате
горию (os – в случае операционной системы, hw – в случае аппаратного
компонента и svc – в случае службы) и id категории (то есть конкрет
ный компонент, на котором был выполнен щелчок, например, «3Com
905b Network Card»). Функция categorized() принимает эти аргумен
ты и извлекает из базы данных список всех серверов, содержащих вы
бранный компонент. После запроса на получения информации из базы
данных функция categorized() передает полученные сведения шабло
```

**424** Глава 11. Создание графического интерфейса

```
ну «categorized.html». В примере 11.16 приводится содержимое шаб
лона «categorized.html».
```
```
Пример 11.16. Шаблон категории (categorized.html)
{% extends "base.html" %}
{% block title %}Server List{% endblock %}
{% block content %}
<h1>{{ category }}::{{ category_name }}</h1>
<div>
<ul>
{% for s in server_list %}
<li><a href="/server_detail/{{ s.id }}/" >{{ s.name }}</a></li>
{% endfor %}
</ul>
</div>
{% endblock %}
```
```
Шаблон «categorized.html» отображает список всех серверов, полу
ченный от функции categorized().
После этого пользователь может щелкнуть на выбранном сервере, что
приведет к вызову функции представления server_detail(). Функция
представления server_detail() принимает параметр с идентификато
ром (id) сервера, извлекает информацию о сервере из базы данных
и передает ее шаблону «server_detail.html».
Содержимое шаблона «server_detail.html» приводится в примере 11.17.
Это самый большой шаблон в приложении, но он очень простой. Его
задача заключается в том, чтобы отобразить отдельные элементы дан
ных для сервера, такие как тип операционной системы, под управле
нием которой работает сервер, установленные в нем аппаратные ком
поненты, службы, запущенные на сервере, и IPадреса, присвоенные
серверу.
```
```
Пример 11.17. Шаблон отображения информации о сервере (server_detail.html)
{% extends "base.html" %}
{% block title %}Server Detail{% endblock %}
```
```
{% block content %}
<div>
Name: {{ server.name }}
</div>
<div>
Description: {{ server.description }}
</div>
<div>
OS: {{ server.os.name }}
</div>
<div>
<div>Services:</div>
```

Django **425**

```
<ul>
{% for service in server.services.all %}
<li>{{ service.name }}</li>
{% endfor %}
</ul>
</div>
<div>
<div>Hardware:</div>
<ul>
{% for hw in server.hardware_component.all %}
<li>{{ hw.manufacturer }} {{ hw.type }} {{ hw.model }}</li>
{% endfor %}
</ul>
</div>
<div>
<div>IP Addresses:</div>
<ul>
{% for ip in server.ipaddress_set.all %}
<li>{{ ip.address }}</li>
{% endfor %}
</ul>
</div>
{% endblock %}
```
```
Этот пример показывает, как создать довольно простое приложение
базы данных, используя платформу Django. Административный ин
терфейс обеспечивает возможность наполнения базы данных, а доба
вив совсем немного строк программного кода, мы сумели создать соб
ственные представления, позволяющие сортировать данные и переме
щаться по ним, как показано на рис. 11.10, 11.11 и 11.12.
```
```
Рис. 11.10. Основная страница приложения управления системами
```

**426** Глава 11. Создание графического интерфейса

### В заключение.

```
Несмотря на то, что создание приложений с графическим интерфей
сом, как кажется многим, не соответствует традиционным обязанно
стям системного администратора, тем не менее, этот навык может ока
заться неоценимым. Иногда вам может даже потребоваться создать
какоенибудь простое приложение для одного из ваших пользовате
лей. Иногда вам может потребоваться создать приложение для само
го себя. Иногда вы можете склоняться к мысли, что в этом нет необхо>
димости , но такие приложения могут помочь выполнить ту или иную
задачу более гладко. Как только вы почувствуете, что создание прило
жений с графическим интерфейсом не вызывает у вас затруднений, вы
будете удивлены тем, как часто вы начали их создавать.
```
```
Рис. 11.11. Приложение управления системами – категория CentOS
```
```
Рис. 11.12. Приложение управления системами – информация о сервере
```

**12**

### Сохранность данных

Сохранность данных в простом, универсальном смысле – это сохране
ние данных для последующего использования. Этим подразумевается,
что данные, сохраненные для последующего использования, не пропа
дут, если процесс, сохранивший их, завершит свою работу. Обычно со
хранность данных достигается путем преобразования их в некоторый
формат и запись на диск. Некоторые форматы, такие как XML или
YAML, доступны человеку для чтения. Некоторые форматы, такие
как файлы базы данных Berkeley DB (bdb) или SQLite, не доступны
для непосредственного использования людьми.

Какие данные может потребоваться сохранять для последующего ис
пользования? Возможно, у вас имеется сценарий, который следит за
датой последнего изменения файлов в каталоге, и вам необходимо пе
риодически запускать его, чтобы узнать, какие файлы изменились
с момента последнего запуска. Информация о файлах – это именно те
данные, которые сохраняются для последующего использования, то
есть для следующего запуска сценария. Вы могли бы сохранять эти
данные в некотором файле. Представьте себе другой случай, когда
у вас имеется компьютер с подозрением на проблемы, возникающие
при работе с сетью, и вы решили запускать сценарий каждые 15 ми
нут, чтобы увидеть, насколько быстро он может опросить другие ком
пьютеры в сети. Вы могли бы сохранять время опроса в файле данных
для последующего использования. В этом случае «для последующего
использования» скорее относится ко времени, когда вы решите за
няться исследованием этих данных, а не ко времени, когда програм
ма, выполняющая сбор данных, обращается к ним.

Мы разобьем наше обсуждение сериализации данных на две катего
рии: простую и реляционную.


**428** Глава 12. Сохранность данных

### Простая сериализация.

```
Существует несколько способов сохранения данных на диск для после
дующего использования. Процесс сохранения данных на диск без со
хранения отношений между частями данных мы называем «простой се
риализацией». Различия между простой и реляционной сериализацией
мы обсудим в разделе, описывающем реляционную сериализацию.
```
**Pickle**

```
Первый и, пожалуй, самый основной механизм «простой сериализа
ции» в языке Python представлен модулем pickle, входящим в состав
стандартной библиотеки языка. Если подумать о консервировании^1
в кулинарном смысле, идея обеспечения сохранности продуктов пита
ния состоит в том, чтобы законсервировать их в банке для последую
щего использования. Кулинарная концепция прекрасно укладывает
ся в образ действия модуля pickle. С помощью этого модуля вы можете
записать объект на диск, завершить работу программы, вернуться
позднее, снова запустить программу, прочитать объект с диска и про
должить взаимодействовать с ним.
Какими возможностями обладает модуль pickle? Ниже приводится
список, взятый из описания модуля pickle в документации к стандарт
ной библиотеке языка Python, где перечислены типы объектов, кото
рые могут сохраняться с его помощью:
```
**-** None, True и False
**-** Целые числа, длинные целые, числа с плавающей точкой, ком
    плексные числа
**-** Обычные строки и строки Юникода
**-** Кортежи, списки, множества и словари, содержащие только те объ
    екты, которые могут сохраняться с помощью модуля pickle
**-** Функции, определенные на верхнем уровне в модуле
**-** Встроенные функции, определенные на верхнем уровне в модуле
**-** Классы, определенные на верхнем уровне в модуле
**-** Экземпляры классов, у которых атрибуты __dict__ и __setstate__()
    могут сохраняться с помощью модуля pickle
Ниже показано, как выполняется сериализация объекта на диск с по
мощью модуля pickle:

```
In [1]: import pickle
In [2]: some_dict = {'a': 1, 'b': 2}
```
```
In [3]: pickle_file = open('some_dict.pkl', 'w')
```
(^1) Pickle – консервировать, мариновать, солить, заквашивать. – _Прим. перев._


Простая сериализация **429**

```
In [4]: pickle.dump(some_dict, pickle_file)
In [5]: pickle_file.close()
```
```
А вот как выглядит файл с сохраненными в нем данными:
jmjones@dinkgutsy:~$ lsl some_dict.pkl
rwrr 1 jmjones jmjones 30 20080120 07:13 some_dict.pkl
jmjones@dinkgutsy:~$ cat some_dict.pkl
(dp0
S'a'
p1
I1
sS'b'
p2
I2
```
```
Вы можете попытаться изучить формат файлов, создаваемых модулем
pickle, и создавать их вручную, но мы не рекомендуем делать это.
Ниже демонстрируется, как восстановить сохраненные ранее данные:
```
```
In [1]: import pickle
In [2]: pickle_file = open('some_dict.pkl', 'r')
```
```
In [3]: another_name_for_some_dict = pickle.load(pickle_file)
In [4]: another_name_for_some_dict
Out[4]: {'a': 1, 'b': 2}
```
```
Обратите внимание, что для восстановления данных мы использовали
объект, имя которого отличается от имени объекта, который сохра
нялся в файле. Не забывайте, что имя – это всего лишь способ сослать
ся на объект.
Интересно отметить, что совершенно необязательно, чтобы между
файлами и сохраняемыми объектами существовало отношение «один
к одному». Вы можете сохранять в одном и том же файле столько объ
ектов, сколько места хватит на жестком диске или в файловой систе
ме. Ниже приводится пример сохранения нескольких словарей в од
ном файле:
In [1]: list_of_dicts = [{str(i): i} for i in range(5)]
```
```
In [2]: list_of_dicts
Out[2]: [{'0': 0}, {'1': 1}, {'2': 2}, {'3': 3}, {'4': 4}]
In [3]: import pickle
In [4]: pickle_file = open('list_of_dicts.pkl', 'w')
In [5]: for d in list_of_dicts:
...: pickle.dump(d, pickle_file)
...:
...:
```
```
In [6]: pickle_file.close()
```

**430** Глава 12. Сохранность данных

```
Мы создали список словарей, объект файла, открытого в режиме для
записи, затем выполнили обход списка словарей и сериализовали ка
ждый из них в один и тот же файл. Обратите внимание, это тот же са
мый метод сохранения, который использовался выше для сохранения
одного объекта в файл, только там мы не выполняли итерации и не вы
зывали метод dump() несколько раз.
Ниже приводится пример восстановления объектов из файла, содер
жащего несколько объектов, и их вывод:
```
```
In [1]: import pickle
In [2]: pickle_file = open('list_of_dicts.pkl', 'r')
```
```
In [3]: while 1:
...: try:
...: print pickle.load(pickle_file)
...: except EOFError:
...: print "EOF Error"
...: break
...:
...:
{'0': 0}
{'1': 1}
{'2': 2}
{'3': 3}
{'4': 4}
EOF Error
```
```
Здесь мы создали объект файла, созданного в предыдущем примере,
открытого в режиме для чтения, и повторяли попытки загружать объ
екты из файла, пока не было возбуждено исключение EOFError. Как ви
дите, словари, полученные из файла, оказались теми же самыми
(и следуют в том же порядке), что и словари, которые мы записали
вфайл.
Но мало того, что мы можем сохранять объекты простых встроенных
типов, мы можем также сохранять объекты созданных нами типов.
Ниже приводится содержимое модуля, который мы будем использо
вать в двух следующих примерах. Этот модуль содержит определение
нашего собственного класса, экземпляры которого мы попробуем со
хранить, а потом восстановить:
```
```
#!/usr/bin/env python
class MyClass(object):
def __init__(self):
self.data = []
def __str__(self):
return "Custom Class MyClass Data:: %s" % str(self.data)
def add_item(self, item):
self.data.append(item)
```

Простая сериализация **431**

```
Следующий модуль импортирует модуль с нашим классом и сохраняет
экземпляр этого класса в файл с помощью модуля pickle:
```
```
#!/usr/bin/env python
import pickle
import custom_class
my_obj = custom_class.MyClass()
my_obj.add_item(1)
my_obj.add_item(2)
my_obj.add_item(3)
pickle_file = open('custom_class.pkl', 'w')
pickle.dump(my_obj, pickle_file)
pickle_file.close()
```
```
В этом примере мы импортировали модуль с нашим классом, создали
экземпляр этого класса, добавили в объект несколько элементов, за
тем сериализовали его. В процессе своей работы этот модуль ничего не
выводит.
Далее приводится модуль, который импортирует модуль с нашим
классом и затем загружает экземпляр этого класса из файла:
```
```
#!/usr/bin/env python
import pickle
import custom_class
pickle_file = open('custom_class.pkl', 'r')
my_obj = pickle.load(pickle_file)
print my_obj
pickle_file.close()
```
```
Ниже приводится вывод, полученный в ходе восстановления данных
из файла:
jmjones@dinkgutsy:~/code$ python custom_class_unpickle.py
Custom Class MyClass Data:: [1, 2, 3]
```
```
Для программного кода, выполняющего восстановление данных, со
вершенно необязательно явно импортировать наш класс. Однако код
должен иметь возможность отыскать модуль, в котором определяется
наш класс. Ниже приводится модуль, который не импортирует модуль
с определением класса:
```
```
#!/usr/bin/env python
import pickle
##import custom_class ##операция импортирования класса закомментирована
pickle_file = open('custom_class.pkl', 'r')
my_obj = pickle.load(pickle_file)
print my_obj
pickle_file.close()
```

**432** Глава 12. Сохранность данных

```
Ниже приводится вывод, полученный в результате запуска модуля,
который не импортирует класс:
```
```
jmjones@dinkgutsy:~/code$ python custom_class_unpickle_noimport.py
Custom Class MyClass Data:: [1, 2, 3]
```
```
А вот что было получено от того же самого модуля, после того как он
и файл с данными были скопированы в другой каталог, где он и был
запущен:
jmjones@dinkgutsy:~/code/cantfind$ python custom_class_unpickle_noimport.py
Traceback (most recent call last):
File "custom_class_unpickle_noimport.py", line 7, in <module>
my_obj = pickle.load(pickle_file)
File "/usr/lib/python2.5/pickle.py", line 1370, in load
return Unpickler(file).load()
File "/usr/lib/python2.5/pickle.py", line 858, in load
dispatch[key](self)
File "/usr/lib/python2.5/pickle.py", line 1090, in load_global
klass = self.find_class(module, name)
File "/usr/lib/python2.5/pickle.py", line 1124, in find_class
__import__(module)
ImportError: No module named custom_class
```
```
Последняя строка сообщает о неудачной попытке выполнить импорт,
потому что модуль pickle не смог загрузить наш модуль с определени
ем класса. Модуль pickle будет пытаться отыскать модуль, содержа
щий ваш класс, и импортировать его, чтобы иметь возможность вер
нуть объект того же типа, что и сохраненный в файле.
Все предыдущие примеры использования модуля pickle прекрасно ра
ботают, но существует еще один момент, о котором мы еще не упоми
нали. По умолчанию модуль pickle использует протокол сохранения
pickle.dump(object_to_pickle, pickle_file). Протокол – это специфика
ция формата записи в файл. Протокол по умолчанию использует фор
мат, практически доступный человеку для восприятия, как было по
казано выше. Другая разновидность протокола – это двоичный фор
мат. Вы можете предпочесть использовать двоичный формат, если за
метите, что операция сохранения ваших объектов начинает занимать
существенное время. Ниже приводится сравнение использования про
токола по умолчанию и двоичного протокола:
```
```
In [1]: import pickle
In [2]: default_pickle_file = open('default.pkl', 'w')
```
```
In [3]: binary_pickle_file = open('binary.pkl', 'wb')
In [4]: d = {'a': 1}
```
```
In [5]: pickle.dump(d, default_pickle_file)
In [6]: pickle.dump(d, binary_pickle_file,1)
```

Простая сериализация **433**

```
In [7]: default_pickle_file.close()
In [8]: binary_pickle_file.close()
```
```
Первый файл с данными, созданный нами (с именем default.pkl ), будет
содержать данные в формате по умолчанию, практически доступном
человеку для восприятия. Второй файл (с именем binary.pkl ) будет со
держать данные в двоичном формате. Обратите внимание, что мы от
крыли файл default.pkl в обычном режиме для записи ('w'), а файл
binary.pkl – в режиме записи двоичных данных ('wb'). Единственное
различие между двумя вызовами метода dump() заключается в том, что
при сохранении в двоичном формате методу передается один дополни
тельный аргумент: число – 1 , означающее, что будет использоваться
«высший» протокол, которым в настоящее время является двоичный
протокол.
Ниже приводится шестнадцатеричный дамп двоичного файла с дан
ными:
jmjones@dinkgutsy:~/code$ hexcat binary.pkl
00000000 80 02 7d 71 00 55 01 61 71 01 4b 01 73 2e ..}q.U.aq.K.s.
```
```
А так выглядит шестнадцатеричный дамп файла с данными, сохра
ненными при использовании протокола по умолчанию:
jmjones@dinkgutsy:~/code$ hexcat default.pkl
00000000 28 64 70 30 0a 53 27 61 27 0a 70 31 0a 49 31 0a (dp0.S'a'.p1.I1.
00000010 73 2e s.
```
```
В этом просмотре дампа нет никакой необходимости, потому что мы
можем воспользоваться простой утилитой cat, чтобы прочитать содер
жимое файла с данными, сохраненными при использовании протоко
ла по умолчанию:
```
```
jmjones@dinkgutsy:~/code$ cat default.pkl
(dp0
S'a'
p1
I1
s.
```
**cPickle**

```
В стандартной библиотеке языка Python присутствует еще одна реали
зация библиотеки Pickle, которая стоит того, чтобы вы обратили на нее
внимание. Она называется cPickle. Как явствует из имени, библиотека
cPickle реализована на языке C. Ранее мы уже предлагали применять
двоичный формат в случаях, когда вы начнете замечать, что на сохра
нение объектов требуется существенное время. В этом же случае можно
попробовать использовать модуль cPickle. Интерфейс модуля cPickle
в точности соответствует интерфейсу «обычного» модуля pickle.
```

**434** Глава 12. Сохранность данных

**shelve**

```
Еще одну возможность сохранения данных предоставляет модуль
shelve. Модуль shelve имеет простой и удобный интерфейс, упрощаю
щий возможность сохранения множества объектов. Под этим подразу
мевается возможность сохранения множества объектов в одном и том
же объектехранилище и простого их восстановления из хранилища.
Сохранение объектов в хранилище shelve напоминает использование
словаря в языке Python. Ниже приводится пример, в котором откры
вается хранилище, в него записываются данные, затем хранилище по
вторно открывается и из него извлекаются сохраненные данные:
```
```
In [1]: import shelve
In [2]: d = shelve.open('example.s')
```
```
In [3]: d
Out[3]: {}
```
```
In [4]: d['key'] = 'some value'
In [5]: d.close()
```
```
In [6]: d2 = shelve.open('example.s')
In [7]: d2
Out[7]: {'key': 'some value'}
```
```
Единственное отличие между использованием shelve и простого слова
ря состоит в том, что объект shelve создается с помощью метода
shelve.open(), а не путем создания экземпляра класса dict или с помо
щью фигурных скобок ({}). Еще одно отличие состоит в том, что при
использовании shelve по завершении работы с данными необходимо
вызывать метод close() объекта shelve.
У объекта shelve имеется пара особенностей. О первой из них мы уже
упоминали: по завершении работы с данными необходимо вызывать
метод close(). Если этого не сделать, то любые изменения, которые бы
ли сделаны в объекте shelve, не будут сохранены. Ниже приводится
пример потери данных изза того, что объект shelve не закрывается.
Для начала нам нужно создать объект shelve, сохранить в нем данные
и выйти из оболочки IPython:
```
```
In [1]: import shelve
In [2]: d = shelve.open('lossy.s')
```
```
In [3]: d['key'] = 'this is a key that will persist'
In [4]: d
Out[4]: {'key': 'this is a key that will persist'}
In [5]: d.close()
```
```
In [6]:
Do you really want to exit ([y]/n)?
```

Простая сериализация **435**

```
Теперь снова запустим IPython, откроем тот же файл хранилища, соз
дадим в нем еще один элемент и выйдем, не закрыв объект shelve:
```
```
In [1]: import shelve
In [2]: d = shelve.open('lossy.s')
In [3]: d
Out[3]: {'key': 'this is a key that will persist'}
In [4]: d['another_key'] = 'this is an entry that will not persist'
In [5]:
Do you really want to exit ([y]/n)?
```
```
Теперь снова запустим оболочку IPython, откроем все тот же файл хра
нилища и посмотрим, что в нем имеется:
In [1]: import shelve
In [2]: d = shelve.open('lossy.s')
In [3]: d
Out[3]: {'key': 'this is a key that will persist'}
```
```
Итак, необходимо вызывать метод close() для всех объектов shelve, со
держимое которых вы меняете, и которые вам хотелось бы сохранить.
Другая особенность касается изменяемых объектов. Запомните, что
изменяемыми объектами называются такие объекты, значение кото
рых можно изменять без повторного присваивания этого значения пе
ременной. Ниже мы создаем объект shelve, добавляем в него элемент,
который представляет собой изменяемый объект (в данном случае –
список), модифицируем изменяемый объект, а затем закрываем объ
ект shelve:
```
```
In [1]: import shelve
In [2]: d = shelve.open('mutable_lossy.s')
In [3]: d['key'] = []
In [4]: d['key'].append(1)
In [5]: d.close()
In [6]:
Do you really want to exit ([y]/n)?
```
```
Поскольку в этом случае вызывается метод close() объекта shelve,
можно было бы ожидать, что значением ключа 'key' будет список [1].
Но это не так. Ниже приводится результат попытки открыть файл хра
нилища, созданного выше, и прочитать из него данные:
In [1]: import shelve
```
```
In [2]: d = shelve.open('mutable_lossy.s')
In [3]: d
Out[3]: {'key': []}
```

**436** Глава 12. Сохранность данных

```
В таком поведении нет ничего странного или неожиданного. В действи
тельности эта особенность shelve описана в документации. Проблема
состоит в том, что модификация сохраняемых изменяемых объектов
не воспринимаются по умолчанию. Однако существует пара способов,
позволяющих обойти этот недостаток. Первый из них специализиро
ванный и узконаправленный, второй – широкий и всеобъемлющий.
Первый, специализированный, подход заключается в том, чтобы про
сто выполнить повторное присваивание по ключу в объекте shelve, как
показано ниже:
In [1]: import shelve
```
```
In [2]: d = shelve.open('mutable_nonlossy.s')
In [3]: d['key'] = []
```
```
In [4]: temp_list = d['key']
In [5]: temp_list.append(1)
```
```
In [6]: d['key'] = temp_list
In [7]: d.close()
```
```
In [8]:
Do you really want to exit ([y]/n)?
```
```
При попытке восстановить сохраненный ранее объект мы получили
следующее:
```
```
In [1]: import shelve
In [2]: d = shelve.open('mutable_nonlossy.s')
In [3]: d
Out[3]: {'key': [1]}
```
```
Список, к которому был добавлен элемент, сохранился.
Второй, широкий и всеобъемлющий подход заключается в изменении
флага writeback объекта shelve. До сих пор мы демонстрировали вызов
метода shelve.open() с единственным параметром – именем файла хра
нилища. Но этот метод может принимать еще и другие параметры, од
ним из которых является флаг writeback. Если во флаге writeback пере
дано значение True, все записи в объекте shelve, к которым выполня
лось обращение, кэшируются в памяти и затем сохраняются при вызо
ве метода close(). Этот прием может оказаться удобным при работе
с изменяемыми объектами, но за это приходится платить. Поскольку
все объекты, к которым производилось обращение, кэшируются и за
тем сохраняются при закрытии объекта (независимо от того, изменя
лись они или нет), объем используемой памяти и время на запись
в файл будут расти пропорционально числу объектов в хранилище,
к которым производился доступ. Поэтому, если у вас имеется большое
число объектов в хранилище, к которым приходится обращаться, то
лучше не устанавливать флаг writeback в значение True.
```

Простая сериализация **437**

```
В следующем примере мы устанавливаем во флаге writeback значение
True и модифицируем содержимое списка, не выполняя повторное его
присваивание ключу в объекте shelve:
In [1]: import shelve
```
```
In [2]: d = shelve.open('mutable_nonlossy.s', writeback=True)
In [3]: d['key'] = []
```
```
In [4]: d['key'].append(1)
In [5]: d.close()
```
```
In [6]:
Do you really want to exit ([y]/n)?
```
```
А теперь проверим, сохранились ли наши изменения:
In [1]: import shelve
```
```
In [2]: d = shelve.open('mutable_nonlossy.s')
In [3]: d
Out[3]: {'key': [1]}
```
```
Как мы и надеялись, изменения были сохранены.
Модуль shelve предлагает простой способ сохранения данных. В нем
имеется пара недостатков, но в целом это очень полезный модуль.
```
**YAML**

```
В зависимости от того, кому задается вопрос, вы можете услышать раз
ные толкования аббревиатуры YAML, например: «YAML ain’t markup
language» (YAML – это не язык разметки) или «yet another markup
language» (еще один язык разметки). В любом случае – это формат
данных, который часто используется для сохранения, восстановления
и обновления данных в виде простого текста. Эти данные часто имеют
иерархическую структуру. Самый простой, пожалуй, способ присту
пить к работе с YAML в языке Python состоит в том, чтобы установить
с помощью утилиты easy_install пакет PyYAML. Но зачем нам использо
вать YAML, который еще требуется устанавливать, когда у нас имеет
ся встроенный модуль pickle? Существуют две основные причины, по
которым YAML оказывается предпочтительнее, чем pickle. Эти две
причины не делают применение YAML наилучшим во всех ситуациях,
но при определенных обстоятельствах они приобретают особую значи
мость. Вопервых, формат YAML пригоден для восприятия человеком.
Его синтаксис напоминает синтаксис конфигурационных файлов. Ес
ли у вас возникают ситуации, когда необходимо предоставить возмож
ность редактирования конфигурационных файлов, YAML будет отлич
ным выбором. Вовторых, синтаксические анализаторы языка YAML
реализованы во многих других языках. Если вам требуется обеспечить
обмен данными между приложением на языке Python и приложением,
```

**438** Глава 12. Сохранность данных

```
написанном на другом языке программирования, YAML может стать
неплохим решением проблемы.
После установки PyYAML вы получаете возможность сохранять и восста
навливать данные в формате YAML. Ниже приводится пример сохра
нения простого словаря:
In [1]: import yaml
```
```
In [2]: yaml_file = open('test.yaml', 'w')
In [3]: d = {'foo': 'a', 'bar': 'b', 'bam': [1, 2,3]}
```
```
In [4]: yaml.dump(d, yaml_file, default_flow_style=False)
In [5]: yaml_file.close()
```
```
Этот пример достаточно прост, чтобы вы могли разобраться в нем са
мостоятельно, и, тем не менее, мы рассмотрим его. Первое, что здесь
делается, – выполняется импортирование модуля YAML (с именем
yaml). Затем открывается файл в режиме для записи, который будет ис
пользоваться для сохранения данных. Далее создается словарь (с име
нем d), содержащий данные, которые требуется сохранить. После это
го мы сохраняем словарь (с именем d) с помощью функции dump() из
модуля yaml. В качестве параметров функции dump() передаются: сло
варь, который требуется сохранить, выходной файл и параметр, сооб
щающий библиотеке YAML, что запись должна производиться в блоч
ном стиле, а не в стиле, заданном по умолчанию, который отчасти на
поминает преобразование сохраняемого объекта данных в строку.
Ниже показано, как выглядит содержимое файла с данными в форма
те YAML:
```
```
jmjones@dinkgutsy:~/code$ cat test.yaml
bam:
1
2
3
bar: b
foo: a
```
```
Когда необходимо восстановить данные, мы выполняем операции, об
ратные тем, что выполнялись в примере с применением функции
dump(). Ниже показано, как получить данные из файла YAML:
```
```
In [1]: import yaml
In [2]: yaml_file = open('test.yaml', 'r')
```
```
In [3]: yaml.load(yaml_file)
Out[3]: {'bam': [1, 2, 3], 'bar': 'b', 'foo': 'a'}
```
```
Как и в примере с функцией dump(), мы сначала импортируем модуль
поддержки языка YAML (yaml). Затем создаем объект файла. На этот
раз мы открываем файл на диске в режиме для чтения. Наконец вызы
```

Простая сериализация **439**

```
вается функция load() из модуля yaml. Функция load() возвращает сло
варь, эквивалентный исходному словарю.
Вы наверняка поймаете себя на том, что при использовании модуля
yaml вы реализуете цикл создания данных, сохранения их на диске, за
тем восстановления с диска и так далее.
Возможно, вам не обязательно сохранять свои данные в формате, дос
тупном для восприятия человеком, поэтому попробуем сохранить сло
варь из предыдущего примера не в блочном режиме. Ниже показано,
как сохранить тот же самый словарь не в блочном режиме:
In [1]: import yaml
```
```
In [2]: yaml_file = open('nonblock.yaml', 'w')
In [3]: d = {'foo': 'a', 'bar': 'b', 'bam': [1, 2,3]}
```
```
In [4]: yaml.dump(d, yaml_file)
In [5]: yaml_file.close()
```
```
Вот как выглядит содержимое файла с данными в формате YAML:
jmjones@dinkgutsy:~/code$ cat nonblock.yaml
bam: [1, 2, 3]
bar: b
foo: a
```
```
Очень похоже на содержимое файла, записанного в блочном режиме,
за исключением списка значений переменной bam. Различия между
этими режимами начинают проявляться с появлением дополнитель
ных уровней вложенности и структур данных, напоминающих масси
вы, таких как списки и словари. Рассмотрим пару примеров, чтобы
увидеть различия. Но прежде заметим, что исследовать примеры будет
проще, если отказаться от просмотра YAMLфайлов с помощью утили
ты cat. Аргумент с файлом в функции dump() из модуля yaml является
необязательным. (Фактически в документации к PyYAML объект типа
«file» называется «stream» (поток), но в действительности большой ро
ли это не играет.) Если функция dump() не получит аргумент с файлом
(или «потоком»), она выведет сериализованный объект в поток стан
дартного вывода. Поэтому в следующем примере мы опустили аргу
мент с объектом типа file и выводим результат работы функции.
Ниже сравниваются некоторые структуры данных, которые сериали
зуются в блочном и в не блочном режимах. В примерах, где присутст
вует аргумент default_flow_style, используется блочный режим форма
тирования, а в примерах, где аргумент default_flow_style отсутствует,
используется не блочный режим форматирования:
```
```
In [1]: import yaml
In [2]: d = {'first': {'second': {'third': {'fourth': 'a'}}}}
```
```
In [3]: print yaml.dump(d, default_flow_style=False)
```

**440** Глава 12. Сохранность данных

```
first:
second:
third:
fourth: a
```
```
In [4]: print yaml.dump(d)
first:
second:
third: {fourth: a}
```
```
In [5]: d2 = [{'a': 'a'}, {'b': 'b'}, {'c': 'c'}]
In [6]: print yaml.dump(d2, default_flow_style=False)
a: a
b: b
c: c
In [7]: print yaml.dump(d2)
{a: a}
{b: b}
{c: c}
In [8]: d3 = [{'a': 'a'}, {'b': 'b'}, {'c': [1, 2, 3, 4, 5]}]
```
```
In [9]: print yaml.dump(d3, default_flow_style=False)
a: a
b: b
c:
1
2
3
4
5
In [10]: print yaml.dump(d3)
{a: a}
{b: b}
c: [1, 2, 3, 4, 5]
```
```
А если нам потребуется сериализовать наш собственный класс? В этом
случае модуль yaml ведет себя практически точно так же, как и модуль
pickle. В следующем примере используется тот же самый модуль
custom_class, который использовался в примере с модулем pickle.
Ниже приводится содержимое модуля, который импортирует модуль
custom_class, создает экземпляр класса MyClass, добавляет несколько
элементов в объект и затем сериализует его:
```
```
#!/usr/bin/env python
import yaml
import custom_class
my_obj = custom_class.MyClass()
my_obj.add_item(1)
my_obj.add_item(2)
```

Простая сериализация **441**

```
my_obj.add_item(3)
yaml_file = open('custom_class.yaml', 'w')
yaml.dump(my_obj, yaml_file)
yaml_file.close()
```
```
Когда мы запустили этот модуль, получили следующий вывод:
jmjones@dinkgutsy:~/code$ python custom_class_yaml.py
jmjones@dinkgutsy:~/code$
```
```
То есть ничего. Это означает, что все идет так, как надо.
Ниже приводится модуль, обратный предыдущему:
#!/usr/bin/env python
```
```
import yaml
import custom_class
```
```
yaml_file = open('custom_class.yaml', 'r')
my_obj = yaml.load(yaml_file)
print my_obj
yaml_file.close()
```
```
Этот сценарий импортирует модули yaml и custom_class, создает объект
файла для чтения данных из файла, созданного предыдущим сценари
ем, загружает объект из файла и выводит его.
Когда мы запустили этот сценарий, то получили следующее:
```
```
jmjones@dinkgutsy:~/code$ python custom_class_unyaml.py
Custom Class MyClass Data:: [1, 2, 3]
```
```
Точно такой же результат мы получили в примере, использующем мо
дуль pickle, демонстрировавшемся ранее в этой главе, откуда следует,
что модуль yaml проявляет именно такое поведение, какое мы и пред
полагали увидеть.
```
**ZODB**

```
Еще один способ сериализации данных основан на применении моду
ля ZODB. ZODB означает «Zope Object Database» (объектная база дан
ных Zope). В простейших случаях использование ZODB напоминает
сериализацию с помощью модуля pickle или yaml, но ZODB обладает
возможностью расти вместе с вашими потребностями. Например,
ZODB предоставляет механизм транзакций – на случай, если вам по
требуется обеспечить атомарность своих операций. А если вам потре
буется легко масштабируемое решение, вы можете использовать ZEO,
систему распределенного хранения объектов.
База данных ZODB имела все шансы попасть не в раздел, описываю
щий «простую сериализацию», а в раздел, где рассказывается о «реля
ционной сериализации». Однако эта объектная база данных не совсем
точно соответствует тому, что мы привыкли называть реляционными
```

**442** Глава 12. Сохранность данных

```
базами данных, хотя вы без труда можете устанавливать отношения
между объектами. Кроме того, мы продемонстрируем лишь некоторые
из наиболее основных возможностей ZODB, поэтому в наших приме
рах она больше напоминает модуль shelve, чем реляционную базу дан
ных. Поэтому мы и решили оставить ZODB в разделе, рассказываю
щем о «простой сериализации».
Установка ZODB выполняется просто – достаточно запустить команду
easy_install ZODB3. Модуль ZODB имеет ряд зависимостей, но утилита
easy_install благополучно разрешит их, и загрузит и установит все,
что необходимо.
Для примера простейшего использования ZODB создадим объектхра
нилище ZODB и добавим в него словарь и список. Ниже приводится
программный код, выполняющий сериализацию словаря и списка:
#!/usr/bin/env python
```
```
import ZODB
import ZODB.FileStorage
import transaction
filestorage = ZODB.FileStorage.FileStorage('zodb_filestorage.db')
db = ZODB.DB(filestorage)
conn = db.open()
```
```
root = conn.root()
root['list'] = ['this', 'is', 'a', 'list']
root['dict'] = {'this': 'is', 'a': 'dictionary'}
transaction.commit()
conn.close()
```
```
По сравнению с pickle или YAML для инициализации работы с ZODB
требуется написать на пару строк программного кода больше, но как
только хранилище будет создано и инициализировано, оно использует
ся ничуть не сложнее других альтернатив. Этот пример достаточно оче
виден, особенно если учесть, что мы уже рассматривали другие приме
ры сохранения данных. И, тем не менее, мы быстро пройдемся по нему.
Вопервых, мы импортируем несколько модулей ZODB, а именно ZODB,
ZODB.FileStorage и transaction. (Мы хотели бы здесь сделать небольшое
замечание. Импортирование модуля, в имени которого отсутствует
идентификационный префикс, выглядит несколько странно. Создается
впечатление, что импортируемый модуль transaction должен иметь пре
фикс ZODB. Но как бы то ни было, имя модуля такое, какое есть, и вам
просто достаточно знать об этом. А теперь можно двигаться дальше.)
Затем создается объект FileStorage, которому указывается имя файла,
который будет использоваться как база данных. Затем создается объ
ект DB и подключается к объекту FileStorage. Затем объект базы дан
ных открывается с помощью метода open() и обретается ссылка на кор
невой узел объекта. С этого момента мы можем добавлять в корень
```

Простая сериализация **443**

```
объекта свои структуры данных, что мы и делаем, используя импрови
зированные список и словарь. После этого мы подтверждаем измене
ния с помощью функции transaction.commit() и затем закрываем соеди
нение с базой данных вызовом метода conn.close().
Как только будет создан контейнер хранилища данных (как объект
файла хранилища в этом примере) и запись данных будет подтвержде
на, у вас может появиться потребность восстановить эти данные.
В следующем примере мы открываем ту же самую базу данных, но на
этот раз мы читаем данные из файла, а не записываем в него:
#!/usr/bin/env python
```
```
import ZODB
import ZODB.FileStorage
```
```
filestorage = ZODB.FileStorage.FileStorage('zodb_filestorage.db')
db = ZODB.DB(filestorage)
conn = db.open()
root = conn.root()
print root.items()
conn.close()
```
```
И если запустить этот сценарий после того, как база данных будет на
полнена, мы могли бы увидеть следующее:
```
```
jmjones@dinkgutsy:~/code$ python zodb_read.py
No handlers could be found for logger "ZODB.FileStorage"
[('list', ['this', 'is', 'a', 'list']), ('dict', {'this': 'is', 'a':
'dictionary'})]
```
```
При описании других механизмов сохранения данных мы рассматри
вали примеры сериализации своих собственных классов, поэтому мы
покажем, как то же самое делается с помощью ZODB. Однако на этот
раз мы не будем использовать тот же самый класс MyClass (позднее объ
ясним, почему). Как и при использовании других механизмов, мы
просто объявим свой класс, создадим экземпляр этого класса и затем
передадим его механизму сериализации для сохранения на диске. Ни
же приводится определение класса, который мы будем использовать
в этот раз:
#!/usr/bin/env python
```
```
import persistent
class OutOfFunds(Exception):
pass
class Account(persistent.Persistent):
def __init__(self, name, starting_balance=0):
self.name = name
self.balance = starting_balance
def __str__(self):
```

**444** Глава 12. Сохранность данных

```
return "Account %s, balance %s" % (self.name, self.balance)
def __repr__(self):
return "Account %s, balance %s" % (self.name, self.balance)
def deposit(self, amount):
self.balance += amount
return self.balance
def withdraw(self, amount):
if amount > self.balance:
raise OutOfFunds
self.balance= amount
return self.balance
```
```
Это очень простой класс, имитирующий банковский счет и предназна
ченный для управления денежными средствами. Мы также определи
ли исключение OutOfFunds, назначение которого объясним позже.
Класс Account наследует класс persistent.Persistent. (Что касается мо
дуля persistent, мы опять могли бы сделать высокопарное отступление
об уместности значимого префикса в имени модуля, который предпо
лагается использовать. Как при беглом знакомстве с этим программ
ным кодом определить, что он использует ZODB? Никак. Но не будем хо
дить по кругу.) Наследование от класса persistent.Persistent позволяет
задействовать скрытые механизмы и облегчает для ZODB сериализа
цию этих данных. В определении класса мы создали собственные реа
лизации методов преобразования класса в строковую форму __str__
и__repr__. Позднее вы увидите их в действии. Мы также создали мето
ды deposit() и withdraw(). Оба метода изменяют атрибут balance объекта
в сторону увеличения или уменьшения, в зависимости от того, какой
метод вызывается. Метод withdraw() проверяет, достаточно ли денег на
балансе (в атрибуте balance), прежде чем списать запрошенную сумму.
Если денег недостаточно, метод withdraw() возбуждает исключение
OutOfFunds, упоминавшееся выше. Оба метода, deposit() и withdraw(),
возвращают остаток средств на счете после выполнения операции.
Ниже приводится программный код, который сохраняет только что
описанный класс:
#!/usr/bin/env python
```
```
import ZODB
import ZODB.FileStorage
import transaction
import custom_class_zodb
```
```
filestorage = ZODB.FileStorage.FileStorage('zodb_filestorage.db')
db = ZODB.DB(filestorage)
conn = db.open()
root = conn.root()
noah = custom_class_zodb.Account('noah', 1000)
print noah
root['noah'] = noah
jeremy = custom_class_zodb.Account('jeremy', 1000)
```

Простая сериализация **445**

```
print jeremy
root['jeremy'] = jeremy
```
```
transaction.commit()
conn.close()
```
```
Этот пример практически идентичен предыдущему примеру использо
вания ZODB, где мы сохраняли словарь и список. Только здесь мы им
портируем свой собственный модуль, создаем два экземпляра нашего
класса и сохраняем эти два объекта в базе данных ZODB. Эти два объ
екта – счет noah и счет jeremy, каждый из которых имеет на балансе
1000 (предположим, $1000.00, но мы не идентифицировали, в какой
валюте исчисляется сумма на счете).
Ниже приводится результат работы этого примера:
```
```
jmjones@dinkgutsy:~/code$ python zodb_custom_class.py
Account noah, balance 1000
Account jeremy, balance 1000
```
```
А если запустить модуль, отображающий содержимое базы данных
ZODB, вот, что мы получим:
jmjones@dinkgutsy:~/code$ python zodb_read.py
No handlers could be found for logger "ZODB.FileStorage"
[('jeremy', Account jeremy, balance 1000), ('noah', Account noah, balance
1000)]
```
```
Наш пример не только создал два объекта, как ожидалось, но и сохра
нил их на диск для последующего использования.
А как нам открыть базу данных и изменить суммы на счетах? Все на
ши усилия были бы бессмысленны, не будь такой возможности. Ниже
приводится фрагмент, открывающий базу данных, созданную ранее,
и выполняющий перевод 300 (повидимому, долларов) со счета noah на
счет jeremy:
```
```
#!/usr/bin/env python
import ZODB
import ZODB.FileStorage
import transaction
import custom_class_zodb
filestorage = ZODB.FileStorage.FileStorage('zodb_filestorage.db')
db = ZODB.DB(filestorage)
conn = db.open()
```
```
root = conn.root()
noah = root['noah']
print "BEFORE WITHDRAWAL"
print "================="
print noah
jeremy = root['jeremy']
print jeremy
```

**446** Глава 12. Сохранность данных

```
print ""
transaction.begin()
noah.withdraw(300)
jeremy.deposit(300)
transaction.commit()
print "AFTER WITHDRAWAL"
print "================"
print noah
print jeremy
print ""
```
```
conn.close()
```
```
Ниже приводятся результаты работы этого сценария:
```
```
jmjones@dinkgutsy:~/code$ python zodb_withdraw_1.py
BEFORE WITHDRAWAL
=================
Account noah, balance 1000
Account jeremy, balance 1000
```
```
AFTER WITHDRAWAL
================
Account noah, balance 700
Account jeremy, balance 1300
```
```
А если запустить наш сценарий, отображающий содержимое базы дан
ных ZODB, то увидим, что данные сохранились:
jmjones@dinkgutsy:~/code$ python zodb_read.py
[('jeremy', Account jeremy, balance 1300), ('noah', Account noah, balance
700)]
```
```
Сумма на счете noah уменьшилась с 1000 до 700, а сумма на счете jeremy
увеличилась с 1000 до 1300.
Причина, по которой мы отказались от использования класса MyClass,
состоит в том, что нам хотелось продемонстрировать работу с транзак
циями. Один из классических способов сделать это – продемонстриро
вать их использование при работе с банковскими счетами. Если вам
требуется гарантировать благополучный перевод средств с одного сче
та на другой без потери средств, то транзакции будут первым инстру
ментом, на который стоит обратить внимание. Ниже приводится при
мер, где используются транзакции в цикле и показано, что деньги ни
куда не пропадают:
#!/usr/bin/env python
```
```
import ZODB
import ZODB.FileStorage
import transaction
import custom_class_zodb
```

Простая сериализация **447**

```
filestorage = ZODB.FileStorage.FileStorage('zodb_filestorage.db')
db = ZODB.DB(filestorage)
conn = db.open()
root = conn.root()
noah = root['noah']
print "BEFORE TRANSFER"
print "==============="
print noah
jeremy = root['jeremy']
print jeremy
print ""
while True:
try:
transaction.begin()
jeremy.deposit(300)
noah.withdraw(300)
transaction.commit()
except custom_class_zodb.OutOfFunds:
print "OutOfFunds Error"
print "Current account information:"
print noah
print jeremy
transaction.abort()
break
```
```
print "AFTER TRANSFER"
print "=============="
print noah
print jeremy
print ""
conn.close()
```
```
Это некоторая модификация предыдущего примера сценария, выпол
няющего перевод средств. Только на этот раз вместо одного перевода он
выполняет переводы по 300 единиц со счета noah на счет jeremy, пока на
счету noah не окажется недостаточно средств для перевода. В момент,
когда на счету оказывается недостаточно средств, сценарий выводит
сообщение о том, что возникло исключение, и информацию о текущем
состоянии счетов. После этого вызывается метод abort() транзакции
и выполнение цикла прерывается. Кроме того, сценарий выводит ин
формацию до и после цикла транзакций. Пока транзакции совершают
ся, и до и после операции общий объем средств на счетах составляет
2000, поскольку изначально на каждом счете имелась сумма 1000.
Ниже приводится результат запуска этого сценария:
```
```
jmjones@dinkgutsy:~/code$ python zodb_withdraw_2.py
BEFORE TRANSFER
===============
Account noah, balance 700
```

**448** Глава 12. Сохранность данных

```
Account jeremy, balance 1300
```
```
OutOfFunds Error
Current account information:
Account noah, balance 100
Account jeremy, balance 2200
AFTER TRANSFER
==============
Account noah, balance 100
Account jeremy, balance 1900
```
```
Перед началом цикла переводов на счете noah имелась сумма 700 еди
ниц и на счете jeremy – 1300 единиц, итого 2000. Когда возникло исклю
чение OutOfFunds, на счете noah имелось 100 единиц и на счете jeremy –
2200, итого 2300. В блоке «AFTER TRANSFER» (после перевода) на
счете noah осталось 100 единиц и на счете jeremy – 1900, итого 2000.
Итак, когда возникло исключение, перед тем как был вызван метод
transaction.abort(), имелись лишние 300 единиц, появление которых
невозможно было бы объяснить. Но прерывание транзакции ликвиди
ровало эту проблему.
База данных ZODB представляет собой решение, занимающее проме
жуточное положение между простыми и реляционными инструмента
ми. Она проста в использовании. Объект, сохраняемый на диске, соот
ветствует объекту в памяти как до сохранения, так и после восстанов
ления. Но у этого инструмента имеются такие дополнительные особен
ности, как транзакции. База данных ZODB стоит того, чтобы на нее
обратили внимание, когда изначально требуется достаточно простой
механизм отображения объектов, расширенные возможности которо
го могут потребоваться позже.
В заключение раздела о простой сериализации: иногда все, что вам
требуется, – это просто сохранять и восстанавливать объекты Python.
Все инструменты, которые мы рассмотрели здесь, прекрасно справля
ются с этой задачей. У каждого из них есть свои сильные и слабые сто
роны. Когда возникнет такая необходимость, вы сможете заняться ис
следованием и выяснить, какой из инструментов лучше подходит для
вас и вашего проекта.
```
### Реляционная сериализация

```
Иногда простой сериализации бывает недостаточно. Иногда возникает
потребность в использовании мощи реляционного анализа. Под реля
ционной сериализацией подразумевается либо сохранение объектов
Python вместе с информацией об их отношениях с другими объектами
Python, либо сохранение реляционных данных (например, в реляци
онной базе данных) и предоставление объектного интерфейса к этим
данным.
```

Реляционная сериализация **449**

**SQLite**

```
Иногда полезно сохранять и работать с данными более структуриро
ванным способом, с учетом отношений между ними. Здесь мы будем
говорить о семействе инструментов хранения информации, которые
называются реляционными базами данных, или СУРБД (системы
управления реляционными базами данных). Мы полагаем, что ранее
вам уже приходилось использовать такие реляционные базы данных,
как MySQL, PostgreSQL или Oracle. Если это так, у вас не должно воз
никать проблем при чтении этого раздела.
Согласно информации, что приводится на вебсайте, SQLite – «это биб
лиотека программного обеспечения, реализующая самодостаточный,
безсерверный, не требующий настройки механизм базы данных SQL
с поддержкой транзакций». Что все это означает? Этот механизм базы
данных работает не в виде отдельного процесса на сервере, а в том же
самом процессе, что и ваш программный код, и вы можете обращаться
к нему как к библиотеке. Данные находятся в файле, а не во множестве
каталогов, разбросанных по нескольким файловым системам. И вме
сто того, чтобы настраивать имя хоста, номер порта, имя пользователя,
пароль и так далее, для организации доступа к данным вы просто ука
зываете в своем программном коде имя файла базы данных, созданно
го библиотекой SQLite. Это предложение также означает, что SQLite
является базой данных с достаточно широкими возможностями. Про
ще говоря, это предложение указывает на два главных преимущества
SQLite: простота в использовании и обладание возможностями, прису
щими «настоящим» базам данных. Еще одно преимущество состоит
в ее распространенности. Поддержка SQLite обеспечивается большин
ством языков программирования в большинстве основных операцион
ных систем.
Теперь, когда вы знаете причины, которые могут побудить к использо
ванию этой базы данных, посмотрим, как ею пользоваться. Мы взяли
следующие определения таблиц из примера, где использовалась плат
форма Django в главе 11. Предположим, что у нас имеется файл с име
нем inventory.sql , содержащий следующий текст:
BEGIN;
CREATE TABLE "inventory_ipaddress" (
"id" integer NOT NULL PRIMARY KEY,
"address" text NULL,
"server_id" integer NOT NULL
)
;
CREATE TABLE "inventory_hardwarecomponent" (
"id" integer NOT NULL PRIMARY KEY,
"manufacturer" varchar(50) NOT NULL,
"type" varchar(50) NOT NULL,
"model" varchar(50) NULL,
"vendor_part_number" varchar(50) NULL,
```

**450** Глава 12. Сохранность данных

```
"description" text NULL
)
;
CREATE TABLE "inventory_operatingsystem" (
"id" integer NOT NULL PRIMARY KEY,
"name" varchar(50) NOT NULL,
"description" text NULL
)
;
CREATE TABLE "inventory_service" (
"id" integer NOT NULL PRIMARY KEY,
"name" varchar(50) NOT NULL,
"description" text NULL
)
;
CREATE TABLE "inventory_server" (
"id" integer NOT NULL PRIMARY KEY,
"name" varchar(50) NOT NULL,
"description" text NULL,
"os_id" integer NOT NULL REFERENCES "inventory_operatingsystem" ("id")
)
;
CREATE TABLE "inventory_server_services" (
"id" integer NOT NULL PRIMARY KEY,
"server_id" integer NOT NULL REFERENCES "inventory_server" ("id"),
"service_id" integer NOT NULL REFERENCES "inventory_service" ("id"),
UNIQUE ("server_id", "service_id")
)
;
CREATE TABLE "inventory_server_hardware_component" (
"id" integer NOT NULL PRIMARY KEY,
"server_id" integer NOT NULL REFERENCES "inventory_server" ("id"),
"hardwarecomponent_id" integer
NOT NULL REFERENCES "inventory_hardwarecomponent" ("id"),
UNIQUE ("server_id", "hardwarecomponent_id")
)
;
COMMIT;
```
```
Тогда мы могли бы создать базу данных SQLite следующей командой:
jmjones@dinkgutsy:~/code$ sqlite3 inventory.db < inventory.sql
```
```
Конечно, здесь мы предполагаем, что вы уже установили SQLite. В сис
темах Ubuntu и Debian установка выполняется простой командой apt–
get install sqlite3. В системах Red Hat следует выполнить команду
yum install sqlite. Для других дистрибутивов Linux, не имеющих ус
тановочных пакетов, других систем UNIX или для Windows вы може
те загрузить исходные тексты и скомпилированные файлы по адресу
http://www.sqlite.org/download.html.
```

Реляционная сериализация **451**

```
Предположим, что библиотека SQLite установлена в системе и база дан
ных была благополучно создана. Мы продолжим нашу работу с ней, на
чав с «подключения» к базе данных и заполнения ее некоторыми дан
ными. Ниже показано все, что необходимо сделать для подключения
к базе данных SQLite:
In [1]: import sqlite3
```
```
In [2]: conn = sqlite3.connect('inventory.db')
```
```
Все, что нам потребовалось, – это импортировать библиотеку SQLite и
затем вызвать функцию connect() в модуле sqlite3. Функция connect()
возвращает объект соединения с базой данных, которому мы присвои
ли имя conn и который мы будем использовать в оставшейся части при
мера. Далее с помощью объекта соединения мы выполняем запрос, до
бавляющий данные в базу:
In [3]: cursor = conn.execute("insert into inventory_operatingsystem (name,
description) values ('Linux', '2.0.34 kernel');")
```
```
Метод execute() возвращает объект курсора базы данных, поэтому мы
решили дать ему имя cursor. Обратите внимание, что мы указали зна
чения только для полей name и description и опустили значение для по
ля id, которое является первичным ключом. Через мгновение вы уви
дите, что это поле получило свое значение. Поскольку это запрос на до
бавление данных в базу, а не запрос на выборку, то мы не ждем от за
проса результирующего набора данных; поэтому мы просто будем
просматривать курсор и извлекать любые результаты, которые он мо
жет хранить:
```
```
In [4]: cursor.fetchall()
Out[4]: []
```
```
Ничего, как мы и ожидали.
In [5]: conn.commit()
```
```
In [6]:
```
```
В действительности мы не должны были подтверждать операцию до
бавления данных. Эти изменения все равно будут сброшены на диск,
когда позднее мы закроем соединение с базой данных. Но никогда не
помешает явно вызвать метод commit(), когда известно, что эти данные
должны быть записаны.
Теперь, когда мы создали и заполнили базу данных SQLite, попробуем
прочитать записанные данные обратно. Для начала запустим оболочку
IPython, импортируем модуль sqlite3 и создадим соединение с файлом
базы данных:
```
```
In [1]: import sqlite3
In [2]: conn = sqlite3.connect('inventory.db')
```

**452** Глава 12. Сохранность данных

```
Теперь мы выполним запрос select и получим курсор с результатами:
In [3]: cursor = conn.execute('select * from inventory_operatingsystem;')
```
```
И, наконец, извлечем данные из курсора:
In [4]: cursor.fetchall()
Out[4]: [(1, u'Linux', u'2.0.34 kernel')]
```
```
Это те самые данные, которые были добавлены выше. Значение полей
name и description хранятся в Юникоде. А поле id заполнено целым чис
лом. Обычно, когда производится вставка данных в базу и при этом не
указывается значение поля первичного ключа, база данных сама за
полнит его, автоматически получая следующее уникальное значение
для этого поля.
Теперь, когда вы познакомились с основными приемами взаимодейст
вия с базой данных SQLite, реализация соединения таблиц, обновле
ния данных и более сложных операций – это, в значительной степени,
вопрос времени. База данных SQLite обеспечивает отличную возмож
ность сохранения данных, особенно когда данные используются един
ственным сценарием или только несколькими пользователями одно
временно. Говоря другими словами, SQLite прекрасно подходит для
решения небольших задач. Однако интерфейс модуля sqlite3 остается
слишком сложным.
```
**Storm ORM**

```
Несмотря на то, что простого SQLинтерфейса к базе данных вполне
достаточно для извлечения, изменения, добавления и удаления дан
ных в базе, тем не менее, часто бывает удобнее не отказываться от про
стоты и удобства языка Python. За последние несколько лет в способах
доступа к базам данных появилось новое направление – объектноори
ентированное представление данных, хранящихся в базе. Это направ
ление называется объектнореляционной проекцией (ObjectRelational
Mapping, ORM). В терминах ORM объект на языке программирования
может соответствовать одной строке в одной таблице базы данных.
Таблицы, связанные отношениями внешнего ключа, могут быть дос
тупны в виде атрибутов такого объекта.
Storm – это инструмент ORM, который недавно был выпущен как про
дукт, распространяемый с открытыми исходными текстами, компани
ей Canonical, которая ведет разработку дистрибутива Linux – Ubuntu.
Storm – это относительно новый продукт среди средств доступа к базам
данных для языка Python, но к нему уже проявляется пристальное
внимание и мы полагаем, что он станет одним из основных средств
ORM в языке Python.
Теперь мы попробуем использовать Storm для доступа к данным в базе,
которая была определена в разделе «SQLite». Первое, что нам следует
сделать, – это создать отображение для интересующих нас таблиц. По
```

Реляционная сериализация **453**

```
скольку мы уже обращались к таблице inventory_operatingsystem и до
бавили в нее одну запись, мы продолжим работу с этой таблицей. Ни
же показано, как выглядит отображение при использовании библиоте
ки Storm:
```
```
import storm.locals
class OperatingSystem(object):
__storm_table__ = 'inventory_operatingsystem'
id = storm.locals.Int(primary=True)
name = storm.locals.Unicode()
description = storm.locals.Unicode()
```
```
Это самое обычное определение класса. Здесь нет ничего сверхъестест
венного. Здесь не наследуется какойто другой класс, кроме встроенного
типа object. Зато имеется несколько атрибутов. Единственное, что вы
глядит немного странно, – это атрибут __storm_table__. С его помощью
библиотека Storm определяет, для доступа к какой таблице будет ис
пользоваться этот объект. Пока все выглядит достаточно просто и впол
не обычно, и, тем не менее, во всем этом всетаки есть капелька магии.
Например, атрибут name отображается на поле name в таблице inventory_
operatingsystem, а атрибут description отображается на поле description
в той же таблице. Как? Магия. Любой атрибут, присутствующий в клас
се проекции Storm, автоматически отображается на одноименное поле
в таблице, имя которой определяется атрибутом __storm_table__.
А что, если нам не нужно, чтобы атрибут description объекта отобра
жался на поле description? Тогда просто передайте методу storm.lo
cals.Type имя требуемого поля в именованном аргументе name. Напри
мер, изменив определение атрибута description на такое: dsc = storm.
locals.Unicode(name='description'), вы тем самым свяжете атрибут dsc
объекта OperatingSystem с тем же самым полем (то есть с полем descrip
tion). Но тогда на описание нужно будет ссылаться не как на атрибут
mapped_object.description, а как на атрибут mapped_object.dsc.
Теперь, когда у нас имеется класс проекции на таблицу в базе данных,
попробуем добавить в нее еще одну строку. В дополнение к нашему древ
нему дистрибутиву Linux на ядре 2.0.34 мы добавим Windows 3.1.1:
import storm.locals
import storm_model
import os
```
```
operating_system = storm_model.OperatingSystem()
operating_system.name = u'Windows'
operating_system.description = u'3.1.1'
db = storm.locals.create_database('sqlite:///%s' % os.path.join(os.getcwd(),
'inventory.db'))
store = storm.locals.Store(db)
store.add(operating_system)
store.commit()
```

**454** Глава 12. Сохранность данных

```
В этом примере мы импортировали модули storm.locals, storm_model и os.
Затем мы создали экземпляр класса OperatingSystem и присвоили значе
ния его атрибутам name и description. (Обратите внимание: в качестве
значений этих атрибутов мы использовали строки Юникода.) Затем
мы создали объект базы данных, вызвав функцию create_database(),
и передали этому методу путь к файлу нашей базы данных SQLite,
inventory.db. Вы могли бы подумать, что объект базы данных будет ис
пользоваться для добавления данных в базу, но это не так, по крайней
мере, не напрямую. Сначала нам нужно создать объект Store, передав
объект базы данных конструктору. После этого мы можем добавить
объект operating_system в объект store. В заключение вызывается ме
тод commit() объекта store, чтобы подтвердить добавление объекта ope
rating_system в базу данных.
Мы также хотели бы убедиться, что вставленные данные действитель
но были записаны в базу данных. Поскольку это база данных SQLite,
можно было бы просто воспользоваться инструментом командной
строки sqlite3. Но если сделать это, то у нас не будет причин написать
программный код, извлекающий данные из базы с помощью Storm.
Итак, ниже приводится простая утилита, которая извлекает и выво
дит все записи из таблицы inventory_operatingsystem (хотя и в довольно
уродливом виде):
import storm.locals
import storm_model
import os
```
```
db = storm.locals.create_database('sqlite:///%s' % os.path.join(os.getcwd(),
'inventory.db'))
```
```
store = storm.locals.Store(db)
for o in store.find(storm_model.OperatingSystem):
print o.id, o.name, o.description
```
```
Первые несколько строк в этом примере поразительно напоминают
первые несколько строк предыдущего примера. Отчасти это сходство
обусловлено тем, что мы просто скопировали программный код из од
ного файла в другой. Впрочем, это не главное. Основная же причина
заключается в том, что в обоих случаях необходимо выполнить одни
и те же подготовительные действия, прежде чем сценарии смогут «об
щаться» с базой данных. Здесь используются те же инструкции им
портирования, что и в предыдущем примере. У нас имеется объект db,
который возвращает функция create_database(). У нас имеется объект
store, созданный конструктором Store(), которому был передан объект
db. Но теперь вместо добавления объекта в хранилище (в объект store)
мы вызываем метод find() объекта store. Этот конкретный вызов метода
find() (то есть store.find(storm_model.OperatingSystem)) возвращает мно
жество всех объектов storm_model.OperatingSystem. Поскольку класс Ope
ratingSystem является проекцией на таблицу inventory_operatingsystem,
```

Реляционная сериализация **455**

```
Storm отыщет все подходящие записи в таблице inventory_operating
system и создаст объект OperatingSystem для каждой из них. Для каждо
го объекта OperatingSystem выводятся значения атрибутов id, name и de
scription. Эти атрибуты являются проекциями на одноименные поля
записей в базе данных.
В нашей базе данных уже имеется одна запись, добавленная в более
раннем примере, приводившемся в разделе «SQLite». Давайте посмот
рим, что получится, если запустить этот сценарий. Мы могли бы ожи
дать, что будет выведена одна запись, хотя она и была добавлена без
использования библиотеки Storm:
```
```
jmjones@dinkgutsy:~/code$ python storm_retrieve_os.py
1 Linux 2.0.34 kernel
```
```
Это в точности соответствует нашим ожиданиям. Теперь сначала по
пробуем запустить сценарий, добавляющий новую запись, а затем сно
ва запустим сценарий, извлекающий данные. На этот раз он должен
вывести старую запись, добавленную ранее (система на базе ядра
Linux 2.0.34), и только что добавленную запись (Windows 3.1.1):
jmjones@dinkgutsy:~/code$ python storm_add_os.py
jmjones@dinkgutsy:~/code$ python storm_retrieve_os.py
1 Linux 2.0.34 kernel
2 Windows 3.1.1
```
```
И снова мы получили именно то, что и ожидали получить.
Но что, если нам потребуется фильтровать данные? Предположим, что
нам потребуется увидеть только те операционные системы, название
которых начинается с последовательности символов «Lin». Ниже при
водится фрагмент программного кода, который делает именно это:
```
```
import storm.locals
import storm_model
import os
db = storm.locals.create_database('sqlite:///%s' % os.path.join(os.getcwd(),
'inventory.db'))
store = storm.locals.Store(db)
for o in store.find(storm_model.OperatingSystem,
storm_model.OperatingSystem.name.like(u'Lin%')):
print o.id, o.name, o.description
```
```
Этот пример идентичен предыдущему примеру, где использовался
метод store.find(), за исключением того, что в этом примере методу
store.find() передается второй параметр: критерий поиска. Вызов
Store.find(storm_model.OperatingSystem,storm_model.OperatingSystem.na
me.like(u'Lin%')) сообщает библиотеке Storm, что требуется отыскать
все объекты OperatingSystem, у которых значение атрибута name начи
нается со строки Юникода Lin. Каждое значение в наборе результа
тов выводится точно так же, как и в предыдущем примере.
```

**456** Глава 12. Сохранность данных

```
И когда мы запустим этот фрагмент, мы увидим следующее:
jmjones@dinkgutsy:~/code$ python storm_retrieve_os_filter.py
1 Linux 2.0.34 kernel
```
```
В базе данных попрежнему присутствует запись с названием операци
онной системы «Windows 3.1.1», но она была отфильтрована, потому
что не начинается со строки «Lin».
```
**SQLAlchemy ORM**

```
В то время как библиотека Storm только начинает обретать сторонни
ков и находится на стадии формирования сообщества, библиотека
SQLAlchemy уже является доминирующим средством ORM для языка
Python. Своим подходом к решению проблемы она напоминает Storm.
Вероятно, лучше было бы сказать, что «библиотека Storm своим под
ходом к решению проблемы напоминает SQLAlchemy», поскольку
библиотека SQLAlchemy появилась раньше. Но, как бы то ни было,
для демонстрации SQLAlchemy мы воспользуемся все той же таблицей
inventory_operatingsystem, для работы с которой только что использова
ли библиотеку Storm.
Ниже приводится определение таблицы и объекта для отображения
таблицы inventory_operatingsystem:
#!/usr/bin/env python
```
```
import os
from sqlalchemy import create_engine
from sqlalchemy import Table, Column, Integer, Text, VARCHAR, MetaData
from sqlalchemy.orm import mapper
from sqlalchemy.orm import sessionmaker
engine = create_engine('sqlite:///%s' % os.path.join(os.getcwd(),
'inventory.db'))
metadata = MetaData()
os_table = Table('inventory_operatingsystem', metadata,
Column('id', Integer, primary_key=True),
Column('name', VARCHAR(50)),
Column('description', Text()),
)
class OperatingSystem(object):
def __init__(self, name, description):
self.name = name
self.description = description
def __repr__(self):
return "<OperatingSystem('%s','%s')>" % (self.name, self.description)
mapper(OperatingSystem, os_table)
Session = sessionmaker(bind=engine, autoflush=True, transactional=True)
session = Session()
```

Реляционная сериализация **457**

```
Самое существенное различие между примерами использования Storm
и SQLAlchemy заключается в определении таблицы, которое использу
ется библиотекой SQLAlchemy для создания проекции вместе с клас
сом таблицы.
Теперь, когда у нас имеется определение таблицы, можно написать
программный код, выполняющий запрос всех записей из таблицы:
```
```
#!/usr/bin/env python
from sqlalchemy_inventory_definition import session, OperatingSystem
```
```
for os in session.query(OperatingSystem):
print os
```
```
Если запустить этот фрагмент теперь, когда в таблице уже имеются не
которые данные, записанные туда в предыдущих примерах, мы уви
дим следующее:
$ python sqlalchemy_inventory_query_all.py <OperatingSystem('Linux','2.0.34
kernel')>
<OperatingSystem('Windows','3.1.1')>
</OperatingSystem></OperatingSystem>
```
```
Если бы нам потребовалось создать еще одну запись, мы легко могли бы
сделать это, просто создав объект OperatingSystem и добавив его в объект
session:
```
```
#!/usr/bin/env python
from sqlalchemy_inventory_definition import session, OperatingSystem
ubuntu_710 = OperatingSystem(name='Linux', description='2.6.2214 kernel')
session.save(ubuntu_710)
session.commit()
```
```
В результате в таблицу будет добавлена другая запись с операционной
системой Linux на другом ядре, более современном. Запустив сцена
рий, запрашивающий все записи, еще раз, мы получим:
```
```
$ python sqlalchemy_inventory_query_all.py
<OperatingSystem('Linux','2.0.34 kernel')>
<OperatingSystem('Windows','3.1.1')>
<OperatingSystem('Linux','2.6.2214 kernel')>
```
```
Фильтрация результатов в SQLAlchemy выполняется также просто.
Например, если бы нам потребовалось выбрать все объекты Operating
System, в которых значение атрибута name начинается с последователь
ности символов «Lin», мы могли бы написать следующий сценарий:
```
```
#!/usr/bin/env python
from sqlalchemy_inventory_definition import session, OperatingSystem
for os in session.query(OperatingSystem).filter(
OperatingSystem.name.like('Lin%')):
print os
```

**458** Глава 12. Сохранность данных

```
И мы могли бы получить следующие результаты:
$ python sqlalchemy_inventory_query_filter.py
<OperatingSystem('Linux','2.0.34 kernel')>
<OperatingSystem('Linux','2.6.2214 kernel')>
```
```
Это был лишь краткий обзор возможностей библиотеки SQLAlchemy.
За дополнительной информацией об использовании SQLAlchemy обра
щайтесь на вебсайт http://www.sqlalchemy.org/. Или приобретите кни
гу Рика Коупленда (Rick Coupland) «Essential SQLAlchemy» (O’Reilly).
```
**В заключение**

```
В этой главе мы рассмотрели несколько различных инструментов, по
зволяющих сохранять данные для последующего использования. Ино
гда вам будет требоваться нечто простое и легковесное, как модуль
pickle. Иногда вам будет требоваться нечто более полнофункциональ
ное, как SQLAlchemy ORM. Как уже было показано, при использова
нии языка Python в вашем распоряжении имеется множество реше
ний, от очень простых до мощных и сложных.
```
```
ПОРТРЕТ ЗНАМЕНИТОСТИ: SQLACLCHEMY
```
**Майк Байер (Mike Bayer)**

```
Майкл Байер – подрядчик на поставку программ
ного обеспечения из НьюЙорка, обладающий де
сятилетним опытом работы с реляционными ба
зами данных всех форм и размеров. После созда
ния множества собственных библиотек абстрак
ции доступа к базам данных на таких языках
программирования, как C, Java и Perl, и после не
скольких лет практической работы с огромными, состоящими
из нескольких серверов, системами Oracle для высшей лиги по
бейсболу он написал SQLAlchemy, как «основной инструмент»
для создания кода SQL и для работы с базами данных. Цель его
состоит в том, чтобы способствовать появлению инструмента ми
рового класса для языка Python, помогающего превратить Py
thon в широко популярную платформу программирования, ка
ковой он достоин быть.
```

**13**

### Командная строка

**Введение**

Командная строка имеет особое значение для системного администра
тора. Ни один другой инструмент не обладает таким уровнем значимо
сти или авторитета, как командная строка. Полное овладение искусст
вом командной строки – это своего рода обряд посвящения для боль
шинства системных администраторов. Многие системные админист
раторы не считают администраторами тех, кто использует программы
с графическим интерфейсом, и называют графический интерфейс кос
тылями. Возможно, это не совсем справедливо, но это устоявшееся
мнение об истинном искусстве владения профессией системного адми
нистратора.

В течение очень долгого времени системы UNIX придерживались фи
лософии, что интерфейс командной строки (Command Line Inteface,
CLI) превосходит по своим возможностям любой графический интер
фейс, который когдалибо разрабатывался. В свете последних событий
создается впечатление, что даже Microsoft решила вернуться к своим
корням. Джеффри Сновер (Jeffrey Snover), архитектор Windows Po
wershell, заявил: «Это было ошибкой – думать, что графический ин
терфейс когдалибо сможет или должен вытеснить интерфейс команд
ной строки».

Даже создатели системы Windows, в которой в течение десятилетий
имелся самый худший интерфейс командной строки из всех современ
ных операционных систем, начинают понимать значимость интерфей
са командной строки, что привело к реализации Windows Powershell.
В этой книге мы не будем касаться операционной системы Windows,
но это очень интересный факт, подчеркивающий важность освоения
командной строки и действительную необходимость создания инстру
ментов командной строки.


**460** Глава 13. Командная строка

```
Однако недостаточно просто овладеть существующими в системе
UNIX инструментами командной строки. Чтобы стать настоящим про
фессионалом командной строки, необходимо научиться создавать соб
ственные инструменты и это может быть самой основной причиной, по
которой вы взяли эту книгу в руки. Эта глава вас не разочарует. За
кончив ее чтение, вы станете мастером по созданию инструментов ко
мандной строки на языке Python.
Это было преднамеренное решение – сконцентрировать внимание на
создании инструментов командной строки в последней главе. Мы хо
тели сначала продемонстрировать вам широчайший выбор приемов
программирования на языке Python, а в заключение рассказать вам,
как можно использовать все эти навыки при создании настоящих ше
девров командной строки.
```
### Основы использования потока стандартного ввода.

**стандартного ввода**

```
Самый простой путь к созданию инструментов командной строки опи
рается на знание того факта, что модуль sys позволяет обрабатывать
аргументы командной строки посредством атрибута sys.argv. В приме
ре 13.1 демонстрируется самый простой инструмент командной стро
ки, какой только возможен:
```
```
Пример 13.1. sysargv.py
#!/usr/bin/env python
```
```
import sys
print sys.argv
```
```
Эти две строки программного кода возвращают на стандартный вывод
все, что вводится в командной строке:
```
```
./sysargv.py
['./sysargv.py']
```
```
и
./sysargv.py foo
```
```
вернет на стандартный вывод
['./sysargv.py', 'test']
```
```
и
./sysargv.py foo bad for you
```
```
вернет на стандартный вывод
['./sysargv.py', 'foo', 'bad', 'for', 'you']
```

Основы использования потока стандартного ввода **461**

```
Добавим немного конкретики и слегка изменим программный код
так, чтобы он подсчитывал количество аргументов командной строки,
как показано в примере 13.2.
```
```
Пример 13.2. sysargv.py
#!/usr/bin/env python
import sys
```
```
#Индексы в языке Python начинаются с нуля, поэтому нужно исключить
#из подсчета саму команду – sys.argv[0]
```
```
num_arguments = len(sys.argv) 1
print sys.argv, "You typed in ", num_arguments, "arguments"
```
```
Вы могли бы подумать: «Как все просто, теперь мне осталось лишь по
лучить параметры командной строки по их индексам из списка
sys.argv и написать некоторую логику их обработки». В общем вы пра
вы, это довольно просто реализовать. Давайте добавим некоторые осо
бенности к нашему приложению командной строки. Последнее, что
мы могли бы сделать, – это вывести сообщение об ошибке в поток стан
дартного вывода сообщений об ошибках в случае отсутствия аргумен
тов командной строки, как показано в примере 13.3.
```
```
Пример 13.3. sysargv>step2.py
#!/usr/bin/env python
import sys
num_arguments = len(sys.argv) 1
```
```
#В случае отсутствия аргументов вывести сообщение
#в поток стандартного вывода сообщений об ошибках.
if num_arguments == 0:
sys.stderr.write('Hey, type in an option silly\n')
else:
print sys.argv, "You typed in ", num_arguments, "arguments"
```
```
Использование sys.argv при создании инструментов командной строки
зачастую является неправильным выбором, несмотря на всю его про
стоту. В стандартной библиотеке языка Python имеется модуль opt
parse, который берет на себя решение одной из самых неудобных задач
в создании качественного инструмента командной строки. Даже для
самых крошечных «разовых» инструментов лучше использовать opt
parse, чем sys.argv, так как у «разовых» инструментов есть свойство со
временем превращаться в нормальные рабочие инструменты. В сле
дующем разделе мы объясним, почему лучше использовать модуль opt
parse, но суть ответа заключается в том, что наличие хорошего модуля
разбора аргументов позволит разрешить самые необычные ситуации.
```

**462** Глава 13. Командная строка

### Введение в optparse.

```
Как упоминалось в предыдущем разделе, даже самый маленький сцена
рий может воспользоваться преимуществами модуля optparse при вы
полнении разбора параметров командной строки. Приступая к изуче
нию возможностей optparse, интереснее будет начать со своеобразного
примера «Hello World», который выполняет обработку параметров и ар
гументов. В примере 13.4 приводится наш сценарий «Hello World».
```
```
Пример 13.4. Hello World для модуля optparse
#!/usr/bin/env python
import optparse
```
```
def main():
p = optparse.OptionParser()
p.add_option('sysadmin', 's', default="BOFH")
options, arguments = p.parse_args()
print 'Hello, %s' % options.sysadmin
if __name__ == '__main__':
main()
```
```
Запуская этот сценарий, мы можем получить различные варианты вы
вода:
$ python hello_world_optparse.py
Hello, BOFH
$ python hello_world_optparse.pysysadmin Noah
Hello, Noah
$ python hello_world_optparse.pys Jeremy
Hello, Jeremy
$ python hello_world_optparse.pyinfinity Noah
Usage: hello_world_optparse.py [options]
hello_world_optparse.py: error: no such option:infinity
```
```
В нашем маленьком примере мы видели, что можно использовать как
короткий –s, так и длинный ––sysadmin параметры, а также значение по
умолчанию. Наконец, мы увидели встроенную возможность обработки
ошибок, когда указали неверный параметр и убедились в удобочитае
мости, которой так не хватает языку Perl.
```
### Простые шаблоны использования optparse

**Шаблон использования без ключей**

```
В предыдущем разделе мы упоминали, что модуль optparse может с ус
пехом использоваться даже в маленьких сценариях. В примере 13.5
показан простой шаблон использования модуля optparse, где сценарий
```

Простые шаблоны использования optparse **463**

```
не предусматривает наличие ключей командной строки, что не мешает
ему использовать преимущества optparse.
```
```
Пример 13.5. Клон команды ls
#!/usr/bin/env python
import optparse
import os
```
```
def main():
p = optparse.OptionParser(description="Python 'ls' command clone",
prog="pyls",
version="0.1a",
usage="%prog [directory]")
options, arguments = p.parse_args()
if len(arguments) == 1:
path = arguments[0]
for filename in os.listdir(path):
print filename
else:
p.print_help()
```
```
if __name__ == '__main__':
main()
```
```
В этом примере мы реализовали на языке Python свою версию коман
ды ls, которая принимает единственный аргумент – путь к каталогу,
содержимое которого требуется вывести. Мы не предусматриваем да
же наличие дополнительных ключей, но попрежнему можем пользо
ваться возможностями модуля optparse, опираясь на них при выборе
пути выполнения программы. Сначала при создании экземпляра клас
са OptionParser мы предоставляем некоторую информацию о реализа
ции и добавляем инструкции о порядке использования для потенци
альных пользователей инструмента. Затем мы проверяем количество
аргументов, и если их число больше или меньше одного, мы выводим
инструкцию о порядке использования инструмента с помощью метода
p.print_help(). Ниже приводится пример правильного использования
нашего инструмента, которому передается имя текущего каталога
«.»:
```
```
$ python no_options.py.
.svn
hello_world_optparse.py
no_options.py
```
```
А теперь посмотрим, что произойдет, если запустить сценарий без ар
гументов:
```
```
$ python no_options.py
Usage: pyls [directory]
```
```
Python 'ls' command clone
Options:
```

**464** Глава 13. Командная строка

```
version show program's version number and exit
h,help show this help message and exit
```
```
Интересно, что поведение, связанное с вызовом метода p.print_help(),
которое мы определили для случая запуска сценария, когда число ар
гументов не равно точно одному, равносильно запуску сценария с клю
чом ––help:
```
```
$ python no_options.pyhelp
Usage: pyls [directory]
```
```
Python 'ls' command clone
Options:
version show program's version number and exit
h,help show this help message and exit
```
```
А так как мы определили параметр ––version, то при его использова
нии мы получим следующее:
```
```
$ python no_options.pyversion
0.1a
```
```
В этом примере модуль optparse оказался полезен даже при создании
«разового» сценария, который может не получить дальнейшего разви
тия.
```
**Шаблон true/false**

```
Бывает очень удобно иметь возможность установить некоторый при
знак в значение true или false. Классическим примером такого шаблона
могут служить ключи: ––quiet, который подавляет вывод в поток стан
дартного вывода, и ––verbose, при установке которого программа перехо
дит в режим вывода более подробной информации. В примере 13.6 пока
зано, как это может выглядеть:
```
```
Пример 13.6. Увеличение и уменьшение подробности вывода
#!/usr/bin/env python
import optparse
import os
```
```
def main():
p = optparse.OptionParser(description="Python 'ls' command clone",
prog="pyls",
version="0.1a",
usage="%prog [directory]")
p.add_option("verbose", "v", action="store_true",
help="Enables Verbose Output",default=False)
options, arguments = p.parse_args()
if len(arguments) == 1:
if options.verbose:
print "Verbose Mode Enabled"
path = arguments[0]
```

Простые шаблоны использования optparse **465**

```
for filename in os.listdir(path):
if options.verbose:
print "Filename: %s " % filename
elif options.quiet:
pass
else:
print filename
else:
p.print_help()
if __name__ == '__main__':
main()
```
```
Используя ключ ––verbose, мы тем самым повышаем уровень подроб
ности информации, выводимой в поток стандартного вывода. Посмот
рим, какая информация выводится на каждом из уровней подробно
сти. Сначала нормальный уровень:
$python true_false.py /tmp
.aksusb
alm.log
amt.log
authTokenData
FLEXnet
helloworld
hsperfdata_ngift
ics10003
ics12158
ics13342
icssuis501
MobileSync.lock.f9e26440fe5adbb6bc42d7bf8f87c1e5fc61a7fe
summary.txt
```
```
Теперь в режиме подробного вывода:
```
```
$ python true_false.pyverbose /tmp
Verbose Mode Enabled
Filename: .aksusb
Filename: alm.log
Filename: amt.log
Filename: authTokenData
Filename: FLEXnet
Filename: helloworld
Filename: hsperfdata_ngift
Filename: ics10003
Filename: ics12158
Filename: ics13342
Filename: icssuis501
Filename: MobileSync.lock.f9e26440fe5adbb6bc42d7bf8f87c1e5fc61a7fe
Filename: summary.txt
```
```
Когда мы указываем ключ ––verbose, атрибут options.verbose получает
значение true, в результате чего выполняется условие и вызывается
```

**466** Глава 13. Командная строка

```
инструкция, которая выводит «Filename:» перед фактическим именем
файла. Обратите внимание, что в этом сценарии при вызове метода
p.add_option() мы определили параметры default=False и action="sto
re_true", указав тем самым, что по умолчанию этот параметр будет
иметь значение false, но если при вызове сценария будет указан ключ
––verbose, этот параметр приобретет значение true. В этом заключается
сущность использования логических параметров с модулем optparse.
```
**Шаблон подсчета числа параметров**

```
Если при использовании типичного инструмента командной строки
операционной системы UNIX, например tcpdump, указать параметр
```
- vvv, вы получите намного более подробный вывод, чем при использо
вании параметра –vv или –v. Вы можете реализовать аналогичное пове
дение, воспользовавшись такой возможностью модуля optparse, как
подсчет количества одинаковых параметров. Например, если вам по
требуется снабдить свой сценарий аналогичными уровнями подробно
сти вывода, вы могли бы сделать это, как показано в примере 13.7.

```
Пример 13.7. Шаблон с подсчетом упоминаний параметра
#!/usr/bin/env python
import optparse
import os
```
```
def main():
p = optparse.OptionParser(description="Python 'ls' command clone",
prog="pyls",
version="0.1a",
usage="%prog [directory]")
p.add_option("v", action="count", dest="verbose")
options, arguments = p.parse_args()
if len(arguments) == 1:
if options.verbose:
print "Verbose Mode Enabled at Level: %s" % options.verbose
path = arguments[0]
for filename in os.listdir(path):
if options.verbose == 1:
print "Filename: %s " % filename
elif options.verbose ==2 :
fullpath = os.path.join(path,filename)
print "Filename: %s | Byte Size: %s" % (filename,
os.path.getsize(fullpath))
else:
print filename
else:
p.print_help()
```
```
if __name__ == '__main__':
main()
```

Простые шаблоны использования optparse **467**

```
При использовании шаблона проектирования с автоматическим под
счетом упоминаний параметра мы можем на основе единственного па
раметра реализовать три варианта действий. Когда этот сценарий вы
зывается с ключом –v, атрибут options.verbose получает значение 1; ко
гда сценарий вызывается с ключом –vv, атрибут options.verbose полу
чает значение 2. Наш сценарий при вызове без ключей просто выводит
имена файлов, при вызове с ключом –v он выводит слово «Filename:»
перед каждым именем файла и, наконец, когда сценарий вызывается
сключом –vv, он выводит не только имя файла, но и его размер в бай
тах. Ниже показан результат вызова сценария с ключом –vv:
```
```
$ python verbosity_levels_count.pyvv /tmp
Verbose Mode Enabled at Level: 2
Filename: .aksusb | Byte Size: 0
Filename: alm.log | Byte Size: 1403
Filename: amt.log | Byte Size: 3038
Filename: authTokenData | Byte Size: 32
Filename: FLEXnet | Byte Size: 170
Filename: helloworld | Byte Size: 170
Filename: hsperfdata_ngift | Byte Size: 102
Filename: ics10003 | Byte Size: 0
Filename: ics12158 | Byte Size: 0
Filename: ics13342 | Byte Size: 0
Filename: ics14183 | Byte Size: 0
Filename: icssuis501 | Byte Size: 0
Filename: MobileSync.lock.f9e26440fe5adbb6bc42d7bf8f87c1e5fc61a7fe | Byte
Size: 0
Filename: summary.txt | Byte Size: 382
```
**Шаблон с вариантами значений параметра**

```
Иногда бывает необходимо предоставить несколько возможных значе
ний параметра. В нашем последнем примере мы создали параметры
––verbose и ––quiet, но точно так же мы могли бы реализовать их как
возможные варианты значений параметра ––chatty. В примере 13.8 по
казано, как выглядит версия предыдущего примера, переделанная для
использования вариантов значений.
```
```
Пример 13.8. Шаблон с вариантами значений параметра
#!/usr/bin/env python
import optparse
import os
```
```
def main():
p = optparse.OptionParser(description="Python 'ls' command clone",
prog="pyls",
version="0.1a",
usage="%prog [directory]")
p.add_option("chatty", "c", action="store", type="choice",
dest="chatty",
```

**468** Глава 13. Командная строка

```
choices=["normal", "verbose", "quiet"],
default="normal")
options, arguments = p.parse_args()
print options
if len(arguments) == 1:
if options.chatty == "verbose":
print "Verbose Mode Enabled"
path = arguments[0]
for filename in os.listdir(path):
if options.chatty == "verbose":
print "Filename: %s " % filename
elif options.chatty == "quiet":
pass
else:
print filename
else:
p.print_help()
if __name__ == '__main__':
main()
```
```
Если запустить эту команду с параметром без значения, как это дела
лось в предыдущем примере, будет получено следующее сообщение об
ошибке:
```
```
$ python choices.pychatty
Usage: pyls [directory]
```
```
pyls: error:chatty option requires an argument
```
```
Если указать в параметре ошибочный аргумент, будет получено другое
сообщение об ошибке, где будут указаны допустимые значения:
$ python choices.pychatty=nuclear /tmp
Usage: pyls [directory]
pyls: error: optionchatty: invalid choice: 'nuclear' (choose from 'normal',
'verbose', 'quiet')
```
```
Одно из удобств использования вариантов значений состоит в том, что
в этом случае сценарий не полагается на то, что подойдет любое вве
денное пользователем значение аргумента. Пользователю позволяется
выбирать только из тех значений, которые вы определите. Ниже пока
зано, как выполняется команда при запуске с допустимым значением
параметра:
$ python choices.pychatty=verbose /tmp
{'chatty': 'verbose'}
Verbose Mode Enabled
Filename: .aksusb
Filename: alm.log
Filename: amt.log
Filename: authTokenData
Filename: FLEXnet
```

Простые шаблоны использования optparse **469**

```
Filename: helloworld
Filename: hsperfdata_ngift
Filename: ics10003
Filename: ics12158
Filename: ics13342
Filename: ics14183
Filename: icssuis501
Filename: MobileSync.lock.f9e26440fe5adbb6bc42d7bf8f87c1e5fc61a7fe
Filename: summary.txt
```
```
Если вы обратили внимание, в первой строке вывода указано слово
«chatty» как ключ, а слово «verbose» как значение. В примере выше
мы добавили инструкцию print для вывода атрибута options, чтобы по
казать вам, как он выглядит с точки зрения программы. В заключение
ниже приводится пример запуска программы со значение quiet в пара
метре ––chatty:
$ python choices.pychatty=quiet /tmp
{'chatty': 'quiet'}
```
**Шаблон использования параметров**

**с несколькими аргументами**

```
По умолчанию для каждого параметра модуль optparse принимает
только один аргумент, но существует возможность определить любое
число аргументов. В примере 13.9 приводится сценарий, представ
ляющий собой еще одну версию команды ls, который может выводить
содержимое сразу двух каталогов.
```
```
Пример 13.9. Вывод содержимого двух каталогов
#!/usr/bin/env python
import optparse
import os
```
```
def main():
p = optparse.OptionParser(description="Lists contents of two directories",
prog="pymultils",
version="0.1a",
usage="%prog [dir dir1 dir2]")
p.add_option("dir", action="store", dest="dir", nargs=2)
options, arguments = p.parse_args()
if options.dir:
for dir in options.dir:
print "Listing of %s:\n" % dir
for filename in os.listdir(dir):
print filename
else:
p.print_help()
```
```
if __name__ == '__main__':
main()
```

**470** Глава 13. Командная строка

```
Если попробовать запустить этот сценарий с единственным аргумен
том параметра ––dir, будет получено следующее сообщение об ошибке:
```
```
[ngift@Macintosh8][H:10238][J:0]# python multiple_option_args.pydir /tmp "
Usage: pymultils [dir dir1 dir2]
```
```
pymultils: error:dir option requires 2 arguments
```
```
Указав требуемое число аргументов параметра ––dir, мы получили сле
дующее:
pymultils: error:dir option requires 2 arguments
[ngift@Macintosh8][H:10239][J:0]# python multiple_option_args.pydir /tmp
/Users/ngift/Music
Listing of /tmp:
.aksusb
FLEXnet
helloworld
hsperfdata_ngift
ics10003
ics12158
ics13342
ics14183
ics15392
icssuis501
MobileSync.lock.f9e26440fe5adbb6bc42d7bf8f87c1e5fc61a7fe
summary.txt
Listing of /Users/ngift/Music:
```
```
.DS_Store
.localized
iTunes
```
### командной строки на языке Python. Внедрение команд оболочки в инструменты

**командной строки на языке Python**

```
В главе 10 мы познакомились со множеством способов использования
модуля subprocess. Создание новых инструментов командной строки
путем обертывания существующих команд сценариями на языке Py
thon и изменения их API, или путем включения одной или нескольких
команд UNIX в сценарии на языке Python представляет собой весьма
интересную область для исследований. Нет ничего сложного в том,
чтобы обернуть инструмент командной строки сценарием на языке Py
thon и изменить ее поведение так, чтобы оно полнее отвечало нашим
требованиям. Можно было бы, например, интегрировать в сценарий
конфигурационный файл, в котором определить значения аргументов
для некоторых параметров или задавать в сценарии значения по умол
чанию для других аргументов. Какие бы требования не предъявля
лись, с помощью модулей subprocess и optparse можно без особых про
блем изменить поведение инструментов командной строки UNIX.
```

Внедрение команд оболочки в инструменты командной строки **471**

```
С другой стороны, смешивание инструментов командной строки со
сценарием на языке Python позволяет создавать интересные инстру
менты, которые не такто просто написать на языке C или Bash. Что
вы скажете насчет смешивания команды dd с многопоточным сценари
ем, где используются очереди, tcpdump с библиотекой регулярных вы
ражений для языка Python или использования специализированной
версии rsync? Все эти «смешанные» команды UNIX 2.0 очень напоми
нают особенности, присутствующие в Web 2.0. Смешивание Python
с утилитами UNIX приводит к появлению новых идей и к решению
проблем различными способами. В этом разделе мы исследуем некото
рые из этих приемов.
```
**Шаблон проектирования «кудзу»: обертывание**

**инструментов сценариями на языке Python**

```
Иногда используемый инструмент командной строки не совсем точно
соответствует тому, что требуется вам. Он может требовать слишком
большого числа параметров или порядок следования аргументов отли
чается от того, к которому вы привыкли. Используя язык программи
рования Python, можно очень легко изменить поведение утилиты и за
ставить ее делать именно то, что вам необходимо. Мы назвали это шаб
лоном проектирования «Кудзу». Для тех, кто не знает, поясним, что
кудзу – это быстрорастущее вьющееся растение, завезенное на юг Со
единенных Штатов из Японии. Кудзу часто поглощает естественный
ландшафт, совершенно меняя его внешний вид. С помощью языка Py
thon вы можете делать то же самое со средой UNIX.
В следующем примере мы обернули команду snmpdf сценарием на язы
ке Python, чтобы упростить ее использование. Для начала посмотрим,
как выглядит обычный запуск команды:
[ngift@Macintosh8][H:10285][J:0]# snmpdfc public v 2c example.com
Description size (kB) Used Available Used%
Memory Buffers 2067636 249560 1818076 12%
Real Memory 2067636 1990704 76932 96%
Swap Space 1012084 64 1012020 0%
/ 74594112 17420740 57173372 23%
/sys 0 0 0 0%
/boot 101086 20041 81045 19%
```
```
Для тех, кто не знаком с командой snmpdf, поясним, что она предназна
чена для удаленного выполнения в системах, обладающих поддерж
кой SNMP и настроенных для получения информации из раздела MIB,
имеющего отношение к дискам. Часто инструменты командной стро
ки, использующие протокол SNMP, обладают большим числом пара
метров, что осложняет их использование. Справедливости ради следу
ет заметить, что создатели вынуждены разрабатывать инструменты,
которые могли бы работать с версиями 1, 2 и 3 протокола SNMP, и до
полнительно разрешать целый ворох других проблем. А что, если эти
```

**472** Глава 13. Командная строка

```
проблемы к вам не относятся и к тому же вы достаточно ленивы? Вы
можете создать собственную кудзуверсию утилиты snmpdf, которая
принимает в качестве аргумента только имя машины. Без всяких со
мнений, это возможно. В примере 13.10 показано, как могла бы вы
глядеть такая утилита.
```
```
Часто, чтобы изменить поведение утилиты UNIX с помощью
языка Python, приходится писать больше строк программного
кода, чем на языке Bash. Но, несмотря на это, мы отдаем пред
почтение языку Python, потому что он позволяет использовать
более богатый набор средств для расширения инструментов под
свои нужды. Кроме того, вы можете протестировать этот про
граммный код точно так же, как вы тестируете другие свои сце
нарии, поэтому часто дополнительный программный код – это
правильный выбор в долгосрочной перспективе.
```
```
Пример 13.10. Обертка для команды snmpdf на языке Python
#!/usr/bin/env python
import optparse
from subprocess import call
```
```
def main():
p = optparse.OptionParser(description="Python wrapped snmpdf command",
prog="pysnmpdf",
version="0.1a",
usage="%prog machine")
p.add_option("c", "community", help="snmp community string")
p.add_option("V", "Version", help="snmp version to use")
p.set_defaults(community="public",Version="2c")
options, arguments = p.parse_args()
SNMPDF = "snmpdf"
if len(arguments) == 1:
machine = arguments[0]
#Измененное действие команды snmpdf
call([SNMPDF, "c", options.community, "v",options.Version, machine])
else:
p.print_help()
```
```
if __name__ == '__main__':
main()
```
```
Этот сценарий уместился примерно в двадцать строк программного ко
да, но он делает нашу жизнь намного проще. Использование волшеб
ных особенностей модуля optparse помогло предусмотреть значения по
умолчанию для некоторых аргументов, наилучшим образом соответ
ствующие нашим потребностям. Например, мы определили, что по
умолчанию будет использоваться версия 2 протокола SNMP, так как
мы знаем, что в нашем вычислительном центре используется только
эта версия протокола. Кроме того, для параметра community мы выбра
ли в качестве значения по умолчанию строку "public", потому что
```

Внедрение команд оболочки в инструменты командной строки на языке Python **473**

```
именно это значение определено в нашей лаборатории исследований
и разработки, например. Самое замечательное, что использование мо
дуля optparse позволило нам гибко изменять значения параметров, не
изменяя сам сценарий.
Обратите внимание, что значения по умолчанию устанавливаются с по
мощью метода set_default(), который позволяет одним вызовом уста
навливать сразу все значения по умолчанию аргументов инструмента
командной строки. Мы включили старые параметры, такие как –c,
и с помощью модуля optparse обернули их новыми значениями, в дан
ном случае – options.community. Хотелось бы надеяться, что этот при
мер достаточно наглядно демонстрирует, как прием «кудзу» и широ
кие возможности языка Python позволяют обернуть инструмент и из
менить его так, чтобы он полнее отвечал нашим потребностям.
```
**Шаблон проектирования «гибрид кудзу»: обертывание**

**инструментов сценариями на языке Python**

**с изменением их поведения**

```
В последнем примере мы существенно облегчили использование ути
литы snmpdf, но не изменили поведение инструмента. Оба инструмента
выводят совершенно идентичную информацию. Другой прием, кото
рый можно использовать, позволяет не только обернуть утилиту
UNIX, но и изменить ее поведение с помощью языка Python.
В следующем примере мы воспользуемся генераторами языка Python
и приемами функционального программирования, чтобы отфильтро
вать результаты нашей команды snmpdf в поисках критически важной
информации и затем добавить к ней флаг "CRITICAL". В примере 13.11
показано, как могла бы выглядеть такая утилита.
```
```
Пример 13.11. Измененная версия команды snmpdf с применением генераторов
#!/usr/bin/env python
import optparse
from subprocess import Popen, PIPE
import re
def main():
p = optparse.OptionParser(description="Python wrapped snmpdf command",
prog="pysnmpdf",
version="0.1a",
usage="%prog machine")
p.add_option("c", "community", help="snmp community string")
p.add_option("V", "Version", help="snmp version to use")
p.set_defaults(community="public",Version="2c")
options, arguments = p.parse_args()
SNMPDF = "snmpdf"
if len(arguments) == 1:
machine = arguments[0]
```

**474** Глава 13. Командная строка

```
#Вложенная функциягенератор
def parse():
"""Возвращает объектгенератор со строкой от команды snmpdf"""
ps = Popen([SNMPDF, "c", options.community,
"v",options.Version, machine],
stdout=PIPE, stderr=PIPE)
return ps.stdout
#Конвейер генераторов для поиска критических значений
pattern = "9[09]%"
outline = (line.split() for line in parse()) #удалить возвраты каретки
flag = (" ".join(row) for row in outline if re.search(pattern,
row[1]))
#поиск по шаблону и объединение соответствующих строк в список
for line in flag: print "%s CRITICAL" % line
#Пример возвращаемого значения
#Real Memory 2067636 1974120 93516 95% CRITICAL
else:
p.print_help()
```
```
if __name__ == '__main__':
main()
```
```
Запустив эту «измененную» версию команды snmpdf, мы получили сле
дующий результат на тестовой машине:
```
```
[ngift@Macintosh8][H:10486][J:0]# python snmpdf_alter.py localhost
Real Memory 2067636 1977208 90428 95% CRITICAL
```
```
Теперь у нас имеется совершенно другой сценарий, который выводит
только значения от 90 процентов и выше, обозначенные нами как кри
тические. Мы могли бы запускать этот сценарий из cron каждую ночь
для опроса нескольких сотен машин и отправлять результаты, полу
ченные от нашего сценария, по электронной почте. Кроме того, мы
могли бы расширить этот сценарий и отыскивать записи с объемом ис
пользования 80 процентов, 70 процентов и выдавать предупреждения
по достижении этих уровней. Такой сценарий легко можно было бы
объединить, например, с Google App Engine, с целью создания вебпри
ложения, выполняющего мониторинг использования дискового про
странства во всей инфраструктуре.
Рассмотрим теперь сам программный код. Здесь есть несколько мо
ментов, отличающих этот сценарий от предыдущих примеров, на ко
торых стоит остановиться. Первое отличие состоит в том, что вместо
функции subprocess.call() используется метод subprocess.Popen(). Если
вам когданибудь потребуется анализировать вывод, получаемый от
утилиты UNIX, то subprocess.Popen() – это именно то, что вам нужно.
Кроме того, обратите внимание, что мы использовали метод stdout.re
adlines(), который возвращает список строк. Это будет важно позднее,
когда эти выходные данные будут пропускаться через серию выраже
нийгенераторов.
```

Внедрение команд оболочки в инструменты командной строки на языке Python **475**

```
В разделе с конвейером генераторов мы пропускаем наш объектгене
ратор через два выражения, выполняющих поиск критических значе
ний в соответствии с заданным нами условием. Как отмечалось выше,
мы легко могли бы добавить еще пару строк с выражениямигенерато
рами, чтобы получить результаты для пороговых значений 70 и 80
процентов.
```
```
Этот инструмент, возможно, оказался немного более сложным,
чем вам хотелось бы. Возможно, лучше было бы разбить его на
несколько небольших и универсальных частей, которые можно
было бы импортировать. И всетаки этот сценарий неплохо ил
люстрирует наш пример.
```
**Шаблон проектирования «гибрид кудзу»: обертывание**

**инструментов сценариями на языке Python**

**с порождением процессов**

```
Наш последний пример был достаточно интересным, но существует еще
один интересный способ изменения поведения существующих инстру
ментов UNIX, основанный на запуске нескольких копий для повыше
ния эффективности. Конечно, это может выглядеть немного странным,
но иногда вам просто необходимо будет творчески подходить к своей
работе. Это одна из сторон профессии системного администратора, ко
гда время от времени для разрешения проблем приходится делать бе
зумные вещи.
В примере этого раздела мы создали тестовый сценарий, который соз
давал файлы образов с помощью команд dd, работающих параллельно.
Возьмем эту идею за основу и создадим инструмент командной строки,
который можно было бы использовать снова и снова. Как минимум,
получим средство создания высокой нагрузки на дисковую подсисте
му вводавывода, которое пригодится для тестирования нового файло
вого сервера. Исходный текст сценария приводится в примере 13.12.
```
```
Пример 13.12. Множественная команда dd
from subprocess import Popen, PIPE
import optparse
import sys
class ImageFile():
"""Создает файлы образов с помощью dd"""
def __init__(self, num=None, size=None, dest=None):
self.num = num
self.size = size
self.dest = dest
def createImage(self):
"""создает N идентичных файлов образов по 10 Мбайт"""
value = "%sMB " % str(self.size/1024)
```

**476** Глава 13. Командная строка

```
for i in range(self.num):
try:
cmd = "dd if=/dev/zero of=%s/file.%s bs=1024 count=%s"\
% (self.dest,i,self.size)
Popen(cmd, shell=True, stdout=PIPE)
except Exception, err:
sys.stderr.write(err)
def controller(self):
"""Запускает множество команд dd"""
p = optparse.OptionParser(description="Launches Many dd",
prog="Many dd",
version="0.1",
usage="%prog [options] dest")
p.add_option('n', 'number', help='set many dd',
type=int)
p.add_option('s', 'size', help='size of image in bytes',
type=int)
p.set_defaults(number=10,
size=10240)
options, arguments = p.parse_args()
if len(arguments) == 1:
self.dest = arguments[0]
self.size = options.size
self.num = options.number
#запуск команд dd
self.createImage()
```
```
def main():
start = ImageFile()
start.controller()
if __name__ == "__main__":
main()
```
```
Теперь при запуске нашей версии команды dd мы можем определять
размер одного файла в байтах, путь и общее число файлов/процессов.
Ниже показано, как выглядит вывод этого инструмента:
```
```
$ ./subprocess_dd.py /tmp/
$ 10240+0 records in
10240+0 records out
10485760 bytes transferred in 1.353665 secs (7746199 bytes/sec)
10240+0 records in
10240+0 records out
10485760 bytes transferred in 1.793615 secs (5846160 bytes/sec)
10240+0 records in
10240+0 records out
10485760 bytes transferred in 2.664616 secs (3935186 bytes/sec)
```
```
...дальнейший вывод опущен для экономии места....
```

Интеграция конфигурационных файлов **477**

```
Сразу же можно сказать, что этот инструмент мог бы пригодиться для
тестирования производительности дисковой подсистемы вводавывода
на высокоскоростных устройствах Fibre SAN или NAS. Приложив еще
немного усилий, можно было бы добавить функции для создания отче
тов в формате PDF и отправки результатов по электронной почте. Сле
дует отметить, что то же самое можно было бы реализовать на основе
потоков выполнения, если потоки соответствуют уровню сложности
проблемы, которую необходимо решить.
```
**Интеграция конфигурационных файлов**

```
Интеграция конфигурационных файлов в инструменты командной
строки имеет особую важность для повышения простоты использова
ния и выполнения дополнительных настроек в будущем. На первый
взгляд разговоры об удобстве использования инструментов командной
строки кажутся немного странными, потому что обычно эта тема рас
сматривается только относительно приложений с графическим интер
фейсом или вебприложений. Это несправедливо, потому что инстру
менты командной строки заслуживают такого же внимательного отно
шения к простоте и удобству использования, какое уделяется при соз
дании приложений с графическим интерфейсом.
Конфигурационный файл может также быть полезным средством для
централизованного управления инструментом командной строки, за
пускаемым на разных машинах. Доступ к разделяемому конфигура
ционному файлу можно обеспечить средствами NFS, после чего сотни
машин могли бы считывать его из универсального инструмента ко
мандной строки, созданного вами. С другой стороны, у вас может
иметься своя система управления настройками, которая также могла
бы использоваться для передачи конфигурационных файлов инстру
ментам, созданным вами.
В состав стандартной библиотеки языка Python входит замечательный
модуль ConfigParser, предназначенный для чтения и записи конфигу
рационных файлов, использующий синтаксис ini файлов. Оказывает
ся, формат .ini является прекрасным способом хранения простых кон
фигурационных данных, не требующим от человека, выполняющего
редактирование файла, использования XML и знаний языка Python.
```
```
Следует иметь в виду, что порядок следования записей в конфи
гурационном файле не имеет значения. Для представления со
держимого конфигурационного файла модуль ConfigParser ис
пользует словарь, и вы должны будете обращаться к нему соот
ветствующим образом, чтобы получить корректное отображение.
```
```
Прежде чем приступить к интегрированию конфигурационных фай
лов в инструмент командной строки, мы создадим конфигурационный
```

**478** Глава 13. Командная строка

```
файл «hello world». Создайте файл с именем hello_config.ini и добавьте
в него следующие строки:
```
```
[Section A]
phrase=Config
```
```
Теперь, когда у нас имеется простейший конфигурационный файл, мы
можем приступить к интегрированию этого файла в наш предыдущий
пример инструмента командной строки «Hello World», как показано
в примере 13.13.
```
```
Пример 13.13. Инструмент командной строки с поддержкой
конфигурационного файла
#!/usr/bin/env python
import optparse
import ConfigParser
def readConfig(file="hello_config.ini"):
Config = ConfigParser.ConfigParser()
Config.read(file)
sections = Config.sections()
for section in sections:
#раскомментируйте следующую строку, чтобы увидеть,
#как выполняется разбор конфигурационного файла
#print Config.items(section)
phrase = Config.items(section)[0][1]
return phrase
def main():
p = optparse.OptionParser()
p.add_option('sysadmin', 's')
p.add_option('config', 'c', action="store_true")
p.set_defaults(sysadmin="BOFH")
```
```
options, arguments = p.parse_args()
if options.config:
options.sysadmin = readConfig()
print 'Hello, %s' % options.sysadmin
```
```
if __name__ == '__main__':
main()
```
```
Если теперь запустить этот инструмент без какихлибо параметров,
мы получим значение по умолчанию BOFH, как и в оригинальной вер
сии программы «Hello World»:
[ngift@Macintosh8][H:10543][J:0]# python hello_config_optparse.py
Hello, BOFH
```
```
Однако, если указать параметр ––config, сценарий прочитает содержи
мое конфигурационного файла и даст такой ответ:
[ngift@Macintosh8][H:10545][J:0]# python hello_config_optparse.pyconfig
Hello, Config
```

В заключение **479**

```
В большинстве случаев вполне достаточно будет для параметра
––config использовать путь к файлу по умолчанию, но позволить
при этом прямо указывать местоположение конфигурационного
файла. Для этого вместо определения действия store_true мож
но сделать следующее:
p.add_option('config', 'c',
help='Path to read in config file')
```
```
Если бы это была более крупная и полезная программа, мы могли бы
передать ее любому пользователю, даже не знающему языка Python.
Реализованный подход позволил бы ему настраивать поведение про
граммы, изменяя значение в строке phrase=Config, без необходимости
касаться программного кода. Даже если пользователь обладает знани
ем языка Python, он будет избавлен от ввода в командной строке одних
и тех же параметров снова и снова, и при этом сохранится гибкость ин
струмента.
```
**В заключение**

```
Модули optparse и ConfigParser, входящие в состав стандартной биб
лиотеки языка Python, очень просты в работе и давно уже включены
в библиотеку, поэтому они должны быть доступны в большинстве сис
тем, с которыми вам придется сталкиваться. Если вам потребуется на
писать множество инструментов командной строки, то есть смысл ис
следовать дополнительные возможности модуля optparse, такие как
функции обратного вызова и расширение самого модуля optparse. Вам
также могут пригодиться несколько взаимосвязанных модулей, кото
рые отсутствуют в стандартной библиотеке, такие как: CommandLine
App ( http://www.doughellmann.com/projects/CommandLineApp/ ), Arg
parse ( http://pypi.python.org/pypi/argparse ) и ConfigObj ( http://pypi.py>
thon.org/pypi/ConfigObj ).
```

**14**

### Практические примеры

**Управление DNS с помощью сценариев**

**на языке Python**

Управление сервером DNS является достаточно простой задачей по
сравнению, например, с управлением конфигурационными файлами
вебсервера Apache. Программное внесение крупномасштабных изме
нений в DNS – вот настоящая проблема, способная сокрушать вычис
лительные центры и провайдеров вебхостинга. Оказывается, в соста
ве языка Python имеется модуль dnspython, который может вам приго
диться в решении подобных задач. Следует отметить, что существует
еще один модуль, имеющий отношение к DNS, – PyDNS, но мы будем
рассматривать только dnspython.

Обязательно ознакомьтесь с документацией, которую вы найдете на
сайте _[http://www.dnspython.org/](http://www.dnspython.org/)_. Кроме того, существует замечатель
ная статья об использовании модуля dnspython, которую вы найдете по
адресу _[http://vallista.idyll.org/~grig/articles/](http://vallista.idyll.org/~grig/articles/)_.

Чтобы начать использовать модуль dnspython, вам необходимо лишь
с помощью утилиты easy_install установить одноименный пакет из
каталога пакетов Python:

```
ngift@Macintosh8][H:10048][J:0]# sudo easy_install dnspython
Password:
Searching for dnspython
Reading http://pypi.python.org/simple/dnspython/
[дальнейший вывод обрезан]
```
Теперь попробуем исследовать модуль с помощью оболочки IPython
так же, как проверялись многие другие идеи в этой книге. В следую
щем примере мы извлекаем записи «A» и «MX» для имени _oreilly.com_ :


Управление DNS с помощью сценариев на языке Python **481**

```
In [1]: import dns.resolver
In [2]: ip = dns.resolver.query("oreilly.com","A")
In [3]: mail = dns.resolver.query("oreilly.com","MX")
In [4]: for i,p in ip,mail:
....: print i,p
....:
....:
208.201.239.37 208.201.239.36
20 smtp1.oreilly.com. 20 smtp2.oreilly.com.
```
```
В этом примере мы присваиваем значения записей «A» переменной ip,
а значения записей «MX» – переменной mail. Результаты, полученные
из записей «A», выведены в верхней строке, а результаты, полученные
из записей «MX», – в нижней. Теперь, когда мы получили некоторое
представление о том, как работает этот модуль, напишем сценарий,
который будет получать значения записей «A» для списка хостов.
```
```
Пример 14.1. Запрос информации для группы хостов
import dns.resolver
hosts = ["oreilly.com", "yahoo.com", "google.com", "microsoft.com", "cnn.com"]
```
```
def query(host_list=hosts):
collection = []
for host in host_list:
ip = dns.resolver.query(host,"A")
for i in ip:
collection.append(str(i))
return collection
if __name__ == "__main__":
for arec in query():
print arec
```
```
Если запустить этот сценарий, будут получены значения всех записей
«A» для указанных хостов, как показано ниже:
```
```
[ngift@Macintosh8][H:10046][J:0]# python query_dns.py
208.201.239.37
208.201.239.36
216.109.112.135
66.94.234.13
64.233.167.99
64.233.187.99
72.14.207.99
207.46.197.32
207.46.232.182
64.236.29.120
64.236.16.20
64.236.16.52
64.236.24.12
```

**482** Глава 14. Практические примеры

```
Одна очевидная проблема, которую можно решить подобным обра
зом, – программно проверить наличие корректных записей «A» для
всех хостов, имена которых присутствуют в файле.
Однако модуль dnspython способен на большее: с его помощью можно
управлять зонами DNS и выполнять более сложные запросы, чем опи
сано здесь. Если вам интересно будет рассмотреть дополнительные
примеры использования модуля, обращайтесь по адресу URL, указан
ному выше.
```
**Использование протокола LDAP для работы**

**с OpenLDAP, Active Directory и другими**

**продуктами из сценариев на языке Python**

```
LDAP – это новомодное словечко для большинства корпораций, а один
из авторов книги даже использовал базу данных LDAP для управле
ния своей домашней локальной сетью. Если вы не знакомы с LDAP,
скажем, что эта аббревиатура расшифровывается как Lightweight Di
rectory Access Protocol (облегченный протокол доступа к сетевому ка
талогу). Одно из самых удачных определений, с которыми нам прихо
дилось сталкиваться, приводится в Википедии: «прикладной прото
кол, позволяющий обращаться к службе каталогов, работающий по
верх протокола TCP/IP». В качестве примера одной из служб можно
назвать службу аутентификации, которая, безусловно, является од
ним из самых популярных применений этого протокола. Примерами
программных продуктов, поддерживающих протокол LDAP, могут
служить Open Directory, Open LDAP, Red Hat Directory Server и Active
Directory. Прикладной интерфейс pythonldap поддерживает взаимо
действие с двумя продуктами – OpenLDAP и Active Directory.
Прикладной интерфейс к LDAP в языке Python называется python
ldap и включает в себя поддержку объектноориентированной обертки
вокруг OpenLDAP 2.x. Существует также поддержка и других компо
нентов LDAP, включая средства обработки файлов LDIF и LDAPv3.
Прежде чем начать работу с этим протоколом, вам необходимо загру
зить пакет из проекта pythonldap, который находится на сайте source
forge по адресу: http://pythonldap.sourceforge.net/download.shtml.
После установки пакета pythonldap, возможно, вам потребуется сна
чала ознакомиться с библиотекой в оболочке IPython. Ниже приводит
ся протокол интерактивного сеанса, где сначала выполнена удачная
попытка подключиться к общедоступному серверу LDAP, а затем не
удачная попытка. Изучение особенностей установки и настройки
LDAP выходит далеко за рамки этой книги и, тем не менее, мы можем
начать тестировать прикладной интерфейс пакета pythonldap, ис
пользуя общедоступный сервер LDAP университета штата Мичиган.
```

Использование протокола LDAP **483**

```
In [1]: import ldap
In [2]: l = ldap.open("ldap.itd.umich.edu")
```
```
In [3]: l.simple_bind()
Out[3]: 1
```
```
Метод simple_bind() сообщает нам, что соединение выполнено успеш
но, но давайте попробуем выполнить неудачную попытку и посмот
рим, как это будет выглядеть:
In [5]: try:
....: l = ldap.open("127.0.0.1")
....: except Exception,err:
....: print err
....:
....:
In [6]: l.simple_bind()
```
```
SERVER_DOWN Traceback (most recent call last)
```
```
/root/<ipython console>
/usr/lib/python2.4/sitepackages/ldap/ldapobject.py in simple_bind(self, who,
cred, serverctrls, clientctrls)
167 simple_bind([who='' [,cred='']])> int
168 """
> 169 return self._ldap_call(self._l.simple_bind,who,cred,
EncodeControlTuples(serverctrls),EncodeControlTuples(clientctrls))
170
171 def simple_bind_s(self,who='',cred='',serverctrls=None,
clientctrls=None):
```
```
/usr/lib/python2.4/sitepackages/ldap/ldapobject.py in _ldap_call(self, func,
*args, **kwargs)
92 try:
93 try:
> 94 result = func(*args,**kwargs)
95 finally:
96 self._ldap_object_lock.release()
SERVER_DOWN: {'desc': "Can't contact LDAP server"}
```
```
Как видно из этого примера, наш программный код не нашел запу
щенный сервер LDAP и разразился ругательствами.
```
**Импортирование файла LDIF**

```
Простое подключение к общедоступному серверу LDAP не настолько
полезная операция, чтобы помочь нам в нашей работе. Ниже приво
дится пример выполнения асинхронного импорта LDIF:
```
```
import ldap
import ldap.modlist as modlist
```

**484** Глава 14. Практические примеры

```
ldif = "somefile.ldif"
def create():
l = ldap.initialize("ldaps://localhost:636/")
l.simple_bind_s("cn=manager,dc=example,dc=com","secret")
dn="cn=root,dc=example,dc=com"
rec = {}
rec['objectclass'] = ['top','organizationalRole','simpleSecurityObject']
rec['cn'] = 'root'
rec['userPassword'] = 'SecretHash'
rec['description'] = 'User object for replication using slurpd'
ldif = modlist.addModlist(attrs)
l.add_s(dn,ldif)
l.unbind_s()
```
```
В этом примере мы сначала инициализируем соединение с локальным
сервером LDAP, затем создаем объект, который будет служить проек
цией базы данных LDAP, и потребуется, когда мы будем выполнять
асинхронный импорт файла LDIF. Обратите внимание, что использо
вание метода l.add_s() указывает, что выполняется асинхронное обра
щение к прикладному интерфейсу.
Это лишь самые основы совместного использования LDAP и Python,
а за дополнительной информацией об использовании пакета python
ldap вам следует обращаться к ресурсу, указанному в начале этого раз
дела. Там, в частности, вы найдете примеры использования LDAPv3 –
Create, Read, Update, Delete (CRUD – создание, чтение, изменение
и удаление) и многие другие.
И последнее, о чем хотелось бы упомянуть: для языка Python сущест
вует инструмент с названием web2ldap, который реализует вебинтер
фейс к LDAP и разработан автором пакета pythonldap. Возможно,
у вас появится желание опробовать его наряду с другими альтернатив
ными решениями управления LDAP через вебинтерфейс. Перейдя по
адресу http://www.web2ldap.de/ , вы найдете официальную документа
цию к этому инструменту, которая очень подробно описывает под
держку LDAPv3.
```
### Составление отчета на основе файлов журналов Apache

**журналов Apache**

```
В настоящее время доля вебсервера Apache составляет примерно 50 про
центов от всех вебсерверов в Интернете. Цель следующего примера со
стоит в том, чтобы показать вам способ составления отчетов на основе
файлов журналов вебсервера Apache. В этом примере рассматривает
ся только часть информации, доступной в файлах журналов Apache,
но вы можете использовать описываемый подход для извлечения лю
бых данных, содержащихся в этих файлах журналов. Данный подход
можно легко адаптировать для работы с огромными файлами данных
и для работы с большим числом данных.
```

Составление отчета на основе файлов журналов Apache **485**

```
В главе 3 приводилось несколько примеров анализа файлов журналов
вебсервера Apache, из которых извлекалась некоторая информация.
В этом примере мы повторно воспользуемся модулями, написанными
для главы 3, чтобы продемонстрировать, как создавать удобочитаемые
отчеты из одного или более файлов журналов. Помимо обработки всех
файлов журналов, список которых определяется отдельно, вы можете
указать этому сценарию, что он должен объединить файлы журналов
и создать единый отчет. Исходный текст сценарий приводится в при
мере 14.2.
```
```
Пример 14.2. Объединенный отчет на основе файлов журналов
веб>сервера Apache
#!/usr/bin/env python
```
```
from optparse import OptionParser
def open_files(files):
for f in files:
yield (f, open(f))
```
```
def combine_lines(files):
for f, f_obj in files:
for line in f_obj:
yield line
```
```
def obfuscate_ipaddr(addr):
return ".".join(str((int(n) / 10) * 10) for n in addr.split('.'))
```
```
if __name__ == '__main__':
parser = OptionParser()
parser.add_option("c", "consolidate", dest="consolidate",
default=False,
action='store_true', help="consolidate log files")
parser.add_option("r", "regex", dest="regex", default=False,
action='store_true', help="use regex parser")
(options, args) = parser.parse_args()
logfiles = args
if options.regex:
from apache_log_parser_regex import generate_log_report
else:
from apache_log_parser_split import generate_log_report
opened_files = open_files(logfiles)
```
```
if options.consolidate:
opened_files = (('CONSOLIDATED', combine_lines(opened_files)),)
```
```
for filename, file_obj in opened_files:
print "*" * 60
print filename
print "" * 60
print "%20s%s" % ("IP ADDRESS", "BYTES TRANSFERRED")
```

**486** Глава 14. Практические примеры

```
print "" * 60
report_dict = generate_log_report(file_obj)
for ip_addr, bytes in report_dict.items():
print "%20s%s" % (obfuscate_ipaddr(ip_addr), sum(bytes))
print "=" * 60
```
```
В самом начале сценария определяются две функции: open_files()
иcombine_lines(). Позднее обе эти функции будут использоваться в ге
нераторах для упрощения программного кода. Функция open_files() –
это функциягенератор, которая принимает список (в действительно
сти – любой итерируемый объект) имен файлов. Для каждого имени
файла она создает кортеж из имени файла и соответствующего ему
объекта открытого файла. Функция combine_lines() принимает итери
руемые объекты открытых файлов в виде единственного аргумента.
Она выполняет обход объектов файлов в цикле for. Для каждого файла
выполняется обход строк в этом файле. И на каждой итерации она –
с помощью инструкции yield – возвращает очередную строку. Итери
руемый объект, получаемый от функции combine_lines(), можно срав
нить с файлом: мы можем выполнять обход строк в этом объекте.
Затем с помощью модуля optparse выполняется разбор аргументов ко
мандной строки, полученных от пользователя. Мы будем принимать
только два аргумента, оба – логического типа: признак объединения
файлов журналов и признак необходимости использовать библиотеку
регулярных выражений. Параметр consolidate сообщает сценарию,
что все файлы должны быть объединены при составлении отчета. Если
сценарию передается этот параметр, мы, в некотором смысле, выпол
няем конкатенацию содержимого файлов. Но к этому мы еще вернем
ся. Параметр regex сообщает сценарию, что вместо библиотеки «split»
следует использовать библиотеку регулярных выражений, которая
была написана нами в главе 3. Обе они предлагают идентичные функ
циональные возможности, но библиотека «split» работает быстрее.
Затем проверяется, был ли указан параметр regex. Если параметр был
указан, то импортируется модуль apache_log_parser_regex. В противном
случае используется модуль apache_log_parser_split. В действительно
сти мы включили этот параметр, чтобы сравнить производительность
двух библиотек. О производительности этого сценария мы поговорим
немного позже.
Затем вызывается функция open_files(), которой передается список
имен файлов, полученный от пользователя. Как мы уже упоминали,
функция open_files() – это функциягенератор, которая возвращает
объект файла для каждого имени во входном списке. Это означает, что
каждый файл открывается фактически, только когда функция возвра
щает соответствующий объект. Теперь, когда у нас имеется итерируе
мый объект с открытыми файлами, мы можем выполнять с ним неко
торые операции. Мы можем выполнить обход всех файлов и составить
отчет по каждому из них или объединить их некоторым способом и со
```

Составление отчета на основе файлов журналов Apache **487**

```
ставить объединенный отчет сразу по всем файлам. Это как раз то ме
сто, где на сцену выходит функция combine_lines(). Если пользователь
передал ключ «consolidate», то «список файлов», по которому будут
выполняться итерации, будет содержать единственный объект, подоб
ный файлу: генератор всех строк во всех файлах.
Далее, независимо от того, настоящие файлы содержатся в списке или
комбинированный файл, каждый из них передается соответствующей
функции generate_log_report(), которая возвращает словарь с IPадре
сами и количеством байтов, отправленных по этим адресам. Для каж
дого файла выводятся строкиразделители и отформатированные стро
ки с результатами работы функции generate_log_report(). Ниже приво
дится вывод, полученный в результате обработки одного файла журна
ла размером 28 Кбайт:
************************************************************
access.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 17479
200.80.230.0 45346
200.40.90.110 8276
130.150.250.0 0
70.0.10.140 2115
70.180.0.220 76992
200.40.90.110 23860
190.20.250.190 499
190.20.250.210 431
60.210.40.20 27681
60.240.70.180 20976
70.0.20.120 1265
190.20.250.210 4268
190.50.200.210 4268
60.100.200.230 0
70.0.20.190 378
190.20.250.250 5936
============================================================
```
```
Вывод, полученный в результате обработки трех файлов журналов
(фактически это три копии одного и того же файла, созданные путем
многократного копирования данных из оригинального файла), выгля
дит, как показано ниже:
```
```
************************************************************
access.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 17479
200.80.230.0 45346
```

**488** Глава 14. Практические примеры

```
<обрезано>
70.0.20.190 378
190.20.250.250 5936
============================================================
************************************************************
access_big.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 1747900
200.80.230.0 4534600
<обрезано>
70.0.20.190 37800
190.20.250.250 593600
============================================================
************************************************************
access_bigger.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 699160000
200.80.230.0 1813840000
<обрезано>
70.0.20.190 15120000
190.20.250.250 237440000
============================================================
```
```
А ниже приводится объединенный отчет для всех трех файлов:
************************************************************
CONSOLIDATED
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 700925379
200.80.230.0 1818419946
<обрезано>
190.20.250.250 238039536
============================================================
```
```
Итак, какова же производительность этого сценария? И каково по
требление памяти? Все тесты, которые приводятся в этом разделе, вы
полнялись на сервере Ubuntu Gutsy, с процессором Athlon 64 X2
5400+ 2.8 ГГц, с объемом ОЗУ 2 Гбайта и с жестким диском Seagate
Barracuda 7200 RPM SATA. Размер файла журнала составлял пример
но 1 Гбайт:
jmjones@ezr:/data/logs$ lsl access*log
rwrr 1 jmjones jmjones 1157080000 20080418 12:46 access_bigger.log
```
```
Ниже приводятся результаты тестирования:
```
```
$ time python summarize_logfiles.pyregex access_bigger.log
```

Составление отчета на основе файлов журналов Apache **489**

```
************************************************************
access_bigger.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 699160000
<обрезано>
190.20.250.250 237440000
============================================================
real 0m46.296s
user 0m45.547s
sys 0m0.744s
```
```
jmjones@ezr:/data/logs$ time python summarize_logfiles.py access_bigger.log
************************************************************
access_bigger.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 699160000
<обрезано>
190.20.250.250 237440000
============================================================
real 0m34.261s
user 0m33.354s
sys 0m0.896s
```
```
При использовании библиотеки, выполняющей извлечение данных
с помощью регулярных выражений, на создание отчета ушло порядка
46 секунд. При использовании версии, использующей метод string.
split(), на создание отчета ушло 34 секунды. Но показатели потребле
ния памяти оказались плачевными. Объем занятой памяти достиг
130 Мбайт. Причина в том, что функция generate_log_report() сохра
няет список переданных байтов для каждого IPадреса в файле журна
ла. Поэтому, чем больше файл, тем больший объем памяти будет по
треблять этот сценарий. Но мы можем с этим коечто сделать. Ниже
приводится менее «жадная до памяти» версия библиотеки, выполняю
щей анализ файла журнала:
```
```
#!/usr/bin/env python
def dictify_logline(line):
'''возвращает словарь, содержащий информацию, извлеченную
из комбинированного файла журнала
```
```
В настоящее время нас интересуют только адреса удаленных хостов
и количество переданных байтов, но в качестве дополнительной меры
мы добавили выборку кода состояния.
'''
split_line = line.split()
return {'remote_host': split_line[0],
'status': split_line[8],
```

**490** Глава 14. Практические примеры

```
'bytes_sent': split_line[9],
}
```
```
def generate_log_report(logfile):
'''возвращает словарь в формате:
remote_host=>[список числа переданных байтов]
Эта функция принимает объект типа file, выполняет обход всех строк
в файле и создает отчет о количестве байтов, переданных
при каждом обращении удаленного хоста к вебсерверу.
'''
report_dict = {}
for line in logfile:
line_dict = dictify_logline(line)
host = line_dict['remote_host']
#print line_dict
try:
bytes_sent = int(line_dict['bytes_sent'])
except ValueError:
##полностью игнорировать непонятные нам ошибки
continue
report_dict[host] = report_dict.setdefault(host, 0) + bytes_sent
return report_dict
```
```
Теперь подсчет общего числа переданных байтов ведется по мере из
влечения значений, а не в вызывающей функции. Ниже приводится
несколько измененная версия сценария summarize_logfiles с новым па
раметром, позволяющим импортировать библиотеку с пониженным
потреблением памяти:
```
```
#!/usr/bin/env python
from optparse import OptionParser
```
```
def open_files(files):
for f in files:
yield (f, open(f))
def combine_lines(files):
for f, f_obj in files:
for line in f_obj:
yield line
def obfuscate_ipaddr(addr):
return ".".join(str((int(n) / 10) * 10) for n in addr.split('.'))
if __name__ == '__main__':
parser = OptionParser()
parser.add_option("c", "consolidate", dest="consolidate",
default=False,
action='store_true', help="consolidate log files")
parser.add_option("r", "regex", dest="regex", default=False,
action='store_true', help="use regex parser")
parser.add_option("m", "mem", dest="mem", default=False,
```

Составление отчета на основе файлов журналов Apache **491**

```
action='store_true', help="use mem parser")
(options, args) = parser.parse_args()
logfiles = args
if options.regex:
from apache_log_parser_regex import generate_log_report
elif options.mem:
from apache_log_parser_split_mem import generate_log_report
else:
from apache_log_parser_split import generate_log_report
opened_files = open_files(logfiles)
```
```
if options.consolidate:
opened_files = (('CONSOLIDATED', combine_lines(opened_files)),)
```
```
for filename, file_obj in opened_files:
print "*" * 60
print filename
print "" * 60
print "%20s%s" % ("IP ADDRESS", "BYTES TRANSFERRED")
print "" * 60
report_dict = generate_log_report(file_obj)
for ip_addr, bytes in report_dict.items():
if options.mem:
print "%20s%s" % (obfuscate_ipaddr(ip_addr), bytes)
else:
print "%20s%s" % (obfuscate_ipaddr(ip_addr), sum(bytes))
print "=" * 60
```
```
Эти изменения привели к тому, что сценарий стал выполняться не
много быстрее, чем версия с большим потреблением памяти:
jmjones@ezr:/data/logs$ time ./summarize_logfiles_mem.pymem
access_bigger.log
************************************************************
access_bigger.log
```
```
IP ADDRESS BYTES TRANSFERRED
```
```
190.40.10.0 699160000
<snip>
190.20.250.250 237440000
============================================================
real 0m30.508s
user 0m29.866s
sys 0m0.636s
```
```
На протяжении работы этого сценария потребление памяти составило
порядка 4 Мбайт. Этот сценарий способен обрабатывать 2 Гбайтные
файлы журналов за одну минуту. Теоретически размеры файлов могут
быть неопределенно большого размера, и это не будет приводить к су
щественному увеличению объемов потребляемой памяти, как в преды
```

**492** Глава 14. Практические примеры

```
дущей версии. Однако, поскольку для хранения данных используется
словарь, каждый ключ которого – это уникальный IPадрес, потребле
ние памяти будет расти с увеличением числа уникальных IPадресов.
Если объем потребляемой памяти станет слишком велик, вы могли бы
заменить словарь какимнибудь хранилищем данных, или даже реля
ционной базой данных, такой как Berkeley DB.
```
### Зеркало FTP.

```
Следующий пример показывает, как соединяться с сервером FTP и ре
курсивно получать все файлы с этого сервера, начиная с некоторого
каталога, определяемого пользователем. Кроме того, этот сценарий
позволяет удалять файлы после того, как они были получены. Вы мо
жете задаться вопросом: «Зачем нужен такой сценарий? Разве все это
нельзя сделать с помощью rsync?». Ответ на него: «Да, это так». Одна
ко как быть, если утилита rsync отсутствует на сервере, где вы работае
те, и у вас недостаточно прав, чтобы установить ее? (Это необычно для
системного администратора, но такое тоже бывает.) Или как быть, ес
ли у вас нет доступа к серверу, откуда вы пытаетесь получить файлы,
через SSH или rsync? В таких ситуациях данный сценарий будет слу
жить альтернативой. Исходный текст сценария зеркалирования при
водится ниже:
```
```
#!/usr/bin/env python
import ftplib
import os
class FTPSync(object):
def __init__(self, host, username, password, ftp_base_dir,
local_base_dir, delete=False):
```
```
self.host = host
self.username = username
self.password = password
self.ftp_base_dir = ftp_base_dir
self.local_base_dir = local_base_dir
self.delete = delete
```
```
self.conn = ftplib.FTP(host, username, password)
self.conn.cwd(ftp_base_dir)
try:
os.makedirs(local_base_dir)
except OSError:
pass
os.chdir(local_base_dir)
```
```
def get_dirs_files(self):
dir_res = []
self.conn.dir('.', dir_res.append)
files = [f.split(None, 8)[1] for f in dir_res if f.startswith('')]
```

Зеркало FTP **493**

```
dirs = [f.split(None, 8)[1] for f in dir_res if f.startswith('d')]
return (files, dirs)
```
```
def walk(self, next_dir):
print "Walking to", next_dir
self.conn.cwd(next_dir)
try:
os.mkdir(next_dir)
except OSError:
pass
os.chdir(next_dir)
```
```
ftp_curr_dir = self.conn.pwd()
local_curr_dir = os.getcwd()
```
```
files, dirs = self.get_dirs_files()
print "FILES:", files
print "DIRS:", dirs
for f in files:
print next_dir, ':', f
outf = open(f, 'wb')
try:
self.conn.retrbinary('RETR %s' % f, outf.write)
finally:
outf.close()
if self.delete:
print "Deleting", f
self.conn.delete(f)
for d in dirs:
os.chdir(local_curr_dir)
self.conn.cwd(ftp_curr_dir)
self.walk(d)
def run(self):
self.walk('.')
if __name__ == '__main__':
from optparse import OptionParser
parser = OptionParser()
parser.add_option("o", "host", dest="host",
action='store', help="FTP host")
parser.add_option("u", "username", dest="username",
action='store', help="FTP username")
parser.add_option("p", "password", dest="password",
action='store', help="FTP password")
parser.add_option("r", "remote_dir", dest="remote_dir",
action='store', help="FTP remote starting directory")
parser.add_option("l", "local_dir", dest="local_dir",
action='store', help="Local starting directory")
parser.add_option("d", "delete", dest="delete", default=False,
action='store_true', help="use regex parser")
```
```
(options, args) = parser.parse_args()
f = FTPSync(options.host, options.username, options.password,
```

**494** Глава 14. Практические примеры

```
options.remote_dir, options.local_dir, options.delete)
f.run()
```
```
Этот сценарий выглядит проще с использованием класса. Конструктор
класса принимает несколько параметров. Чтобы соединиться с серве
ром, конструктору необходимо передать имя удаленного хоста (host),
имя пользователя (username) и пароль (password). Параметры ftp_ba
se_dir и local_base_dir передаются, чтобы переместиться в требуемые
каталоги на стороне сервера и на стороне локального компьютера. Па
раметр delete – это обычный флаг, который указывает, требуется ли
удалять файлы на удаленном сервере после их загрузки. В определе
нии конструктора видно, что этому параметру по умолчанию присваи
вается значение False.
После установки этих значений в виде атрибутов объекта выполняется
соединение с указанным сервером FTP и производится регистрация.
Затем осуществляется переход в начальный каталог на стороне серве
ра и в начальный каталог на локальном компьютере. Прежде чем вы
полнить переход в требуемый каталог на локальном компьютере, сце
нарий сначала пытается создать его. Если каталог уже существует, бу
дет получено исключение OSError, которое игнорируется сценарием.
В классе определяются три дополнительных метода: get_dirs_files(),
walk() и run(). Метод get_dirs_files() определяет, какие файлы нахо
дятся в текущем каталоге и какие из них являются обычными файла
ми, а какие каталогами. (К слову сказать, такой способ будет работать
только в случае сервера, работающего под управлением UNIX.) Опре
деление, какие из файлов являются обычными файлами, а какие ката
логами, производится по первому символу в строках полученного спи
ска. Если первый символ d, значит, – это каталог. Если первый символ
‘–’, значит, – это файл. Благодаря этому сценарий не будет следовать
за символическими ссылками или заниматься обработкой блочных
устройств.
Следующий метод, который определен в классе, – это метод walk().
В этом методе выполняется вся основная работа. Метод walk() прини
мает единственный параметр: следующий каталог, который требуется
посетить. Прежде чем двинуться дальше, напомним, что это рекурсив
ная функция. Она будет вызывать саму себя. Если какойлибо каталог
содержит другие каталоги, метод walk() также обойдет их. Метод
walk() сначала переходит в указанный каталог на стороне сервера. За
тем выполняется переход в одноименный каталог на локальном ком
пьютере, при этом, в случае необходимости, каталог создается. Потом
текущая позиция на сервере FTP и на локальном компьютере сохраня
ется в переменных ftp_curr_dir и local_curr_dir для последующего ис
пользования. Далее с помощью метода get_dirs_files(), о котором уже
говорилось выше, производится получение списков файлов и катало
гов. Загрузка каждого файла в каталоге производится с помощью ме
тода FTP retrbinary(). Кроме того, если был установлен флаг delete,
```

Зеркало FTP **495**

```
выполняется удаление файла. Затем выполняется переход в текущие
каталоги на стороне сервера FTP и на локальном компьютере и вызы
вается метод walk() для обхода нижележащих каталогов. Переход в те
кущие каталоги выполняется для того, чтобы при возвращении из ре
курсивных вызовов метода walk() мы оказались в том же самом месте,
где и были.
Последний метод, который определен в классе, – это метод run(). Ме
тод run() создан исключительно для удобства. Он просто вызывает ме
тод walk() и передает ему текущий каталог FTP.
В сценарии предусмотрена только самая необходимая обработка оши
бок и исключительных ситуаций. Вопервых, сценарий не проверяет
правильность аргументов командной строки и поэтому пользователь
должен обеспечить передачу, по крайней мере, трех параметров – име
ни удаленного хоста, имени пользователя и пароля. Если какойлибо
из этих параметров будет отсутствовать, сценарий очень быстро завер
шится с сообщением об ошибке. Кроме того, если произошло исключе
ние, сценарий не повторяет попытку загрузить файл. То есть, если
чтото будет препятствовать загрузке файла, мы получим исключение,
и работа программы на этом завершится. Если сценарий завершит ра
боту на полпути, во время загрузки файлов, то при следующем запуске
сценарий повторно загрузит файлы, которые уже были загружены.
В такой реализации есть свой плюс, который состоит в том, что если
файл был загружен только частично, он не будет удален на стороне
сервера.
```

### Приложение

### Приложение. Функции обратного вызова

Концепция функций обратного вызова и передачи функций в виде па
раметров может оказаться вам незнакомой. Если это так, то вам опре
деленно стоит углубиться в ее изучение, чтобы понять ее достаточно
хорошо для применения на практике или, по крайней мере, настоль
ко, чтобы понимать, что происходит в сценарии, когда вы будете
встречать ее. В языке Python функции являются «обычными» объек
тами, то есть вы можете передавать их и обращаться с ними как с объ
ектами, потому что они действительно являются объектами. Рассмот
рим пример 1.

_Пример 1. Функции – типичные объекты_

```
In [1]: def foo():
...: print foo
...:
...:
```
```
In [2]: foo
Out[2]: <function foo at 0x1233270>
```
```
In [3]: type(foo)
Out[3]: <type 'function'>
```
```
In [4]: dir(foo)
Out[4]:
['__call__',
'__class__',
'__delattr__',
'__dict__',
'__doc__',
'__get__',
'__getattribute__',
'__hash__',
'__init__',
'__module__',
'__name__',
'__new__',
'__reduce__',
'__reduce_ex__',
```

Функции обратного вызова **497**

```
'__repr__',
'__setattr__',
'__str__',
'func_closure',
'func_code',
'func_defaults',
'func_dict',
'func_doc',
'func_globals',
'func_name']
```
```
Простое обращение к функции, такой как foo из предыдущего приме
ра, не приводит к ее вызову. Ссылаясь на имя функции, можно полу
чать значения любых атрибутов функции, которые она имеет, и даже
обращаться к функции по другому имени, как показано в примере 2.
```
```
Пример 2. Обращение к функции по имени
In [1]: def foo():
...: """это строка документирования"""
...: print "IN FUNCTION FOO"
...:
...:
In [2]: foo
Out[2]: <function foo at 0x8319534>
In [3]: foo.__doc__
Out[3]: 'this is a docstring'
```
```
In [4]: bar = foo
In [5]: bar
Out[5]: <function foo at 0x8319534>
```
```
In [6]: bar.__doc__
Out[6]: 'this is a docstring'
In [7]: foo.a = 1
```
```
In [8]: bar.a
Out[8]: 1
In [9]: foo()
IN FUNCTION FOO
```
```
In [10]: bar()
IN FUNCTION FOO
```
```
Здесь была создана новая функция foo, так чтобы она содержала стро
ку документирования. После этого мы заявили, что переменная bar бу
дет указывать на только что созданную функцию foo. В языке Python
то, что вы привыкли считать переменными, в действительности явля
ется просто именами, указывающими (или ссылающимися) на некото
рые объекты. Процесс присваивания имени объекту называется «свя
зыванием имени». Поэтому, когда мы создали функцию foo, на самом
```

**498** Приложение

```
деле мы создали объект функции, а затем связали его с именем foo.
Воспользовавшись интерактивной оболочкой IPython, чтобы получить
основную информацию об имени foo, мы получили сообщение о том,
что это функция foo. Интересно то, что оболочка сказала то же самое
и об имени bar, а именно, что это функция foo. Мы установили значе
ние атрибута функции foo и сумели обратиться к нему с помощью име
ни bar. А вызов по именам foo и bar дал одинаковые результаты.
Одно из мест в этой книге, где мы используем функции обратного вы
зова, – это глава 5 «Сети». Передача функций в качестве параметров,
как это сделано в указанной главе в примере, демонстрирующем ис
пользование модуля ftplib, обеспечивает высокий динамизм во время
выполнения и гибкость во время разработки и может даже расширять
возможности повторной используемости программного кода. Даже ес
ли вы полагаете, что вам никогда не придется использовать функции
обратного вызова, сама перестройка процесса мышления при добавле
нии этих знаний к вашему мыслительному арсеналу представляет
большую ценность.
```

### Алфавитный указатель

**Специальные символы**

\ (символ обраного слеша),
экранированные последовательности,
105
! (восклицательный знак), выполнение
команд системной оболочки, 64
!! (два восклицательных знака),
выполнение команд системной
оболочки, 65
%quickref, команда, 59
%TAB, последовательность, 58
' (апостроф), создание строк, 103
? (вопросительный знак), получение
справки, 34, 58
_ (символ подчеркивания)
в именах переменных, 67
__, (два символа подчеркивания),
объект, 88
___, (три символа подчеркивания),
объект, 88

**A**

Active Directory, использование из
сценариев на языке Python, 482
alias, функция (специальная), 61, 95
Apache, сервер
анализ журналов (пример), 146
работа с конфигурационным файлом
(пример), 131
appscript, проект, 294
ARP, протокол, 271
asr, утилита, 296
attrib, атрибут (ElementTree), 155

**B**

bookmark, функция (специальная), 69
Boto (вебслужбы Amazon), 301

```
Buildout, инструмент, 335
разработка с использованием, 339
bzip2, алгоритм сжатия, 248
```
```
C
call(), функция (subprocess), 351
cd, функция (специальная), 68
close(), метод, 136
close(), метод (shelve), 434
close(), функция (модуль socket), 187
cmp(), функция, 231
ConfigParser, модуль, 477
connect(), метод (модуль ftplib), 197
connect(), функция (модуль socket), 187
__contains__(), оператор, 107
cPickle, библиотека, 433
cron
запуск процессов, 382
```
```
D
.deb, пакеты, 47
dhist, функция (специальная), 71
dircmp(), функция (модуль filecmp), 231
distutils, 314, 332
Django, платформа разработки веб
приложений, 404
приложение базы данных, создание
(пример), 413
dnspython, модуль, 480
DOM (Document Object Model –
объектная модель документа), 154
drawString(), метод (ReportLab), 178
DSCL (Directory Services Command
Line – командная строка службы
каталогов), 293
```

**500** Алфавитный указатель

**E**

easy_install, модуль, 315
дополнительные особенности, 318
easy_install, утилита, 48
edit, функция (специальная), 55
.egg, файлы (пакеты), 48
eggs, формат
для управления пакетами, 314, 324
преобразование отдельного файла .py
в пакет, 322
ElementTree, библиотека, 153
email, пакет, 181
end(), метод, 130
endswith(), метод, 109
__enter__(), метод, 136
EPM, менеджер пакетов, 344
exec_command(), метод, 207
__exit__(), метод, 136

**F**

fields(), метод, 75
file, объект, создание, 135
filecmp, модуль, 230
find(), метод, 108
find(), метод (ElementTree), 155
findall(), метод, 121, 125, 126
findall(), метод (ElementTree), 155
finditer(), метод, 126
fnmatch, модуль, 239
fork(), метод, 385
FTP, зеркало, 492
ftplib, модуль, 195

**G**

gdchart, модуль, 174
get(), метод (ElementTree), 155
getresponse(), метод (модуль httplib), 195
glob, модуль, 239
GNU/Linux, операционная система
PyInotify, модуль, 291
администрирование систем Red Hat
Linux, 298
администрирование систем Ubuntu,
299
управление серверами Windows
из Linux, 309
Google App Engine, 302
grep(), метод, 74
groupdict(), метод, 130

```
groups(), метод, 130
gzip, сжатие, 248
```
```
H
HardwareComponent, класс, 415
HBox (PyGTK), 397
hist, функция, 91
HTML, получение из формата ReST, 169
httplib, модуль, 193
```
```
I
IMAP, протокол, 161
imaplib, модуль, 162
import, инструкция, 39
In, встроенная переменная, 52, 53
in, оператор, 107
index(), метод, 108
__IP, переменная, 66
IPAddress, класс (Django), 417
ipy_user_conf.py, файл, 56
IPython, интерактивная оболочка, 45, 48
edit, функция (специальная), 55
автоматизация и сокращения, 95
взаимодействие с IPython, 49
возможность дополнения, 54
загрузка и установка, 29, 46
история команд, 90
настройка, 56
сбор информации, 81
.ipython, каталог, 56
IPython, сообщество пользователей, 45
```
```
J
join(), метод, 116
```
```
L
LDAP, использование из сценариев на
языке Python, 482
LDIF файлы, импортирование, 483
listdir(), функция (модуль os), 232
lower(), метод, 113
ls(), функция (Scapy), 217
lsmagic, функция (специальная), 57
lstrip(), метод, 110
```
```
M
macro, функция (специальная), 95
magic, функция (специальная), 58
```

Алфавитный указатель **501**

match(), метод, 126
mglob, команда, 80
MIB (Management Information Base –
база управляющей информации), 253
MVC (ModelViewController – модель
представлениеконтроллер), 405
MVT (ModelViewTemplate – модель
представлениешаблон), 405

**N**

\n, символ новой строки, 105
__name__, переменная, 88
NetSNMP, 255, 256
исследование центра обработки
данных
получение множества значений,
263
расширение возможностей, 271
установка и настройка, 254
NetSNMP, библиотека, 254
not in, оператор, 107

**O**

OID (идентификаторы объектов), 253
open(), метод, 135
open(), метод (shelve), 434
OpenLDAP, использование из сценариев
на языке Python, 482
OperatingSystem, класс (Django), 417
optparse, модуль, 462
os, модуль, 222
listdir(), функция, 232
remove(), метод, 235
копирование, перемещение,
переименование и удаление, 224
пути, каталоги и файлы, 226
OSA (Open Scripting Architecture –
открытая архитектура сценариев), 294
Out, встроенная переменная, 53

**P**

page, функция (специальная), 81
paramiko, библиотека, 206, 208
parse(), метод (ElementTree), 154
pdef, функция (специальная), 82
PDFфайлы, сохранение данных, 178
pdoc, функция (специальная), 82
Perspective Broker (брокер
перспективы), механизм, 213

```
Pexpect, инструмент, 275
pfile, функция (специальная), 82
pickle, модуль, 428
pinfo, функция (специальная), 83
platform, модуль, 279
Plist управление файлами, 298
Plone, система управления
содержимым, 336
POP3, протокол, 161
Popen(), функция (subprocess), 351
Popen(), функция (модуль subprocess),
368
poplib, модуль, 162
print, инструкция, 51
processing, модуль, 379
psearch, функция (специальная), 86
psource, функция (специальная), 85
pwd, функция (специальная), 72
pyappscript, проект, 294
PyDNS, модуль, 480
PyGTK, приложения
простое приложение (пример), 392
PyInotify, модуль для GNU/Linux, 291
Pyro, платформа, 202
PySNMP, библиотека, 254
pysysinfo, модуль, 39
Python Package Index, каталог пакетов
Python, 330
Python
мотивация к использованию, 28
простота в изучении, 28
пакеты, 48
сообщество пользователей, 45
стандартная библиотека языка, 26
pythonldap, модуль, 482
pythonreportlab, пакет, 178
pythontextile, пакет, 172
```
```
R
re, модуль, 120
read(), метод, 135, 137
readline(), метод, 137
readlines(), метод, 137
rec, директива, 80
recv(), функция (модуль socket), 187
rehash, функция (специальная), 65
rehashx, функция (специальная), 67
remove(), метод (модуль os), 235
rep, функция (специальная), 98
replace(), метод, 117
```

**502** Алфавитный указатель

ReportLab, библиотека, 178
__repr__, представление строк, 106
request(), метод (модуль httplib), 195
reset, функция (специальная), 97
ReST (reStructuredText) формат, 169, 330
преобразование в формат HTML, 169
ReSTless, утилита, 330
retbinary(), метод (модуль ftplib), 197
rstrip(), метод, 110
rsync, утилита, 241, 492
run, функция (специальная), 97

**S**

s, атрибут, 76
save, функция (специальная), 98
save(), метод (ReportLab), 178
SAX, simple API for XML (простой
прикладной интерфейс для работы
с форматом XML), 153
Scapy, программа, 216
создание сценариев, 219
screen, приложение, 364
search(), метод, 126
search(), метод (imaplib), 163
send(), функция (модуль socket), 187
Server, класс (Django), 417
Service, класс (Django), 417
setuptools, библиотека, 314
easy_install, модуль
дополнительные особенности, 318
точки входа, 329
SFTP (Secure FTP), 208
sh, профиль, 77
shelve, модуль, 160, 174, 434
showPage(), метод (ReportLab), 178
shutil, модуль
копирование дерева данных
(пример), 224
перемещение дерева данных
(пример), 225
удаление дерева данных (пример),
226
SMTP, аутентификация, 181
smtplib, пакет, 180
SNMP, протокол, 252
NetSNMP, 254, 256
расширение возможностей Net
SNMP, 271
SNMP, протокол, 252
гибридные инструменты SNMP, 270

```
интеграция в сеть предприятия
с помощью Zenoss, 276
исследование центра обработки
данных, 260
получение множества значений,
263
управление устройствами, 275
установка и настройка, 254
snmpstatus, инструмент, 270
socket, модуль, 186
socket(), функция (модуль socket), 187
span(), метод, 130
split(), метод, 113
splitlines(), метод, 115
SQLAlchemy, 244
SQLAlchemy ORM, 456
SQLite, библиотека, 449
SSH, протокол, 206
start(), метод, 130
startswith(), метод, 109
starttls(), метод, 182
store, функция (специальная), 97
Storm ORM, 452
__str__, представление строк, 106
str, тип, 103
StringIO, модуль, 143
strip(), метод, 110
subprocess модуль, 350
subprocess, модуль, 32
subprocess.call, 31, 32
Supervisor, уилита, 361
sys, модуль, 141
sys.argv, атрибут, 460
sysDescr OID, 253, 257
system_profiler, утилита, 156
```
```
T
tag, атрибут (ElementTree), 155
tar, утилита, 246
tarfile, модуль, 246
text, атрибут (ElementTree), 155
textile, модуль, 172
time, утилита (UNIX), 123
timeit(), функция, 122
Trac, вики (wiki), 184
Trac, система отслеживания проблем,
184
Twisted, платформа, 209
TwistwdSNMP, библиотека, 254
```

Алфавитный указатель **503**

**U**

UDP порты для работы с SNMP, 252
upper(), метод, 113
urllib, модуль, 145, 197
urllib2, модуль, 199

**V**

VBox (PyGTK), 397
virtualenv, инструмент, 339
VMware, 300

**W**

web2ldap, инструмент, 484
who, функция (специальная), 88
who_ls, функция (специальная), 88
whos, функция (специальная), 89
with, инструкция, 136
wrapper(), функция (curses), 401
write(), метод, 136, 139
writelines(), метод, 139

**X**

XMLRPC, 200

**Y**

YAML, формат данных, 437

**Z**

Zenoss API, 254
управление серверами Windows из
Linux, 309
Zenoss, прикладной интерфейс, 276
ZODB, модуль, 441

**А**

Аарон Хиллегасс (Aaron Hillegass), 164
автоматизация и сокращения, 95
автоматизация пересоздания
раздела, 296
автоматизированный сбор
информации, 160
автоматизированный прием
электронной почты, 161
автоматическое восстановление
системы, 296
администрирование
Red Hat Linux, 298

```
Solaris, 299
Ubuntu, 299
активная версия пакета, изменение, 322
анализ журналов, 146
апострофы, создание строк, 103
архивирование данных, 246
проверка содержимого файлов TAR,
249
аутентификация
при установке пакетов, 323
по протоколу SMTP, 181
```
```
Б
блоки программного кода,
редактирование, 55
брокер перспективы (Perspective
Broker), механизм, 213
```
```
В
ввод
стандартный ввод и вывод, 140
вебприложения, создание, 403
вебслужбы Amazon на основе Boto, 301
взаимодействие с IPython, 49
взаимодействия между процессами, 199
Вилле Вайнио (Ville Vainio), 47
виртуализация, 300
виртуальные окружения, собственные,
342
вложения (электронная почта),
отправка, 183
внедрение команд оболочки
в инструменты командной строки
на языке Python, 470
восстановление данных, 246
вывод
стандартный ввод и вывод, 140
вывод результатов в IPython и в Python,
52
вызов удаленных процедур, 199
Pyro, платформа, 202
XMLRPC, 200
выполнение инструкций, 30
выполнение системных команд, 64
```
```
Г
генератор объект, 228
гибридные инструменты SNMP
(создание), 270
```

**504** Алфавитный указатель

гистограмма, создание, 174
графический интерфейс, создание, 390
Django, платформа разработки веб
приложений, 404
вебприложения, 403
приложение базы данных (пример),
413
приложение для просмотра файла
журнала вебсервера Apache
с помощью curses, 398
с помощью Django, 405
с помощью PyGTK, 394
пример (простое приложение
PyGTK), 392
теория, 390

**Д**

данные, 221
os, модуль, 222
rsync, утилита, 241
архивирование, сжатие,
отображение и восстановление, 246
копирование, перемещение,
переименование и удаление, 224
метаданные, 244
объединение данных, 233
поиск шаблону, 239
пути, каталоги и файлы, 226
сравнение, 230
демоны, 384
дерево данных
копирование с помощью модуля
shutil (пример), 224
перемещение с помощью модуля
shutil (пример), 225
удаление с помощью модуля shutil
(пример), 226
деревья каталогов
переименование файлов, 240
поиск дубликатов, 235
синхронизация с помощью утилиты
rsync, 241
Джим Фултон (Jim Fulton), 335
диаграммы, создание, 174
дополнение, функция, 54

**З**

заголовки определений, вывод, 82
загрузка IPython, 29, 46
задержка выполнения потоков, 376

```
запись в файлы, 139
запуск
демона, 384
команд командной оболочки, 31
зеркало FTP, 492
```
```
И
идентификаторы объектов (OID), 253
извлечение данных из строк, 107
поиск внутри строки, 107
извлечение среза строки, 109
изменение регистра символов, 113
импортирование
модулей, 31, 32
файла LDIF, 483
инвентаризация множества
компьютеров, 263
интеграция конфигурационных файлов,
477
исследование центра обработки данных,
260
получение множества значений, 263
история команд, 90
история результатов, 93
```
```
К
кавычки, создание строк, 103
каталог NFS с исходными текстами, 283
каталог пакетов Python (Python Package
Index, PyPI), 26
каталоги
архивирование, 246
обход с помощью модуля os, 226
объединение деревьев каталогов, 233
поиск по шаблону, 239
синхронизация с помощью утилиты
rsync, 241
сравнение с помощью модуля
filecmp, 230
текущий, идентификация
с помощью pwd, 72
установка распакованного
дистрибутива с исходными
текстами в, 321
Кевин Гиббс (Kevin Gibbs), 302
ключи ssh, 282
коды возврата, использование
с помощью модуля subprocess, 352
команд история, 90
```

Алфавитный указатель **505**

командная оболочка UNIX, 61
! (восклицательный знак), 65
!! (два восклицательных знака), 65
alias, функция, 61
bookmark, функция, 69
cd, функция, 68
dhist, функция, 71
pwd, функция, 72
rehash, функция, 65
rehashx, функция, 67
sh, профиль, 77
выполнение системных команд, 64
обработка строк, 73
подстановка переменных, 72
командная строка, 459
ConfigParser, модуль, 477
optparse, модуль, 462
внедрение команд оболочки, 470
интеграция конфигурационных
файлов, 477
основы использования потока
стандартного ввода, 460
конкатенация строк, 116
конфигурационные файлы, при
установке пакетов, 323
конфликты между пакетами,
устранение, 339
кроссплатформенное
администрирование систем, 285
кроссплатформенное
программирование на языке Python
в UNIX, 279
круговая диаграмма, создание, 175

**М**

менеджеры контекста, 136
метаданные, 244
многозадачность
и потоки выполнения, 365
и процессы, 378
многострочный текст, 104
разбиение на отдельные строки, 115
модули
импортирование, 31, 32
мотивация к использованию Python, 28

**Н**

настройка IPython, 56
неформатированные строки, 105
в регулярных выражениях, 124

```
нумерованные строки приглашения
к вводу, 50
```
```
О
обертки, 31
импортирование сценариев, 31
обертывание инструментов командной
строки сценариями на языке Python,
470
облачная обработка данных (cloud
computing), 301
вебслужбы Amazon на основе Boto,
301
обновление пакетов, 319
обработка событий в потоке, 377
обработка строк, 73
обработчики событий, 391
обход дерева MIB, 258
объединение в строку, 116
объединение данных, 233
объектнореляционная проекциея
(ObjectRelational Mapping, ORM), 452
объекты управления (в MIB), 253
операционные системы, 278
OS X, 293
PyInotify, модуль для GNU/Linux,
291
администрирование систем
Red Hat Linux, 298
Solaris, 299
Ubuntu, 299
виртуализация, 300
кроссплатформенное
программирование на языке
Python в UNIX, 279
облачная обработка данных (cloud
computing), 301
управление серверами Windows из
Linux, 309
определение типа операционной
системы, 280, 285
основы Python, 29
выполнение инструкций, 30
повторное использование
программного кода, 39
функции, 35
основы использования потока
стандартного ввода, 460
открытый ключ ssh, создание, 282
отображение данных, 246
```

**506** Алфавитный указатель

отступы в языке Python, 35
очереди, потоки выполнения, 370

**П**

пакеты
сторонних производителей, 26
установка в файловую систему, 319
передача электронной почты, 180
переименование файлов в деревьях
каталогов, 240
перемещение файлов
с помощью утилиты rsync, 241
пересоздание раздела, 296
планирование запуска процессов, 382
повторное использование программного
кода, 39
погонщик данных, 222
поддержка readline, 90
подстановка переменных, 72
поиск
внутри строк, 107, 117
и регулярные выражения, 120
дубликатов в объединяемых
каталогах, 235
объемов памяти (пример), 265
файлов и каталогов по шаблону, 239
потоки выполнения, 365
приглашение к вводу в IPython
ивPython, 52
прием электронной почты, 161
приложение базы данных, создание
с помощью Django (пример), 413
приложение для просмотра файла
журнала вебсервера Apache
с помощью curses, 398
с помощью Django, 405
с помощью PyGTK, 394
проверка порта (пример), 188
с использованием Twisted, 211
с использованием модуля socket, 188
программирование для OS X, 293
простая сериализация, 428
pickle, модуль, 428
shelve, модуль, 434
YAML, формат данных, 437
ZODB, модуль, 441
сPickle, библиотека, 433
простота языка Python, 28
профили, 77

```
процессы, 350, 378
subprocess модуль, 350
использование кодов возврата,
352
демоны, 384
и многозадачность, 378
планирование запуска, 382
потоки выполнения, 365
управление с помощью программы
screen, 364
управление с помощью программы
Supervisor, 361
```
```
Р
разбор XML с помощью библиотеки
ElementTree, 153
разделители, разбиение строк, 113
распространение информации, 180
отправка вложений электронной
почты, 183
передача электронной почты, 180
регулярные выражения, 120
и неформатированные строки, 124
резервное копирование, 222
проверка содержимого файлов TAR,
249
результатов история, 93
реляционная сериализация, 448
SQLAlchemy ORM, 456
SQLite, библиотека, 449
Storm ORM, 452
ручной сбор информации, 163
```
```
С
сайты, защищенные паролем, установка
пакетов, 323
сбор информации, 81
автоматизированный, 160
вручную, 163
прием электронной почты, 161
связывание имен, 497
сериализация
простая, 428
pickle, модуль, 428
shelve, модуль, 434
YAML, формат данных, 437
ZODB, модуль, 441
сPickle, библиотека, 433
реляционная, 448
SQLAlchemy ORM, 456
```

Алфавитный указатель **507**

SQLite, библиотека, 449
Storm ORM, 452
сетевые приложения, управляемые
событиями, 209
сети, 186
ftplib, модуль, 195
httplib, модуль, 193
Scapy, программа, 216
создание сценариев, 219
socket, модуль, 186
SSH, протокол, 206
Twisted, платформа, 209
urllib, модуль, 197
urllib2, модуль, 199
вызов удаленных процедур
Pyro, платформа, 202
XMLRPC, 200
сетевые клиенты, 186
сжатие данных, 246
символ вопросительного знака (?),
получение справки, 34
синхронизация каталогов с помощью
утилиты rsync, 241
скомпилированное регулярное
выражение, 121
сложные задачи, решение на языке
Python, 22
соглашения по именованию
два символа подчеркивания, 67
создание документации и отчетов, 159
автоматизированный сбор
информации, 160
прием электронной почты, 161
распространение информации, 180
отправка вложений электронной
почты, 183
передача электронной почты, 180
сбор информации вручную, 163
форматирование информации, 174
сохранение в виде файлов PDF,
178
создание собственных виртуальных
окружений, 342
сообщество пользователей Python, 25,
45
составление отчета на основе файлов
журналов Apache, 484
сохранность данных, 427
простая сериализация, 428
pickle, модуль, 428
shelve, модуль, 434

```
YAML, формат данных, 437
ZODB, модуль, 441
сPickle, библиотека, 433
реляционная сериализация, 448
SQLAlchemy ORM, 456
SQLite, библиотека, 449
Storm ORM, 452
специальные функции, 56
alias, 61, 95
bookmark, 69
cd, 68
dhist, 71
edit, 55
lsmagic, 57
macro, 95
magic, 58
page, 81
pdef, 82
pdoc, 82
pfile, 82
pinfo, 83
psearch, 86
psource, 85
pwd, 72
rehash, 65
rehashx, 67
rep, 98
reset, 97
run, 97
save, 98
store, 97
who, 88
who_ls, 88
whos, 89
справка
%quickref, команда, 59
знак вопроса (?), 58
по специальным функциям, 56
справочная документация
символ вопросительного знака (?), 34
сравнение данных, 230
содержимое файлов и каталогов, 230
сравнение контрольных сумм, 233
сравнение контрольных сумм, 233
сравнение строк
upper() и lower(), методы, 113
стандартная библиотека, 26
стандартный ввод и вывод, 140
стандартный вывод, подавление, 351
```

**508** Алфавитный указатель

строки, 103
Apache, анализ журналов (пример),
146
Apache, работа с конфигурационным
файлом (пример), 131
извлечение данных
поиск внутри строки, 107
изменение регистра символов, 113
неформатированные строки, 105, 124
объединение (конкатенация), 116
поиск внутри строки, 107
регулярные выражения, 120
разбиение по символам
разделителям, 113
создание (тип str), 103
создание (Юникод), 118
строки Юникода, 118
удаление ведущих и завершающих
пробельных символов, 110
удаление содержимого, 110
строковое представление, 51
сценарии консоли, 329

**Т**

таблица псевдонимов, 65, 67
таймер внутри потока, 376
текстовые файлы
работа с файлами, 134
анализ журналов, 146
запись в файлы, 139
разбор XML с помощью
библиотеки ElementTree, 153
чтение из файлов, 137
создание файлов, 135
текущий каталог
идентификация, 72
текущий рабочий каталог, установка
дистрибутива с исходными
текстами в, 321
теневая история, 93
точки входа, 329
тройные кавычки, 104

**У**

удаление
ведущих и завершающих
пробельных символов в строках,
110
закладок, 70

```
переменных из интерактивного
пространства имен, 97
содержимого строки, 110
сохраняемых переменных, 97
файлов, 235
управление DNS с помощью сценариев
на языке Python, 480
управление пакетами, 313
Buildout, инструмент, 335
EPM, менеджер пакетов, 344
virtualenv, инструмент, 339
регистрация пакета в Python Package
Index, 330
создание пакетов с помощью
distutils, 332
управление серверами Windows из
Linux, 309
управление устройствами через SNMP,
275
управляющий сценарий, на основе ssh,
284
условные инструкции
в Perl и Bash, 23
установка IPython, 29, 46
установка пакетов в файловую систему,
319
```
```
Ф
файлы
архивирование, 246
метаданные, 244
обход с помощью модуля os, 226
объединение деревьев каталогов, 233
переименование в деревьях
каталогов, 240
поиск по шаблону, 239
работа с файлами, 134
анализ журналов, 146
запись в файлы, 139
разбор XML с помощью
библиотеки ElementTree, 153
чтение из файлов, 137
создание файлов, 135
сравнение с помощью модуля
filecmp, 230
удаление, 235
Фернандо Перез (Fernando Perez), 46
фоновый режим, 259
форматирование информации, 174
сохранение в виде файлов PDF, 178
```

Алфавитный указатель **509**

функции, 35
функции обратного вызова, 496
функция автодополнения, 33

**Ч**

чтение из файлов, 137

**Ш**

шаблоны использования optparse
True/False, 464
без ключей, 462
подсчета числа параметров, 466
с вариантами значений параметра,
467
с несколькими аргументами, 469
шаблон проектирования «гибрид кудзу»
обертывание инструментов
сценариями на языке Python
с изменением их поведения, 473
обертывание инструментов
сценариями на языке Python
с порождением процессов, 475
шаблон проектирования «кудзу», 471
обертывание инструментов
сценариями на языке Python, 471
обертывание инструментов
сценариями на языке Python
с изменением их поведения, 473
обертывание инструментов
сценариями на языке Python
с порождением процессов, 475

**Э**

экранированные последовательности,
105
электронная почта
(входящая), обработка, 161
(исходящая), запись, 180
отправка вложений, 183

**Я**

Ян Байкинг (Ian Bicking), 340


По договору между издательством «СимволПлюс» и Интернетмага
зином «Books.Ru – Книги России» единственный легальный способ
получения данного файла с книгой ISBN 9785932861493, назва
ние «Python в системном администрировании UNIX и Linux» – по
купка в Интернетмагазине «Books.Ru – Книги России». Если Вы по
лучили данный файл какимлибо другим образом, Вы нарушили
международное законодательство и законодательство Российской
Федерации об охране авторского права. Вам необходимо удалить
данный файл, а также сообщить издательству «СимволПлюс»
(piracy@symbol.ru), где именно Вы получили данный файл.
