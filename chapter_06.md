# Глава 6. Данные

**Введение**

Управление данными, файлами и каталогами – это одна из причин, по
которым ИТорганизациям необходимы системные администраторы.
У какого системного администратора не возникало необходимости об
рабатывать все файлы в дереве каталогов, отыскивать или заменять
некоторый текст, и если вам еще не пришлось писать сценарий, кото
рый переименовывает все файлы в дереве каталогов, скорее всего это
ожидает вас в будущем. Эти умения составляют суть деятельности сис
темного администратора или, по крайней мере, хорошего системного
администратора. В этой главе мы сосредоточим свое внимание на дан
ных, файлах и каталогах.

Сисадмины постоянно должны перегонять данные из одного места
в другое. Ежедневное перемещение данных у одних системных адми
нистраторов составляет большую часть их работы, у других меньшую.
В индустрии производства мультипликационных фильмов постоянная
«перегонка» данных из одного места в другое является необходимым
условием, потому что для производства цифровых фильмов требуются
терабайты и терабайты пространства. Различные требования предъяв
ляются к операциям ввода/вывода на дисковые накопители, исходя из
качества и разрешения изображения, просматриваемого в каждый
конкретный момент времени. Если данные необходимо «перегонять»
на жесткий диск для просмотра, чтобы к ним был постоянный доступ
в ходе оцифровки, то объектами перемещения будут «свежие» несжа
тые или с незначительной степенью сжатия файлы изображений с вы
соким разрешением. Необходимость перемещения файлов обусловле
на тем, что в анимационной индустрии вообще используются два типа
накопителей. Существуют недорогие, емкие, медленные, надежные
накопители и быстрые, дорогостоящие накопители, которые нередко
представляют собой JBOD («just a bunch of disks» – простой дисковый
массив), объединенные в массив RAID 0 для обеспечения большей про
изводительности. Системного администратора, которому прежде всего
приходится иметь дело с данными, в киноиндустрии часто называют
«погонщиком данных».
Погонщик данных должен постоянно перемещать и переносить новые
данные из одного места в другое. Часто для этого используются такие
утилиты, как rsync, scp или mv. Эти простые, но мощные инструмен
ты могут использоваться в сценариях на языке Python для выполне
ния самых невероятных действий.
С помощью стандартной библиотеки языка Python можно делать по
трясающие вещи без дополнительных затрат. Преимущества стан
дартной библиотеки состоят в том, что ваши сценарии перемещения
данных будут работать везде, независимо от наличия платформозави
симой версии, например, утилиты tar.
Кроме того, не забывайте про резервное копирование. Существует мас
са сценариев и приложений резервного копирования, для создания ко
торых требуется смехотворный объем программного кода на языке Py
thon. Мы хотим предупредить вас, что создание дополнительных тес
тов для проверки программного кода, выполняющего резервное копи
рование, не только желательно, но и необходимо. Вы обязательно
должны провести как модульное, так и функциональное тестирование,
если вы используете собственные сценарии резервного копирования.
Кроме того, часто бывает необходимо выполнить обработку данных до,
после или в процессе перемещения. Конечно, Python прекрасно подхо
дит для решения и таких задач. Инструмент дедупликации, то есть
инструмент, который отыскивает дубликаты файлов и выполняет не
которые действия над ними, очень полезно иметь под рукой, поэтому
мы покажем, как создать его. Это один из примеров работы с непре
кращающимся потоком данных, с чем часто приходится сталкиваться
системным администраторам.
```
**Использование модуля OS**

**для взаимодействия с данными**

```
Если вам когданибудь приходилось создавать кроссплатформенные
сценарии командной оболочки, вы по достоинству оцените то обстоя
тельство, что модуль OS предоставляет переносимый прикладной ин
терфейс доступа к системным службам. В Python 2.5 модуль OS содер
жит более 200 методов, многие из которых предназначены для работы
с данными. В этом разделе мы рассмотрим многие из методов этого мо
дуля, которые пригодятся системным администраторам, которым час
то приходится иметь дело с данными.
```

Использование модуля OS для взаимодействия с данными **223**

```
Всякий раз, когда приходится исследовать новый модуль, оболочка
IPython оказывается незаменимым инструментом для этого, поэтому
давайте начнем наше путешествие по модулю OS с помощью оболочки
IPython, в которой будем выполнять действия, наиболее часто встре
чающиеся в практике. В примере 6.1 показано, как это делается.
```
```
Пример 6.1. Исследование методов модуля OS, наиболее часто
используемых при работе с данными
In [1]: import os
```
```
In [2]: os.getcwd()
Out[2]: '/private/tmp'
```
```
In [3]: os.mkdir("/tmp/os_mod_explore")
In [4]: os.listdir("/tmp/os_mod_explore")
Out[4]: []
In [5]: os.mkdir("/tmp/os_mod_explore/test_dir1")
```
```
In [6]: os.listdir("/tmp/os_mod_explore")
Out[6]: ['test_dir1']
```
```
In [7]: os.stat("/tmp/os_mod_explore")
Out[7]: (16877, 6029306L, 234881026L, 3, 501, 0, 102L,
1207014425, 1207014398, 1207014398)
In [8]: os.rename("/tmp/os_mod_explore/test_dir1",
"/tmp/os_mod_explore/test_dir1_renamed")
In [9]: os.listdir("/tmp/os_mod_explore")
Out[9]: ['test_dir1_renamed']
In [10]: os.rmdir("/tmp/os_mod_explore/test_dir1_renamed")
```
```
In [11]: os.rmdir("/tmp/os_mod_explore/")
```
```
В этом примере, после того как был импортирован модуль OS, в строке
[2] мы получили имя текущего рабочего каталога, затем в строке [3]
создали новый каталог. После этого в строке [4] с помощью метода
os.listdir() было получено содержимое этого вновь созданного катало
га. Затем мы воспользовались методом os.stat(), который похож на ко
манду stat в Bash, а затем в строке [8] переименовали каталог. В строке
[9] мы убедились, что каталог был переименован, и после этого мы уда
лили все созданные нами каталоги с помощью метода os.rmdir().
Этот пример ни в коем случае нельзя считать исчерпывающим иссле
дованием модуля OS. Кроме этого существует большое число методов,
которые могут вам пригодиться при работе с данными, включая мето
ды изменения прав доступа и методы создания символических ссылок.
Чтобы познакомиться с перечнем доступных методов модуля OS, обра
щайтесь к документации для своей версии Python или воспользуйтесь
функцией дополнения по клавише табуляции в оболочке IPython.

### и удаление данных Копирование, перемещение, переименование и удаление данных

Во вводном разделе главы мы говорили о перегонке данных, кроме то
го у вас уже есть некоторое представление о том, как можно использо
вать модуль OS, поэтому теперь мы можем сразу перейти на более вы
сокий уровень – к модулю shutil, который предназначен для работы
с более крупномасштабными элементами данных. Модуль shutil со
держит методы копирования, перемещения, переименования и удале
ния данных, как и модуль OS, но эти действия могут выполняться над
целыми деревьями данных.
Исследование модуля shutil в оболочке IPython – это самый увлека
тельный способ знакомства с ним. В примере ниже мы будем использо
вать метод shutil.copytree(), но в этом модуле имеется множество дру
гих методов копирования, принцип действия которых несколько отли
чается. Чтобы увидеть, в чем заключается разница между различными
методами копирования, обращайтесь к документации по стандартной
библиотеке языка Python. Взгляните на пример 6.2.
```
```
Пример 6.2. Использование модуля shutil для копирования дерева данных
In [1]: import os
In [2]: os.chdir("/tmp")
In [3]: os.makedirs("test/test_subdir1/test_subdir2")
In [4]: lslR
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test/
```
```
./test:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./test/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
```
```
./test/test_subdir1/test_subdir2:
In [5]: import shutil
```
```
In [6]: shutil.copytree("test", "testcopy")
In [19]: lslR
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test/
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 testcopy/
./test:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./test/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
./test/test_subdir1/test_subdir2:
```
```
./testcopy:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./testcopy/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
```
```
./testcopy/test_subdir1/test_subdir2:
```
```
Очевидно, что это очень простые и, вместе с тем, невероятно полезные
действия, а кроме того, вы легко можете использовать подобный про
граммный код внутри более сложного, кроссплатформенного сцена
рия, выполняющего перемещение данных. Первое, что приходит в го
лову, – подобный программный код можно использовать для переме
щения данных из одной файловой системы в другую по определенному
событию. При производстве мультипликационных фильмов часто бы
вает необходимо дождаться завершения работы над последними кад
рами, чтобы потом преобразовать их в последовательность, пригодную
для редактирования.
Мы могли бы написать сценарий, который в качестве задания для пла
нировщика cron дожидается, пока в каталоге появится «x» кадров.
После того как сценарий обнаружит, что в каталоге находится необхо
димое число кадров, он мог бы переместить этот каталог в другой ката
лог, где эти кадры будут подвергнуты обработке, или просто перемес
тить их на другой накопитель, достаточно быстрый, чтобы иметь воз
можность воспроизводить несжатый фильм с высоким разрешением.
Однако модуль shutil может не только копировать файлы, в нем также
имеются методы для перемещения и удаления деревьев данных. В при
мере 6.3 демонстрируется возможность перемещения нашего дерева,
а в примере 6.4 – возможность его удаления.
```
```
Пример 6.3. Перемещение дерева данных с помощью модуля shutil
In [20]: shutil.move("testcopy", "testcopymoved")
```
```
In [21]: lslR
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test/
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 testcopymoved/
```
```
./test:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
./test/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
```
```
./test/test_subdir1/test_subdir2:
./testcopymoved:
total 0
drwxrxrx 3 ngift wheel 102 Mar 31 22:27 test_subdir1/
```
```
./testcopymoved/test_subdir1:
total 0
drwxrxrx 2 ngift wheel 68 Mar 31 22:27 test_subdir2/
./testcopymoved/test_subdir1/test_subdir2:
```
```
Пример 6.4. Удаление дерева данных с помощью модуля shutil
In [22]: shutil.rmtree("testcopymoved")
```
```
In [23]: shutil.rmtree("testcopy")
In [24]: ll
```

Перемещение дерева данных является более впечатляющей операци
ей, чем удаление, поскольку после удаления нам нечего демонстриро
вать. Многие из этих простых примеров можно было бы объединить
с другими действиями в более сложные сценарии. Одна из разновидно
стей сценариев, которая могла бы быть полезна на практике, – это сце
нарий резервного копирования, копирующий дерево каталогов на се
тевой диск и затем создающий архив, имя которого включает текущие
дату и время. К счастью, у нас имеется пример, реализующий на язы
ке Python именно эти действия, который приводится в разделе этой
главы, посвященном резервному копированию.

### Работа с путями, каталогами и файлами


Невозможно говорить о работе с данными, не принимая во внимание
пути, каталоги и файлы. Любой системный администратор должен
уметь написать сценарий, который производит обход каталога, выпол
няет поиск по условию и затем какимнибудь образом обрабатывает
результат. Мы опишем некоторые интересные способы, позволяющие
это сделать.
Как всегда, все необходимые для выполнения задания инструменты
можно найти в стандартной библиотеке языка Python. Язык Python не
зря пользуется репутацией «батарейки входят в комплект поставки».
В примере 6.5 демонстрируется, как создать сценарий обхода катало
га, содержащий функции, которые явно возвращают файлы, каталоги
и пути.

```
Пример 6.5. Сценарий обхода каталога
import os
path = "/tmp"
def enumeratepaths(path=path):
"""Возвращает пути ко всем файлам в каталоге в виде списка"""
path_collection = []
for dirpath, dirnames, filenames in os.walk(path):
for file in filenames:
fullpath = os.path.join(dirpath, file)
path_collection.append(fullpath)
return path_collection
```
```
def enumeratefiles(path=path):
"""Возвращает имена всех файлов в каталоге в виде списка"""
file_collection = []
for dirpath, dirnames, filenames in os.walk(path):
for file in filenames:
file_collection.append(file)
```
```
return file_collection
def enumeratedir(path=path):
"""Возвращает имена всех подкаталогов в каталоге в виде списка"""
dir_collection = []
for dirpath, dirnames, filenames in os.walk(path):
for dir in dirnames:
dir_collection.append(dir)
return dir_collection
```
```
if __name__ == "__main__":
print "\nRecursive listing of all paths in a dir:"
for path in enumeratepaths():
print path
```
```
print "\nRecursive listing of all files in dir:"
for file in enumeratefiles():
print file
print "\nRecursive listing of all dirs in dir:"
for dir in enumeratedir():
print dir
```
```
На ноутбуке, работающем под управлением Mac OS, вывод этого сце
нария выглядит, как показано ниже:
```
```
[ngift@Macintosh7][H:12022][J:0]# python enumarate_file_dir_path.py
Recursive listing of all paths in a dir:
/tmp/.aksusb
/tmp/ARD_ABJMMRT
/tmp/com.hp.launchport
/tmp/error.txt
/tmp/liten.py
/tmp/LitenDeplicationReport.csv
/tmp/ngift.liten.log
/tmp/hsperfdata_ngift/58920
/tmp/launchh36okI/Render
/tmp/launchqy1S9C/Listeners
/tmp/launchRTJzTw/:0
/tmp/launchd150.wDvODl/sock

Recursive listing of all files in dir:
.aksusb
ARD_ABJMMRT
com.hp.launchport
error.txt
liten.py
LitenDeplicationReport.csv
ngift.liten.log
58920
Render
Listeners
:0
sock
Recursive listing of all dirs in dir:
.X11unix
hsperfdata_ngift
launchh36okI
launchqy1S9C
launchRTJzTw
launchd150.wDvODl
sshYcE2t6PfnO
```
```
Небольшое примечание к предыдущему фрагменту программного ко
да: метод os.walk() возвращает объектгенератор, благодаря которому
вы сможете выполнить обход дерева каталогов самостоятельно:
```
```
In [2]: import os
In [3]: os.walk("/tmp")
Out[3]: [generator object at 0x508e18]
```
```
Вот как это выглядит при вызове метода в оболочке IPython. Вы може
те заметить, что наличие генератора дает нам возможность использо
вать его метод path.next(). Мы не будем углубляться в обсуждение ге
нераторов, но вы должны знать, что метод os.walk() возвращает объ
ектгенератор. Генераторы очень полезны для системного программи
рования. Все, что вам необходимо знать о генераторах, вы найдете на
сайте Дэвида Бизли (David Beazely) по адресу: http://www.dabeaz.com/
generators/.
In [2]: import os
```
```
In [3]: os.walk("/tmp")
Out[3]: [generator object at 0x508e18]
```
```
In [4]: path = os.walk("/tmp")
In [5]: path.

path.__class__ path.__init__ path.__repr__ path.gi_running
path.__delattr__ path.__iter__ path.__setattr__ path.next
path.__doc__ path.__new__ path.__str__ path.send
path.__getattribute__ path.__reduce__ path.close path.throw
path.__hash__ path.__reduce_ex__ path.gi_frame
In [5]: path.next()
Out[5]:
('/tmp',
['.X11unix',
'hsperfdata_ngift',
'launchh36okI',
'launchqy1S9C',
'launchRTJzTw',
'launchd150.wDvODl',
'sshYcE2t6PfnO'],
['.aksusb',
'ARD_ABJMMRT',
'com.hp.launchport',
'error.txt',
'liten.py',
'LitenDeplicationReport.csv',
'ngift.liten.log'])
```
```
Вскоре мы познакомимся с генераторами поближе, но сначала созда
дим модуль, обладающий прозрачным прикладным интерфейсом, с по
мощью которого можно будет получать файлы, каталоги и пути.
Теперь, когда мы выполнили основную реализацию задачи обхода ка
талога, попробуем создать объектноориентированный модуль, чтобы
впоследствии его легко можно было импортировать и использовать.
Модуль с жестко заданными исходными данными получился бы коро
че, но универсальный модуль, который потом можно будет использо
вать в разных сценариях, облегчит нам жизнь гораздо существеннее.
Взгляните на пример 6.6.
```
```
Пример 6.6. Модуль многократного использования для обхода каталога
import os
```
```
class diskwalk(object):
"""Интерфейс доступа к коллекциям, получаемым при обходе каталога """
def __init__(self, path):
self.path = path
```
```
def enumeratePaths(self):
"""Возвращает пути ко всем файлам в каталоге в виде списка"""
path_collection = []
for dirpath, dirnames, filenames in os.walk(self.path):
for file in filenames:
fullpath = os.path.join(dirpath, file)
path_collection.append(fullpath)
return path_collection

def enumerateFiles(self):
"""Возвращает имена всех файлов в каталоге в виде списка"""
file_collection = []
for dirpath, dirnames, filenames in os.walk(self.path):
for file in filenames:
file_collection.append(file)
```
```
return file_collection
def enumerateDir(self):
"""Возвращает имена всех подкаталогов в каталоге в виде списка"""
dir_collection = []
for dirpath, dirnames, filenames in os.walk(self.path):
for dir in dirnames:
dir_collection.append(dir)
return dir_collection
```
```
Как видите, внесением небольших изменений нам удалось создать от
личный интерфейс для модификаций в будущем. Главная прелесть
этого нового модуля заключается в том, что его можно импортировать
в другие сценарии.


### Сравнение данных.


Сравнение данных – очень важная операция для системного админи
стратора. Вы часто могли задавать себе вопросы: «Какие файлы в этих
двух каталогах различны? Сколько копий одного и того же файла су
ществует у меня в системе?» В этом разделе вы найдете способы, кото
рые позволят вам ответить на эти и другие вопросы.
Когда приходится иметь дело с огромными объемами важных данных,
часто бывает необходимо сравнить деревья каталогов и файлов, чтобы
узнать, какие изменения были внесены. Это становится еще более
важным, когда дело доходит до создания сценариев, перемещающих
данные. Судный день будет вам гарантирован, если ваш сценарий пе
ремещения больших объемов данных повредит какиелибо критиче
ски важные данные.
В этом разделе мы сначала исследуем несколько легковесных методов
сравнения файлов и каталогов, а затем перейдем к вычислению и срав
нению контрольных сумм файлов. В стандартной библиотеке языка
Python имеется несколько модулей, которые помогут выполнить срав
нение; мы рассмотрим filecmp и os.listdir.
```
**Использование модуля filecmp**

```
Модуль filecmp содержит функции для быстрого и эффективного срав
нения файлов и каталогов. Модуль filecmp вызывает функцию os.stat()
для двух файлов и возвращает значение True, если результаты вызова
os.stat() одни и те же для обоих файлов, и False, если полученные результаты отличаются. Обычно функция os.stat() вызывается, чтобы определить, не используют ли два файла одни и те же индексные узлы на диске и не имеют ли они одинаковые размеры, но сравнение содержимого файлов при этом не производится.
Чтобы полностью понять, как работает модуль filecmp, нам потребуется
создать три файла. Для этого перейдем в каталог /tmp , создадим файл
с именем file0.txt и запишем в него «0». Затем создадим файл с именем
file1.txt и запишем в него «1». Наконец, создадим файл с именем
file00.txt и запишем в него «0». Эти файлы будут использоваться в ка
честве объектов сравнения в следующем фрагменте:

```
In [1]: import filecmp
In [2]: filecmp.cmp("file0.txt", "file1.txt")
Out[2]: False
In [3]: filecmp.cmp("file0.txt", "file00.txt")
Out[3]: True
```

Как видите, функция cmp() вернула значение True при сравнении фай
лов file0.txt и file00.txt , и False при сравнении файлов file1.txt
и file0.txt.
Функция dircmp() имеет множество атрибутов, которые сообщают о раз
личиях между двумя деревьями каталогов. Мы не будем рассматри
вать каждый атрибут, но продемонстрируем несколько примеров вы
полнения действий, которые могут быть вам полезны. Для этого при
мера в каталоге /tmp были созданы два подкаталога, в каждый из ко
торых были скопированы файлы из предыдущего примера. В каталоге
dirB был создан дополнительный файл с именем file11.txt , в который
была записана строка «11»:
```
```
In [1]: import filecmp
In [2]: pwd
Out[2]: '/private/tmp'
In [3]: filecmp.dircmp("dirA", "dirB").diff_files
Out[3]: []
In [4]: filecmp.dircmp("dirA", "dirB").same_files
Out[4]: ['file1.txt', 'file00.txt', 'file0.txt']
In [5]: filecmp.dircmp("dirA", "dirB").report()
diff dirA dirB
Only in dirB : ['file11.txt']
Identical files : ['file0.txt', 'file00.txt', 'file1.txt']
```
```
Возможно, вас удивило, что атрибут diff_files не содержит ничего,
хотя мы создали файл file11.txt с уникальной информацией в нем. Де
ло в том, что атрибут diff_files выявляет различия только между од
ноименными файлами.
Затем взгляните на результат вывода атрибута same_files и обратите
внимание, что он сообщает об идентичных файлах в двух каталогах.
Наконец, в последнем примере был сгенерирован отчет. Он наглядно
сообщает о различиях между двумя файлами. Это был лишь очень
краткий обзор возможностей модуля filecmp, поэтому мы рекомендуем
обратиться к документации в стандартной библиотеке языка Python,
чтобы получить полное представление о имеющихся возможностях,
для описания которых мы не располагаем достаточным пространством
в книге.
```
**Использование os.listdir**

```
Еще один легковесный способ сравнения двух каталогов основан на
использовании метода os.listdir(). Метод os.listdir() можно пред
ставлять себе как аналог команды ls – он возвращает список обнару
женных файлов. Язык Python поддерживает множество интересных
способов работы со списками, поэтому вы можете использовать метод
os.listdir() для выявления различий между каталогами, просто пре
образуя списки во множества и затем вычитая одно множество из дру
гого. Ниже показано, как это делается в оболочке IPython:
```
```
In [1]: import os
In [2]: dirA = set(os.listdir("/tmp/dirA"))
```
```
In [3]: dirA
Out[3]: set(['file1.txt', 'file00.txt', 'file0.txt'])
```
```
In [4]: dirB = set(os.listdir("/tmp/dirB"))
In [5]: dirB
Out[5]: set(['file1.txt', 'file00.txt', 'file11.txt', 'file0.txt'])
In [6]: dirA dirB
Out[6]: set([])
In [7]: dirBdirA
Out[7]: set(['file11.txt'])
```
```
В этом примере можно видеть, что мы преобразовали два списка во
множества, а затем выполнили операцию вычитания, чтобы выявить
различия. Обратите внимание, что в строке [7] было получено имя
file11.txt, потому что dirB является надмножеством для dirA, но в стро
ке [6] был получен пустой результат, потому что множество dirA содер
жит элементы, которые содержатся в множестве dirB. При использова
нии множеств легко можно создать простое объединение двух струк
тур данных, вычитая полные пути в одном каталоге из путей в другом
каталоге, и копируя найденные различия. Объединение данных мы
рассмотрим в следующем разделе.
Однако этот подход имеет существенные ограничения. Фактическое
имя файла часто может вводить в заблуждение, поскольку ничто не мешает иметь файл с нулевым размером, имя которого совпадает с име
нем файла, имеющим размер 200 Гбайт. В следующем разделе мы
представим несколько лучший способ обнаружения различий между
каталогами и объединения их содержимого.
```
### Объединение данных

```
Как быть, когда необходимо не просто сравнить файлы с данными, но
еще и объединить два дерева каталогов в одно? Главная проблема со
стоит в том, чтобы объединить содержимое одного дерева с другим без
создания дубликатов файлов.
Вы могли бы просто вслепую скопировать файлы из одного каталога
в другой и затем удалить дубликаты файлов, но гораздо эффективнее
было бы вообще не создавать дубликаты. Достаточно простое решение
этой проблемы состоит в том, чтобы сравнить два каталога с помощью
функции dircmp() из модуля filecmp и затем скопировать уникальные
файлы с помощью приема, основанного на использовании os.listdir,
описанного выше. Наилучшее решение заключается в использовании
контрольных сумм MD5, о чем рассказывается в следующем разделе.
```
**Сравнение контрольных сумм MD5**

```
Вычисление контрольной суммы MD5 файла и сравнение ее с кон
трольной суммой другого файла напоминает стрельбу из гранатомета
по движущейся мишени. Такое мощное оружие вводится в действие,
когда требуется полная уверенность в своих действиях, хотя 100про
центную гарантию может дать только побайтовое сравнение файлов.
В примере 6.7 показана функция, которая принимает путь к файлу
и возвращает его контрольную сумму.
```
```
Пример 6.7. Вычисление контрольной суммы MD5 файла
import hashlib
def create_checksum(path):
"""
Читает файл. Вычисляет контрольную сумму файла, строку за строкой.
Возвращает полную контрольную сумму для всего файла.
"""
fp = open(path)
checksum = hashlib.md5()
while True:
buffer = fp.read(8192)
if not buffer: break
checksum.update(buffer)
fp.close()
checksum = checksum.digest()
return checksum
Ниже приводится пример использования этой функции в интерактив
ной оболочке IPython для сравнения двух файлов:
```
```
In [2]: from checksum import createChecksum
In [3]: if createChecksum("image1") == createChecksum("image2"):
...: print "True"
...:
...:
True
```
```
In [5]: if createChecksum("image1") == createChecksum("image_unique"):
print "True"
...:
...:
```
```
В этом примере контрольные суммы файлов сравниваются вручную, но
мы вполне можем использовать программный код, написанный ранее,
который возвращает список путей, для рекурсивного сравнивания де
рева каталогов и получить список дубликатов. Прелесть удобного API
состоит в том, что его теперь можно использовать в оболочке IPython
с целью тестирования наших решений в интерактивном режиме. За
тем, если решение работает, мы можем создать другой модуль. В при
мере 6.8 приводится программный код, который отыскивает дублика
ты файлов.
```
```
Пример 6.8. Вычисление контрольных сумм MD5 в дереве каталогов
с целью поиска дубликатов файлов
In [1]: from checksum import createChecksum
```
```
In [2]: from diskwalk_api import diskwalk
In [3]: d = diskwalk('/tmp/duplicates_directory')
```
```
In [4]: files = d.enumeratePaths()
In [5]: len(files)
Out[5]: 12
In [6]: dup = []
```
```
In [7]: record = {}
In [8]: for file in files:
compound_key = (getsize(file),create_checksum(file))
if compound_key in record:
dup.append(file)
else:
record[compound_key] = file
```
```
...:
...:
```
```
In [9]: print dup
['/tmp/duplicates_directory/image2']
Фрагмент программного кода, который еще не встречался нам в пре
дыдущих примерах, начинается в строке [7]. Здесь мы создали пустой
словарь, и затем сохраняем вычисленные контрольные суммы в виде
ключей. Благодаря этому легко можно определить, была ли ранее вы
числена та или иная контрольная сумма. Если была, мы помещаем
файл в список дубликатов. Теперь давайте выделим часть программ
ного кода, которую позднее мы сможем использовать в разных сцена
риях. В конце концов, это очень удобно. Как это сделать, показано
в примере 6.9.

```
Пример 6.9. Поиск дубликатов
from checksum import create_checksum
from diskwalk_api import diskwalk
from os.path import getsize
def findDupes(path = '/tmp'):
dup = []
record = {}
d = diskwalk(path)
files = d.enumeratePaths()
for file in files:
compound_key = (getsize(file),create_checksum(file))
if compound_key in record:
dup.append(file)
else:
#print "Creating compound key record:", compound_key
record[compound_key] = file
return dup
```
```
if __name__ == "__main__":
dupes = findDupes()
for dup in dupes:
print "Duplicate: %s" % dup
```
```
Запустив этот сценарий, мы получили следующий результат:
[ngift@Macintosh7][H:10157][J:0]# python find_dupes.py
Duplicate: /tmp/duplicates_directory/image2
```
```
Мы надеемся, вы заметили, что этот пример демонстрирует преиму
щества повторного использования существующего программного ко
да. Теперь у нас имеется универсальный модуль, получающий путь
к дереву каталогов и возвращающий список дубликатов файлов. Это
уже само по себе удобно, но мы можем пойти еще дальше и автомати
чески удалить дубликаты.
Удаление файлов в языке выполняется очень просто – с помощью ме
тода os.remove(). Для этого примера у нас имеется множество файлов
размером 10 Мбайт в нашем каталоге /tmp. Попробуем удалить один
из них, воспользовавшись методом os.remove():

```
In [1]: import os
In [2]: os.remove("10
10mbfile.0 10mbfile.1 10mbfile.2 10mbfile.3 10mbfile.4
10mbfile.5 10mbfile.6 10mbfile.7 10mbfile.8
```
```
In [2]: os.remove("10mbfile.1")
In [3]: os.remove("10
10mbfile.0 10mbfile.2 10mbfile.3 10mbfile.4 10mbfile.5
10mbfile.6 10mbfile.7 10mbfile.8
```
```
Обратите внимание, как функция дополнения по клавише табуляции
в оболочке IPython позволяет увидеть список соответствующих фай
лов. Вы должны знать, что метод os.remove() удаляет файлы, ничего не
сообщая и навсегда, что может не всегда соответствовать нашим жела
ниям. Учитывая это обстоятельство, мы можем реализовать простой
метод, который будет удалять дубликаты, и затем расширить его. По
скольку интерактивная оболочка IPython позволяет легко проверить
эту идею, мы напишем проверочную функцию прямо в ней и сразу же
проверим ее:
In [1]: from find_dupes import findDupes
```
```
In [2]: dupes = findDupes("/tmp")
In [3]: def delete(file):
import os
...: print "deleting %s" % file
...: os.remove(file)
...:
...:
In [4]: for dupe in dupes:
...: delete(dupe)
...:
...:
In [5]: for dupe in dupes:
delete(dupe)
...:
...:
deleting /tmp/10mbfile.2
deleting /tmp/10mbfile.3
deleting /tmp/10mbfile.4
deleting /tmp/10mbfile.5
deleting /tmp/10mbfile.6
deleting /tmp/10mbfile.7
deleting /tmp/10mbfile.8
```
```
В этом примере мы несколько усложнили свой метод удаления, доба
вив в него инструкцию print, которая выводит имена удаляемых фай
лов. Мы уже создали достаточно много программного кода, пригодного
для многократного использования, поэтому у нас нет никаких причин останавливаться на достигнутом. Мы можем создать еще один модуль,
который будет выполнять различные операции удаления, получая объ
ект типа file. Этот модуль даже не требуется привязывать к поиску
дубликатов, его можно использовать для удаления любых файлов. Ис
ходный текст модуля приводится в примере 6.10.

```
Пример 6.10. Модуль delete
#!/usr/bin/env python
import os
```
```
class Delete(object):
"""Методы удаления, работающие с объектами типа file"""
```
```
def __init__(self, file):
self.file = file
```
```
def interactive(self):
"""Интерактивный режим удаления"""
```
```
input = raw_input("Do you really want to delete %s [N]/Y" % self.file)
if input.upper() == "Y":
print "DELETING: %s" % self.file
status = os.remove(self.file)
else:
print "Skipping: %s" % self.file
return
def dryrun(self):
"""Имитация удаления"""
print "Dry Run: %s [NOT DELETED]" % self.file
return
def delete(self):
```
```
"""Удаляет файл без дополнительных условий"""
print "DELETING: %s" % self.file
try:
status = os.remove(self.file)
except Exception, err:
print err
return status
if __name__ == "__main__":
from find_dupes import findDupes
dupes = findDupes('/tmp')
for dupe in dupes:
delete = Delete(dupe)
#delete.dryrun()
#delete.delete()
#delete.interactive()
```
```
В этом модуле имеется три различных метода удаления. Метод удале
ния в интерактивном режиме запрашивает у пользователя подтверждение для каждого файла, который предполагается удалить. Это может
показаться раздражающим, но этот метод обеспечивает хорошую за
щиту для тех, кто впоследствии будет сопровождать или изменять этот
программный код.
Метод пробного режима всего лишь имитирует удаление. И, наконец,
имеется метод, который удаляет файлы безвозвратно. В конце модуля
можно увидеть закомментированные варианты использования каждо
го из трех методов. Ниже приводятся примеры каждого из методов
в действии:

**-** Пробный режим

```
ngift@Macintosh7][H:10197][J:0]# python delete.py
Dry Run: /tmp/10mbfile.1 [NOT DELETED]
Dry Run: /tmp/10mbfile.2 [NOT DELETED]
Dry Run: /tmp/10mbfile.3 [NOT DELETED]
Dry Run: /tmp/10mbfile.4 [NOT DELETED]
Dry Run: /tmp/10mbfile.5 [NOT DELETED]
Dry Run: /tmp/10mbfile.6 [NOT DELETED]
Dry Run: /tmp/10mbfile.7 [NOT DELETED]
Dry Run: /tmp/10mbfile.8 [NOT DELETED]
```
**-** Интерактивный режим

```
ngift@Macintosh7][H:10201][J:0]# python delete.py
Do you really want to delete /tmp/10mbfile.1 [N]/YY
DELETING: /tmp/10mbfile.1
Do you really want to delete /tmp/10mbfile.2 [N]/Y
Skipping: /tmp/10mbfile.2
Do you really want to delete /tmp/10mbfile.3 [N]/Y
```
**-** Удаление
    [ngift@Macintosh7][H:10203][J:0]# python delete.py
    DELETING: /tmp/10mbfile.1
    DELETING: /tmp/10mbfile.2
    DELETING: /tmp/10mbfile.3
    DELETING: /tmp/10mbfile.4
    DELETING: /tmp/10mbfile.5
    DELETING: /tmp/10mbfile.6
    DELETING: /tmp/10mbfile.7
    DELETING: /tmp/10mbfile.8

```
Вы можете согласиться, что приемы инкапсуляции, подобные тем, что
были продемонстрированы выше, очень удобны, когда приходится
иметь дело с данными, потому что вы можете предотвратить возникно
вение проблем в будущем, абстрагировавшись от конкретной ситуа
ции и решая универсальную задачу. В данном случае нам необходимо
было реализовать удаление дубликатов файлов, поэтому был создан
модуль, который универсальным способом отыскивает файлы и удаля
ет их. Мы могли бы создать еще один инструмент, который получает объект типа file и выполняет сжатие файла. И мы действительно вскоре подойдем к этому примеру.

### Поиск файлов и каталогов по шаблону.

До сих пор мы рассматривали способы обработки каталогов и файлов
и такие действия, как поиск дубликатов, удаление каталогов, переме
щение каталогов и так далее. Следующий шаг в освоении дерева ката
логов состоит в применении поиска по шаблону либо как самостоя
тельной операции, либо в комбинации с предыдущими приемами. Как
и все прочее в языке Python, реализация поиска по шаблону расшире
ния или имени файла выполняется очень просто. В этом разделе мы
продемонстрируем несколько общих проблем, связанных с поиском по
шаблону, и применим приемы, использовавшиеся ранее, для создания
простых, но мощных инструментов.
Очень часто системным администраторам приходится сталкиваться
с необходимостью отыскать и удалить, переместить, переименовать или
скопировать файлы определенных типов. Самый простой подход к ре
шению этой задачи в языке Python заключается в использовании моду
ля fnmatch или glob. Основное отличие между этими двумя модулями
заключается в том, что функция fnmatch() при сопоставлении имени
файла с шаблоном UNIX возвращает значение True или False, а функ
ция glob() возвращает список путей к файлам, имена которых соответ
ствуют шаблону. Для создания более сложных инструментов поиска по
шаблону можно использовать регулярные выражения. Об использова
нии регулярных выражений более подробно рассказывается в главе 3.
В примере 6.11 показано, как используются функции fnmatch() и glob().
Здесь мы снова повторно использовали программный код, созданный
нами ранее, импортировав класс diskwalk из модуля diskwalk_api.
```
```
Пример 6.11. Использование функций fnmatch() и glob()
в интерактивном режиме для поиска файлов
In [1]: from diskwalk_api import diskwalk
```
```
In [2]: files = diskwalk("/tmp")
In [3]: from fnmatch import fnmatch
```
```
In [4]: for file in files:
...: if fnmatch(file,"*.txt"):
...: print file
...:
...:
/tmp/file.txt
```
```
In [5]: from glob import glob
In [6]: import os
In [7]: os.chdir("/tmp")
In [8]: glob("*")
Out[8]: ['file.txt', 'image.iso', 'music.mp3']
```
```
В этом примере, после того как мы воспользовались нашим модулем
diskwalk_api, у нас появился список полных путей к файлам, находя
щимся в каталоге /tmp. После этого мы использовали функцию
fnmatch(), чтобы определить соответствие каждого файла шаблону
"*.txt". Функция glob() отличается тем, что она сразу выполняет со
поставление с шаблоном и возвращает список имен файлов. Функция
glob() является более высокоуровневой по отношению к функции
fnmatch(), но обе они являются незаменимыми инструментами при ре
шении немного разных задач.
Функцию fnmatch() особенно удобно использовать в комбинации с про
граммным кодом, создающим фильтр для поиска данных в дереве ка
талогов. Часто при работе с каталогами бывает необходимо работать
с файлами, имена которых соответствуют определенным шаблонам.
Чтобы увидеть этот прием в действии, мы попробуем решить классиче
скую задачу системного администрирования по переименованию всех
файлов в дереве каталогов, имена которых соответствуют заданному
шаблону. Имейте в виду, что переименовывать файлы так же просто,
как удалять, сжимать или обрабатывать их. Для решения подобных
задач используется простой алгоритм:

```
1. Получить путь к файлу в каталоге.
2. Выполнить дополнительную фильтрацию – в эту операцию может
    быть вовлечено несколько фильтров, таких как имя файла, расши
    рение, размер, уникальность и так далее.
3. Выполнить действие над файлом – скопировать, удалить, сжать,
    прочитать и так далее. Как это делается, показано в примере 6.12.

```
Пример 6.12. Переименование файлов с расширением .mp3 в файлы
с расширением .txt
In [1]: from diskwalk_api import diskwalk
In [2]: from shutil import move
```
```
In [3]: from fnmatch import fnmatch
In [4]: files = diskwalk("/tmp")
```
```
In [5]: for file in files:
if fnmatch(file, "*.mp3"):
#здесь можно сделать все, что угодно: удалить, переместить
#переименовать ...хмм, переименовать
move(file, "%s.txt" % file)
```
```
In [6]: lsl /tmp/
total 0
rwrr 1 ngift wheel 0 Apr 1 21:50 file.txt
rwrr 1 ngift wheel 0 Apr 1 21:50 image.iso
rwrr 1 ngift wheel 0 Apr 1 21:50 music.mp3.txt
rwrr 1 ngift wheel 0 Apr 1 22:45 music1.mp3.txt
rwrr 1 ngift wheel 0 Apr 1 22:45 music2.mp3.txt
rwrr 1 ngift wheel 0 Apr 1 22:45 music3.mp3.txt
```
```
При использовании программного кода, разработанного ранее, пере
именование всех файлов с расширением .mp3 в каталоге уложилось
в четыре строки легко читаемого программного кода на языке Python.
Если вы один из немногих системных администраторов, кто не прочи
тал ни одного эпизода из «BOFH» («Bastard Operator From Hell»), то
вам не сразу станет очевидно, что можно было бы дальше сделать
сэтим фрагментом кода.
Представьте, что у вас имеется технологический файловый сервер, ко
торый используется исключительно как высокопроизводительное
хранилище файлов с далеко не безграничной емкостью. Вы стали за
мечать, что диски сервера стали часто переполняться, потому что па
рочка недобросовестных пользователей принялись размещать на них
сотни гигабайтов файлов MP3. Конечно, вы могли бы ввести квотиро
вание дискового пространства для пользователей, но нередко квотиро
вание порождает больше проблем, чем решает. Одно из решений состо
ит в том, чтобы написать сценарий для запуска его из планировщика
cron каждую ночь, который будет отыскивать файлы MP3 и выпол
нять над ними «случайные» операции. По понедельникам он мог бы
давать этим файлам расширение .txt , по вторникам – сжимать их
в ZIPархивы, по средам – перемещать в каталог /tmp , по четвергам –
удалять их и отсылать владельцу полный список удаленных файлов
MP3 по электронной почте. Мы не можем советовать вам сделать это,
если, конечно, вы не являетесь владельцем компании, на которую ра
ботаете, но для настоящего «чертова ублюдка оператора» этот пример
можно считать воплощением мечты.

### Обертка для rsync

Как вы уже, наверное, знаете, rsync – это инструмент командной стро
ки, первоначально разрабатывавшийся Эндрю Триджеллом (Andrew
Tridgell) и Полом Маккерра (Paul Mackerra). В конце 2007 года стала
доступна для тестирования версия 3, включающая еще более широкий
перечень параметров, чем оригинальная версия.
За эти годы для нас rsync превратился в основной инструмент переме
щения данных из пункта А в пункт Б. Объем страницы справочного
руководства и количество возможных параметров просто поражают,
поэтому мы рекомендуем познакомиться с ними поближе. Без преуве
личения утилиту rsync можно считать уникальным, наиболее полез
ным инструментом командной строки, из всех, что когдалибо созда
вались для системных администраторов.
К этому стоит добавить, что язык Python предоставляет несколько спо
собов управления поведением rsync. Одна из проблем, с которой мы
столкнулись, состояла в том, чтобы обеспечить копирование данных
в запланированное время. Мы не раз попадали в ситуации, когда было
необходимо синхронизировать терабайты данных между двумя файло
выми серверами настолько быстро, насколько это возможно, но мы со
всем не хотели контролировать этот процесс вручную. Это как раз та си
туация, в которой Python действительно может сыграть значимую
роль.
С помощью языка Python можно придать утилите rsync немного искус
ственного интеллекта и настроить ее под свои нужды. В такой ситуа
ции сценарий на языке Python используется как связующий про
граммный код, который заставляет утилиты UNIX выполнять такие
вещи, для которых они никогда не предназначались, и благодаря это
му вы получаете возможность создавать очень гибкие и легко настраи
ваемые инструменты. Вы здесь действительно ограничены только ва
шим воображением. В примере 6.13. приводится очень простой сцена
рий, который представляет собой обертку для rsync.
```
```
Пример 6.13. Простая обертка для rsync
#!/usr/bin/env python
#обертка вокруг rsync для синхронизации содержимого двух каталогов
from subprocess import call
import sys
source = "/tmp/sync_dir_A/" #Обратите внимание на завершающий символ слеша
target = "/tmp/sync_dir_B"
rsync = "rsync"
arguments = "a"
cmd = "%s %s %s %s" % (rsync, arguments, source, target)
```
```
def sync():
```
```
ret = call(cmd, shell=True)
if ret != 0:
print "rsync failed"
sys.exit(1)
sync()
```
```
Этот пример жестко определяет синхронизацию двух каталогов и вы
водит сообщение об ошибке, если команда не сработала. Однако мы
могли бы реализовать нечто более интересное и решить проблему, с ко
торой часто приходится сталкиваться. Нас часто вызывали, чтобы
синхронизировать два очень больших каталога, но мы при этом не со
бирались следить за синхронизацией данных всю ночь. Но, если вы не
контролируете процесс синхронизации, вы можете обнаружить, что
процесс был прерван на полпути, при этом данные и целая ночь време
ни были потрачены впустую, а сам процесс синхронизации придется опять запускать на следующий день. Используя Python, вы можете
создать более агрессивную, высокомотивированную команду rsync.
Что могла бы делать высокомотивированная команда rsync? Она могла
бы делать то же самое, что и вы, если бы контролировали процесс син
хронизации двух каталогов: она могла бы пытаться продолжать син
хронизацию до самого конца и затем посылала бы сообщение по элек
тронной почте с описанием того, что было сделано. В примере 6.14
приводится немного более продвинутый сценарийобертка для rsync.
```
```
Пример 6.14. Команда rsync, которая не завершается,
пока не выполнит задание
#!/usr/bin/env python
#обертка вокруг rsync для синхронизации содержимого двух каталогов
from subprocess import call
import sys
import time
"""эта мотивированная команда rsync будет пытаться синхронизировать
каталоги, пока не синхронизирует их"""
source = "/tmp/sync_dir_A/" #Note the trailing slash
target = "/tmp/sync_dir_B"
rsync = "rsync"
arguments = "av"
cmd = "%s %s %s %s" % (rsync, arguments, source, target)
```
```
def sync():
while True:
ret = call(cmd, shell=True)
if ret !=0:
print "resubmitting rsync"
time.sleep(30)
else:
print "rsync was succesful"
subprocess.call("mails 'jobs done' bofh@example.com",
shell=True)
sys.exit(0)
sync()
```
```
Этот сценарий максимально упрощен и содержит жестко определен
ные данные, но это – пример полезного инструмента, который можно
создать для автоматизации чегото, что вам обычно приходится кон
тролировать вручную. В этот сценарий можно добавить такие особен
ности, как возможность устанавливать интервал между попытками
и ограничивать количество попыток, проверять объем свободного дис
кового пространства на машине, с которой устанавливается соедине
ние, и так далее.

### Метаданные: данные о данных.

Большинство системных администраторов начинают вникать в суть де
ла, когда принимаются интересоваться не только данными, но и дан
ными о данных. Метаданные, или данные о данных, часто могут иг
рать более важную роль, чем сами данные. Например, в кинопроиз
водстве и в телевидении одни и те же данные часто хранятся в несколь
ких каталогах внутри файловой системы или даже в разных файловых
системах. Слежение за такими данными часто приводит к созданию
своего рода системы управления метаданными.
Метаданные – это данные о том, как организованы и как используют
ся определенные файлы, что может быть очень важно для приложе
ния, для процесса производства мультипликационного фильма или
для процедуры восстановления из резервной копии. Python также
сможет помочь в этом, поскольку на этом языке легко можно реализо
вать как чтение, так и запись метаданных.
Рассмотрим использование популярного средства ORM (ObjectRelati
onal Mapping – объектнореляционная проекция) SQLAlchemy для соз
дания метаданных о файловой системе. К счастью, для SQLAlchemy
имеется очень качественная документация, а кроме того, этот продукт
работает с SQLite. На наш взгляд, это потрясающая комбинация, по
зволяющая разрабатывать собственные решения по управлению мета
данными.
В примерах выше мы выполняли обход файловой системы в режиме
реального времени, производили запросы и выполняли действия над
обнаруженными файлами. Это невероятно удобно, но поиск по круп
ным файловым системам, содержащим миллионы файлов, отнимет
слишком много времени иногда только для того, чтобы выполнить
единственную операцию. В примере 6.15 мы покажем, на что могут
быть похожи самые простые метаданные, объединив приемы обхода
каталогов со средством ORM.
```
```
Пример 6.15. Создание метаданных о файловой системе
с помощью SQLAlchemy
#!/usr/bin/env python
from sqlalchemy import create_engine
from sqlalchemy import Table, Column, Integer, String, MetaData, ForeignKey
from sqlalchemy.orm import mapper, sessionmaker
import os
#путь
path = " /tmp"
#Часть 1: Создание механизма
engine = create_engine('sqlite:///:memory:', echo=False)
#Часть 2: метаданные
metadata = MetaData()
filesystem_table = Table('filesystem', metadata,
Column('id', Integer, primary_key=True),
Column('path', String(500)),
Column('file', String(255)),
)
metadata.create_all(engine)
```
```
#Часть 3: класс отображения
class Filesystem(object):
```
```
def __init__(self, path, file):
self.path = path
self.file = file
def __repr__(self):
return "[Filesystem('%s','%s')]" % (self.path, self.file)
#Часть 4: функция отображения
mapper(Filesystem, filesystem_table)
#Часть 5: создание сеанса
Session = sessionmaker(bind=engine, autoflush=True, transactional=True)
session = Session()
```
```
#Часть 6: обход файловой системы и заполнение базы данных результатами
for dirpath, dirnames, filenames in os.walk(path):
for file in filenames:
fullpath = os.path.join(dirpath, file)
record = Filesystem(fullpath, file)
session.save(record)
```
```
#Часть 7: подтверждение записи данных в базу
session.commit()
```
```
#Часть 8: запрос
for record in session.query(Filesystem):
print "Database Record Number: %s, Path: %s , File: %s " \
% (record.id,record.path, record.file)
```
```
Этот сценарий проще представлять себе как последовательность проце
дур, выполняемых одна за другой. В первой части создается механизм,
который в действительности является лишь несколько необычным
способом определения базы данных, которая будет использоваться для
хранения метаданных. Во второй части определяется экземпляр клас
са метаданных и создается таблица в базе данных. В третьей части оп
ределяется класс, который будет отображаться в только что созданную
таблицу базы данных. В четвертой части вызывается функция отобра
жения, которая производит объектнореляционную проекцию, а по
просту – отображает класс в таблицу. В пятой части создается сеанс
связи с базой данных. Обратите внимание, что здесь указано несколь
ко именованных аргументов, включая autoflush и transactional.
Теперь, когда создание объектнореляционной проекции закончено,
в шестой части мы выполняем уже знакомые нам действия – извлекаем имена файлов и полные пути при обходе дерева каталогов. Однако здесь
имеется пара интересных приемов. Обратите внимание, что для каждо
го пути и имени файла создается отдельная запись, которая затем со
храняется в базе данных. После этого – в седьмой части – мы подтвер
ждаем транзакцию в нашей базе данных, «расположенной в памяти».
Наконец, в восьмой части выполняется запрос – на языке Python, ко
нечно, возвращающий записи, которые мы поместили в базу данных.
Этот пример мог бы стать для вас прекрасной возможностью поэкспе
риментировать в создании собственных решений использования мета
данных с применением SQLAlchemy в вашей компании или у клиен
тов. Этот пример можно расширить такими дополнительными воз
можностями, как выполнение реляционных запросов или запись ре
зультатов в файл и так далее.

### Архивирование, сжатие, отображение и восстановление

Действия с большими объемами данных представляют собой пробле
му, с которой системные администраторы сталкиваются изо дня
в день. Для выполнения своей работы они часто используют tar, dd,
gzip, bzip, bzip2, hdiutil, asr и другие утилиты.
Хотите верьте, хотите нет, но и в этом случае «батарейки входят в ком
плект поставки» – стандартная библиотека языка Python имеет встро
енную поддержку TARфайлов, zlibфайлов и gzipфайлов. Если вам
требуется сжатие и архивирование, значит, у вас не будет никаких про
блем, т. к. язык Python предлагает богатый выбор необходимых инст
рументов. Давайте поближе посмотрим на дедушку всех архиваторов –
tar – и увидим, как стандартная библиотека реализует его поддержку.

### Использование модуля tarfile для создания архивов TAR

Создать архив TAR очень просто, даже слишком просто. В примере 6.16
мы создаем очень большой файл. Обратите внимание, что синтаксис
создания архива намного более простой, чем даже синтаксис использо
вания самой команды tar.
```
```
Пример 6.16. Создание большого текстового файла
In [1]: f = open("largeFile.txt", "w")
```
```
In [2]: statement = "This is a big line that I intend to write over and over
again."
```
```
ln [3]: x = 0
In [4]: for x in xrange(20000):
...: x += 1
...: f.write("%s\n" % statement)
...:
...:
In [4]: lsl
rwrr 1 root root 1236992 Oct 25 23:13 largeFile.txt
```
```
Теперь, когда у нас имеется большой файл, наполненный мусором, пе
редадим его архиватору TAR, как показано в примере 6.17.
```
```
Пример 6.17. Архивирование содержимого файла
In [1]: import tarfile
In [2]: tar = tarfile.open("largefile.tar", "w")
```
```
In [3]: tar.add("largeFile.txt")
In [4]: tar.close()
```
```
In [5]: ll
rwrr 1 root root 1236992 Oct 25 23:15 largeFile.txt
rwrr 1 root root 1236992 Oct 26 00:39 largefile.tar
```
```
Как видите, был создан обычный архив TAR, причем намного более
простым способом, чем с использованием команды tar. Этот пример оп
ределенно создает прецедент к использованию оболочки IPython для
выполнения повседневной работы по системному администрированию.
Несмотря на удобство создания архивов TAR с помощью Python, тем
не менее, практически бесполезно упаковывать в архив одинединст
венный файл. Используя тот же самый прием обхода каталогов, кото
рый мы уже столько раз применяли в этой главе, можно упаковать
вархив TAR весь каталог /tmp , для чего достаточно выполнить обход
дерева каталогов и добавить в архив каждый файл, находящийся в ка
талоге /tmp , как показано в примере 6.18.
```
```
Пример 6.18. Архивирование содержимого дерева каталогов
In [27]: import tarfile
```
```
In [28]: tar = tarfile.open("temp.tar", "w")
In [29]: import os
```
```
In [30]: for root, dir, files in os.walk("/tmp"):
....: for file in filenames:
....:
KeyboardInterrupt
```
```
In [30]: for root, dir, files in os.walk("/tmp"):
....: for file in files:
....: fullpath = os.path.join(root,file)
....: tar.add(fullpath)
....:
....:
```
```
In [33]: tar.close()
```

В том, чтобы добавить в архив содержимое дерева каталогов при его
обходе, нет ничего сложного, и это очень неплохой прием, потому что
его можно объединить с другими приемами, рассматривавшимися
в этой главе. Представьте, что вы архивируете каталог, заполненный
мультимедийными файлами. Было бы неразумно архивировать дубли
каты, поэтому у вас вполне может появиться желание перед архивиро
ванием заменить дубликаты символическими ссылками. Обладая зна
ниями, полученными в этой главе, вы легко сможете написать сцена
рий, который сделает это и сэкономит вам немного дискового про
странства.
Поскольку создание простых архивов TAR – занятие довольно скуч
ное, давайте приправим его сжатием bzip2, что заставит ваш процес
сор скулить и жаловаться на то, как много выпало работы на его долю.
Алгоритм сжатия bzip2 иногда может оказаться отличной штукой.
Посмотрим, насколько впечатляющим он действительно может быть.
Создадим текстовый файл размером 60 Мбайт и сожмем его до 10 Кбайт,
как показано в примере 6.19!
```
```
Пример 6.19. Создание архива TAR, сжатого по алгоритму bzip2
In [1: tar = tarfile.open("largefilecompressed.tar.bzip2", "w|bz2")
In [2]: tar.add("largeFile.txt")
```
```
In [3]: lsh
foo1.txt fooDir1/ largeFile.txt largefilecompressed.tar.bzip2*
foo2.txt fooDir2/ largefile.tar
ln [4]: tar.close()
```
```
In [5]: lslh
rwrr 1 root root 61M Oct 25 23:15 largeFile.txt
rwrr 1 root root 61M Oct 26 00:39 largefile.tar
rwxrxrx 1 root root 10K Oct 26 01:02 largefilecompressed.tar.bzip2*
```
```
Что самое удивительное, алгоритму bzip2 удалось сжать текстовый
файл размером 61 Мбайт в 10 Кбайт, хотя мы и смошенничали, ис
пользуя одни и те же данные снова и снова. Конечно, этот эффект был
получен далеко не бесплатно, потому что в системе на базе двухъядер
ного процессора AMD на это потребовалось несколько минут.
Теперь попробуем двинуться дальше и создать сжатый архив другими
доступными способами, начав с gzip. Синтаксис при этом меняется
весьма незначительно, как показано в примере 6.20.
```
```
Пример 6.20. Создание архива TAR, сжатого по алгоритму gzip
In [10]: tar = tarfile.open("largefile.tar.gzip", "w|gz")
```
```
In [11]: tar.add("largeFile.txt")
ln [12]: tar.close()
In [13]: lslh
rwrr 1 root root 61M Oct 26 01:20 largeFile.txt
rwrr 1 root root 61M Oct 26 00:39 largefile.tar
rwxrxrx 1 root root 160K Oct 26 01:24 largefile.tar.gzip*
```

Архив gzip тоже отличается невероятно маленьким размером, уме
стившись в 160 Кбайт, причем на моей машине сжатый архив TAR
был создан за несколько секунд. В большинстве ситуаций это непло
хой компромисс.

### содержимого файлов TAR Использование модуля tarfile для проверки

**содержимого файлов TAR**

Теперь, когда у нас имеется инструмент создания файлов TAR, есть
смысл попробовать проверить содержимое файлов TAR. Создать файл
TAR – это лишь полдела. Если вы проработали системным админист
ратором достаточно продолжительное время, вам, вероятно, случалось
«погореть» с некачественной резервной копией или случалось быть об
виненным в создании некачественной резервной копии.
Чтобы воспроизвести эту ситуацию и подчеркнуть важность проверки
архивов TAR, мы поделимся историей о нашем вымышленном друге,
которую назовем «Проблема пропавшего архива TAR». Имена, назва
ния и факты являются вымышленными. Любые совпадения с действи
тельностью являются случайными.
Наш друг работал в крупной телестудии в качестве системного адми
нистратора и отвечал за поддержку отдела, во главе которого стоял по
настоящему невыдержанный человек. У этого руководителя была ре
путация неправдивого, импульсивного и невыдержанного человека.
Если возникала ситуация, когда этот сумасшедший совершал промах,
например не укладывался в оговоренные с клиентом сроки или выпол
нял свою часть программы не в соответствии с требуемыми характери
стиками, он с большим удовольствием лгал и перекладывал ответст
венность на когонибудь другого. Зачастую этим кемнибудь другим
оказывался наш друг, системный администратор.
К сожалению, наш друг отвечал за содержание резервных копий этого
сумасшедшего. Ему уже стало казаться, что настало время подыски
вать другую работу, но он работал в этой студии уже много лет, у него
было много друзей, и он не хотел потерять все изза этих временных
неурядиц. Ему требовалась система, позволяющая убедиться, что он
охватил резервированием все данные, и поэтому он ввел регистраци
онную систему, которая классифицировала содержимое всех архивов
TAR, которые автоматически создавались для этого сумасшедшего,
так как понимал, что может «погореть», и это лишь вопрос времени,
когда сумасшедший опять не уложится в сроки и ему потребуется при
чина для оправдания.
Однажды нашему другу Вильяму позвонил начальник и сказал:
«Вильям, зайдите ко мне немедленно, у нас неприятности с резервны
ми копиями». Вильям сразу же пошел к начальнику и узнал, что этот
сумасшедший, Алекс, обвинил Вильяма в повреждении архива со
съемкой телешоу, изза чего произошла задержка с передачей про
граммы клиенту. Срыв Алексом сроков сдачи совершенно вывел Боба,
начальника Алекса, из себя.
Начальник сказал Вильяму, что, по словам Алекса, резервная копия
содержала только поврежденные файлы и что изза этого были сорва
ны сроки подготовки шоу. В ответ Вильям сказал боссу, что был уве
рен в том, что рано или поздно его обвинят в порче архива и поэтому
втайне написал на языке Python сценарий, который проверяет содер
жимое всех создаваемых им архивов TAR и записывает расширенные
сведения об атрибутах файлов до и после резервного копирования.
Оказалось, что Алекс так и не приступал к работе над шоу и что в тече
ние нескольких месяцев архивировалась пустая папка.
Когда Алекс был поставлен перед фактами, он быстро пошел на попят
ную и попытался перевести внимание на другую проблему. К несча
стью для Алекса, этот случай стал последней каплей и пару месяцев
спустя он исчез с работы. Возможно, он уехал или был уволен, но это
уже не важно, наш друг успешно решил проблему пропавшего архива
TAR.
Мораль этой истории заключается в том, что, когда приходится иметь
дело с резервными копиями, с ними следует обращаться как с ядер
ным оружием, так как резервные копии могут хранить в себе такие
опасности, о которых вы даже не подозреваете.
Ниже демонстрируется несколько способов проверки содержимого
файла TAR, созданного ранее:

```
In [1]: import tarfile
In [2]: tar = tarfile.open("temp.tar","r")
```
```
In [3]: tar.list()
rwrr ngift/wheel 2 20080404 15:17:14 tmp/file00.txt
rwrr ngift/wheel 2 20080404 15:15:39 tmp/file1.txt
rwrr ngift/wheel 0 20080404 20:50:57 tmp/temp.tar
rwrr ngift/wheel 2 20080404 16:19:07 tmp/dirA/file0.txt
rwrr ngift/wheel 2 20080404 16:19:07 tmp/dirA/file00.txt
rwrr ngift/wheel 2 20080404 16:19:07 tmp/dirA/file1.txt
rwrr ngift/wheel 2 20080404 16:19:52 tmp/dirB/file0.txt
rwrr ngift/wheel 2 20080404 16:19:52 tmp/dirB/file00.txt
rwrr ngift/wheel 2 20080404 16:19:52 tmp/dirB/file1.txt
rwrr ngift/wheel 3 20080404 16:21:50 tmp/dirB/file11.txt
In [4]: tar.name
Out[4]: '/private/tmp/temp.tar'
In [5]: tar.getnames()
Out[5]:
['tmp/file00.txt',
'tmp/file1.txt',
'tmp/temp.tar',
'tmp/dirA/file0.txt',
'tmp/dirA/file00.txt',
'tmp/dirA/file1.txt',
'tmp/dirB/file0.txt',
'tmp/dirB/file00.txt',
'tmp/dirB/file1.txt',
'tmp/dirB/file11.txt']
In [10]: tar.members
Out[10]:
[<TarInfo 'tmp/file00.txt' at 0x109eff0>,
<TarInfo 'tmp/file1.txt' at 0x109ef30>,
<TarInfo 'tmp/temp.tar' at 0x10a4310>,
<TarInfo 'tmp/dirA/file0.txt' at 0x10a4350>,
<TarInfo 'tmp/dirA/file00.txt' at 0x10a43b0>,
<TarInfo 'tmp/dirA/file1.txt' at 0x10a4410>,
<TarInfo 'tmp/dirB/file0.txt' at 0x10a4470>,
<TarInfo 'tmp/dirB/file00.txt' at 0x10a44d0>,
<TarInfo 'tmp/dirB/file1.txt' at 0x10a4530>,
<TarInfo 'tmp/dirB/file11.txt' at 0x10a4590>]
```
```
Эти примеры показывают, как получить имена файлов, хранящиеся
в архиве TAR, чтобы впоследствии иметь возможность их проанализи
ровать в сценарии, проверяющем данные. Извлечение файлов из архи
вов выполняется ничуть не сложнее. Если вам потребуется извлечь все
файлы из архива TAR в текущий рабочий каталог, можно воспользо
ваться следующей функцией:
In [60]: tar.extractall()
```
```
drwxrwxrwx 7 ngift wheel 238 Apr 4 22:59 tmp/
```
```
Если вы чрезвычайно подозрительны, каковыми и должны быть, то
вы могли бы реализовать подсчет контрольных сумм MD5 случайных
файлов при извлечении их из архива и сравнивать их с соответствую
щими контрольными суммами, которые были сохранены до упаковки
файлов в архив. Это очень эффективный способ убедиться в том, что
целостность данных не нарушена.
Ни одно разумное решение не должно основываться на предположе
нии, что архив был создан без ошибок. По крайней мере, хотя бы выбо
рочная проверка архивов должна выполняться автоматически. Но
лучше, если сразу после создания каждый архив будет открываться
и проверяться.
```
