### Глава 10. Процессы и многозадачность

**Введение**

Обращение с процессами для системного администратора UNIX/Linux –
это реалии жизни. Вы должны знать о сценариях запуска системных
служб, уровнях запуска, демонах, о заданиях планировщика cron,
о долгоживущих процессах, о многозадачности и о массе других про
блем. К счастью, язык Python делает работу с процессами удивительно
простым делом. Начиная с версии Python 2.4, появился универсаль
ный модуль subprocess, позволяющий порождать новые процессы
и обмениваться информацией с ними через устройства стандартного
ввода, стандартного вывода и стандартного вывода сообщений об ошиб
ках. Обмен информацией с процессами – это лишь один из аспектов ра
боты с ними; не менее важно понимать, как развертывать и управлять
процессами, работающими продолжительное время.

**Модуль subprocess**

В версии Python 2.4 появился новый модуль subprocess, занявший место нескольких старых модулей: os.system, os.spawn, os.popen и popen2.
Модуль subprocess принес революционные изменения в жизнь системных администраторов и разработчиков, которым приходится иметь
дело с процессами и постоянно прибегать к командам оболочки. Те
перь имеется универсальный модуль для работы с процессами, кото
рый, в конечном счете, может использоваться для управления группа
ми процессов.
Модуль subprocess можно считать самым важным для системного ад
министратора модулем, потому что он обеспечивает унифицирован
ный интерфейс к системе. Модуль subprocess отвечает в языке Python
за выполнение следующих действий: порождение новых процессов, соединение с потоками стандартного ввода, стандартного вывода,
стандартного вывода сообщений об ошибках и получение кодов воз
врата от этих процессов.
Чтобы подогреть ваш интерес, будем следовать принципу KISS (Keep
Its Syntax Simple – сохраняй синтаксис как можно проще) и с помо
щью модуля subprocess выполним простейший вызов системной ути
литы, как показано в примере 10.1.
```
```
Пример 10.1. Простейший пример использования модуля subprocess
In [4]: subprocess.call('dfk', shell=True)
Filesystem 1024blocks Used Available Capacity Mounted on
/dev/disk0s2 97349872 80043824 17050048 83% /
devfs 106 106 0 100% /dev
fdesc 1 1 0 100% /dev
maphosts 0 0 0 100% /net
map auto_home 0 0 0 100% /home
Out[4]: 0
```
```
Используя тот же простой синтаксис, можно использовать перемен
ные окружения. В примере 10.2 показано, как можно получить объем
дискового пространства, занимаемого домашним каталогом.
```
```
Пример 10.2. Объем используемого дискового пространства
In [7]: subprocess.call('duhs $HOME', shell=True)
28G /Users/ngift
Out[7]: 0
```
```
Следует отметить один интересный прием, позволяющий при исполь
зовании модуля subprocess подавить вывод в поток стандартного выво
да. Многие интересуются только возможностью запускать команды
системы, но никак не беспокоятся о стандартном выводе. Часто в та
ких случаях бывает необходимо подавить стандартный вывод вызова
subprocess.call(). К счастью, сделать это очень просто, как показано
в примере 10.3.
```
```
Пример 10.3. Подавление стандартного вывода вызова subprocess.call()
In [3]: import subprocess
```
```
In [4]: ret = subprocess.call("pingc 1 10.0.1.1",
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
```
```
По поводу этих двух примеров и вызова subprocess.call() имеется не
сколько общих примечаний. Обычно при использовании функции sub
process.call() необходимо просто запустить команду, а вывод от нее
сохранять не требуется. Если же необходимо захватить вывод коман
ды, то следует использовать функцию subprocess.Popen(). Между функ
циями subprocess.call() и subprocess.Popen() существует еще одно су
```

**352** Глава 10. Процессы и многозадачность

```
щественное отличие. Функция subprocess.call() блокирует выполне
ние сценария до получения ответа, в то время как функция subpro
cess.Popen() – нет.
```
**Использование кодов возврата с помощью**

**модуля subprocess**

```
Интересно заметить, что при использовании subprocess.call() можно
получать коды возврата, чтобы определить, насколько успешно была
выполнена команда. Если у вас есть опыт программирования на языке
C или Bash, вы должны быть близко знакомы с кодами возврата. Часто
взаимозаменяемые фразы «код выхода» или «код возврата» использу
ются для обозначения кода состояния системного процесса.
Каждый процесс возвращает код возврата при выходе, и значение ко
да возврата может использоваться, чтобы определить, какие действия
должна предпринять программа. Вообще, если программа возвращает
значение, отличное от нуля, это свидетельствует об ошибке. Самое оче
видное для разработчика использование кода возврата – определить,
какие действия выполнять, если процесс вернул значение кода, отлич
ное от нуля, свидетельствующее об ошибке. Но существует множество
более интересных, хотя и не таких очевидных способов использования
кодов возврата. Существуют специальные значения кодов возврата,
которые свидетельствуют о том, что искомый объект не найден, что
файл не является исполняемой программой или программа была за
вершена комбинацией клавиш CtrlC. В этом разделе мы будем исполь
зовать все эти коды возвратов в программах на языке Python.
В следующем списке приводятся наиболее распространенные коды
возврата с их назначением:
0 Успешное завершение
1 Общая ошибка
2 Неправильное использование встроенных команд оболочки
126 Вызываемая команда не может быть выполнена
127 Команда не найдена
128 Неверный аргумент команды exit
128+n Фатальная ошибка по сигналу «n»
130 Сценарий был завершен нажатием комбинации клавиш CtrlC
255 Указан код завершения за пределами допустимого диапазона
Наиболее практичный пример, где эти сведения могли бы применять
ся, – это использование кодов 0 и 1, которые просто свидетельствуют об
успешном или неудачном завершении только что выполненной коман
ды. Рассмотрим несколько простых примеров использования кодов,
возвращаемых функцией subprocess.call(). Взгляните на пример 10.4.
```

Модуль subprocess **353**

```
Пример 10.4. Код, возвращаемый функцией subprocess.call() в случае неудачи
In [16]: subprocess.call("ls /foo", shell=True)
ls: /foo: No such file or directory
Out[16]: 1
```
```
Поскольку этот каталог отсутствует, мы получили код возврата 1, сви
детельствующий об ошибке. Мы можем записывать код возврата в пе
ременную и затем использовать его в условных инструкциях, как по
казано в примере 10.5.
```
```
Пример 10.5. Условные инструкции, проверяющие код возврата,
получаемый от функции subprocess.call()
In [25]: ret = subprocess.call("ls /foo", shell=True)
ls: /foo: No such file or directory
In [26]: if ret == 0:
....: print "success"
....: else:
....: print "failure"
....:
....:
failure
```
```
Ниже приводится пример получения кода возврата «команда не най
дена», который имеет значение 127. Это может быть полезно для соз
дания инструмента, который может пытаться запускать различные
похожие команды оболочки на основе информации об их доступности.
Например, можно было бы сначала попробовать запустить команду
rsync, и если будет получен код возврата 127, попытаться выполнить
команду scp – r, как показано в примере 10.6.
```
```
Пример 10.6. Код 127, возвращаемый функцией subprocess.call()
In [28]: subprocess.call("rsync /foo /bar", shell=True)
/bin/sh: rsync: command not found
Out[28]: 127
```
```
Возьмем предыдущий пример и сделаем его менее абстрактным. Часто
при создании кроссплатформенного программного кода, который дол
жен работать в различных UNIXподобных системах, вы можете столк
нуться с ситуацией, когда для достижения определенного результата
необходимо использовать различные системные программы в зависи
мости от того, в какой операционной системе выполняется сценарий.
Каждая из систем HPUX, AIX, Solars, FreeBSD и Red Hat может
иметь разные утилиты, которые делают то, что вам требуется. Сцена
рий мог бы попытаться выполнить с помощью модуля subprocess сна
чала одну команду, а получив код возврата 127, попытаться выпол
нить другую команду, и так далее.
К сожалению, значения кодов возврата могут изменяться от системы
к системе, поэтому, если вы пишете кроссплатформенный сценарий,
возможно, желательнее будет анализировать лишь нулевое и ненуле
```

**354** Глава 10. Процессы и многозадачность

```
вое значение кода выхода. Ради примера, ниже показан код возврата,
который был получен в Solaris 10 при выполнении той же команды,
что раньше выполнялась в Red Hat Enterprise Linux 5:
ash3.00# python
Python 2.4.4 (#1, Jan 9 2007, 23:31:33) [C] on sunos5
Type "help", "copyright", "credits" or "license" for more information.
>>> import subprocess
>>> subprocess.call("rsync", shell=True)
/bin/sh: rsync: not found
1
```
```
Мы попрежнему можем использовать определенные коды возврата,
предварительно определив тип операционной системы. После опреде
ления типа системы можно было бы проверить наличие определенной
команды. Если вы предполагаете писать такой программный код, тогда
для вас будет совсем нелишним познакомиться поближе с модулем
platform. О работе с этим модулем подробно рассказывалось в главе 8,
поэтому вы можете обращаться к ней за дополнительной информацией.
Взгляните на пример 10.7, в котором модуль platform используется
в интерактивном режиме в оболочке IPython, чтобы определить, ка
кую команду передать функции subprocess.call().
```
```
Пример 10.7. Использование модулей platform и subprocess, чтобы убедиться,
что команда выполняется в Solaris 10
In [1]: import platform
In [2]: import subprocess
In [3]: platform?
Namespace: Interactive
File: /usr/lib/python2.4/platform.py
Docstring:
This module tries to retrieve as much platformidentifying data as
possible. It makes this information available via function APIs.
(Этот модуль пытается получить максимально возможный объем информации,
идентифицирующей операционную систему, и обеспечивает доступ к этой
информации через функции API.)
If called from the command line, it prints the platform
information concatenated as single string to stdout. The output
format is useable as part of a filename.
(При вызове из командной строки выводит на устройство stdout информацию
о платформе в виде единой строки. Строка имеет такой формат, что может
использоваться как имя файла.)
In [4]: if platform.system() == 'SunOS':
....: print "yes"
....:
yes
In [5]: if platform.release() == '5.10':
....: print "yes"
```

Модуль subprocess **355**

```
....:
yes
```
```
In [6]: if platform.system() == 'SunOS':
...: ret = subprocess.call('cp /tmp/foo.txt /tmp/bar.txt', shell=True)
...: if ret == 0:
...: print "Success, the copy was made on %s %s " %
(platform.system(), platform.release())
...:
Success, the copy was made on SunOS 5.10
```
```
Как видите, модуль platform в соединении с функцией subprocess.call()
может оказаться эффективным средством в создании кроссплатфор
менного программного кода. За подробной информацией об использо
вании модуля platform при создании кроссплатформенного про
граммного кода для UNIXподобных систем обращайтесь к главе 8.
Взгляните на пример 10.8.
```
```
Пример 10.8. Захват вывода от команды средствами модуля subprocess
In [1]: import subprocess
In [2]: p = subprocess.Popen("dfh", shell=True, stdout=subprocess.PIPE)
In [3]: out = p.stdout.readlines()
In [4]: for line in out:
...: print line.strip()
...:
...:
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 78Gi 15Gi 85% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
```
```
Обратите внимание, что метод readlines() возвращает список, в кото
ром строки завершаются символом новой строки. Для их удаления мы
использовали вызов метода line.strip(). Кроме того, модуль subprocess
поддерживает возможность взаимодействия с устройствами стандарт
ного ввода и стандартного вывода для создания каналов (или цепочек
команд). Ниже приводится простой пример взаимодействия с устройст
вом стандартного вывода процесса. На языке Python можно реализо
вать такую интересную вещь, как «фабрику» цепочек команд, которая
выглядела бы на на языке Bash устрашающе. Всего несколько строк
простого программного кода, и мы можем выполнять и выводить ре
зультаты последовательности команд, число которых определяется
числом аргументов, как показано в примере 10.9.
```
```
Пример 10.9. «Фабрика» команд с использованием модуля subprocess
def multi(*args):
for cmd in args:
```

**356** Глава 10. Процессы и многозадачность

```
p = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE)
out = p.stdout.read()
print out
```
```
Ниже приводится пример этой простой функции в действии:
```
```
In [28]: multi("dfh", "ls l /tmp", "tail /var/log/system.log")
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 80Gi 13Gi 87% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
lrwxrxrx@ 1 root admin 11 Nov 24 23:37 /tmp> private/tmp
```
```
Feb 21 07:18:50 dhcp126 /usr/sbin/ocspd[65145]: starting
Feb 21 07:19:09 dhcp126 login[65151]: USER_PROCESS: 65151 ttys000
Feb 21 07:41:05 dhcp126 login[65197]: USER_PROCESS: 65197 ttys001
Feb 21 07:44:24 dhcp126 login[65229]: USER_PROCESS: 65229 ttys002
```
```
Благодаря мощи языка Python и синтаксической конструкции *args
мы можем запускать последовательности из произвольного числа ко
манд, используя нашу функцию в качестве фабрики. Каждая команда
извлекается из начала списка методом args.pop(0).^1 Если бы мы ис
пользовали вызов метода без аргумента args.pop(), команды извлека
лись бы в обратном порядке. Поскольку такой способ извлечения ко
манд может приводить к путанице, мы переписали функцию, реализо
вав ее на основе простого цикла for:^2
```
```
def multi(*args):
for cmd in args:
p = subprocess.Popen(cmd, shell=True, stdout = subprocess.PIPE)
out = p.stdout.read()
print out
```
(^1) Метод pop() в приведенном примере не используется, кроме того, args – это
кортеж, а у кортежей нет метода pop(). Вероятно, раньше, в черновом вари
анте книги, этот пример был реализован иначе, с преобразованием кортежа
аргументов в список аргументов. Такая функция могла бы выглядеть при
мерно так:
def multi(*args):
cmd = list(args)
while len(cmd) > 0:
p = subprocess.Popen(cmd.pop(0), shell=True,
stdout = subprocess.PIPE)
out = p.stdout.read()
print out
_Прим. перев._
(^2) Этот пример полностью повторяет предыдущий... См. сноску 1. – _Прим. пе>
рев._


Модуль subprocess **357**

```
Системным администраторам часто приходится запускать последова
тельности команд, поэтому определенно имеет смысл создать модуль,
который упростил бы эту возможность. Давайте посмотрим, как мож
но было бы реализовать такой модуль с применением механизма на
следования. Исходный текст модуля приводится в примере 10.10.
```
```
Пример 10.10. Модуль>обертка вокруг модуля subprocess
#!/usr/bin/env python
from subprocess import call
import time
import sys
```
```
"""
subtube – это модуль, упрощающий и автоматизирующий некоторые аспекты
применения subprocess
"""
```
```
class BaseArgs(object):
"""Основной класс, выполняющий разбор именованных аргументов"""
```
```
def __init__(self, *args, **kwargs):
self.args = args
self.kwargs = kwargs
if self.kwargs.has_key("delay"):
self.delay = self.kwargs["delay"]
else:
self.delay = 0
if self.kwargs.has_key("verbose"):
self.verbose = self.kwargs["verbose"]
else:
self.verbose = False
def run (self):
"""Вы должны реализовать метод run"""
raise NotImplementedError
```
```
class Runner(BaseArgs):
"""
Упрощает вызов subprocess.call и запускает последовательность команд.
Конструктор класса Runner принимает N позиционных аргументов
и следующие необязательные аргументы:
[необязательные именованные аргументы]
delay=1, задержка в секундах
verbose=True, подробный отчет о выполняемых действиях
```
```
Порядок использования:
cmd = Runner("lsl", "df h", verbose=True, delay=3)
cmd.run()
"""
```
```
def run(self):
for cmd in self.args:
```

**358** Глава 10. Процессы и многозадачность

```
if self.verbose:
print "Running %s with delay=%s" % (cmd, self.delay)
time.sleep(self.delay)
call(cmd, shell=True)
```
```
А теперь посмотрим, как пользоваться нашим новым модулем:
In [8]: from subtube import Runner
In [9]: r = Runner("dfh", "du h /tmp")
In [10]: r.run()
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 80Gi 13Gi 87% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
4.0K /tmp
In [11]: r = Runner("dfh", "du h /tmp", verbose=True)
```
```
In [12]: r.run()
Running dfh with delay=0
Filesystem Size Used Avail Capacity Mounted on
/dev/disk0s2 93Gi 80Gi 13Gi 87% /
devfs 107Ki 107Ki 0Bi 100% /dev
fdesc 1.0Ki 1.0Ki 0Bi 100% /dev
maphosts 0Bi 0Bi 0Bi 100% /net
map auto_home 0Bi 0Bi 0Bi 100% /home
Running duh /tmp with delay=0
4.0K /tmp
```
```
Если представить, что у нас настроен доступ через ssh ко всем нашим
машинам, мы легко могли бы выполнить, например, такое действие:
```
```
machines = ['homer', 'marge','lisa', 'bart']
for machine in machines:
r = Runner("ssh " + machine + "dfh", "ssh " + machine + "du h /tmp")
r.run()
```
```
Это топорный пример запуска команд на удаленной машине, но сама
идея достойна более пристального внимания, потому что в группе Red
Hat Emerging Technology разрабатывается проект, упрощающий
управление крупными кластерами компьютеров из сценариев на языке
Python. Согласно информации, которая приводится на вебсайте Func,
«Ниже приводится интересный, хотя и искусственный пример выпол
нения перезагрузки всех систем, где запущен демон httpd. Искусст
венный, да, но реализовать не составляет труда, благодаря Func».
О Func (FUNC) упоминалось в главе 8, где рассматривалась собствен
ная система «управления», способная работать в любой UNIXподоб
ной системе.
results = fc.Client("*").service.status("httpd")
for (host, returns) in results.iteritems():
```

Модуль subprocess **359**

```
if returns == 0:
fc.Client(host).reboot.reboot()
```
```
Модуль subprocess обеспечивает унифицированный интерфейс взаи
модействия с системой, с его помощью достаточно легко организовать
запись данных в поток стандартного ввода. В примере 10.11 мы запус
каем утилиту подсчета числа слов, предлагая ей подсчитать количест
во символов, и записываем в ее поток стандартного ввода строку сим
волов.
```
```
Пример 10.11. Организация связи с потоком стандартного ввода
через модуль subprocess
In [35]: p = subprocess.Popen("wcc", shell=True, stdin=subprocess.PIPE)
In [36]: p.communicate("charactersinword")
16
```
```
Эквивалентная команда на языке Bash выглядит, как показано ниже:
```
```
> echo charactersinword | wcc
```
```
Попробуем на этот раз сымитировать поведение Bash и перенаправить
файл в поток стандартного ввода. Для начала нам необходимо запи
сать чтонибудь в файл; сделаем это с использованием нового синтак
сиса Python 2.6. Запомните, что при использовании Python 2.5 необхо
димо использовать идиому импорта будущих возможностей:
```
```
In [5]: from __future__ import with_statement
In [6]: with open('temp.txt', 'w') as file:
...: file.write('charactersinword')
```
```
Теперь можно повторно открыть файл привычным способом и прочи
тать его содержимое в виде строки, присвоив полученное значение пе
ременной f:
```
```
In [7]: file = open('temp.txt')
In [8]: f = file.read()
```
```
После этого можно «перенаправить» файл на вход ожидающего про
цесса:
```
```
In [9]: p = subprocess.Popen("wcc", shell=True, stdin=subprocess.PIPE)
In [10]: p.communicate(f)
```
```
In [11]: p.communicate(f)
16
```
```
В командной оболочке Bash эквивалентная последовательность ко
манд выглядит, как показано ниже:
```
```
% echo charactersinword > temp.txt
% wcc < temp.txt
16
```

**360** Глава 10. Процессы и многозадачность

```
Теперь посмотрим, как реализовать конвейерную обработку с приме
нением нескольких команд, которая часто используется в сценариях
на языке командной оболочки. Посмотрим сначала, как выглядит по
следовательность команд, объединенных в конвейер, на языке Bash,
а затем реализуем ту же самую последовательность на языке Python.
На практике нам очень часто приходится иметь дело с файлами жур
налов. В примере 10.12 мы определяем, какая командная оболочка ис
пользуется суперпользователем root на ноутбуке Macintosh.
```
```
Пример 10.12. Объединение команд в цепочку с помощью модуля subprocess
На языке Bash это действие выполняется следующей простой це
почкой команд:
[ngift@Macintosh6][H:10014]> cat /etc/passwd | grep 0:0 | cutd ':' f 7
/bin/sh
Аналогичная последовательность на языке Python:
In [7]: p1 = subprocess.Popen("cat /etc/passwd", shell=True,
stdout=subprocess.PIPE)
In [8]: p2 = subprocess.Popen("grep 0:0", shell=True, stdin=p1.stdout,
stdout=subprocess.PIPE)
In [9]: p3 = subprocess.Popen("cutd ': ' f 7", shell=True,
stdin=p2.stdout,
stdout=subprocess.PIPE)
In [10]: print p3.stdout.read()
/bin/sh
```
```
Тем не менее, хотя мы можем реализовать некоторое действие с помо
щью модуля subprocess, организовав каналы, но это еще не означает, что
только так и следовало действовать. В предыдущем примере мы получи
ли имя командной оболочки пользователя root, объединив в конвейер
последовательность команд. Но для выполнения подобных действий
в языке Python имеется встроенный модуль, поэтому очень важно знать,
когда можно избежать использования модуля subprocess – язык Python
может содержать встроенный модуль, который способен выполнить не
обходимое действие. Многое из того, что можно сделать в командной
оболочке, например, создать архив в формате tar или zip, можно реали
зовать и на языке Python без использования команд системы. Поэтому,
когда вы обнаруживаете, что приходится реализовывать очень сложную
конвейерную обработку с использованием модуля subprocess, поищите
встроенный эквивалент в языке Python. Взгляните на пример 10.13.
```
```
Пример 10.13. Использование модуля pwd для работы с базой данных
паролей вместо subprocess
In [1]: import pwd
```
```
In [2]: pwd.getpwnam('root')
Out[2]: ('root', '********', 0, 0, 'System Administrator', '/var/root',
'/bin/sh')
```

Использование программы Supervisor для управления процессами **361**

```
In [3]: shell = pwd.getpwnam('root')[1]
In [4]: shell
Out[4]: '/bin/sh'
```
```
Модуль subprocess позволяет одновременно передавать данные в поток
стандартного ввода и принимать данные из потока стандартного выво
да процесса, а также получать данные из потока стандартного вывода
сообщений об ошибках. Рассмотрим пример, демонстрирующий это.
Обратите внимание, что мы используем команду ed upper.py для авто
матического переключения в редактор Vim из интерактивной оболоч
ки IPython, когда нам необходимо написать фрагмент программного
кода, который может представлять собой блок, аналогичный приве
денному в примере 10.14.
```
```
Пример 10.14. Передача данных в поток стандартного ввода и прием данных
из потока стандартного вывода и из потока стандартного
вывода сообщений об ошибках
import subprocess
```
```
p = subprocess.Popen("tr az AZ", shell=True, stdin=subprocess.PIPE,
stdout=subprocess.PIPE)
output, error = p.communicate("translatetoupper")
print output
```
```
Когда происходит возврат из редактора в оболочку IPython, она авто
матически выполняет фрагмент программного кода, и мы получаем
следующий результат:
done. Executing edited code...
TRANSLATETOUPPER
```
**Использование программы Supervisor**

**для управления процессами**

```
Системному администратору часто приходится управлять процесса
ми. Когда вебразработчики узнают, что их системный администратор
является специалистом в языке Python, они очень удивляются, пото
му что очень немногие вебплатформы на языке Python предлагают
элегантные способы управления долгоживущими процессами. Про
грамма Supervisor поможет в ситуациях, когда необходимо организо
вать управление долгоживущими процессами, и обеспечит их повтор
ный запуск после перезагрузки системы.
В действительности программа Supervisor может значительно больше,
чем просто оказывать помощь в развертывании вебприложений, – у нее
есть масса применений общего характера. Supervisor может использо
ваться как кроссплатформенный контроллер управления процессами
и взаимодействия с ними. Supervisor может запускать, останавливать
и перезапускать другие программы в UNIXподобных системах. Кроме
```

**362** Глава 10. Процессы и многозадачность

```
того, Supervisor может выполнять перезапуск «обрушившихся» про
цессов, что может оказаться очень удобным. Соавтор программы Su
pervisor, Крис Макдоног (Chris McDonough), сообщил нам, что она мо
жет также использоваться для управления «плохими» процессами, то
есть процессами, потребляющими, например, слишком много памяти
или процессорного времени. Supervisor обеспечивает возможность
удаленного управления посредством XMLRPC Interface Extensions
Event Notification System.
Основной интерес для большинства администраторов UNIXподобных
систем будут представлять программы supervisord– демон, который
запускает программы как дочерние процессы, и supervisorctl – кли
ентская программа, позволяющая просматривать файлы журналов
и управлять процессами. Кроме того, существует и вебинтерфейс, но,
поскольку эта книга о UNIXподобных системах, двинемся дальше.
К моменту написания этих строк последней была версия программы
Supervisor 3.0.x. Последнюю версию руководства к программе всегда
можно получить по адресу http://supervisord.org/manual/current/. Ус
тановка программы Supervisor не вызывает никаких сложностей – ее
можно установить с помощью утилиты easy_install. Предположим,
что мы с помощью virtualenv создали отдельный каталог для изолиро
ванной среды Python, в этом случае установить программу Supervisor
можно с помощью следующей команды:
```
```
bin/easy_install supervisor
```
```
Она установит Supervisor в каталог bin. Если воспользоваться утили
той easy_install в системной среде Python, то установка будет выпол
нена в каталог, например, /usr/local/bin или в каталог по умолчанию
для сценариев.
Следующий этап, который следует выполнить перед запуском демона
программы Supervisor, заключается в создании простого сценария,
который, как в следующем примере, выводит текст, ожидает 3 секун
ды и завершает свою работу. Такой сценарий, конечно, нельзя назвать
долгоживущим процессом, но с его помощью мы продемонстрируем
одну из самых сильных сторон программы Supervisor – способность
автоматически перезапускать программы, превращая их в некоторое
подобие демонов. Теперь можно заполнить файл supervisord.conf , ис
пользуя для этого специальную команду echo_supervisord_conf. В этом
примере мы просто заполняем файл /etc/supervisord.conf. Следует от
метить, что конфигурационный файл программы Supervisor может на
ходиться в любом месте, потому что демон supervisord можно запус
кать с параметром, указывающим его местоположение.
```
```
echo_supervisord_conf > /etc/supervisord.conf
```
```
Выполнив эти подготовительные действия, мы готовы приступить к соз
данию очень простого примера процесса, который будет завершаться
через несколько секунд после запуска. Чтобы обеспечить непрерыв
```

Использование программы Supervisor для управления процессами **363**

```
ную работу процесса, мы воспользуемся возможностью программы Su
pervisor перезапускать процессы, как показано в примере 10.15.
```
```
Пример 10.15. Простой пример перезапуска процесса с помощью программы
Supervisor
#!/usr/bin/env python
import time
print "Daemon runs for 3 seconds, then dies"
time.sleep(3)
print "Daemons dies"
```
```
Как уже упоминалось ранее, чтобы обеспечить запуск дочерних про
цессов под управлением supervisord, нам необходимо отредактировать
конфигурационный файл и добавить в него наше приложение. Давай
те двинемся дальше и добавим в файл /etc/supervisord.conf пару строк:
[program:daemon]
command=/root/daemon.py ; программа (можно указывать относительные пути
; с учетом переменной PATH и передавать аргументы)
autorestart=true ; перезапускать при необходимости (по умолчанию:
true)
```
```
Теперь можно запустить демон supervisord и затем с помощью про
граммы supervisorctl запускать процессы и следить за ними:
```
```
[root@localhost]~# supervisord
[root@localhost]~# supervisorctl
daemon RUNNING pid 32243, uptime 0:00:02
supervisor>
```
```
Здесь мы можем воспользоваться командой help, чтобы ознакомиться
с доступными параметрами программы supervisorctl:
```
```
supervisor> help
Documented commands (type help topic):
========================================
EOF exit maintail quit restart start stop version
clear help open reload shutdown status tail
```
```
Теперь запустим наш процесс, которому в конфигурационном файле
мы дали имя daemon, и затем будем следить за его работой, пока он не
завершится, после чего он волшебным образом будет перезапущен,
почти как Франкенштейн. Процесс живет, умирает и снова оживает.
supervisor> stop daemon
daemon: stopped
supervisor> start daemon
daemon: started
```
```
И в заключение нашей игры мы можем в интерактивном режиме про
сматривать, что выводится этой программой в поток стандартного вы
вода:
```

**364** Глава 10. Процессы и многозадачность

```
supervisor> tailf daemon
== Press CtrlC to exit ==
for 3 seconds, then die
Daemon died
Daemon runs for 3 seconds, then dies
```
**Использование программы screen**

**для управления процессами**

```
Альтернативный подход к управлению процессами заключается в ис
пользовании программы GNU screen. Как системному администрато
ру вам необходимо умение работать с программой screen, даже если вы
не собираетесь управлять программами из сценариев на языке Python.
Одна из основных особенностей программы screen заключается в том,
что она позволяет отсоединяться от долгоживущего процесса и вновь
возвращаться к нему. Это настолько полезная возможность, что на
наш взгляд владение этой программой можно рассматривать как один
из основных навыков работы с системой UNIX.
Рассмотрим типичную ситуацию, когда могло бы потребоваться отсо
единиться от долгоживущего вебприложения, такого как trac. Суще
ствует несколько способов настройки trac, но самый простой состоит
в том, чтобы отсоединиться от отдельного процесса trac с помощью
программы screen.
Все, что необходимо для запуска процесса под управлением програм
мы screen, – это поместить команду screen перед командой запуска
долгоживущего процесса, а затем нажать комбинации клавиш CtrlA
иCtrlD, чтобы отсоединиться от сеанса. Чтобы вновь подключиться
к этому процессу, вам достаточно просто снова ввести команду screen
и нажать клавишу CtrlA еще раз.
В примере 10.16 производится запуск программы tracd внутри сеанса
screen. Как только процесс запустится, мы можем просто отсоединить
ся от сеанса, нажав комбинации клавиш CtrlA и CtrlD, если, конечно,
предполагается, что позднее мы вновь будем подключаться к сеансу.
```
```
Пример 10.16. Запуск программ на языке Python под управлением
программы screen
screen python2.4 /usr/bin/tracdhostname=trac.example.comport 8888
rsingleenvauth=*,/home/noahgift/tracinstance/conf/
password,tracadminaccount /home/example/tracinstance/
```
```
Чтобы опять подключиться к этому сеансу, можно ввести команду:
[root@cent ~]# screenr
There are several suitable screens on:
4797.pts0.cent (Detached)
24145.pts0.cent (Detached)
Type "screen [d]r [pid.]tty.host" to resume one of them.
```

Потоки выполнения в Python **365**

```
Возможно, это не самый лучший подход для использования в рабочей
среде, но для нужд разработки или личного использования он облада
ет определенными достоинствами.
```
**Потоки выполнения в Python**

```
Потоки выполнения нередко рассматриваются как необходимое зло.
Несмотря на то, что многим потоки не нравятся, тем не менее, они по
зволяют решать задачи, когда приходится одновременно иметь дело
сразу с несколькими вещами. Потоки выполнения – это не процессы,
потому что они выполняются в пределах одного и того же процесса
и совместно используют память процесса. Это одно из самых больших
преимуществ и одновременно самый большой недостаток потоков.
Преимущество заключается в том, что можно создавать в памяти
структуры данных, которые будут доступны всем потокам выполнения
без использования механизмов межпроцессных взаимодействий (IPC).
Но при работе с потоками имеются свои подводные камни. Часто три
виальная программа, состоящая из нескольких десятков строк про
граммного кода, с введением потоков выполнения может стать чрез
вычайно сложной. Многопоточные программы сложно отлаживать без
использования всеобъемлющей трассировки, но и в этом случае отлад
ка остается очень сложной процедурой, потому что вывод трассиро
вочной информации может оказаться слишком объемным и запутан
ным. Один из авторов создал систему исследования центров обработки
данных с помощью протокола SNMP, но реализовать в ней полную
поддержку потоков выполнения оказалось очень непросто.
Однако существуют определенные стратегии, упрощающие создание
многопоточных приложений, и реализация надежной библиотеки трас
сировки – одна из таких стратегий. При этом они могут оказаться
очень удобным инструментом в решении сложных задач.
Знание основ программирования многопоточных приложений может
оказаться полезным для системного администратора. Вот несколько
примеров, когда потоки выполнения могут пригодиться в повседнев
ной практике системного администратора: исследование локальной
сети в автоматическом режиме, извлечение нескольких вебстраниц
одновременно, нагрузочное тестирование сервера и выполнение сете
вых операций.
Сохраняя верность принципу KISS, рассмотрим один из самых про
стых примеров использования нескольких потоков выполнения. Сле
дует заметить, что для использования модуля threading необходимо по
нимание объектноориентированного программирования. Если у вас
недостаточный опыт объектноориентированного программирования
(ООП) или вообще его нет, тогда этот пример может оказаться непо
нятным для вас. В этом случае мы могли бы порекомендовать приобре
```

**366** Глава 10. Процессы и многозадачность

```
сти книгу Марка Лутца (Mark Lutz) «Learning Python» (O’Reilly)^1 и по
знакомиться с некоторыми основами ООП, однако можно обратиться
к главе 1 «Введение» в этой книге и попрактиковаться на некоторых
примерах, которые там приводятся. В конечном счете, объектноори
ентированное программирование достойно того, чтобы изучать его.
Поскольку эта книга посвящена практическому применению языка
Python, давайте перейдем непосредственно к примеру многопоточного
приложения, где используются самые простые приемы многопоточно
го программирования. В этом простом многопоточном сценарии ис
пользуется модуль threading. В сценарии устанавливается значение
глобальной переменной, и затем переопределяется метод run() потока
выполнения. Наконец, запускается пять потоков выполнения, каж
дый из которых выводит свой номер.
Во многих отношениях этот пример чрезмерно упрощен и имеет пло
хой дизайн, потому что в нем сразу несколько потоков используют од
ну и ту же глобальную переменную. Часто совместно с потоками луч
ше использовать очереди, так как они могут принять на себя всю
сложность организации доступа к совместно используемым данным.
Исходный текст сценария приводится в примере 10.17.
```
```
Пример 10.17. Простейший многопоточный сценарий
#не совсем правильно организован доступ к совместно используемым данным
import threading
import time
count = 1
class KissThread(threading.Thread):
def run(self):
global count
print "Thread # %s: Pretending to do stuff" % count
count += 1
time.sleep(2)
print "done with stuff"
for t in range(5):
KissThread().start()
[ngift@Macintosh6][H:10464][J:0]> python thread1.py
Thread # 1: Pretending to do stuff
Thread # 2: Pretending to do stuff
Thread # 3: Pretending to do stuff
Thread # 4: Pretending to do stuff
Thread # 5: Pretending to do stuff
done with stuff
done with stuff
done with stuff
```
(^1) Марк Лутц. «Изучаем Python» – Пер. с англ. – СПб.: СимволПлюс, 2009. –
_Прим. перев._


Потоки выполнения в Python **367**

```
done with stuff
done with stuff
```
```
#common.py
import subprocess
import time
IP_LIST = [ 'google.com',
'yahoo.com',
'yelp.com',
'amazon.com',
'freebase.com',
'clearink.com',
'ironport.com' ]
```
```
cmd_stub = 'pingc 5 %s'
def do_ping(addr):
print time.asctime(), "DOING PING FOR", addr
cmd = cmd_stub % (addr,)
return subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
from common import IP_LIST, do_ping
import time
z = []
#for i in range(0, len(IP_LIST)):
for ip in IP_LIST:
p = do_ping(ip)
z.append((p, ip))
```
```
for p, ip in z:
print time.asctime(), "WAITING FOR", ip
p.wait()
print time.asctime(), ip, "RETURNED", p.returncode
```
```
jmjones@dinkgutsy:thread_discuss$ python nothread.py
Sat Apr 19 06:45:43 2008 DOING PING FOR google.com
Sat Apr 19 06:45:43 2008 DOING PING FOR yahoo.com
Sat Apr 19 06:45:43 2008 DOING PING FOR yelp.com
Sat Apr 19 06:45:43 2008 DOING PING FOR amazon.com
Sat Apr 19 06:45:43 2008 DOING PING FOR freebase.com
Sat Apr 19 06:45:43 2008 DOING PING FOR clearink.com
Sat Apr 19 06:45:43 2008 DOING PING FOR ironport.com
Sat Apr 19 06:45:43 2008 WAITING FOR google.com
Sat Apr 19 06:45:47 2008 google.com RETURNED 0
Sat Apr 19 06:45:47 2008 WAITING FOR yahoo.com
Sat Apr 19 06:45:47 2008 yahoo.com RETURNED 0
Sat Apr 19 06:45:47 2008 WAITING FOR yelp.com
Sat Apr 19 06:45:47 2008 yelp.com RETURNED 0
Sat Apr 19 06:45:47 2008 WAITING FOR amazon.com
Sat Apr 19 06:45:57 2008 amazon.com RETURNED 1
Sat Apr 19 06:45:57 2008 WAITING FOR freebase.com
Sat Apr 19 06:45:57 2008 freebase.com RETURNED 0
```

**368** Глава 10. Процессы и многозадачность

```
Sat Apr 19 06:45:57 2008 WAITING FOR clearink.com
Sat Apr 19 06:45:57 2008 clearink.com RETURNED 0
Sat Apr 19 06:45:57 2008 WAITING FOR ironport.com
Sat Apr 19 06:46:58 2008 ironport.com RETURNED 0
```
```
В качестве оговорки к следующим примерам многопоточных
сценариев следует заметить, что они являются достаточно
сложными примерами и те же самые действия могут быть реа
лизованы на основе применения функции subprocess.Popen().
Эта функция является лучшим выбором, когда требуется запус
тить группу процессов и дождаться их завершения. Если вам
необходимо организовать взаимодействие с каждым процессом,
то можно использовать функцию subprocess.Popen() в комплексе
с потоками выполнения. Основная цель этих примеров – проде
монстрировать, что многозадачность нередко требует уступок
и компромиссов. Часто бывает очень трудно определить, какая
модель лучше отвечает требованиям – потоки выполнения, про
цессы или асинхронные библиотеки, такие как stackless или
twisted. Ниже приводится пример опроса с помощью утилиты
ping большого массива IPадресов.
```
```
Теперь, когда у нас имеется своеобразная программа «Hello World» для
потоков выполнения, можно перейти к реализации сценария, кото
рый оценит любой системный администратор. Возьмем за основу наш
сценарий и изменим его так, чтобы он опрашивал узлы в сети. Это
можно считать начальным этапом на пути создания универсального
инструмента для работы с сетью. Программный код сценария приво
дится в примере 10.18.
```
```
Пример 10.18. Многопоточная версия утилиты ping
#!/usr/bin/env python
from threading import Thread
import subprocess
from Queue import Queue
num_threads = 3
queue = Queue()
ips = ["10.0.1.1", "10.0.1.3", "10.0.1.11", "10.0.1.51"]
def pinger(i, q):
"""опрос подсети"""
while True:
ip = q.get()
print "Thread %s: Pinging %s" % (i, ip)
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
else:
print "%s: did not respond" % ip
```

Потоки выполнения в Python **369**

```
q.task_done()
for i in range(num_threads):
```
```
worker = Thread(target=pinger, args=(i, queue))
worker.setDaemon(True)
worker.start()
for ip in ips:
queue.put(ip)
print "Main Thread Waiting"
queue.join()
print "Done"
```
```
Когда мы запустили этот, достаточно простой фрагмент программного
кода, мы получили следующий результат:
```
```
[ngift@Macintosh6][H:10432][J:0]# python ping_thread_basic.py
Thread 0: Pinging 10.0.1.1
Thread 1: Pinging 10.0.1.3
Thread 2: Pinging 10.0.1.11
Main Thread Waiting
10.0.1.1: is alive
Thread 0: Pinging 10.0.1.51
10.0.1.3: is alive
10.0.1.51: is alive
10.0.1.11: did not respond
Done
```
```
Этот пример заслуживает того, чтобы разобрать его на понятные час
ти, но сначала – небольшое пояснение. Пример разработки многопо
точной версии утилиты ping с целью опроса подсети – это отличный
способ продемонстрировать применение потоков. «Обычная» програм
ма на языке Python, не использующая потоки выполнения, потребова
ла бы времени для своего выполнения N * (среднее время ожидания от
вета на каждый запрос ping). Утилита ping может возвращать один из
двух вариантов ответа: время отклика хоста и сообщение об истечении
предельного времени ожидания. В типичной сети можно столкнуться
с обоими вариантами.
Это означает, что на выполнение приложения, использующего утилиту
ping для опроса хостов сети класса C, состоящей из 254 адресов, может
потребоваться до 254 * (~ 3 секунды), что может составить до 12.7 ми
нут. При использовании потоков это время можно уменьшить до не
скольких секунд. Именно поэтому потоки имеют важное значение для
разработки сетевых приложений. Теперь сделаем еще шаг и подума
ем, какие условия могут встретиться в действительности. Сколько
подсетей может существовать в типичном центре обработки данных?
20? 30? 50? Очевидно, что программа, выполняющая опрос последова
тельным способом, быстро теряет свою практическую ценность, и мно
гопоточная версия становится идеальным выбором.
```

**370** Глава 10. Процессы и многозадачность

```
Теперь вернемся к нашему простому сценарию и рассмотрим некото
рые особенности реализации. Первое, на что следует обратить внима
ние, – это импортируемые модули, в частности, наибольший интерес
для нас представляют модули threading и Queue. Как уже отмечалось
выше, разработка многопоточных приложений без использования оче
редей намного сложнее, и многим оказывается не под силу. Всякий
раз, когда вам требуется прибегнуть к использованию потоков, жела
тельно использовать модуль Queue. Почему? Этот модуль снижает по
требность в явной реализации защиты данных с помощью мьютексов,
потому что внутренние механизмы самих очередей обеспечивают необ
ходимую защиту данных.
Представьте, что вы фермер/ученый, живущий в Средние века, и вы
заметили, что вороны, которых часто называют «убийцами» (если ин
тересно узнать, почему, обращайтесь в Википедию), атакуют ваши по
ля с зерновыми стаями по 20 или более особей.
Это очень умные птицы и их невозможно испугать, бросая камни, так
как вы сможете бросать не чаще, чем один камень каждые 3 секунды,
а численность стаи может достигать 50 особей. Чтобы отпугнуть всех
ворон, может потребоваться до нескольких минут, но за этот промежу
ток времени урожаю может быть нанесен существенный ущерб. Как
ученый, знающий математику, вы понимаете, что эта проблема легко
разрешима. Вам нужно лишь набрать кучу камней и затем расставить
работников, чтобы они могли одновременно брать камни из кучи и бро
сать в ворон.
Если следовать этой стратегии, 30 работников, выбирая камни из кучи,
могли бы закидать камнями 50 ворон менее чем за 10 секунд. Это осно
ва использования потоков и очередей в сценариях на языке Python. Вы
нанимаете группу работников для выполнения какойлибо работы,
и когда очередь опустеет, задание можно считать выполненным.
Очереди обеспечивают способ передачи заданий «группе» работников
централизованным образом. Один из самых важных элементов нашей
простой программы – это вызов метода join(). Описание метода
queue.join() гласит следующее:
Namespace: Interactive
File: /System/Library/Frameworks/Python.framework/Versions/2.5/lib/
python2.5/
Queue.py
Definition: Queue.Queue.join(self)
Docstring:
Blocks until all items in the Queue have been gotten and processed.
(Блокирует выполнение вызывающей программы, пока не будут обработаны
все элементы очереди)
```
```
The count of unfinished tasks goes up whenever an item is added to the
queue. The count goes down whenever a consumer thread calls task_done()
to indicate the item was retrieved and all work on it is complete.
```

Потоки выполнения в Python **371**

```
(Всякий раз, когда в очередь добавляется новый элемент, увеличивается счетчик
невыполненных задач. Всякий раз, когда пользовательский поток вызывает метод
task_done(), чтобы показать, что изъятый из очереди элемент обработан,
счетчик уменьшается.)
```
```
When the count of unfinished tasks drops to zero, join() unblocks.
(Когда счетчик заданий уменьшается до нуля, метод join() возвращает
управление вызывающей программе.)
```
```
Метод join() представляет собой простой способ предотвратить завер
шение выполнения главного потока программы до того, как остальные
потоки выполнения получат шанс завершить обработку элементов
очереди. Возвращаясь к метафоре с фермером, главный поток можно
сравнить с фермером, который собирает кучу камней и уходит, а ра
ботники выстраиваются в линию, готовясь бросать камни. Если в на
шем примере закомментировать вызов метода queue.join(), отрица
тельные последствия этого не замедлят сказаться. Попробуем заком
ментировать вызов queue.join():
```
```
print "Main Thread Waiting"
#Если закомментировать вызов метода join, главная программа завершится
#до того, как потоки получат возможность выполнить свою работу
#queue.join()
print "Done"
```
```
Теперь посмотрим, что выдаст наш замечательный сценарий. Взгля
ните на пример 10.19.
```
```
Пример 10.19. Пример, когда главный поток выполнения программы
завершает работу раньше других потоков
[ngift@Macintosh6][H:10189][J:0]# python ping_thread_basic.py
Main Thread Waiting
Done
Unhandled exception in thread started by
Error in sys.excepthook:
```
```
Original exception was:
```
```
Теперь, ознакомившись с теорией применения в сценариях потоков вы
полнения и очередей, пройдемся по программному коду шаг за шагом.
В самом начале мы жестко определили несколько значений, которые
в более универсальных программах обычно передаются в виде аргумен
тов командной строки. Переменная num_threads содержит число рабо
чих потоков, переменная queue– это экземпляр очереди и, наконец,
ips – это список IPадресов, которые мы должны поместить в очередь:
```
```
num_threads = 3
queue = Queue()
ips = ["10.0.1.1", "10.0.1.3", "10.0.1.11", "10.0.1.51"]
```
```
Следующая функция выполняет основную работу в программе. Она вы
зывается каждым потоком и извлекает очередной IPадрес из очереди.
```

**372** Глава 10. Процессы и многозадачность

```
Примечательно, что адреса выталкиваются из очереди в том же поряд
ке, в каком они находятся в списке. Такая реализация позволяет из
влекать элементы, пока очередь не опустеет. В конце цикла while вы
зывается метод q.task_done() – это имеет важное значение, потому что
он сообщает методу join() о том, что был обработан очередной элемент,
извлеченный из очереди. Или, говоря простым языком, он сообщает
о том, что задание выполнено. Посмотрим, что говорится в описании
метода Queue.Queue.task_done():
```
```
File: /System/Library/Frameworks/Python.framework/Versions/2.5/lib/
python2.5/
Queue.py
Definition: Queue.Queue.task_done(self)
Docstring:
Indicate that a formerly enqueued task is complete.
(Свидетельствует о том, что очередное задание в очереди было выполнено.)
Used by Queue consumer threads. For each get() used to fetch a task,
a subsequent call to task_done() tells the queue that the processing
on the task is complete.
(Вызывается потокомпотребителем. Каждому вызову метода get(), используемому
для извлечения задания, должен соответствовать вызов метода task_done(),
который сообщает очереди, что задание выполнено.)
If a join() is currently blocking, it will resume when all items
have been processed (meaning that a task_done() call was received
for every item that had been put() into the queue).
(Метод join() вернет управление вызывающей программе, когда будут обработаны
все элементы (то есть для каждого элемента, помещенного в очередь вызовом
метода put(), будет вызван метод task_done()))
Raises a ValueError if called more times than there were items
placed in the queue.
(При вызове большее число раз, чем имелось элементов в очереди, возбуждает
исключение ValueError)
```
```
Из описания видно, что между методами q.get() и q.task_done() суще
ствует взаимосвязь и в конечном счете они связаны с методом q.join().
Это практически начало, середина и конец истории:
```
```
def pinger(i, q):
"""опрос подсети"""
while True:
ip = q.get()
print "Thread %s: Pinging %s" % (i, ip)
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
else:
```

Потоки выполнения в Python **373**

```
print "%s: did not respond" % ip
q.task_done()
```
```
Ниже мы используем простой цикл for, который управляет созданием
группы потоков выполнения. Примечательно, что эта группа просто
«сидит и ждет», пока чтонибудь не появится в очереди. В программе
ничего не происходит, пока управление не достигнет следующего раз
дела.
В нашей программе кроется одна малозаметная хитрость, которая пре
дохраняет программу от попадания в ловушку. Обратите внимание на
вызов метода setDaemon(True). Если этого не сделать перед вызовом ме
тода start() потока, программа зависнет на неопределенный срок.
Причина практически незаметна на первый взгляд и заключается в том,
что программа может завершить свою работу, только если потоки вы
полняются в режиме демонов. Вы могли заметить, что в функции
pinger() используется бесконечный цикл. Поскольку поток, вызвав
ший такую функцию, никогда сам не завершится, нам пришлось объя
вить их потокамидемонами. Чтобы убедиться в справедливости вы
шесказанного, просто закомментируйте строку worker.setDaemon(True)
и запустите программу. Заметим лишь, что без вызова этого метода
программа будет крутиться вхолостую неопределенно продолжитель
ное время. Обязательно проверьте это у себя, так как это поможет вам
частично снять с процесса покров таинственности:
```
```
for i in range(num_threads):
worker = Thread(target=pinger, args=(i, queue))
worker.setDaemon(True)
worker.start()
```
```
К этому моменту в нашей программе имеется группа готовых к работе
потоков, ожидающих, пока мы дадим им задание. Как только мы по
местим элементы в очередь, нашим потокам тут же будет послан сиг
нал, что можно извлечь задание из очереди, которое в данном случае
заключается в том, чтобы опросить указанный IPадрес:
for ip in ips:
queue.put(ip)
```
```
Наконец, мы достигли критической строки, зажатой между двумя ин
струкциями print, которая в конечном счете управляет программой.
Как уже говорилось ранее, вызвав метод очереди join(), главный по
ток программы становится в ожидание, пока не опустеет очередь зада
ний. Именно поэтому потоки и очередь напоминают шоколад с арахи
совым маслом. Каждый из них обладает своей прелестью, но вместе
они создают особый вкус.
```
```
print "Main Thread Waiting"
queue.join()
print "Done"
```

**374** Глава 10. Процессы и многозадачность

```
Чтобы лучше понять принципы использования потоков и очередей,
нам нужно сделать еще один шаг вперед и добавить в наш пример еще
одну группу потоков и еще одну очередь. В первом примере мы опра
шивали с помощью утилиты ping список IPадресов, которые извлека
ли из очереди. В следующем примере мы заставим первую группу по
токов помещать IPадреса, от которых был получен ответ, во вторую
очередь.
После этого вторая группа потоков будет извлекать IPадреса из вто
рой очереди, производить опрос с помощью утилиты arping и возвра
щать IPадреса вместе с MACадресами. Исходный текст примера при
водится в примере 10.20.
```
```
Пример 10.20. Несколько очередей и несколько групп потоков
#!/usr/bin/env python
#Требуется Python2.5 или выше
from threading import Thread
import subprocess
from Queue import Queue
import re
```
```
num_ping_threads = 3
num_arp_threads = 3
in_queue = Queue()
out_queue = Queue()
ips = ["10.0.1.1", "10.0.1.3", "10.0.1.11", "10.0.1.51"]
def pinger(i, iq, oq):
"""опрос подсети"""
while True:
ip = iq.get()
print "Thread %s: Pinging %s" % (i, ip)
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
#print "%s: is alive" % ip
#поместить ответившие IPадреса во вторую очередь
oq.put(ip)
else:
print "%s: did not respond" % ip
iq.task_done()
def arping(i, oq):
"""извлекает ответивший IPадрес из очереди и получает MACадрес"""
while True:
ip = oq.get()
p = subprocess.Popen("arpingc 1 %s" % ip,
shell=True,
stdout=subprocess.PIPE)
out = p.stdout.read()
```

Потоки выполнения в Python **375**

```
#отыскать и извлечь MACадрес из потока стандартного вывода
result = out.split()
pattern = re.compile(":")
macaddr = None
for item in result:
if re.search(pattern, item):
macaddr = item
print "IP Address: %s | Mac Address: %s " % (ip, macaddr)
oq.task_done()
#Поместить IPадреса в очередь
for ip in ips:
in_queue.put(ip)
```
```
#Породить группу потоков, вызывающих утилиту ping
for i in range(num_ping_threads):
```
```
worker = Thread(target=pinger, args=(i, in_queue, out_queue))
worker.setDaemon(True)
worker.start()
#Породить группу потоков, вызывающих утилиту arping
for i in range(num_arp_threads):
worker = Thread(target=arping, args=(i, out_queue))
worker.setDaemon(True)
worker.start()
```
```
print "Main Thread Waiting"
#Гарантировать, что программа не завершит работу,
#пока не опустеют обе очереди
in_queue.join()
out_queue.join()
print "Done"
```
```
После запуска этого сценария мы получили следующие результаты:
python2.5 ping_thread_basic_2.py
Main Thread Waiting
Thread 0: Pinging 10.0.1.1
Thread 1: Pinging 10.0.1.3
Thread 2: Pinging 10.0.1.11
Thread 0: Pinging 10.0.1.51
IP Address: 10.0.1.1 | Mac Address: [00:00:00:00:00:01]
IP Address: 10.0.1.51 | Mac Address: [00:00:00:80:E8:02]
IP Address: 10.0.1.3 | Mac Address: [00:00:00:07:E4:03]
10.0.1.11: did not respond
Done
```
```
Для реализации этого решения мы лишь немного расширили преды
дущий пример, добавив в него еще одну группу потоков и еще одну
очередь. Это достаточно важный прием, чтобы поместить его в свой ар
сенал, потому что модуль queue делает использование потоков более
```

**376** Глава 10. Процессы и многозадачность

```
простым и более безопасным делом. Можно даже сказать, что этот
прием относится к разряду обязательных к применению.
```
**Задержка выполнения потоков с помощью**

**threading.Timer**

```
В языке Python имеется еще одна особенность, имеющая отношение
к потокам, которая может оказаться удобной при решении задач сис
темного администрирования. Она существенно упрощает запуск функ
ции с задержкой по времени, как показано в примере 10.21.
```
```
Пример 10.21. Таймер внутри потока
#!/usr/bin/env python
from threading import Timer
import sys
import time
import copy
```
```
#простейшая обработка ошибок
if len(sys.argv) != 2:
print "Must enter an interval"
sys.exit(1)
```
```
#функция, которая будет вызываться с задержкой по времени
def hello():
print "Hello, I just got called after a %s sec delay" % call_time
#поток, который реализует задержку по времени
delay = sys.argv[1]
call_time = copy.copy(delay) #копирование задержки для использования позднее
t = Timer(int(delay), hello)
t.start()
```
```
#показать, что программа не блокируется и продолжает работать
print "waiting %s seconds to run function" % delay
for x in range(int(delay)):
print "Main program is still running for %s more sec" % delay
delay = int(delay) 1
time.sleep(1)
```
```
Если запустить этот фрагмент, можно увидеть, что главный поток про
граммы продолжает работу и при этом происходит отложенный вызов
функции:
[ngift@Macintosh6][H:10468][J:0]# python thread_timer.py 5
waiting 5 seconds to run function
Main program is still running for 5 more sec
Main program is still running for 4 more sec
Main program is still running for 3 more sec
Main program is still running for 2 more sec
Main program is still running for 1 more sec
Hello, I just got called after a 5 sec delay
```

Потоки выполнения в Python **377**

**Обработка событий в потоке**

```
Эта книга предназначена для системных администраторов, поэтому
давайте применим описанную выше методику для решения более
практичной задачи. В этом примере мы возьмем на вооружение прием
с отложенным запуском и объединим его с циклом ожидания событий,
в котором будем проверять наличие расхождений в именах файлов ме
жду двумя каталогами. Мы могли бы пойти дальше и проверять время
последнего изменения файлов, но, следуя принципу сохранения мак
симальной простоты примеров, мы посмотрим, как в этом цикле про
веряется ожидаемое событие и как, в случае его появления, вызывает
ся метод обработки.
Этот модуль легко можно преобразовать в более универсальный инст
румент, но пока в примере 10.22 жестко определены каталоги, кото
рые будут синхронизироваться с задержкой с помощью команды rsync
```
- av ––delete, если между ними будут обнаружены различия.

```
Пример 10.22. Инструмент синхронизации каталогов
#!/usr/bin/env python
from threading import Timer
import sys
import time
import copy
import os
from subprocess import call
class EventLoopDelaySpawn(object):
"""Класс обработки события, который запускает метод из потока задержки"""
def __init__(self, poll=10,
wait=1,
verbose=True,
dir1="/tmp/dir1",
dir2="/tmp/dir2"):
```
```
self.poll = int(poll)
self.wait = int(wait)
self.verbose = verbose
self.dir1 = dir1
self.dir2 = dir2
def poller(self):
"""Интервал опроса"""
time.sleep(self.poll)
if self.verbose:
print "Polling at %s sec interval" % self.poll
```
```
def action(self):
if self.verbose:
print "waiting %s seconds to run Action" % self.wait
```

**378** Глава 10. Процессы и многозадачность

```
ret = call("rsyncavdelete %s/ %s" % (self.dir1, self.dir2),
shell=True)
```
```
def eventHandler(self):
#Если в каталогах имеются файлы с разными именами
if os.listdir(self.dir1) != os.listdir(self.dir2):
print os.listdir(self.dir1)
t = Timer((self.wait), self.action)
t.start()
if self.verbose:
print "Event Registered"
else:
if self.verbose:
print "No Event Registered"
def run(self):
"""Цикл проверки события с отложенным запуском обработчика"""
try:
while True:
self.eventHandler()
self.poller()
except Exception, err:
print "Error: %s " % err
finally:
sys.exit(0)
E = EventLoopDelaySpawn()
E.run()
```
```
Внимательные читатели могут заметить, что строго говоря, задержка
здесь не является строго необходимой, и это действительно так. Но
как бы то ни было, задержка может дать дополнительное преимущест
во. Если добавить задержку, скажем, на 5 секунд, можно было бы пре
рвать выполнение потока в случае наступления другого события, на
пример, в случае неожиданного удаления основного каталога. Задерж
ка, реализованная в виде потока, представляет собой замечательный
механизм создания операций с отложенным выполнением, которые
можно отменить.
```
**Процессы**

```
Потоки – это не единственный способ использования многозадачности
в языке Python. В действительности процессы обладают некоторыми
преимуществами перед потоками, т. к. они, в отличие от потоков в язы
ке Python, могут выполняться на разных процессорах. На самом деле,
изза наличия глобальной блокировки интерпретатора (Global Inter
preter Lock, GIL) в каждый момент времени может выполняться толь
ко один поток управления и только на одном процессоре. Поэтому для
решения «тяжеловесных» задач на языке Python потоки являются не
```

Модуль processing **379**

```
лучшим выбором. В таких случаях обработку лучше производить
в разных процессах.
Процессы будут лучшим выбором, если для решения задачи потребу
ется задействовать несколько процессоров. Кроме того, существует
множество библиотек, которые просто не могут работать с потоками
управления. Например, текущая реализация библиотеки NetSNMP
для языка Python не является асинхронной, поэтому при необходимо
сти выполнения параллельной обработки следует использовать ветв
ление процессов.
Потоки в приложении совместно используют одну и ту же область па
мяти, в то время как процессы полностью независимы друг от друга
и для организации взаимодействия с процессом требуется приложить
больше усилий. Обмен информацией с процессами с помощью каналов
может оказаться непростым делом, но, к счастью, существует библио
тека processing, которую мы здесь подробно рассмотрим. Идут разго
воры о включении библиотеки processing в стандартную библиотеку
языка Python, поэтому будет совсем нелишним познакомиться с ней
поближе.
Ранее мы упоминали альтернативный метод создания множества про
цессов, основанный на использовании функции subprocess.Popen(). Во
многих случаях это отличный выбор для организации параллельного
выполнения программного кода. В главе 13 вы найдете пример, где
этот прием используется для создания множества процессов dd.
```
```
Как упоминалось ранее, реализация параллельной обработки
данных никогда не отличалась простотой. Этот пример можно
было счесть неэффективным, потому что в нем используется
функция subprocess.Popen(), вместо того чтобы с помощью моду
ля processing создавать дочерние процессы, в которых вызывать
функцию subprocess.call(). Однако с точки зрения крупного
приложения использование прикладного интерфейса, напоми
нающего очереди, имеет свои преимущества и сравнимо с при
мером многопоточного приложения, приведенного выше. В на
стоящее время идут разговоры об объединении модулей process
ing и Subprocess, потому что модулю Subprocess недостает воз
можности управления группой процессов, которая присутствует
в модуле processing. Этот запрос был сделан в системе PEP (Py
thon Enhancement Proposal – система приема предложений по
улучшению Python) для модуля Subprocess: http://www.py>
thon.org/dev/peps/pep>0324/.
```
**Модуль processing**

```
Так что же это за модуль processing, о котором мы упомянули выше?
На момент написания книги «processing – это пакет для языка Python,
который поддерживает возможность порождения процессов с помо
щью API модуля threading из стандартной библиотеки...». Одна из за
```

**380** Глава 10. Процессы и многозадачность

```
мечательных особенностей модуля processing заключается в том, что
он до определенной степени соответствует прикладному интерфейсу
модуля threading. Это означает, что вам не придется изучать новый
API, чтобы порождать новые процессы вместо потоков. Подробнее о мо
дуле processing можно прочитать по адресу: http://pypi.python.org/py>
pi/processing.
Теперь, когда мы получили некоторые сведения о модуле processing,
рассмотрим пример 10.23.
```
```
Пример 10.23. Введение в модуль processing
#!/usr/bin/env python
from processing import Process, Queue
import time
```
```
def f(q):
x = q.get()
print "Process number %s, sleeps for %s seconds" % (x,x)
time.sleep(x)
print "Process number %s finished" % x
q = Queue()
```
```
for i in range(10):
q.put(i)
i = Process(target=f, args=[q])
i.start()
```
```
print "main process joins on queue"
i.join()
print "Main Program finished"
```
```
Запустив этот фрагмент, мы получили следующее:
```
```
[ngift@Macintosh7][H:11199][J:0]# python processing1.py
Process number 0, sleeps for 0 seconds
Process number 0 finished
Process number 1, sleeps for 1 seconds
Process number 2, sleeps for 2 seconds
Process number 3, sleeps for 3 seconds
Process number 4, sleeps for 4 seconds
main process joins on queue
Process number 5, sleeps for 5 seconds
Process number 6, sleeps for 6 seconds
Process number 8, sleeps for 8 seconds
Process number 7, sleeps for 7 seconds
Process number 9, sleeps for 9 seconds
Process number 1 finished
Process number 2 finished
Process number 3 finished
Process number 4 finished
Process number 5 finished
Process number 6 finished
```

Модуль processing **381**

```
Process number 7 finished
Process number 8 finished
Process number 9 finished
Main Program finished
```
```
Все, что делает эта программа, это предписывает каждому процессу
приостановиться на количество секунд, соответствующее порядково
му номеру процесса. Как видите, интерфейс модуля прост и понятен.
Теперь, когда у нас имеется своего рода программа «Hello World», де
монстрирующая использование модуля processing, можно создать что
нибудь более интересное. Если вы помните, в разделе с описанием по
токов управления мы создали простой многопоточный сценарий, вы
полняющий опрос подсети. Поскольку прикладной интерфейс модуля
processing очень напоминает интерфейс модуля threading, мы можем
реализовать практически идентичный сценарий, используя процессы
вместо потоков управления, как показано в примере 10.24.
```
```
Пример 10.24. Утилита ping на основе процессов
#!/usr/bin/env python
from processing import Process, Queue, Pool
import time
import subprocess
from IPy import IP
import sys
```
```
q = Queue()
ips = IP("10.0.1.0/24")
def f(i,q):
while True:
if q.empty():
sys.exit()
print "Process Number: %s" % i
ip = q.get()
ret = subprocess.call("pingc 1 %s" % ip,
shell=True,
stdout=open('/dev/null', 'w'),
stderr=subprocess.STDOUT)
if ret == 0:
print "%s: is alive" % ip
else:
print "Process Number: %s didn’t find a response for %s " % (i, ip)
```
```
for ip in ips:
q.put(ip)
```
```
#q.put("192.168.1.1")
for i in range(50):
p = Process(target=f, args=[i,q])
p.start()
```
```
print "main process joins on queue"
```

**382** Глава 10. Процессы и многозадачность

```
p.join()
print "Main Program finished"
```
```
Этот сценарий удивительно похож на многопоточную версию, которая
рассматривалась ранее. Если запустить этот сценарий, мы увидим
примерно следующее:
[обрезано]
10.0.1.255: is alive
Process Number: 48 didn't find a response for 10.0.1.216
Process Number: 47 didn't find a response for 10.0.1.217
Process Number: 49 didn't find a response for 10.0.1.218
Process Number: 46 didn't find a response for 10.0.1.219
Main Program finished
[обрезано]
[ngift@Macintosh7][H:11205][J:0]#
```
```
Этот пример требует дополнительных пояснений. Хотя прикладные
интерфейсы модулей очень похожи, между ними всетаки есть некото
рые отличия. Обратите внимание, что каждый из процессов запускает
ся внутри бесконечного цикла, где выполняется извлечение элементов
из очереди. Чтобы сообщить процессу о том, что он должен завершить
работу, мы добавили условную инструкцию, которая проверяет, не
опустела ли очередь. Каждый из 50 дочерних процессов сначала про
веряет, не опустела ли очередь, и если в очереди нет элементов, про
цесс сам «убивает» себя, вызывая функцию sys.exit().
Если в очереди еще имеются элементы, то процесс благополучно из
влекает очередной элемент, в данном случае – IPадрес, и приступает
к выполнению своего задания, то есть выполняет опрос заданного IP
адреса с помощью утилиты ping. Главная программа использует метод
join(), точно так же, как и версия сценария, реализованная на основе
потоков, и ожидает, пока очередь не опустеет. После того как все рабо
чие процессы завершатся, и очередь опустеет, следующая ниже инст
рукция print сообщит о завершении программы.
Благодаря похожести прикладного интерфейса модуль processing ис
пользовать так же просто, как и модуль threading. В главе 7 мы обсуж
дали практическую реализацию на основе модуля processing сцена
рия, использующего библиотеку NetSNMP, которая по своей природе
не является асинхронным расширением для языка Python.
```
**Планирование запуска процессов Python**

```
Теперь, когда мы рассмотрели разнообразные способы работы с про
цессами в языке Python, нам следует поговорить о способах планиро
вания выполнения этих процессов. Для запуска программ, написан
ных на языке Python, вполне подходит старый добрый планировщик
cron.
```

Планирование запуска процессов Python **383**

```
Одна из новых замечательных особенностей планировщика cron, имею
щегося в большинстве POSIXсовместимых систем, заключается во вве
дении каталогов планирования. Это и есть то, изза чего мы используем
cron, так как достаточно просто скопировать сценарий на языке Python
в один из четырех каталогов по умолчанию: /etc/cron.daily , /etc/cron.ho>
urly , /etc/cron.monthly и /etc/cron.weekly.
Достаточно много системных администраторов хотя бы раз в своей
жизни обеспечивали возможность отправки отчета об использовании
дискового пространства по электронной почте. Для этого вы просто по
мещаете в каталог /etc/cron.daily сценарий на языке Bash, который со
держит примерно следующее:
dfh | mail s "Nightly Disk Usage Report" staff@example.com
```
```
Сохранив сценарий под именем /etc/cron.daily/diskusage.sh , вы начи
наете каждый день получать по электронной почте отчеты, имеющие
примерно такой вид:
From: gurupythonsysadmin@example.com
Subject: Nightly Disk Usage Report
Date: February 24, 2029 10:18:57 PM EST
To: staff@example.com
Filesystem Size Used Avail Use% Mounted on
/dev/hda3 72G 16G 52G 24% /
/dev/hda1 99M 20M 75M 21% /boot
tmpfs 1010M 0 1010M 0% /dev/shm
```
```
Но существует лучший путь. Даже для реализации заданий планиров
щика cron можно использовать преимущества языка Python вместо
Bash или Perl. В действительности планировщик cron и Python прекрас
но работают вместе. Давайте возьмем сценарий на языке Bash и реали
зуем его на языке Python, как показано в примере 10.25.
```
```
Пример 10.25. Отсылка ежедневного отчета об использовании дискового
пространства по электронной почте
import smtplib
import subprocess
import string
p = subprocess.Popen("dfh", shell=True, stdout=subprocess.PIPE)
MSG = p.stdout.read()
FROM = "gurupythonsysadmin@example.com"
TO = "staff@example.com"
SUBJECT = "Nightly Disk Usage Report"
msg = string.join((
"From: %s" % FROM,
"To: %s" % TO,
"Subject: %s" % SUBJECT,
"",
MSG), "\r\n")
```

**384** Глава 10. Процессы и многозадачность

```
server = smtplib.SMTP('localhost')
server.sendmail(FROM, TO, msg)
server.quit()
```
```
Это тривиальный рецепт создания автоматизированного отчета об ис
пользовании дискового пространства на базе cron, но он прекрасно по
дойдет для решения множества задач. Теперь подробнее рассмотрим,
что делает этот небольшой фрагмент программного кода на языке Py
thon. В первую очередь, с помощью subprocess.Popen() выполняется
чтение потока стандартного вывода команды df. Затем создаются пе
ременные для заполнения полей From, To и Subject. Затем объединени
ем всех строк создается сообщение. Это самая сложная часть сцена
рия. В заключение мы указываем имя localhost в качестве имени сер
вера исходящей почты и передаем переменные, созданные ранее,
функции server.sendmail().
Для того чтобы использовать такой сценарий, его обычно помещают
вфайл /etc/cron.daily/nightly_disk_report.py.
Если вы еще только начинаете знакомиться с языком Python, можете
использовать этот программный код как шаблон для быстрого созда
ния работающих сценариев. В главе 4 мы немного подробнее обсужда
ли вопрос создания сообщений электронной почты, поэтому за допол
нительной информацией вы можете обращаться к этой главе.
```
**Запуск демона**

```
Работа с демонами – это данность для любого, кто потратил на опера
ционную систему UNIX больше времени, чем необходимо для беглого
знакомства. Демоны выполняют практически любые операции – от об
работки запросов до пересылки файлов на принтер (например, lpd),
приема запросов HTTP и передачи файлов (например, демон httpd веб
сервера Apache).
Так что же такое демон? Часто под демоном понимают выполняющий
ся в фоновом режиме процесс, который не имеет управляющего терми
нала. Если вы знакомы с механизмом управления заданиями в UNIX,
у вас может сложиться мнение, что добавление символа & в конце ко
манды создаст демона. Или нажатие комбинации CtrlZ после запуска
процесса с последующей командой bg создаст демона. В обоих случаях
вы получите фоновые процессы, но ни один из этих способов не отры
вает процесс от командной оболочки и не лишает его управляющего
терминала (возможно, принадлежащего процессу командной оболоч
ки). Итак, три основных признака демона: выполнение в фоновом ре
жиме, отсутствие связи с процессом, запустившим его, и отсутствие
управляющего терминала. Процесс, запущенный в фоновом режиме
при помощи механизма управления заданиями, отвечает только пер
вому требованию.
```

Запуск демона **385**

```
Ниже приводится фрагмент программного кода, в котором определя
ется функция daemonize(). Она превращает вызывающий ее процесс
в демона – в том смысле, в каком говорилось в предыдущем парагра
фе. Эта функция была взята из рецепта «Forking a Daemon Process on
Unix», который приводится во втором издании книги Дэвида Ашера
(David Asher) «Python Cookbook» (O’Reilly) на страницах 388389.
Этот программный код достаточно близко следует рекомендациям, ко
торые предлагает Ричард Стивенс (Richard Stevens) в своей книге
«UNIX Network Programming: The Sockets Networking API» (O’Reilly)
в качестве «правильного» способа создания демона. Для тех, кто не
знаком с книгой Стивенса, заметим, что она обычно рассматривается
как справочник по сетевому программированию, а также как руково
дство по созданию демонов в UNIX. Исходный текст функции приво
дится в примере 10.26.
```
```
Пример 10.26. Функция daemonize
import sys, os
def daemonize (stdin='/dev/null', stdout='/dev/null', stderr='/dev/null'):
# Выполнить первое ветвление процесса.
try:
pid = os.fork()
if pid > 0:
sys.exit(0) # Первый родительский процесс завершает работу.
except OSError, e:
sys.stderr.write("fork #1 failed: (%d) %s\n" % (e.errno, e.strerror))
sys.exit(1)
# Отключиться от родительского окружения.
os.chdir("/")
os.umask(0)
os.setsid()
# Выполнить второе ветвление.
try:
pid = os.fork()
if pid > 0:
sys.exit(0) # Второй родительский процесс завершает работу.
except OSError, e:
sys.stderr.write("fork #2 failed: (%d) %s\n" % (e.errno, e.strerror))
sys.exit(1)
# Теперь процесс стал демоном,
# выполнить перенаправление стандартных дескрипторов.
for f in sys.stdout, sys.stderr: f.flush()
si = file(stdin, 'r')
so = file(stdout, 'a+')
se = file(stderr, 'a+', 0)
os.dup2(si.fileno(), sys.stdin.fileno())
os.dup2(so.fileno(), sys.stdout.fileno())
os.dup2(se.fileno(), sys.stderr.fileno())
```
```
Первое, что делает эта функция, – с помощью функции fork() произво
дит ветвление процесса. В этом случае создается копия работающего
```

**386** Глава 10. Процессы и многозадачность

```
процесса, и эта копия рассматривается как «дочерний» процесс, а ори
гинал – как «родительский» процесс. После создания копии родитель
ский процесс может завершить свою работу. Для этого проверяется
идентификатор процесса pid после ветвления. Если идентификатор
представлен положительным числом, это означает, что выполняется
родительский процесс. Если вы никогда не программировали ветвле
ние процессов с помощью функции fork(), это может показаться вам
странным. После возврата из функции os.fork() в системе появляется
две копии одного и того же работающего процесса. Обе они проверяют
код, возвращаемый функцией fork(), который в дочернем процессе бу
дет иметь значение 0, а в родительском процессе – соответствовать иден
тификатору процесса. Любое ненулевое значение возвращается только
родительскому процессу, который должен завершить работу. Если
здесь возникло исключение, процесс просто завершается. Если этот
сценарий вызывается из интерактивной командной оболочки (такой
как Bash), вы в этот момент вернетесь в строку приглашения к вводу,
потому что тот процесс, который вы запускали, только что завершил
работу. Но дочерний процесс продолжает свою работу.
Затем процесс изменяет рабочий каталог на / (os.chdir("/"), устанав
ливает маску в значение 0 (os.umask(0)) и создает новый сеанс (os.set
sid()). Изменение каталога на / переводит процесс демона в каталог,
который всегда существует. Дополнительное преимущество, которое
дает операция перехода в каталог /, заключается в том, что долгожи
вущий процесс не будет препятствовать возможности отмонтировать
файловую систему, если получилось, что он был запущен из каталога
в файловой системе, которую вы пожелаете отмонтировать. Затем про
цесс изменяет свою маску режима создания файлов на маску с более
широкими правами. Если демон должен создавать файлы с правами
доступа для группы, унаследованная маска с более ограниченными
правами может давать отрицательный эффект. Последнее из этих трех
действий (os.setsid()), пожалуй, наименее знакомо большинству чи
тателей. Функция setsid() выполняет множество действий. Вопер
вых, она делает процесс лидером нового сеанса. Далее, она делает про
цесс лидером новой группы процессов. Наконец, пожалуй, самое важ
ное для демонов – она лишает процесс управляющего терминала.
Факт отсутствия управляющего терминала означает, что процесс не
может пасть жертвой неумышленных (или преднамеренных) опера
ций с механизмом управления заданиями с какоголибо терминала.
Для долгоживущих процессов, таких как демоны, очень важно ис
ключить возможность прерывания работы.
Но самое интересное на этом не заканчивается. После вызова функции
os.setsid() производится повторное ветвление. Первое ветвление про
цесса и вызов функции setsid() лишь готовят почву для второго ветв
ления – они отсоединяют процесс от какоголибо управляющего тер
минала и делают его лидером сеанса. Второе ветвление означает, что
получившийся процесс не может быть лидером сеанса, а также то, что
```

Запуск демона **387**

```
процесс не может приобрести управляющий терминал. Второе ветвле
ние не является обязательной процедурой и выполняется больше из
предосторожности. Без второго ветвления процесс мог бы приобрести
управляющий терминал, открыв любое терминальное устройство без
флага O_NOCTTY.
Последнее, что делает функция, – выполняет очистку файлов и произ
водит их реорганизацию. Выталкивается информация в стандартных
потоках вывода и вывода сообщений об ошибках (sys.stdout и sys.
stderr). Тем самым гарантируется вывод информации, которая еще не
была выведена. Функция daemonize() позволяет вызывающей програм
ме определять файлы, которые будут играть роль потоков stdin, stdout
иstderr. По умолчанию в качестве всех трех файлов используется уст
ройство /dev/null. В этом месте функция принимает либо указанные
пользователем файлы, либо значения по умолчанию и устанавливает
стандартный ввод, стандартный вывод и стандартный вывод сообще
ний об ошибках в соответствие этим файлам.
Как можно использовать функцию daemonize()? Предположим, что
у нас имеется программный код демона в виде сценария daemonize.py.
В примере 10.27 приводится пример сценария, использующего эту
функцию.
```
```
Пример 10.27. Использование функции daemonize()
from daemonize import daemonize
import time
import sys
```
```
def mod_5_watcher():
start_time = time.time()
end_time = start_time + 20
while time.time() < end_time:
now = time.time()
if int(now) % 5 == 0:
sys.stderr.write('Mod 5 at %s\n' % now)
else:
sys.stdout.write('No mod 5 at %s\n' % now)
time.sleep(1)
```
```
if __name__ == '__main__':
daemonize(stdout='/tmp/stdout.log', stderr='/tmp/stderr.log')
mod_5_watcher()
```
```
Этот сценарий сначала переходит в режим демона, определяя при
этом, что в качестве стандартного вывода будет использоваться файл
/tmp/stdout.log , а в качестве стандартного вывода сообщений об ошиб
ках будет использоваться файл /tmp/stderr.log. Затем в течение 20 се
кунд, с интервалами в 1 секунду между проверками, он отслеживает
текущее время. Если время, выраженное в секундах, делится на пять
без остатка, производится запись сообщения в поток стандартного вы
вода сообщений об ошибках. Если время не делится на пять, произво
```

**388** Глава 10. Процессы и многозадачность

```
дится запись сообщения в поток стандартного вывода. Так как процесс
использует файлы /tmp/stdout.log и /tmp/stderr.log в качестве стан
дартного вывода и стандартного вывода сообщений об ошибках, соот
ветственно, то мы имеем возможность наблюдать эти сообщения после
запуска этого примера...
Сразу же после запуска сценария происходит возврат в строку пригла
шения к вводу:
jmjones@dinkgutsy:code$ python use_daemonize.py
jmjones@dinkgutsy:code$
```
```
И ниже приводится результат работы примера:
```
```
jmjones@dinkgutsy:code$ cat /tmp/stdout.log
No mod 5 at 1207272453.18
No mod 5 at 1207272454.18
No mod 5 at 1207272456.18
No mod 5 at 1207272457.19
No mod 5 at 1207272458.19
No mod 5 at 1207272459.19
No mod 5 at 1207272461.2
No mod 5 at 1207272462.2
No mod 5 at 1207272463.2
No mod 5 at 1207272464.2
No mod 5 at 1207272466.2
No mod 5 at 1207272467.2
No mod 5 at 1207272468.2
No mod 5 at 1207272469.2
No mod 5 at 1207272471.2
No mod 5 at 1207272472.2
jmjones@dinkgutsy:code$ cat /tmp/stderr.log
Mod 5 at 1207272455.18
Mod 5 at 1207272460.2
Mod 5 at 1207272465.2
Mod 5 at 1207272470.2
```
```
Это действительно очень простой пример написания демона, но мы на
деемся, что он наглядно демонстрирует некоторые базовые понятия.
Вы можете использовать функцию daemonize() для создания демона,
который следит за состоянием каталога, выполняет мониторинг сети,
сетевых серверов и всего, что угодно, и работает продолжительное
(или неопределенно продолжительное) время.
```
### В заключение.

```
Хотелось бы надеяться, что эта глава продемонстрировала, насколько
широкими и мощными возможностями обладает язык Python для ра
боты с процессами. В языке Python реализован весьма изящный
и сложный прикладной интерфейс для работы с потоками выполне
ния, но при этом всегда полезно помнить о существовании GIL. Если
```

В заключение **389**

```
вы связаны с вводомвыводом, тогда зачастую эта блокировка не явля
ется проблемой, но если вам требуется загрузить работой несколько
процессоров, то лучше будет использовать несколько процессов. Неко
торые считают, что процессы предпочтительнее, чем потоки, даже ес
ли бы не было блокировки GIL. Главная причина появления такого
мнения состоит в том, что отладка многопоточного программного кода
может превратиться в кошмар.
Наконец, будет совсем не лишним поближе познакомиться с модулем
subprocess, если вы с ним еще не знакомы. Subprocess – это универ
сальный модуль, построенный по принципу «все в одном», предназна
ченный для работы с... ну. пусть будет, с подпроцессами.
```
